{"context": {"topic": "Light travels in straight lines, yet bends at material boundaries. Given geometrical optics, consider what hypotheses follow about refractive indices.", "ancestors": ["[Definition] The refractive index n of a material is the ratio of the speed of light in vacuum c to its speed v in the material.", "[Law] Snell’s law states n₁ sin θ₁ = n₂ sin θ₂ at an interface between media with refractive indices n₁ and n₂.", "[Variable] θ₁ is the angle between an incident ray and the normal to the interface.", "[Variable] θ₂ is the angle between the refracted ray and that normal.", "[Constraint] For a given θ₁ and n₁, θ₂ is uniquely determined by n₂ by θ₂ = arcsin[(n₁/n₂) sin θ₁]."]}, "accepted": "From the constraint θ₂ = arcsin[(n₁/n₂) sin θ₁], the argument of arcsin must not exceed 1, so (n₁/n₂) sin θ₁ ≤ 1. Rearranging gives n₂ ≥ n₁ sin θ₁, establishing the minimum refractive index for the second medium that permits a real refracted ray.\n\nHYPOTHESIS: A refracted ray exists only if n₂ ≥ n₁ sin θ₁.\n\nVERIFICATION: Both sides are dimensionless; equality gives the critical-angle condition.", "rejected": "For any angles θ₁ and θ₂, Snell’s law n₁ sin θ₁ = n₂ sin θ₂ remains valid regardless of the value of n₂ relative to n₁.", "E_acc": 0.27839869260787964, "C_acc": 0.45930972695350647, "G_acc": 0.534897059902765, "D_acc": 0.7384981028735638, "H_acc": 0.21682586520910263, "Q_acc": 0.5246541084260181, "E_rej": 0.36139243841171265, "C_rej": 0.3965715169906616, "G_rej": 0.5429156748577952, "D_rej": 0.8035702109336853, "H_rej": 0.1964297890663147, "Q_rej": 0.5787576263770462, "Delta_Q": -0.05410351795102808, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Neurons transmit electrical signals, yet communication is chemical at synapses. Given neurobiology, consider what hypotheses follow about signal integration.", "ancestors": ["[Definition] A postsynaptic neuron sums incoming signals at its soma.", "[Variable] Let v(t) be the membrane potential at the soma at time t.", "[Law] v(t) changes only if the net synaptic current I_syn(t) is nonzero.", "[Constraint] I_syn(t) equals the sum of individual synaptic currents from activated inputs."]}, "accepted": "The premises link the somatic membrane potential v(t) to the net synaptic current I_syn(t), which is the sum of activated input currents. Because v(t) changes only when I_syn(t)≠0, a measurable change in v(t) directly reports that the summed input has crossed the zero-current boundary.\n\nHYPOTHESIS: A detectable deviation in v(t) certifies that the total activated synaptic current has become nonzero.\n\nVERIFICATION: Units consistent (v in mV, I_syn in pA); holds whenever the neuron’s leak and capacitive currents cancel to leave I_syn as the sole driver of dv/dt.", "rejected": "A detectable deviation in v(t) certifies that each individual activated synaptic current is independently nonzero.", "E_acc": 0.7350627183914185, "C_acc": 0.08886420726776123, "G_acc": 0.5278238749929837, "D_acc": 0.7892785146832466, "H_acc": 0.17483454942703247, "Q_acc": 0.7486829970564162, "E_rej": 0.3165920674800873, "C_rej": 0.3154723644256592, "G_rej": 0.543818613248212, "D_rej": 0.7916853427886963, "H_rej": 0.2083146572113037, "Q_rej": 0.5781524728451457, "Delta_Q": 0.17053052421127046, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Work transfers energy, yet identical work can result in different motions. Given work–energy relations, consider what hypotheses can be justified about energy partitioning.", "ancestors": ["[Definition] Work W is the line integral of force dotted with differential displacement.", "[Variable] Let K denote kinetic energy.", "[Law] The work–energy theorem states W = ΔK for a point particle.", "[Variable] Let U denote potential energy.", "[Constraint] W = ΔK + ΔU for a system where only conservative forces act.", "[Limit] ΣE_other = 0 is required for W = ΔK + ΔU to equal total energy change."]}, "accepted": "Using the work–energy theorem for a conservative system, the work done equals the change in mechanical energy.  \nHYPOTHESIS: For any motion governed solely by conservative forces, W = ΔK + ΔU and the total mechanical energy E = K + U remains constant.  \nVERIFICATION: Units of W, ΔK, ΔU are all joules; holds when ΣE_other = 0.", "rejected": "For any motion governed solely by conservative forces, W = ΔK + ΔU and the total mechanical energy E = K + U continually increases.", "E_acc": 0.22067692875862122, "C_acc": 0.35527345538139343, "G_acc": 0.5397591732617002, "D_acc": 0.7893921136856079, "H_acc": 0.18279589712619781, "Q_acc": 0.5426990552281495, "E_rej": 0.30585193634033203, "C_rej": 0.15503311157226562, "G_rej": 0.5337851007352583, "D_rej": 0.7793428897857666, "H_rej": 0.27582138776779175, "Q_rej": 0.5957924179150723, "Delta_Q": -0.053093362686922774, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Organelles compartmentalize processes, yet the cell acts as one system. Given cell biology, consider what hypotheses can be justified about coordination.", "ancestors": ["[Definition] An organelle is a specialized membrane-bound subunit within a cell that performs a defined biochemical task.", "[Definition] A cell is the smallest unit that can carry out all life processes independently.", "[Law] Diffusion between two locations inside a cell proceeds down the concentration gradient at a rate proportional to the gradient magnitude.", "[Variable] Let C be the local concentration of a diffusible signaling molecule.", "[Constraint] Organelles remain physically separate compartments separated by at least one lipid bilayer.", "[Limit] The diffusion constant D for the signaling molecule sets a finite upper bound on the speed of inter-organelle molecular communication."]}, "accepted": "The diffusion law and the organelle-separation constraint jointly imply that any concentration difference of the signaling molecule between two organelles relaxes at a finite, gradient-limited rate. Because the diffusion constant D sets an upper speed bound and the compartments are separated by at least one bilayer, the inter-organelle signaling time cannot fall below a minimum set by the distance and D.  \n\nHYPOTHESIS: The minimum signaling time between two organelles for the diffusible molecule is τ_min = d²/(2D), where d is the bilayer-separated distance between their nearest membrane points.  \n\nVERIFICATION: Units check—d² (m²)/D (m² s⁻¹) gives seconds, valid for diffusive times in three dimensions.", "rejected": "The bilayer-separated distance d between two organelles relaxes at a gradient-limited rate because the minimum signaling time τ_min = d²/(2D) sets the diffusion constant D.", "E_acc": 0.48969417810440063, "C_acc": 0.15239796042442322, "G_acc": 0.5470128222950734, "D_acc": 0.8021456748247147, "H_acc": 0.14076679944992065, "Q_acc": 0.672183680825401, "E_rej": 0.21863195300102234, "C_rej": 0.34626641869544983, "G_rej": 0.5462213862629142, "D_rej": 0.8429623544216156, "H_rej": 0.1570376455783844, "Q_rej": 0.5584692857402843, "Delta_Q": 0.11371439508511672, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Changing conditions shifts equilibrium, yet equilibrium is restored. Given Le Chatelier’s principle, consider what hypotheses can be justified about stress response.", "ancestors": ["[Definition] A system at equilibrium has equal forward and reverse reaction rates.", "[Law] Le Chatelier’s principle states that a perturbed equilibrium shifts to reduce the imposed stress.", "[Variable] Q is the instantaneous reaction quotient.", "[Constraint] Q must equal the equilibrium constant K for the equilibrium position to remain unchanged."]}, "accepted": "Because Q and K are both dimensionless ratios of concentrations (or pressures), their relative magnitudes dictate the direction the reaction must proceed to restore equilibrium.  \nHYPOTHESIS: If Q < K, the forward reaction rate exceeds the reverse rate until Q equals K.  \nVERIFICATION: Both Q and K are unitless; the inequality holds for any elementary reaction at fixed temperature.", "rejected": "Because Q and K are both dimensionless ratios of concentrations (or pressures), their relative magnitudes dictate the direction the reaction must proceed to restore equilibrium at any temperature, pressure, or phase.", "E_acc": 0.18484941124916077, "C_acc": 0.3800358474254608, "G_acc": 0.5533871044171974, "D_acc": 0.7448829412460327, "H_acc": 0.2484794706106186, "Q_acc": 0.5142537159612403, "E_rej": 0.19332978129386902, "C_rej": 0.2792756259441376, "G_rej": 0.5342120281420648, "D_rej": 0.7512282431125641, "H_rej": 0.3109646961092949, "Q_rej": 0.5281353938393295, "Delta_Q": -0.01388167787808925, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Periodic trends repeat, yet irregularities occur. Given periodic law, consider what hypotheses follow about electron shielding.", "ancestors": ["[Definition] Effective nuclear charge Zeff is the net positive charge experienced by an electron in a multi-electron atom.", "[Law] Zeff = Z − S, where Z is the proton number and S is the shielding constant.", "[Variable] S is the electron shielding constant.", "[Constraint] S increases with each additional inner electron.", "[Limit] S ≤ Z − 1 for a neutral atom.", "[Limit] S is not an integer in Slater’s rules."]}, "accepted": "Using Zeff = Z − S and the requirement S ≤ Z − 1 for a neutral atom, the effective nuclear charge is bounded below by 1.  \nHYPOTHESIS: For any neutral atom, Zeff ≥ 1.  \nVERIFICATION: Units cancel to give a dimensionless charge; equality holds for hydrogen (Z = 1, S = 0).", "rejected": "For any ionic species, neutral or charged, Zeff ≥ 1.", "E_acc": 0.06305401027202606, "C_acc": 0.8409814834594727, "G_acc": 0.5581451362086227, "D_acc": 0.7882574200630188, "H_acc": 0.1372481882572174, "Q_acc": 0.40627559881831987, "E_rej": 0.5201911330223083, "C_rej": 0.23224475979804993, "G_rej": 0.5531068388081621, "D_rej": 0.8040139675140381, "H_rej": 0.19598603248596191, "Q_rej": 0.6614339459629264, "Delta_Q": -0.2551583471446065, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Negative feedback stabilizes systems, yet positive feedback amplifies change. Given regulation, consider what hypotheses can be justified about control mechanisms.", "ancestors": ["[Definition] Negative feedback is a process where the output of a system reduces the input that produced it.", "[Definition] Positive feedback is a process where the output of a system increases the input that produced it.", "[Variable] Let G be the open-loop gain of a feedback system.", "[Constraint] For negative feedback, the closed-loop gain equals G/(1 + GH), where H is the feedback fraction."]}, "accepted": "Using the closed-loop gain expression for negative feedback, the magnitude of the closed-loop gain is always less than the open-loop gain G whenever the feedback fraction H is positive.  \nHYPOTHESIS: For any negative-feedback system with positive feedback fraction H, the closed-loop gain is strictly smaller in magnitude than the open-loop gain G.  \nVERIFICATION: Units cancel in G/(1+GH) leaving dimensionless gain ratio < 1 for H > 0.", "rejected": "For any negative-feedback system with positive feedback fraction H, the closed-loop gain is strictly larger in magnitude than the open-loop gain G.", "E_acc": 0.6728907823562622, "C_acc": 0.1480599045753479, "G_acc": 0.5462877746904269, "D_acc": 0.8188031713167826, "H_acc": 0.17116662114858627, "Q_acc": 0.7281567808783923, "E_rej": 0.3669535219669342, "C_rej": 0.29705438017845154, "G_rej": 0.5415771532570943, "D_rej": 0.8427487313747406, "H_rej": 0.1572512686252594, "Q_rej": 0.611815230618231, "Delta_Q": 0.11634155026016135, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellites remain in free fall without colliding with Earth. Given gravity and inertia, consider what hypotheses follow about orbital motion.", "ancestors": ["[Definition] Free fall is motion under gravity alone.", "[Law] Newton’s law of gravitation states F = G m M r⁻².", "[Variable] m denotes the satellite mass.", "[Constraint] F supplies the centripetal force m v² r⁻¹.", "[Limit] r must exceed the planet’s radius."]}, "accepted": "Equating the gravitational force to the required centripetal force and solving for speed yields v = √(GM/r), which decreases as orbital radius increases.  \nHYPOTHESIS: A satellite in circular orbit must have speed v = √(GM/r) with r larger than the planet’s radius.  \nVERIFICATION: Units check: [GM/r]^{½} gives (m³ s⁻² m⁻¹)^{½} = m s⁻¹, valid for circular orbits under gravity alone.", "rejected": "A satellite in circular orbit with speed v = √(GM/r) must have an orbital radius r larger than the planet’s radius.", "E_acc": 0.49216708540916443, "C_acc": 0.2653249502182007, "G_acc": 0.5268006937694736, "D_acc": 0.7527274787425995, "H_acc": 0.28665218502283096, "Q_acc": 0.6218255515792407, "E_rej": 0.37511003017425537, "C_rej": 0.16716299951076508, "G_rej": 0.5168224809458479, "D_rej": 0.7529026865959167, "H_rej": 0.30887164175510406, "Q_rej": 0.6021582784829661, "Delta_Q": 0.019667273096274585, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymes lower activation energy, yet do not change equilibrium. Given catalysis, consider what hypotheses can be justified about reaction control.", "ancestors": ["[Definition] Activation energy (Ea) is the minimum energy required to initiate a reaction.", "[Law] A catalyst, including an enzyme, reduces Ea without altering the equilibrium constant Keq.", "[Variable] Let kcat denote the catalytic rate constant of the enzyme-substrate complex.", "[Constraint] kcat is finite, so the maximal velocity Vmax = kcat [E]total remains bounded by the total enzyme concentration."]}, "accepted": "Because the catalyst lowers Ea but leaves Keq unchanged, the forward and reverse rate constants must both increase by the same factor; since kcat is finite, this factor equals the ratio of the catalytic rate constant to the uncatalyzed rate constant.\n\nHYPOTHESIS: The catalytic acceleration factor for an enzyme equals kcat/kuncat and is identical for the forward and reverse directions.\n\nVERIFICATION: Dimensionless ratio; valid under the same temperature and medium conditions used to define kcat and kuncat.", "rejected": "The catalytic acceleration factor for an enzyme equals kcat/kuncat and is independent of the equilibrium constant Keq.", "E_acc": 0.1878165453672409, "C_acc": 0.36111685633659363, "G_acc": 0.5359104697126895, "D_acc": 0.7626418968041738, "H_acc": 0.2737075090408325, "Q_acc": 0.516461314742143, "E_rej": 0.4460240602493286, "C_rej": 0.1958552598953247, "G_rej": 0.5341274655947927, "D_rej": 0.8052753806114197, "H_rej": 0.19472461938858032, "Q_rej": 0.6430442733981181, "Delta_Q": -0.12658295865597513, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Capacitors store energy, yet no charge crosses the dielectric. Given circuits, consider what hypotheses follow about energy storage mechanisms.", "ancestors": ["[Definition] A capacitor is a two-terminal device storing energy in an internal electric field.", "[Definition] Energy storage E equals the work done to separate electric charges onto opposing conductive plates.", "[Law] Work W equals the integrated product of instantaneous voltage U times transferred charge q.", "[Variable] Let U be the constant potential difference between plates during incremental charge transfer.", "[Constraint] The dielectric between plates is an electrical insulator permitting no steady charge transport.", "[Limit] Therefore the separated charges that constitute the stored energy reside only on the facing surfaces of the plates."]}, "accepted": "Integrating the constant voltage U over the transferred charge q gives the stored energy E = U·q, a direct consequence of the work–energy relation and the fixed potential difference maintained during charging.\n\nHYPOTHESIS: The electrostatic energy stored in a capacitor equals the product of the constant plate voltage and the total charge transferred to either plate, E = U·q.\n\nVERIFICATION: Units check—U in volts (J C⁻¹) times q in coulombs yields E in joules.", "rejected": "The electrostatic energy stored in a capacitor equals the product of the constant plate voltage and the total charge transferred to either plate, with U and q treated as mutually independent variables.", "E_acc": 0.7940616011619568, "C_acc": 0.09905136376619339, "G_acc": 0.5493789896936505, "D_acc": 0.7653821955124537, "H_acc": 0.1698450744152069, "Q_acc": 0.7643759371950486, "E_rej": 0.36723700165748596, "C_rej": 0.2489723563194275, "G_rej": 0.5637251010048203, "D_rej": 0.8376121819019318, "H_rej": 0.16238781809806824, "Q_rej": 0.6244053040049039, "Delta_Q": 0.1399706331901447, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "White light separates into colors, yet recombines into white again. Given dispersion, consider what hypotheses follow about wavelength dependence.", "ancestors": ["[Definition] White light is the superposition of electromagnetic waves spanning the approximately 400–700 nm range.", "[Law] In a dispersive medium, the refractive index n is a function of vacuum wavelength λ.", "[Variable] The angular deviation θ of a ray exiting a prism depends on n(λ).", "[Constraint] For a fixed exit face, a unique θ corresponds to each λ.", "[Limit] Recombination of dispersed rays into white light requires all θ(λ) to converge to a common path."]}, "accepted": "The refractive-index dispersion n(λ) forces each wavelength to leave the prism at its own angle θ(λ), so the exiting beam fans into a spectrum. Recombination to white light demands that this fan be exactly cancelled, which is possible only if the θ(λ) curve is flattened to a single value across 400–700 nm.\n\nHYPOTHESIS: A single prism cannot reconstitute white light after dispersion because its monotonic n(λ) gives a one-to-one θ(λ) mapping that prevents all wavelengths from sharing a common exit angle.\n\nVERIFICATION: Units dimensionless; holds for any transparent dispersive prism in the visible range.", "rejected": "The refractive-index dispersion n(λ) forces each wavelength to leave the prism at its own angle θ(λ), so the exiting beam fans into a spectrum whose total angular spread equals the sum of n(λ) and θ(λ).", "E_acc": 0.13832464814186096, "C_acc": 0.5444827079772949, "G_acc": 0.5226377535445863, "D_acc": 0.7802673242986202, "H_acc": 0.18761832267045975, "Q_acc": 0.47442003614869466, "E_rej": 0.4139155447483063, "C_rej": 0.21457146108150482, "G_rej": 0.513177911634557, "D_rej": 0.7556878328323364, "H_rej": 0.30539020895957947, "Q_rej": 0.6044944992056116, "Delta_Q": -0.13007446305691694, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exothermic reactions release heat, yet products are more stable. Given energy diagrams, consider what hypotheses can be justified about bond energies.", "ancestors": ["[Definition] Reaction enthalpy ΔH is the energy difference between products and reactants.", "[Variable] Bond energy E_b is the energy required to break a specific bond in isolation.", "[Law] The total enthalpy change equals the sum of bond energies broken minus the sum of bond energies formed.", "[Constraint] An exothermic release (ΔH < 0) demands that the sum of product bond energies exceeds the sum of reactant bond energies."]}, "accepted": "Using the enthalpy definition and bond-energy law, the exothermic constraint ΔH < 0 translates to ΣE_b(products) – ΣE_b(reactants) > 0, so the product bonds must outweigh the reactant bonds by a positive margin.\n\nHYPOTHESIS: For any exothermic reaction, the combined isolated bond energies of the products exceed those of the reactants by the positive quantity –ΔH.\n\nVERIFICATION: Both sides carry energy units, and the relation holds wherever the bond-additivity law applies.", "rejected": "For any endothermic reaction, the combined isolated bond energies of the products exceed those of the reactants by the positive quantity –ΔH.", "E_acc": 0.7899742722511292, "C_acc": 0.0711316168308258, "G_acc": 0.5563892518403009, "D_acc": 0.8011349240938822, "H_acc": 0.19954949617385864, "Q_acc": 0.7743158438786243, "E_rej": 0.4409071207046509, "C_rej": 0.17265887558460236, "G_rej": 0.5634423890151083, "D_rej": 0.8124359250068665, "H_rej": 0.18756407499313354, "Q_rej": 0.6541596163995564, "Delta_Q": 0.12015622747906785, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Images form in mirrors and lenses, yet magnification varies with distance. Given ray optics, consider what hypotheses can be justified about focal properties.", "ancestors": ["[Definition] A mirror is a smooth reflecting surface.", "[Definition] A lens is a transparent refracting medium with curved faces.", "[Variable] f is the focal length of a mirror or lens.", "[Law] Rays parallel to the optical axis pass through or appear to pass through a single point called the focal point at distance f from the surface.", "[Constraint] For spherical mirrors and thin lenses, 1/f = 1/u + 1/v where u is object distance and v is image distance.", "[Limit] 1/v must be non-negative for real images."]}, "accepted": "Using the mirror/lens equation and the real-image requirement 1/v ≥ 0, the object distance u must satisfy 1/u ≤ 1/f.  \nHYPOTHESIS: For any spherical mirror or thin lens with positive focal length f, a real image is formed only when the object is placed no closer than one focal length, i.e. u ≥ f.  \nVERIFICATION: Units consistent (both sides length⁻¹); valid for paraxial rays in spherical mirror/thin-lens regime.", "rejected": "A real image is formed only when a spherical mirror or thin lens with positive focal length f has the object placed no closer than one focal length, i.e. u ≥ f.", "E_acc": 0.3686673045158386, "C_acc": 0.37402835488319397, "G_acc": 0.5524578586752925, "D_acc": 0.7584405690431595, "H_acc": 0.23872964084148407, "Q_acc": 0.5741012418376549, "E_rej": 0.4305550754070282, "C_rej": 0.21127662062644958, "G_rej": 0.5387003649292248, "D_rej": 0.6751925218850374, "H_rej": 0.2090710997581482, "Q_rej": 0.6087826658838562, "Delta_Q": -0.03468142404620134, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric charges exert forces, yet stationary charges do no work. Given electrostatics, consider what hypotheses follow about electric potential.", "ancestors": ["[Definition] Electric potential V at a point is the scalar potential energy per unit positive test charge qₜ at that point.", "[Variable] The test charge is qₜ.", "[Law] The electrostatic force on qₜ is F = –∇(qₜ V).", "[Constraint] If qₜ is stationary, its displacement dr is zero."]}, "accepted": "For a stationary test charge the displacement is zero, so the work done by the electrostatic force vanishes; because the force derives from the potential energy qₜV, this requires the spatial gradient of V to vanish wherever the charge is held fixed.\n\nHYPOTHESIS: At any location where a test charge qₜ is constrained to remain stationary, the electric potential gradient satisfies ∇V = 0.\n\nVERIFICATION: Units consistent (V m⁻¹); valid only at points where the charge is mechanically fixed.", "rejected": "Wherever the spatial gradient of V vanishes, a test charge qₜ is thereby constrained to remain stationary.", "E_acc": 0.3819361627101898, "C_acc": 0.362137109041214, "G_acc": 0.5249742582465322, "D_acc": 0.804352288444837, "H_acc": 0.12589296698570251, "Q_acc": 0.5954294396445177, "E_rej": 0.6149053573608398, "C_rej": 0.17457494139671326, "G_rej": 0.5446017804954734, "D_rej": 0.842913031578064, "H_rej": 0.15708696842193604, "Q_rej": 0.7113508845014233, "Delta_Q": -0.11592144485690559, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric charges exert forces, yet stationary charges do no work. Given electrostatics, consider what hypotheses follow about electric potential.", "ancestors": ["[Definition] The electrostatic force F on a test charge q in field E is F = qE.", "[Law] For stationary charges the work W done by F in any displacement dl is dW = F·dl.", "[Variable] Let Φ be the scalar electric potential.", "[Law] The work done is dW = –q dΦ.", "[Constraint] The work W is zero for any closed path when charges are stationary.", "[Limit] Hence Φ is single-valued at every point in the electrostatic domain."]}, "accepted": "The premises link work to both the electric field and the potential difference.  Combining the two expressions for incremental work, F·dl = –q dΦ, and inserting F = qE, gives qE·dl = –q dΦ.  Cancelling the test charge q (non-zero) and integrating over an arbitrary path from point A to point B yields the potential difference.\n\nHYPOTHESIS: The potential difference between any two points in an electrostatic field is ΔΦ = –∫_A^B E·dl.\n\nVERIFICATION: Units check—E in V m⁻¹, dl in m, so E·dl in V, matching Φ in volts; valid for stationary charges.", "rejected": "Integrating qE·dl = –q dΦ over an arbitrary path from A to B gives ΔΦ = ∫_A^B E·dl.", "E_acc": 0.4033714234828949, "C_acc": 0.34682270884513855, "G_acc": 0.5148147479631007, "D_acc": 0.7390802532434464, "H_acc": 0.18139788508415222, "Q_acc": 0.5842860970087349, "E_rej": 0.34364601969718933, "C_rej": 0.3566901683807373, "G_rej": 0.5294688525609672, "D_rej": 0.6820786446332932, "H_rej": 0.31792135536670685, "Q_rej": 0.5422731361351907, "Delta_Q": 0.042012960873544225, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Particles behave like waves, yet are detected as localized impacts. Given wave–particle duality, consider what hypotheses can be justified about measurement.", "ancestors": ["[Definition] A particle's de Broglie wavelength λ is h/p where h is Planck's constant and p is its momentum.", "[Definition] A probability amplitude ψ(x,t) gives the probability density |ψ|² of detecting the particle at position x and time t.", "[Law] The evolution of ψ(x,t) is governed by the Schrödinger equation.", "[Constraint] Upon position measurement, the wavefunction collapses to a narrow spike centered at the measured value.", "[Limit] The product of uncertainties of position (Δx) and momentum (Δp) satisfies ΔxΔp ≥ ℏ/2."]}, "accepted": "The de Broglie wavelength λ = h/p and the uncertainty principle ΔxΔp ≥ ℏ/2 link a particle’s wave and particle attributes.  Requiring the position uncertainty Δx to be at least of the order of λ sets a lower bound on the momentum uncertainty, which in turn fixes a minimum spatial spread for any wave packet description of the particle.\n\nHYPOTHESIS: A particle whose de Broglie wavelength is λ cannot be localized within a region smaller than λ/4π.\n\nVERIFICATION: Both sides have units of length; the bound saturates the uncertainty principle when Δx = λ/4π and Δp = ℏ/2Δx = h/λ = p.", "rejected": "The de Broglie wavelength λ = h/p and the uncertainty principle ΔxΔp ≥ ℏ/2 link a particle’s wave and particle attributes, so demanding the position uncertainty Δx to be smaller than λ/4π still permits an arbitrarily sharp momentum definition.", "E_acc": 0.48536962270736694, "C_acc": 0.18463337421417236, "G_acc": 0.5589409919921309, "D_acc": 0.8203044980764389, "H_acc": 0.12457454204559326, "Q_acc": 0.6720758557785302, "E_rej": 0.11877622455358505, "C_rej": 0.21072295308113098, "G_rej": 0.5650204864796251, "D_rej": 0.8833454847335815, "H_rej": 0.11665451526641846, "Q_rej": 0.5714960194658488, "Delta_Q": 0.10057983631268141, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Liquids flow, yet resist compression. Given intermolecular forces, consider what hypotheses can be justified about cohesion.", "ancestors": ["[Definition] Cohesion is the net attractive force between like molecules in a liquid.", "[Variable] Let r denote the mean intermolecular spacing in the liquid.", "[Variable] Let U(r) denote the pair potential energy between two molecules.", "[Law] The derivative F = –dU/dr gives the intermolecular force.", "[Constraint] For equilibrium spacing r₀, F(r₀) = 0 and d²U/dr²|r₀ > 0.", "[Limit] The maximum tensile stress before cavitation is σ_max = n·|F_max|, where n is molecular number density and F_max is the maximum attractive force."]}, "accepted": "The premises define cohesion through the attractive force F = –dU/dr and link the maximum tensile stress before cavitation to the peak attractive force.  Because F must vanish at equilibrium and be attractive for r > r₀, F(r) possesses a minimum (most negative) value F_max < 0; the stress threshold σ_max is proportional to this extremum.\n\nHYPOTHESIS: The liquid’s cavitation strength satisfies σ_max = n · |dU/dr|_max, where |dU/dr|_max is the maximum slope of the pair potential.\n\nVERIFICATION: Both sides have units of (number density) × (energy/distance) = N m⁻², the unit of stress.", "rejected": "The peak attractive force F_max is reached because the liquid’s cavitation strength equals σ_max = n·|F_max|.", "E_acc": 0.5387933254241943, "C_acc": 0.2058008462190628, "G_acc": 0.5349678758939262, "D_acc": 0.766891073435545, "H_acc": 0.14897819608449936, "Q_acc": 0.66595179864089, "E_rej": 0.5467730760574341, "C_rej": 0.2322872281074524, "G_rej": 0.5318935765253627, "D_rej": 0.7850036919116974, "H_rej": 0.2149963080883026, "Q_rej": 0.6594543000743215, "Delta_Q": 0.00649749856656856, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrochemical cells produce voltage, yet materials are consumed. Given electrochemistry, consider what hypotheses follow about energy conversion.", "ancestors": ["[Definition] An electrochemical cell converts chemical energy to electrical energy via redox reactions at two electrodes.", "[Law] The overall cell potential E_cell equals E_cathode – E_anode under standard conditions.", "[Variable] During operation the extent of reaction ξ increases monotonically with charge Q passed, Q = nFξ.", "[Constraint] Consumption of electroactive species causes their concentrations c to decline, and by the Nernst equation E_cell depends on c."]}, "accepted": "As charge passes the extent of reaction increases and concentrations fall, so the Nernst potential must decrease; combining this with the fixed relation E_cell = E_cathode – E_anode implies that the cathode potential falls and the anode potential rises until the difference reaches zero.\n\nHYPOTHESIS: The cell potential E_cell approaches zero monotonically as the reaction proceeds toward completion.\n\nVERIFICATION: At equilibrium E_cell = 0 V, consistent with units of volts and the condition ξ → ξ_max.", "rejected": "As the cathode potential rises and the anode potential falls, the difference E_cell = E_cathode – E_anode approaches zero.", "E_acc": 0.1705859899520874, "C_acc": 0.5751034021377563, "G_acc": 0.5704057591501623, "D_acc": 0.7721619407335917, "H_acc": 0.23180272430181503, "Q_acc": 0.48148838410464423, "E_rej": 0.23881709575653076, "C_rej": 0.24920311570167542, "G_rej": 0.5907472760300152, "D_rej": 0.7966822683811188, "H_rej": 0.20331773161888123, "Q_rej": 0.578958641306963, "Delta_Q": -0.09747025720231872, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exothermic reactions release heat, yet products are more stable. Given energy diagrams, consider what hypotheses can be justified about bond energies.", "ancestors": ["[Definition] An exothermic reaction releases heat (q > 0) to the surroundings.", "[Definition] Products are more stable than reactants when their potential energy E_p is lower.", "[Definition] Bond energy B is the energy required to break one mole of bonds in isolated gaseous species.", "[Constraint] The enthalpy change ΔH equals ΣB_broken − ΣB_formed."]}, "accepted": "Using the enthalpy definition ΔH = ΣB_broken − ΣB_formed, an exothermic reaction (q > 0) corresponds to ΔH < 0, which requires ΣB_broken < ΣB_formed.  \nHYPOTHESIS: In an exothermic reaction the total bond energy of the bonds formed in the products exceeds that of the bonds broken in the reactants.  \nVERIFICATION: Both sides of the inequality carry energy units (kJ mol⁻¹), consistent with the enthalpy definition.", "rejected": "In an exothermic reaction the total bond energy of the bonds broken in the reactants exceeds that of the bonds formed in the products.", "E_acc": 0.26993510127067566, "C_acc": 0.3121146857738495, "G_acc": 0.564172669313848, "D_acc": 0.8076627254486084, "H_acc": 0.14043289422988892, "Q_acc": 0.5788813827559353, "E_rej": 0.21769167482852936, "C_rej": 0.0412106066942215, "G_rej": 0.581882257014513, "D_rej": 0.8987233936786652, "H_rej": 0.10127660632133484, "Q_rej": 0.6430588506162167, "Delta_Q": -0.06417746786028145, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysts increase reaction rate, yet remain unchanged. Given reaction mechanisms, consider what hypotheses can be justified about pathways.", "ancestors": ["[Definition] A catalyst is a substance that participates in a reaction and increases its rate without being consumed.", "[Definition] An elementary step is a reaction that occurs as a single molecular event.", "[Definition] A mechanism is a sequence of elementary steps that describes how overall reactants become products.", "[Constraint] The sum of the catalyst-containing steps in the mechanism must equal the overall stoichiometry of the net reaction.", "[Limit] The catalyst exits every elementary step with the same chemical identity it had entering that step."]}, "accepted": "Because every elementary step conserves the catalyst’s identity and the summed mechanism must reproduce the overall stoichiometry, the catalyst must appear at least once as a reactant and once as a product within the sequence of steps.  \nHYPOTHESIS: A catalyst must participate in at least two elementary steps of any mechanism that converts overall reactants to products.  \nVERIFICATION: Counting catalyst appearances gives units of “steps”; the statement holds for all valid mechanisms satisfying the given definitions and constraints.", "rejected": "A catalyst must participate in at least two elementary steps of any chemical reaction, whether or not a mechanism is given.", "E_acc": 0.6605989933013916, "C_acc": 0.1218215674161911, "G_acc": 0.5344762540305965, "D_acc": 0.8178259531656901, "H_acc": 0.24140837788581848, "Q_acc": 0.7201349881578548, "E_rej": 0.23378455638885498, "C_rej": 0.24392935633659363, "G_rej": 0.5380597694776952, "D_rej": 0.8771133422851562, "H_rej": 0.1536083221435547, "Q_rej": 0.5890232857875526, "Delta_Q": 0.13111170237030223, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrons occupy quantized energy levels, yet transitions appear continuous in spectra. Given quantum chemistry, consider what hypotheses follow about emission.", "ancestors": ["[Definition] An electronic state is a solution of the time-independent Schrödinger equation labeled by quantum numbers n,l,m.", "[Law] Energy eigenvalue E_n scales as −Z²/n² for one-electron atoms.", "[Variable] Photon energy ε equals |E_n − E_k| when an electron drops from state n to state k.", "[Limit] Dipole selection rules require Δl = ±1 and Δm = 0,±1, constraining allowed n→k pairs.", "[Constraint] Spectral line wavelengths λ satisfy ε = hc/λ, mapping discrete ε to discrete λ."]}, "accepted": "The energy difference ε = |E_n − E_k| = Z²(1/k² − 1/n²) and the dipole selection rule Δl = ±1 together restrict observable spectral lines to transitions whose initial and final angular-momentum quantum numbers differ by exactly one unit.  \nHYPOTHESIS: For one-electron atoms, every emitted photon wavelength satisfies λ = hc / [Z²(1/k² − 1/n²)] with the additional constraint that |l_n − l_k| = 1.  \nVERIFICATION: Units check—hc has eV·nm, Z²(1/k² − 1/n²) is dimensionless, yielding λ in nm.", "rejected": "For one-electron atoms, every emitted photon wavelength satisfies λ = hc / [Z²(1/k² − 1/n²)] with the additional constraint that |l_n − l_k| = 2.", "E_acc": 0.4223596453666687, "C_acc": 0.2856532037258148, "G_acc": 0.5426950931723695, "D_acc": 0.7707650363445282, "H_acc": 0.1696305274963379, "Q_acc": 0.6153062260185834, "E_rej": 0.2971697151660919, "C_rej": 0.24115753173828125, "G_rej": 0.5648844948154874, "D_rej": 0.7821423411369324, "H_rej": 0.21785765886306763, "Q_rej": 0.5885390095063485, "Delta_Q": 0.026767216512234904, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Gravitational force decreases with distance, yet orbital motion remains stable. Given Newtonian gravitation, consider what hypotheses follow about orbital balance.", "ancestors": ["[Law] Gravitational force F between two point masses m₁ and m₂ separated by r is F = G m₁ m₂ r⁻² directed along the line joining them.", "[Variable] Orbital speed v of mass m in circular orbit of radius r about central mass M is v = √(G M r⁻¹).", "[Constraint] Centripetal force required for circular motion equals gravitational force: m v² r⁻¹ = G m M r⁻².", "[Limit] Binding persists for any positive r; no lower or upper distance bound exists within Newtonian gravitation alone."]}, "accepted": "Combining the orbital speed formula with the centripetal–gravitational balance, the orbital period T = 2πr/v emerges as a function of radius alone.  \nHYPOTHESIS: The orbital period of a test mass in a circular orbit about a central mass M is T = 2π√(r³/GM).  \nVERIFICATION: Units check: [r³/GM]^{½} has dimensions T, matching the left side.", "rejected": "The orbital period determines the orbital radius rather than the radius determining the period.", "E_acc": 0.49165189266204834, "C_acc": 0.31702524423599243, "G_acc": 0.5907562323845923, "D_acc": 0.7389208227396011, "H_acc": 0.20737388730049133, "Q_acc": 0.6292885412462055, "E_rej": 0.05600187927484512, "C_rej": 0.6597071886062622, "G_rej": 0.562517388316337, "D_rej": 0.6927430033683777, "H_rej": 0.3072569966316223, "Q_rej": 0.4051855047349818, "Delta_Q": 0.22410303651122365, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrical power depends on both voltage and current, yet devices heat differently. Given energy transfer, consider what hypotheses can be justified about efficiency.", "ancestors": ["[Definition] Instantaneous electrical power P delivered to a device equals the product of voltage V across it and current I through it: P = V × I.", "[Variable] Let E denote the energy transferred to the device during a time interval t.", "[Law] By energy conservation, E equals the time integral of P over t: E = ∫P dt.", "[Constraint] Joule heating power P_d dissipated in a resistive device is I²R, where R is its resistance.", "[Limit] Since P_d ≤ P, the useful power available for non-thermal work cannot exceed P - P_d."]}, "accepted": "Combining the instantaneous power definition P = VI with the Joule-heating constraint P_d = I²R and the limit P_d ≤ P yields the inequality I²R ≤ VI, which simplifies to I ≤ V/R for any resistive device.\n\nHYPOTHESIS: The current through a resistive device cannot exceed the ratio of the applied voltage to its resistance, I ≤ V/R.\n\nVERIFICATION: Units check: A ≤ V/Ω = A, confirming dimensional consistency.", "rejected": "The current through a resistive device is independent of the applied voltage across it.", "E_acc": 0.6866226196289062, "C_acc": 0.13609421253204346, "G_acc": 0.5516324577038176, "D_acc": 0.7519180526336035, "H_acc": 0.09867951273918152, "Q_acc": 0.7296100941758292, "E_rej": 0.005236863158643246, "C_rej": 0.9751694798469543, "G_rej": 0.5025707586901262, "D_rej": 0.6968254446983337, "H_rej": 0.30317455530166626, "Q_rej": 0.3160989481257275, "Delta_Q": 0.41351114605010175, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy flows through ecosystems, yet matter cycles. Given ecology, consider what hypotheses follow about trophic levels.", "ancestors": ["[Definition] A trophic level is a functional classification of organisms based on their feeding position in a food web.", "[Variable] Let P denote the rate of energy input captured by primary producers.", "[Law] Net primary productivity P equals total photosynthetic energy capture minus plant respiration.", "[Constraint] Energy transfer efficiency k from one trophic level to the next is typically less than 0.1.", "[Variable] Let T_i be the energy content contained in trophic level i, with i=1 denoting primary producers.", "[Limit] T_{i+1}=k T_i sets an upper bound on energy available to the next trophic level."]}, "accepted": "Using the energy transfer limit T_{i+1}=k T_i with k<0.1, the energy content of each successive trophic level is bounded by a factor of ten below its predecessor. Iterating this bound from the primary producers (i=1) gives T_n ≤ k^{n-1} T_1, so the energy available at trophic level n drops by at least an order of magnitude for each step above the base. HYPOTHESIS: For any trophic level n ≥ 2, the energy content T_n ≤ 0.1^{n-1} T_1. VERIFICATION: Units (J m^{-2}) cancel; inequality holds whenever the standard 10 % ecological transfer efficiency applies.", "rejected": "For any trophic level n ≥ 2, the energy content T_n = 0.1^{n-1} T_1.", "E_acc": 0.28217655420303345, "C_acc": 0.3093074858188629, "G_acc": 0.5460267298640247, "D_acc": 0.8203681334853172, "H_acc": 0.13399022817611694, "Q_acc": 0.5826714189493942, "E_rej": 0.17121614515781403, "C_rej": 0.4330647885799408, "G_rej": 0.5583577638608404, "D_rej": 0.8335583209991455, "H_rej": 0.1664416790008545, "Q_rej": 0.5264909349032678, "Delta_Q": 0.05618048404612641, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Particles behave like waves, yet are detected as localized impacts. Given wave–particle duality, consider what hypotheses can be justified about measurement.", "ancestors": ["[Definition] The de Broglie wavelength λ of a particle is λ = h/p, where h is Planck constant and p is linear momentum.", "[Variable] Let ψ(x,t) denote the complex-valued wavefunction assigned to the particle.", "[Law] The probability density P(x,t) of detecting the particle at position x and time t is P(x,t)=|ψ(x,t)|².", "[Constraint] The integral ∫P(x,t)dx over all space equals 1 at any fixed t.", "[Limit] Simultaneous precise values for non-commuting observables A and B cannot be assigned; their commutator [A,B]≠0.", "[Definition] A measurement localizes the particle at a recorded position x₀ within detector resolution Δx≥λ."]}, "accepted": "Using the de Broglie relation λ = h/p and the measurement requirement Δx ≥ λ, the spatial resolution of any position measurement is bounded from below by the particle’s wavelength. Combining these gives Δx ≥ h/p, so for a given experimental resolution Δx the momentum cannot exceed h/Δx without violating the resolution limit.\n\nHYPOTHESIS: A position measurement with spatial resolution Δx imposes an upper bound p ≤ h/Δx on the particle’s momentum.\n\nVERIFICATION: Units check: h/Δx has kg·m·s⁻¹, matching momentum units.", "rejected": "A position measurement with spatial resolution Δx imposes a lower bound p ≥ h/Δx on the particle’s momentum.", "E_acc": 0.46485087275505066, "C_acc": 0.27872228622436523, "G_acc": 0.5481484041665681, "D_acc": 0.7515486292541027, "H_acc": 0.20013326406478882, "Q_acc": 0.6236368848592975, "E_rej": 0.398331880569458, "C_rej": 0.3925936818122864, "G_rej": 0.5412062539398903, "D_rej": 0.7500059902667999, "H_rej": 0.24999400973320007, "Q_rej": 0.5742238756763982, "Delta_Q": 0.04941300918289926, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Human activity alters ecosystems, yet feedback effects emerge. Given environmental biology, consider what hypotheses follow about sustainability.", "ancestors": ["[Definition] Human activity is any deliberate physical or chemical intervention by people in a biological system.", "[Variable] Let r be the rate of net primary productivity altered by human activity.", "[Constraint] Altered r feeds back to subsequent human resource extraction decisions.", "[Limit] There exists a minimum viable r below which altered ecosystems cannot sustain their original services."]}, "accepted": "The premises link human-driven alteration of net primary productivity (r) to subsequent resource decisions and impose a lower viability bound. Combining the feedback loop with the hard limit implies that once r falls below this bound, extraction must cease or the system collapses, so the minimal sustainable state occurs when the altered rate exactly equals the viability threshold.\n\nHYPOTHESIS: Human resource extraction must be managed so that the altered net primary productivity rate r does not decline below the minimum viable value r_min.\n\nVERIFICATION: Units of r and r_min are identical (mass or energy per area per time), and the inequality r ≥ r_min defines the operational regime.", "rejected": "Human resource extraction must be managed so that the altered net primary productivity rate r is allowed to decline indefinitely below the minimum viable value r_min.", "E_acc": 0.3714454174041748, "C_acc": 0.29509904980659485, "G_acc": 0.544132765266113, "D_acc": 0.7123759463429451, "H_acc": 0.3960925564169884, "Q_acc": 0.5641063019400462, "E_rej": 0.295535147190094, "C_rej": 0.3446948528289795, "G_rej": 0.5600935413531261, "D_rej": 0.7534596920013428, "H_rej": 0.30817538499832153, "Q_rej": 0.5516146817622939, "Delta_Q": 0.012491620177752294, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Diffraction becomes significant when apertures are small. Given wave optics, consider what hypotheses can be justified about resolution limits.", "ancestors": ["[Definition] Diffraction is the bending of a wave when its front encounters an obstacle or aperture.", "[Variable] λ is the wavelength of the wave.", "[Variable] D is the characteristic diameter of the aperture.", "[Law] The angular position θ of the first minimum in Fraunhofer diffraction is given by sinθ ≈ λ/D for small angles.", "[Limit] θmin is the smallest angular separation at which two incoherent point sources can be resolved.", "[Constraint] For diffraction-limited resolution, θmin ∝ λ/D."]}, "accepted": "Using the diffraction-limited resolution constraint θmin ∝ λ/D and the Fraunhofer first-minimum formula sinθ ≈ λ/D, the smallest resolvable angular separation scales linearly with wavelength for a fixed aperture.\n\nHYPOTHESIS: For a fixed aperture diameter D, halving the wavelength λ halves the minimum resolvable angular separation θmin.\n\nVERIFICATION: Both sides are dimensionless angles; relation holds in the Fraunhofer small-angle regime.", "rejected": "For a fixed aperture diameter D, the minimum resolvable angular separation θmin equals λ/D without any trigonometric factor.", "E_acc": 0.30210253596305847, "C_acc": 0.39000260829925537, "G_acc": 0.551359161559958, "D_acc": 0.7916843295097351, "H_acc": 0.16967865824699402, "Q_acc": 0.5642710715183058, "E_rej": 0.2339099645614624, "C_rej": 0.22462546825408936, "G_rej": 0.5416326682607178, "D_rej": 0.7830804884433746, "H_rej": 0.21691951155662537, "Q_rej": 0.5684985759027769, "Delta_Q": -0.004227504384471059, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysts increase reaction rate, yet remain unchanged. Given reaction mechanisms, consider what hypotheses can be justified about pathways.", "ancestors": ["[Definition] A catalyst is a species that increases the rate of a chemical reaction and is regenerated unchanged.", "[Variable] Let k_cat be the rate constant of the catalysed pathway.", "[Variable] Let k_uncat be the rate constant of the uncatalysed pathway.", "[Law] k_cat is larger than k_uncat at the same temperature.", "[Constraint] The catalyst appears as a reactant in an early step and as a product in a later step of the mechanism.", "[Limit] The overall stoichiometry of the reaction is identical in the presence or absence of the catalyst."]}, "accepted": "The premises establish that a catalyst accelerates a reaction (k_cat > k_uncat) while being regenerated, so its concentration remains constant over a catalytic cycle.  Because the catalyst is both consumed and re-formed, its steady-state concentration must be conserved.\n\nHYPOTHESIS: The net change in catalyst concentration over one complete catalytic cycle is exactly zero.\n\nVERIFICATION: Units check—concentration change has units of mol L⁻¹, and zero change is dimensionally consistent.", "rejected": "The net change in catalyst concentration over one complete catalytic cycle equals the rate constant k_cat.", "E_acc": 0.517584502696991, "C_acc": 0.09563752263784409, "G_acc": 0.5532403915422037, "D_acc": 0.7856199257075787, "H_acc": 0.22792618721723557, "Q_acc": 0.6811272910097614, "E_rej": 0.15051685273647308, "C_rej": 0.6328913569450378, "G_rej": 0.5628711218596436, "D_rej": 0.8343903124332428, "H_rej": 0.1656096875667572, "Q_rej": 0.481468102533836, "Delta_Q": 0.19965918847592545, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "White light separates into colors, yet recombines into white again. Given dispersion, consider what hypotheses follow about wavelength dependence.", "ancestors": ["[Definition] Dispersion is the dependence of refractive index n on vacuum wavelength λ.", "[Law] In vacuum the speed of light c is constant for all λ.", "[Variable] Phase velocity in a medium is v(λ)=c/n(λ).", "[Constraint] v(λ) is single‐valued for each λ in a given medium."]}, "accepted": "Because n(λ) varies with wavelength while c is fixed, the phase velocity v(λ)=c/n(λ) must change with wavelength; the single-valued constraint on v(λ) then forces n(λ) to be likewise single-valued, so dispersion implies a one-to-one mapping between λ and n in any given medium.\n\nHYPOTHESIS: In a dispersive medium the refractive index n(λ) is a single-valued function of vacuum wavelength, so any two distinct wavelengths yield two distinct phase velocities.\n\nVERIFICATION: Units consistent (n dimensionless, v in m s⁻¹), valid for any transparent dispersive medium.", "rejected": "Because n(λ) varies with wavelength while c is fixed, the phase velocity v(λ)=c/n(λ) must be the same for all wavelengths in any dispersive vacuum.", "E_acc": 0.6773834228515625, "C_acc": 0.11990886926651001, "G_acc": 0.559633115415636, "D_acc": 0.8374295433362325, "H_acc": 0.15421248972415924, "Q_acc": 0.7432245357801246, "E_rej": 0.3892664313316345, "C_rej": 0.36530253291130066, "G_rej": 0.548754007439129, "D_rej": 0.8476643264293671, "H_rej": 0.19041959196329117, "Q_rej": 0.6039611303946003, "Delta_Q": 0.13926340538552429, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Neurons transmit electrical signals, yet communication is chemical at synapses. Given neurobiology, consider what hypotheses follow about signal integration.", "ancestors": ["[Definition] A neuron is a cell specialized to transmit electrical impulses called action potentials.", "[Variable] Let v denote the membrane potential difference across the neuronal plasma membrane.", "[Law] An action potential is a rapid, transient, all-or-none depolarization of v that propagates along the axon.", "[Definition] A synapse is a specialized junction where the plasma membrane of one neuron closely opposes the membrane of another neuron or an effector cell.", "[Constraint] At chemical synapses, the presynaptic neuron converts the electrical signal of an action potential into secretion of neurotransmitter molecules that bind receptors on the postsynaptic membrane."]}, "accepted": "Using the definition that an action potential is an all-or-none depolarization of the membrane potential v, the threshold for triggering this event must be a specific, finite increment above the resting potential.  \nHYPOTHESIS: A neuron will fire an action potential if and only if v rises at least to the threshold value v_thresh, where v_thresh − v_rest > 0.  \nVERIFICATION: Units of v are mV; inequality holds whenever the membrane is depolarized beyond the unique firing threshold.", "rejected": "A neuron will fire an action potential only if v rises exactly to the threshold value v_thresh, where v_thresh − v_rest = 0 mV.", "E_acc": 0.422572523355484, "C_acc": 0.27636268734931946, "G_acc": 0.5300982501357794, "D_acc": 0.7745817253986994, "H_acc": 0.19977804273366928, "Q_acc": 0.6124574103703101, "E_rej": 0.08042728900909424, "C_rej": 0.2098781317472458, "G_rej": 0.5324561171167131, "D_rej": 0.8181774318218231, "H_rej": 0.18182256817817688, "Q_rej": 0.5340970133231687, "Delta_Q": 0.07836039704714137, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Complex structures arise gradually, yet appear well-designed. Given evolutionary theory, consider what hypotheses can be justified about cumulative change.", "ancestors": ["[Definition] Complexity C is a scalar quantifying the number of interdependent parts in an organism.", "[Law] Cumulative change ΔC is the additive increment of C summed over n successive generations.", "[Constraint] Natural selection imposes a zero lower bound on fitness W.", "[Limit] No organism can produce ΔC exceeding its genome’s additive information I."]}, "accepted": "Summing ΔC over n generations gives total complexity Cₙ = C₀ + ΣΔC, and each ΔC is bounded above by the genome’s additive information I.  Hence the maximum attainable complexity after any number of generations is set by the initial complexity plus the cumulative information ceiling.\n\nHYPOTHESIS: For any lineage, the complexity after n generations satisfies Cₙ ≤ C₀ + nI.\n\nVERIFICATION: Both sides carry the same “information-equivalent complexity” units, and equality is reached only when every generation achieves the maximal ΔC = I.", "rejected": "For any lineage, the complexity after n generations is Cₙ = C₀ + nΔC with every ΔC treated as independent of the genome’s additive information I.", "E_acc": 0.182855486869812, "C_acc": 0.6453734636306763, "G_acc": 0.5677209009008948, "D_acc": 0.8232231214642525, "H_acc": 0.11915034055709839, "Q_acc": 0.492055723752128, "E_rej": 0.2520048916339874, "C_rej": 0.35068148374557495, "G_rej": 0.557905449939426, "D_rej": 0.8691131770610809, "H_rej": 0.13088682293891907, "Q_rej": 0.5777802138472907, "Delta_Q": -0.0857244900951627, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Acids donate protons, yet strength varies widely. Given acid–base theory, consider what hypotheses follow about dissociation.", "ancestors": ["[Definition] An acid is a proton donor.", "[Definition] Acid strength is measured by the equilibrium constant Ka for HA ⇌ H⁺ + A⁻.", "[Variable] Let Ka denote the acid dissociation constant.", "[Constraint] Ka depends only on temperature for a given acid."]}, "accepted": "The acid dissociation constant Ka quantifies how far the equilibrium HA ⇌ H⁺ + A⁻ lies to the right; because Ka is fixed at a given temperature, the ratio [H⁺][A⁻]/[HA] must equal this constant.  \nHYPOTHESIS: For any acid at fixed temperature, the product of the concentrations [H⁺][A⁻] equals Ka multiplied by the concentration of undissociated acid [HA].  \nVERIFICATION: Units check—both sides have concentration², consistent with the equilibrium expression.", "rejected": "At fixed temperature, if the product [H⁺][A⁻] equals Ka multiplied by [HA], then the acid is at equilibrium.", "E_acc": 0.2718386948108673, "C_acc": 0.32500165700912476, "G_acc": 0.5820542224682868, "D_acc": 0.7484542826811472, "H_acc": 0.25373395532369614, "Q_acc": 0.5572795825389524, "E_rej": 0.03967736288905144, "C_rej": 0.8990054130554199, "G_rej": 0.5737353245494887, "D_rej": 0.7888050377368927, "H_rej": 0.2111949622631073, "Q_rej": 0.383490702486597, "Delta_Q": 0.17378888005235538, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mutations alter DNA, yet many are neutral. Given evolution, consider what hypotheses follow about genetic robustness.", "ancestors": ["[Definition] A mutation is a heritable change in DNA sequence.", "[Definition] Neutral mutations have no effect on fitness.", "[Variable] f denotes fitness.", "[Constraint] Δf = 0 for neutral mutations."]}, "accepted": "Neutral mutations leave fitness unchanged, so any measurable trait strictly tied to fitness must remain invariant once the mutation is fixed.  \nHYPOTHESIS: The mean population fitness does not change across generations in which only neutral mutations fix.  \nVERIFICATION: Δf = 0 by definition, so the predicted fitness difference is identically zero.", "rejected": "The mean population fitness increases across generations in which only neutral mutations fix.", "E_acc": 0.40569400787353516, "C_acc": 0.30102840065956116, "G_acc": 0.5515498907438346, "D_acc": 0.7961774865786234, "H_acc": 0.1499854400753975, "Q_acc": 0.6160494536871002, "E_rej": 0.016037993133068085, "C_rej": 0.7472435235977173, "G_rej": 0.5385452882785883, "D_rej": 0.8006959855556488, "H_rej": 0.1993040144443512, "Q_rej": 0.4032805465427893, "Delta_Q": 0.2127689071443109, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase changes occur at fixed temperatures, yet energy continues to flow. Given thermodynamics, consider what hypotheses can be justified about latent heat.", "ancestors": ["[Definition] Latent heat (L) is the energy absorbed or released per unit mass during an isothermal phase transition.", "[Law] During a phase change at constant pressure, the heat energy exchanged is ΔQ = mL.", "[Variable] Temperature (T) remains constant over the duration of the process.", "[Constraint] In a pure substance, L is fixed at the standard transition temperature."]}, "accepted": "Because the latent heat L is fixed for a pure substance at its standard transition temperature and the temperature remains constant during the phase change, the total heat exchanged is strictly proportional to the mass transformed.\n\nHYPOTHESIS: For any pure substance undergoing a complete phase transition at its standard transition temperature, the mass-specific energy cost equals the tabulated latent heat L.\n\nVERIFICATION: Units check: [L] = J kg⁻¹, matching energy per mass.", "rejected": "The latent heat L governs the energy cost per unit mass even when the pure substance is driven through its transition far from the standard temperature.", "E_acc": 0.4024119973182678, "C_acc": 0.30154943466186523, "G_acc": 0.5444619893678464, "D_acc": 0.7791350285212199, "H_acc": 0.1679876148700714, "Q_acc": 0.6083343543539135, "E_rej": 0.30780988931655884, "C_rej": 0.2767012119293213, "G_rej": 0.5553761014016345, "D_rej": 0.8729378283023834, "H_rej": 0.12706217169761658, "Q_rej": 0.6099592931801454, "Delta_Q": -0.0016249388262319364, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Populations grow, yet stabilize over time. Given population dynamics, consider what hypotheses can be justified about carrying capacity.", "ancestors": ["[Definition] The carrying capacity K is the maximum population size that an environment can sustain indefinitely.", "[Variable] Let N(t) be the population size at time t.", "[Law] The logistic growth equation is dN/dt = rN(1 − N/K) with intrinsic rate r.", "[Constraint] For K > 0, dN/dt ≥ 0 when 0 ≤ N ≤ K.", "[Limit] lim_{t→∞} N(t) = K for any initial 0 < N(0) < K."]}, "accepted": "The logistic equation’s equilibrium at N = K is globally attracting for all positive sub-critical initial densities.  \nHYPOTHESIS: A population governed by the logistic growth law will always reach half of its carrying capacity, N = K/2, at the exact instant when its absolute growth rate dN/dt is maximal.  \nVERIFICATION: Differentiating dN/dt with respect to N gives the maximum at N = K/2, and units of dN/dt are population·time⁻¹.", "rejected": "The logistic equation’s equilibrium at N = K is globally attracting for all super-critical initial densities.", "E_acc": 0.16359588503837585, "C_acc": 0.4748277962207794, "G_acc": 0.5383855308464263, "D_acc": 0.8066649883985519, "H_acc": 0.138283371925354, "Q_acc": 0.5092949729238171, "E_rej": 0.05746633559465408, "C_rej": 0.10839013010263443, "G_rej": 0.5204875695926603, "D_rej": 0.7755971550941467, "H_rej": 0.22440284490585327, "Q_rej": 0.5323385351046455, "Delta_Q": -0.02304356218082837, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mutations alter DNA, yet many are neutral. Given evolution, consider what hypotheses follow about genetic robustness.", "ancestors": ["[Definition] A mutation is a heritable change in the DNA sequence.", "[Variable] Let μ denote the per-site mutation rate.", "[Constraint] The genetic code is degenerate, allowing multiple codons to specify the same amino acid.", "[Limit] Most possible single-nucleotide changes in coding DNA produce synonymous mutations.", "[Law] Neutral mutations have fitness effect s = 0.", "[Constraint] Constant μ and degeneracy together increase the fraction of mutations that are neutral."]}, "accepted": "Degeneracy of the genetic code and a constant per-site mutation rate μ together raise the fraction of neutral mutations above the value expected for a non-degenerate code.  \nHYPOTHESIS: The fraction of neutral mutations exceeds 1 – (1 – P_syn) · (1 – P_stop), where P_syn is the probability that a random single-nucleotide change is synonymous and P_stop is the probability it creates a premature stop codon.  \nVERIFICATION: Dimensionless probabilities yield a dimensionless fraction; equality holds if all non-synonymous/non-stop mutations are strongly selected, providing a lower bound.", "rejected": "The fraction of neutral mutations exceeds 1 – (1 – P_syn) · (1 – P_stop) even when epistatic interactions between sites make P_syn and P_stop context-dependent genome-wide averages.", "E_acc": 0.2673599123954773, "C_acc": 0.4975251853466034, "G_acc": 0.5406527174636722, "D_acc": 0.8268330792586008, "H_acc": 0.17278990149497986, "Q_acc": 0.5369211058442791, "E_rej": 0.14205609261989594, "C_rej": 0.3008006513118744, "G_rej": 0.5256844820687547, "D_rej": 0.7393566519021988, "H_rej": 0.2606433480978012, "Q_rej": 0.5094005895080045, "Delta_Q": 0.027520516336274614, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Carbon forms long chains, yet maintains four bonds. Given valence theory, consider what hypotheses can be justified about versatility.", "ancestors": ["[Definition] Valence electrons are the outer-shell electrons available for bonding.", "[Law] The octet rule states an atom is stable with eight valence electrons.", "[Variable] Z equals the atomic number of carbon, Z = 6.", "[Constraint] Carbon has four valence electrons, satisfying n = Z − 2 = 4.", "[Definition] A single covalent bond shares two electrons between two atoms.", "[Constraint] Carbon can form four single covalent bonds to complete its octet."]}, "accepted": "Carbon’s four valence electrons and its capacity to form four single covalent bonds jointly dictate that every additional bond partner supplies two electrons; hence the total electron count contributed by ligands must reach eight.\n\nHYPOTHESIS: A carbon atom achieves octet stability only if the sum of electrons shared through its single covalent bonds equals exactly eight.\n\nVERIFICATION: Units are electrons; regime is neutral carbon forming only single bonds; count 4 bonds × 2 e⁻/bond = 8 e⁻.", "rejected": "Carbon’s four valence electrons and its capacity to form four single covalent bonds dictate that any number of ligands may be chosen independently of the total electron count required to reach eight.", "E_acc": 0.5377498865127563, "C_acc": 0.22366338968276978, "G_acc": 0.5639824975015861, "D_acc": 0.8259687920411428, "H_acc": 0.15327800065279007, "Q_acc": 0.6792547458605397, "E_rej": 0.031127803027629852, "C_rej": 0.40935707092285156, "G_rej": 0.5628125630651734, "D_rej": 0.8571129441261292, "H_rej": 0.14288705587387085, "Q_rej": 0.4971633225745921, "Delta_Q": 0.18209142328594757, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Liquids flow, yet resist compression. Given intermolecular forces, consider what hypotheses can be justified about cohesion.", "ancestors": ["[Definition] Cohesion is the net attractive intermolecular force among like molecules within a liquid phase.", "[Variable] Let U(r) denote the pair potential energy between two molecules separated by distance r.", "[Law] U(r) reaches a minimum U_min at an equilibrium separation r_0 where attractive and repulsive components balance.", "[Constraint] In the liquid state, the average intermolecular spacing of molecules equals r_0.", "[Limit] Cohesion energy per molecule, E_coh, equals half the sum of U_min contributions from nearest neighbors.", "[Limit] E_coh sets the minimum energy barrier against volume compression of the liquid."]}, "accepted": "Because the liquid’s average spacing equals the potential minimum r₀, every molecule sits at the energy minimum U_min with its nearest neighbors; summing these pairwise minima and halving to avoid double-counting gives the cohesion energy per molecule, E_coh = ½ z U_min, where z is the nearest-neighbor count.  This E_coh is the energy barrier against uniform volume compression, so any external pressure P that would reduce the volume must supply at least PΔV ≥ N E_coh for N molecules.\n\nHYPOTHESIS: The minimum isothermal compression pressure required to overcome cohesion in a liquid with nearest-neighbor count z is P_min = ½ z U_min / v_mol, where v_mol is the molecular volume.\n\nVERIFICATION: Units check—[U_min] = J, [v_mol] = m³, so P_min has J m⁻³ = N m⁻² = Pa, consistent with pressure.", "rejected": "Because the liquid’s average spacing equals the potential minimum r₀, every molecule sits at the energy minimum U_min with its nearest neighbors; summing these pairwise minima and halving to avoid double-counting gives the cohesion energy per molecule, E_coh = ½ z U_min, where z is the nearest-neighbor count, and this E_coh equals the pressure P_min required for volume compression.", "E_acc": 0.43910425901412964, "C_acc": 0.29761630296707153, "G_acc": 0.5451808089273982, "D_acc": 0.78923624381423, "H_acc": 0.17547644674777985, "Q_acc": 0.6215437829843723, "E_rej": 0.3373048007488251, "C_rej": 0.3152965009212494, "G_rej": 0.5501229458022863, "D_rej": 0.8667124211788177, "H_rej": 0.13328757882118225, "Q_rej": 0.6081704555545003, "Delta_Q": 0.013373327429871962, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Neurons transmit electrical signals, yet communication is chemical at synapses. Given neurobiology, consider what hypotheses follow about signal integration.", "ancestors": ["[Definition] A postsynaptic neuron sums input currents from synapses.", "[Variable] Let w denote the synaptic weight of an input.", "[Variable] Let I denote the current contributed by one synapse, so I = w·V with V presynaptic voltage.", "[Law] The net somatic current I_net is the linear algebraic sum of all individual I.", "[Limit] A neuron fires only when I_net crosses the fixed spike threshold T."]}, "accepted": "Summing the linear input currents I = w·V and requiring the total to reach the fixed threshold T yields a direct algebraic condition on the weights.  \nHYPOTHESIS: A neuron fires if and only if the algebraic sum of its synaptic weights multiplied by their respective presynaptic voltages equals or exceeds the spike threshold, ΣwᵢVᵢ ≥ T.  \nVERIFICATION: Both sides carry units of current (A), and the inequality holds whenever the summed somatic current reaches the fixed threshold.", "rejected": "A neuron fires if and only if the algebraic sum of its independent synaptic weights multiplied by their respective presynaptic voltages equals or exceeds the spike threshold, ΣwᵢVᵢ ≥ T.", "E_acc": 0.28952160477638245, "C_acc": 0.37248554825782776, "G_acc": 0.5283329595944711, "D_acc": 0.7644209116697311, "H_acc": 0.1447054147720337, "Q_acc": 0.5564396045569863, "E_rej": 0.5074454545974731, "C_rej": 0.24144473671913147, "G_rej": 0.5433402433991432, "D_rej": 0.8395123481750488, "H_rej": 0.16048765182495117, "Q_rej": 0.664466442167759, "Delta_Q": -0.1080268376107727, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Photosynthesis stores energy, yet depends on light availability. Given plant biology, consider what hypotheses can be justified about energy flow.", "ancestors": ["[Definition] P is the chemical energy stored in carbohydrate bonds produced by photosynthesis.", "[Variable] I is the instantaneous photosynthetic photon flux density incident on a leaf surface.", "[Law] P is proportional to I under light-limiting conditions with constant quantum yield φ.", "[Constraint] φ cannot exceed 1 mol fixed carbon per 8 mol absorbed photons due to electron transport stoichiometry.", "[Limit] P saturates at Pmax when I reaches Isat and all available reaction centers are photochemically engaged."]}, "accepted": "The premises link photon flux I to carbohydrate energy P via a proportional light-limited regime and impose both a quantum-yield ceiling and a saturating ceiling Pmax. Combining the proportionality P = φI with the stoichiometric cap φ ≤ 1/8 and the saturation condition P ≤ Pmax yields a single crossover intensity Isat = Pmax/φmin where the yield limit intersects the capacity limit.\n\nHYPOTHESIS: The leaf-level carbohydrate energy production P equals φI for I ≤ 8Pmax and clamps to Pmax for I > 8Pmax.\n\nVERIFICATION: Units check—φI has mol C m⁻² s⁻¹, matching P; 8Pmax/φmin gives the same photon flux units as I.", "rejected": "The leaf-level carbohydrate energy production P equals φI for all values of I, even after the reaction centers are fully engaged.", "E_acc": 0.5296984910964966, "C_acc": 0.2412785291671753, "G_acc": 0.5163929770642426, "D_acc": 0.7347741164267063, "H_acc": 0.1971520185470581, "Q_acc": 0.6411720583389978, "E_rej": 0.3480692505836487, "C_rej": 0.34036651253700256, "G_rej": 0.5153454005485401, "D_rej": 0.7878531515598297, "H_rej": 0.2121468484401703, "Q_rej": 0.575772498245351, "Delta_Q": 0.06539956009364678, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Waves transfer energy without mass transport, yet the medium oscillates. Given wave mechanics, consider what hypotheses follow about local versus global motion.", "ancestors": ["[Definition] A wave is a propagating disturbance in which energy E transfers through a medium without net transport of mass.", "[Variable] The local displacement of a medium particle is y(x,t), a function of position x and time t.", "[Law] For a sinusoidal wave y(x,t)=A sin(kx−ωt), the particle velocity is v_p=∂y/∂t=−Aω cos(kx−ωt).", "[Constraint] The maximum particle speed satisfies v_{p,max}=Aω, independent of any wave speed v."]}, "accepted": "Using the given sinusoidal form, the maximum particle speed is v_{p,max}=Aω.  Because the wave transmits energy without mass transport, the particle displacement must remain bounded, so Aω must be finite; hence for any real wave the product of amplitude and angular frequency has an upper bound set by the medium’s yield criteria.\n\nHYPOTHESIS: A propagating sinusoidal wave in a medium obeys Aω ≤ v_{crit}, where v_{crit} is the maximum particle speed the medium can sustain without structural failure.\n\nVERIFICATION: Both A (length) and ω (time⁻¹) yield speed (length/time), matching the units of v_{crit}.", "rejected": "A propagating sinusoidal wave in a medium obeys A + ω = v_{crit}, where v_{crit} is the maximum particle speed the medium can sustain without structural failure.", "E_acc": 0.39790913462638855, "C_acc": 0.2583366334438324, "G_acc": 0.5549634693888947, "D_acc": 0.7756598889827728, "H_acc": 0.2518528550863266, "Q_acc": 0.608644799864851, "E_rej": 0.4520799219608307, "C_rej": 0.25057753920555115, "G_rej": 0.5770232687937096, "D_rej": 0.8456109762191772, "H_rej": 0.15438902378082275, "Q_rej": 0.6545964153716342, "Delta_Q": -0.04595161550678317, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Isotopes share chemical properties, yet differ in mass. Given nuclear composition, consider what hypotheses can be justified about atomic identity.", "ancestors": ["[Definition] Isotopes of an element have identical proton numbers, Z.", "[Definition] The mass number, A, is the sum of protons, Z, and neutrons, N, in a nucleus.", "[Variable] For a fixed Z, A may vary by differing N.", "[Constraint] Atomic identity is fixed by the value of Z alone."]}, "accepted": "Isotopes of a fixed element share the same proton count Z, so any mass-number difference ΔA arises solely from a neutron difference ΔN.  Because A = Z + N, subtracting the isotopic relation gives ΔA = ΔN.\n\nHYPOTHESIS: For any two isotopes of the same element, the difference in mass numbers equals the difference in neutron numbers: ΔA = ΔN.\n\nVERIFICATION: Both ΔA and ΔN are dimensionless counts, and the equation holds for every isotope pair of a given element.", "rejected": "For any two nuclei with the same mass number A, the difference in proton numbers equals the difference in neutron numbers: ΔZ = ΔN.", "E_acc": 0.268882691860199, "C_acc": 0.41697633266448975, "G_acc": 0.5643728138612849, "D_acc": 0.8157656937837601, "H_acc": 0.13431009650230408, "Q_acc": 0.5598662329039403, "E_rej": 0.08778692781925201, "C_rej": 0.7802523970603943, "G_rej": 0.5806378129470561, "D_rej": 0.8689155578613281, "H_rej": 0.13108444213867188, "Q_rej": 0.44708782888150644, "Delta_Q": 0.11277840402243389, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase changes occur at fixed temperatures, yet energy continues to flow. Given thermodynamics, consider what hypotheses can be justified about latent heat.", "ancestors": ["[Definition] Latent heat L is energy absorbed or released per unit mass during an isothermal phase change.", "[Variable] Let m denote mass of the substance.", "[Variable] Let Q be the total heat exchanged during the phase change.", "[Law] Q = mL exactly during the fixed-temperature transition."]}, "accepted": "Using the definition of latent heat and the law Q = mL, we derive that for any isothermal phase change, the ratio of total heat exchanged to mass equals the substance’s latent heat.  \nHYPOTHESIS: During an isothermal phase change, the specific latent heat L equals Q/m.  \nVERIFICATION: Units check: [Q]/[m] = J kg⁻¹, matching L’s definition.", "rejected": "During an isothermal phase change, the ratio Q/m equals the specific latent heat L because the substance’s latent heat determines the total heat exchanged per unit mass.", "E_acc": 0.20795224606990814, "C_acc": 0.33131706714630127, "G_acc": 0.5582648880469302, "D_acc": 0.8179379055897394, "H_acc": 0.0827065110206604, "Q_acc": 0.5630921680169801, "E_rej": 0.34455135464668274, "C_rej": 0.3632081151008606, "G_rej": 0.5319353481754661, "D_rej": 0.8860450685024261, "H_rej": 0.11395493149757385, "Q_rej": 0.6029243735596537, "Delta_Q": -0.03983220554267353, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exothermic reactions release heat, yet products are more stable. Given energy diagrams, consider what hypotheses can be justified about bond energies.", "ancestors": ["[Definition] Reaction enthalpy ΔH equals the energy of products minus the energy of reactants.", "[Definition] Bond enthalpy is the energy required to break one mole of a specific bond in the gas phase.", "[Law] In exothermic reactions ΔH < 0.", "[Constraint] In exothermic reactions the energy of products is below the energy of reactants.", "[Law] The net bond enthalpy difference favors product bonds over reactant bonds."]}, "accepted": "Using the enthalpy definition and the exothermic constraint, the bond enthalpy law implies that the summed bond enthalpies of the products exceed those of the reactants by an amount that equals the negative of the reaction enthalpy.\n\nHYPOTHESIS: The total bond enthalpy of the products exceeds that of the reactants by exactly |ΔH| in any exothermic reaction.\n\nVERIFICATION: Units (kJ mol⁻¹) match on both sides; equation holds for gas-phase reactions where bond enthalpies are defined.", "rejected": "The total bond enthalpy of the products exceeds that of the reactants by exactly |ΔH| independent of the reaction enthalpy.", "E_acc": 0.21540315449237823, "C_acc": 0.28546443581581116, "G_acc": 0.574437180334436, "D_acc": 0.8336279988288879, "H_acc": 0.14577138423919678, "Q_acc": 0.5745639565932964, "E_rej": 0.03329969197511673, "C_rej": 0.8811754584312439, "G_rej": 0.5703047039652509, "D_rej": 0.8247096538543701, "H_rej": 0.17529034614562988, "Q_rej": 0.3952286528556475, "Delta_Q": 0.1793353037376489, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymes lower activation energy, yet do not change equilibrium. Given catalysis, consider what hypotheses can be justified about reaction control.", "ancestors": ["[Definition] The activation energy Ea is the minimum energy input required for reactants to reach the transition state.", "[Law] The rate constant k equals A e^(–Ea/RT) where A is the pre-exponential factor, R is the gas constant, and T is absolute temperature.", "[Variable] A catalyst, denoted C, provides an alternative reaction pathway with a lower activation energy Ea'.", "[Constraint] The equilibrium constant K depends only on standard Gibbs energy change ΔG° and is independent of any catalyst C."]}, "accepted": "The Arrhenius law shows that the rate constant k increases exponentially as the activation energy Ea decreases, and a catalyst C provides a new pathway with a lower Ea′. Because the equilibrium constant K is fixed for a given reaction, the catalyst must accelerate the forward and reverse rates equally; hence the ratio of the catalysed to uncatalysed rate constants equals the ratio of their pre-exponential factors multiplied by the Boltzmann factor containing the difference in activation energies.\n\nHYPOTHESIS: For any catalyst C, the ratio of catalysed to uncatalysed rate constants is k_catalysed / k_uncatalysed = (A′/A) e^{(Ea – Ea′)/RT}.\n\nVERIFICATION: The exponent is dimensionless and the ratio is unity when Ea = Ea′ and A′ = A, recovering the uncatalysed limit.", "rejected": "The Arrhenius law shows that the rate constant k increases exponentially as the activation energy Ea decreases, and a catalyst C provides a new pathway with a lower Ea′; because the equilibrium constant K is fixed for a given reaction, the catalysed and uncatalysed rate constants are equal when the pre-exponential factors and activation energies match, implying the catalyst accelerates the forward and reverse rates unequally.", "E_acc": 0.20570838451385498, "C_acc": 0.42140913009643555, "G_acc": 0.5382738236548903, "D_acc": 0.8181255124509335, "H_acc": 0.18664810806512833, "Q_acc": 0.5300457457495213, "E_rej": 0.11754226684570312, "C_rej": 0.42523467540740967, "G_rej": 0.5524231381714344, "D_rej": 0.8680353164672852, "H_rej": 0.13196468353271484, "Q_rej": 0.5211109675467015, "Delta_Q": 0.008934778202819849, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Work transfers energy, yet identical work can result in different motions. Given work–energy relations, consider what hypotheses can be justified about energy partitioning.", "ancestors": ["[Definition] Work W is the line integral of force F along path s.", "[Law] The work–energy theorem states W = ΔK for kinetic energy K.", "[Variable] Let E denote the total mechanical energy E = K + U with potential U.", "[Constraint] W adds to E only when non-conservative forces act; conservative forces swap K and U.", "[Limit] Identical W does not constrain the ratio ΔK/ΔU because the path determines U(s)."]}, "accepted": "The work–energy theorem equates the line-integral work W to the kinetic change ΔK, while the mechanical energy E = K + U is altered by W only when non-conservative forces act; conservative forces merely reshuffle K and U leaving E fixed.  Hence, for any process in which W is delivered solely by conservative forces, the total mechanical energy remains unchanged, so the work appears as an exact exchange between kinetic and potential forms.\n\nHYPOTHESIS: If W is performed exclusively by conservative forces, then ΔK + ΔU = 0 and E remains constant.\n\nVERIFICATION: Energy units [kg·m²/s²] balance in ΔK + ΔU = 0; holds for all closed systems with only conservative forces.", "rejected": "If E remains constant, then W is performed exclusively by conservative forces.", "E_acc": 0.3576062321662903, "C_acc": 0.3827490210533142, "G_acc": 0.504780534101883, "D_acc": 0.8283542133867741, "H_acc": 0.1811116486787796, "Q_acc": 0.5792478500690778, "E_rej": 0.09488635510206223, "C_rej": 0.5799106955528259, "G_rej": 0.5191053939634003, "D_rej": 0.7786878943443298, "H_rej": 0.2766401320695877, "Q_rej": 0.4443784118746408, "Delta_Q": 0.13486943819443697, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Interference produces stable patterns, yet individual waves remain unchanged. Given superposition, consider what hypotheses can be justified about linearity.", "ancestors": ["[Definition] Superposition is the vector addition of instantaneous wave amplitudes at each point in space and time.", "[Law] Linearity guarantees that the sum of any two valid wave solutions is itself a valid wave solution.", "[Variable] Let k denote the proportionality constant between input amplitude and output amplitude in a linear medium.", "[Constraint] k must be independent of wave amplitude for the medium to remain linear."]}, "accepted": "Because linearity requires the proportionality constant k to be amplitude-independent, any deviation from strict proportionality marks the onset of nonlinearity.  \nHYPOTHESIS: A medium remains linear only while the output amplitude equals k times the input amplitude to within a relative deviation of 1%.  \nVERIFICATION: Dimensionless ratio; criterion tested by comparing measured output/input amplitude with the constant k.", "rejected": "A medium remains linear only while the output amplitude equals k times the input amplitude to within an absolute deviation of 1 m⁻¹.", "E_acc": 0.20478637516498566, "C_acc": 0.5561473369598389, "G_acc": 0.5594203298678622, "D_acc": 0.7162448018789291, "H_acc": 0.25125153362751007, "Q_acc": 0.4802143181441352, "E_rej": 0.3051302134990692, "C_rej": 0.35551393032073975, "G_rej": 0.5700300824828446, "D_rej": 0.7442494630813599, "H_rej": 0.25575053691864014, "Q_rej": 0.5577171334065497, "Delta_Q": -0.07750281526241454, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrons occupy quantized energy levels, yet transitions appear continuous in spectra. Given quantum chemistry, consider what hypotheses follow about emission.", "ancestors": ["[Definition] An electron occupies a discrete orbital with a quantized energy Eₙ.", "[Definition] A photon carries energy E = hν where h is Planck’s constant and ν is frequency.", "[Law] Transition energy equals the difference between two quantized levels: ΔE = Eₘ - Eₙ.", "[Variable] ΔE is the unique photon energy emitted during an electron transition.", "[Constraint] Spectral lines have a natural linewidth γ caused by the finite lifetime τ of the upper state via γ = ħ/τ.", "[Limit] Instrumental resolution δν obscures the discrete linewidth γ, making the spectrum appear continuous."]}, "accepted": "The premises link the natural linewidth γ of a spectral line to the lifetime τ of the upper state and note that instrumental resolution δν can mask this discreteness. For the line to remain resolvably discrete, the instrument must not blur it into a continuum. Requiring the observed width to exceed the instrumental spread gives the minimal condition δν < ħ/τ.\n\nHYPOTHESIS: A spectral line is resolvably discrete only if the instrumental resolution satisfies δν < ħ/τ.\n\nVERIFICATION: Both sides have units of frequency (s⁻¹), and the inequality holds in the regime where the natural width is larger than the instrumental broadening.", "rejected": "A spectral line is resolvably discrete only if the instrumental resolution satisfies δν < ħτ.", "E_acc": 0.8005470037460327, "C_acc": 0.032107286155223846, "G_acc": 0.5561332821962424, "D_acc": 0.7273464232683182, "H_acc": 0.2970582991838455, "Q_acc": 0.7607327550672925, "E_rej": 0.18168561160564423, "C_rej": 0.49515587091445923, "G_rej": 0.5399365138728172, "D_rej": 0.754635363817215, "H_rej": 0.24536463618278503, "Q_rej": 0.4898524212185293, "Delta_Q": 0.27088033384876326, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase changes occur at fixed temperatures, yet energy continues to flow. Given thermodynamics, consider what hypotheses can be justified about latent heat.", "ancestors": ["[Law] During a first-order phase change, the temperature T of a pure substance remains constant while the two phases coexist.", "[Variable] Let L denote the latent heat of the phase change, the specific energy required to convert the substance between the two phases at the fixed T.", "[Definition] L is defined by the energy Q exchanged per unit mass m, so L = Q/m.", "[Constraint] Energy conservation requires Q to equal the difference between the final and initial internal energies of the substance.", "[Limit] L≠0 because the internal energy of the substance differs between the two phases even though T is identical for both."]}, "accepted": "Because the latent heat L is finite and non-zero while the temperature remains fixed during coexistence, the internal-energy difference between the phases must be supplied or removed entirely as the exchanged energy Q.  Energy conservation therefore links the mass m that changes phase to the total energy exchanged: Q = mL.\n\nHYPOTHESIS: The mass m of a pure substance that undergoes a complete first-order phase change at constant temperature is directly proportional to the total energy Q exchanged, with the proportionality constant 1/L.\n\nVERIFICATION: Units check—Q in J, m in kg, L in J kg⁻¹ gives m = Q/L dimensionally consistent.", "rejected": "During a first-order phase change, the mass m that changes phase is inversely proportional to the temperature T, even while T is held constant.", "E_acc": 0.4032655358314514, "C_acc": 0.2352725714445114, "G_acc": 0.5172361297300085, "D_acc": 0.7741747945547104, "H_acc": 0.12942861765623093, "Q_acc": 0.6192644695518538, "E_rej": 0.4988716244697571, "C_rej": 0.257198691368103, "G_rej": 0.5189484617148992, "D_rej": 0.8663807511329651, "H_rej": 0.1336192488670349, "Q_rej": 0.6619256667501758, "Delta_Q": -0.042661197198322065, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Translation reads codons, yet errors are rare. Given molecular machinery, consider what hypotheses can be justified about redundancy.", "ancestors": ["[Definition] A codon is a three-nucleotide mRNA sequence.", "[Definition] A tRNA carries one amino acid and one anticodon triplet.", "[Variable] A_i represents the set of tRNAs that can pair with codon i.", "[Constraint] Wobble base-pairing lets one non-Watson-Crick anticodon position bind to multiple codons.", "[Constraint] Synonymous codons have tRNA sets with overlap in A_i.", "[Limit] Overlap sets an upper bound on the number of distinct tRNAs required to read all codons."]}, "accepted": "By treating each codon as a vertex and each tRNA as a hyper-edge that covers the codons it can read, the overlap constraint implies that the hypergraph has a bounded covering number.  The wobble rule enlarges every hyper-edge, so the minimum number of tRNAs needed to cover all 64 codons is strictly less than 64.\n\nHYPOTHESIS: The size of the smallest tRNA set that can read every codon is at most 46.\n\nVERIFICATION: Dimensional check—pure count, consistent with sequenced bacterial genomes that encode 30–46 tRNA species.", "rejected": "By treating each codon as a vertex and each tRNA as a hyper-edge that covers the codons it can read, the overlap constraint implies that the hypergraph has a bounded covering number, and the same bound applies to the minimum number of aminoacyl-tRNA synthetases required to charge all tRNAs.", "E_acc": 0.19034700095653534, "C_acc": 0.47609633207321167, "G_acc": 0.5871639578836039, "D_acc": 0.7691074497997761, "H_acc": 0.20567560195922852, "Q_acc": 0.5125715552130714, "E_rej": 0.3270835280418396, "C_rej": 0.07899830490350723, "G_rej": 0.5837128236889839, "D_rej": 0.8091303408145905, "H_rej": 0.19086965918540955, "Q_rej": 0.6418070644140244, "Delta_Q": -0.12923550920095295, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric charges exert forces, yet stationary charges do no work. Given electrostatics, consider what hypotheses follow about electric potential.", "ancestors": ["[Definition] Electric potential V at a point is the work W per unit charge q∞ done to bring a vanishingly small test charge q∞ from infinity to that point.", "[Variable] W is the work done by an external agent against the electrostatic force.", "[Constraint] For stationary charges, the electrostatic force is conservative.", "[Law] In a conservative field, work W depends only on endpoints, not path.", "[Limit] Because W is path-independent, the closed-loop integral ∮dV = 0."]}, "accepted": "Because the electrostatic field is conservative, the work W to move any test charge between two points equals the charge times the potential difference, W = q∞(Vb – Va).  Setting the start and end points identical gives Va = Vb, so W must vanish for any closed loop.\n\nHYPOTHESIS: The work done by an external agent to transport a test charge around any closed path in a static electric field is exactly zero.\n\nVERIFICATION: Units check: q∞(Vb – Va) has units C·V = J, matching work; result holds for all electrostatic regimes.", "rejected": "Because the electrostatic field is conservative, the work W to move any test charge between two points is independent of the potential difference.", "E_acc": 0.16190537810325623, "C_acc": 0.6679564714431763, "G_acc": 0.5198485485743731, "D_acc": 0.7746918648481369, "H_acc": 0.20543742924928665, "Q_acc": 0.453344658901915, "E_rej": 0.5693206191062927, "C_rej": 0.1368449479341507, "G_rej": 0.5121688839280978, "D_rej": 0.8287858366966248, "H_rej": 0.17121416330337524, "Q_rej": 0.6944967239396647, "Delta_Q": -0.24115206503774966, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "The frequency of a wave remains constant across media, yet speed and wavelength change. Given wave propagation, consider what hypotheses can be justified about medium dependence.", "ancestors": ["[Definition] Wave frequency f is the number of crests passing a fixed point per unit time.", "[Variable] Let v denote the wave speed in a homogeneous linear medium.", "[Law] The relation v = f λ holds with λ the spatial wavelength.", "[Constraint] f is fixed at the boundary between two media, forcing v and λ to adjust jointly."]}, "accepted": "Because the frequency f is fixed at the interface while the wave speed v changes from medium 1 to medium 2, the wavelength λ must scale in direct proportion to v.  \nHYPOTHESIS: When a wave crosses into a medium where its speed is higher, its wavelength increases by the same factor as the speed increase.  \nVERIFICATION: λ₂/λ₁ = v₂/v₁ with [m s⁻¹]/[m s⁻¹] dimensionless, valid for any homogeneous linear media.", "rejected": "Because the frequency f is fixed at the interface while the wavelength λ changes from medium 1 to medium 2, the wave speed v must scale in direct proportion to λ.", "E_acc": 0.3361244797706604, "C_acc": 0.3170919120311737, "G_acc": 0.5446918592788279, "D_acc": 0.7431103338797888, "H_acc": 0.22138860076665878, "Q_acc": 0.5728405400800208, "E_rej": 0.4177255928516388, "C_rej": 0.24378810822963715, "G_rej": 0.5362774607783649, "D_rej": 0.8048820197582245, "H_rej": 0.2438974753022194, "Q_rej": 0.6204022047866602, "Delta_Q": -0.04756166470663936, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Proteins fold into precise shapes, yet small changes disrupt function. Given biochemistry, consider what hypotheses follow about structure–function relations.", "ancestors": ["[Definition] A protein’s primary sequence is its linear order of amino acids.", "[Law] The free-energy difference ΔG between folded and unfolded states equals ΔH – TΔS.", "[Variable] ΔG = G_folded – G_unfolded.", "[Constraint] Folding is spontaneous only if ΔG < 0.", "[Limit] A single mutation can alter ΔG by changing ΔH or ΔS.", "[Constraint] If ΔG becomes positive the native fold is no longer the minimal-energy state."]}, "accepted": "Because ΔG = ΔH – TΔS and folding is spontaneous only when ΔG < 0, the native fold remains the minimal-energy state only while ΔH – TΔS stays negative; a single mutation that raises ΔH or lowers ΔS can flip the sign.  \nHYPOTHESIS: A single mutation that increases ΔH by more than TΔS or decreases ΔS by more than ΔH/T destabilises the native fold.  \nVERIFICATION: Units consistent (ΔH in J mol⁻¹, TΔS in J mol⁻¹, ratio dimensionless).", "rejected": "A single mutation that destabilises the native fold therefore increases ΔH by more than TΔS or decreases ΔS by more than ΔH/T.", "E_acc": 0.778063952922821, "C_acc": 0.06254003942012787, "G_acc": 0.5687132885213941, "D_acc": 0.7460322231054306, "H_acc": 0.18282172083854675, "Q_acc": 0.765578108234331, "E_rej": 0.22748762369155884, "C_rej": 0.03535684570670128, "G_rej": 0.5586187415174209, "D_rej": 0.7678855657577515, "H_rej": 0.23211443424224854, "Q_rej": 0.603264335996937, "Delta_Q": 0.16231377223739407, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "The frequency of a wave remains constant across media, yet speed and wavelength change. Given wave propagation, consider what hypotheses can be justified about medium dependence.", "ancestors": ["[Variable] f denotes frequency.", "[Variable] λ denotes wavelength.", "[Variable] v denotes wave speed.", "[Law] v = f λ.", "[Constraint] f is constant across media.", "[Constraint] λ is proportional to v when f is constant."]}, "accepted": "Because f is fixed across media and v = f λ, any observed change in wavelength directly mirrors the change in wave speed.  \nHYPOTHESIS: When a wave enters a medium where its speed is lower, its wavelength decreases by the same fractional amount.  \nVERIFICATION: Units check: [v] = m s⁻¹, [f] = s⁻¹, [λ] = m, so v/f yields m.", "rejected": "Because f is fixed across media and v = f λ, any observed change in wave speed directly mirrors the change in wavelength.", "E_acc": 0.2068542242050171, "C_acc": 0.41773831844329834, "G_acc": 0.5457557316869497, "D_acc": 0.7471585621436437, "H_acc": 0.17710652947425842, "Q_acc": 0.5193808093915383, "E_rej": 0.3539605140686035, "C_rej": 0.3529411256313324, "G_rej": 0.5129031956195831, "D_rej": 0.8270276486873627, "H_rej": 0.17297235131263733, "Q_rej": 0.58628886282444, "Delta_Q": -0.06690805343290174, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcription produces RNA, yet DNA remains unchanged. Given gene expression, consider what hypotheses follow about information flow.", "ancestors": ["[Definition] Transcription is enzyme-catalyzed synthesis of RNA from a DNA template strand.", "[Law] Gene expression is proportional to the steady-state concentration of the corresponding messenger RNA.", "[Variable] Let k_tx denote the transcription rate of a gene in RNA molecules per unit time.", "[Constraint] During transcription, the DNA template strand remains chemically unaltered."]}, "accepted": "The transcription rate k_tx directly governs the instantaneous production of RNA molecules from a gene. Because gene expression is proportional to the steady-state mRNA concentration, any sustained change in k_tx must translate into a proportional change in that concentration.\n\nHYPOTHESIS: A twofold increase in k_tx produces a twofold increase in steady-state mRNA concentration, provided that mRNA degradation rate remains constant.\n\nVERIFICATION: Units balance (RNA/time × time = RNA), valid when degradation is first-order and unchanged.", "rejected": "A twofold increase in k_tx increases the steady-state mRNA concentration by adding 2·k_tx RNA molecules to the existing pool.", "E_acc": 0.18904456496238708, "C_acc": 0.48085325956344604, "G_acc": 0.5934230168350041, "D_acc": 0.7996558398008347, "H_acc": 0.22164072841405869, "Q_acc": 0.5169944160617888, "E_rej": 0.5232224464416504, "C_rej": 0.14866463840007782, "G_rej": 0.5877685505547561, "D_rej": 0.7435615956783295, "H_rej": 0.25643840432167053, "Q_rej": 0.6678559950669296, "Delta_Q": -0.15086157900514086, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "pH measures acidity logarithmically, yet equal changes do not represent equal effects. Given logarithmic scales, consider what hypotheses can be justified about perception.", "ancestors": ["[Definition] pH = –log[H⁺] measures acidity logarithmically.", "[Variable] ΔpH = pH₂ – pH₁ quantifies a change.", "[Law] A ΔpH of 1 corresponds to a tenfold change in [H⁺].", "[Limit] Equal ΔpH does not imply equal chemical or biological effect."]}, "accepted": "Using the logarithmic definition of pH and the tenfold rule for hydrogen-ion concentration, a change of 0.30 pH units corresponds to a doubling or halving of [H⁺].\n\nHYPOTHESIS: A ΔpH of 0.30 indicates a two-fold change in hydrogen-ion concentration.\n\nVERIFICATION: 10^(0.30) ≈ 2.0, consistent with the tenfold-per-unit-pH law.", "rejected": "A doubling of [H⁺] corresponds to a ΔpH of 0.30.", "E_acc": 0.292900413274765, "C_acc": 0.5285939574241638, "G_acc": 0.5754698996121684, "D_acc": 0.8187493085861206, "H_acc": 0.12822896242141724, "Q_acc": 0.5481722778951128, "E_rej": 0.4580390751361847, "C_rej": 0.2509414553642273, "G_rej": 0.5648554492120942, "D_rej": 0.7516405582427979, "H_rej": 0.24835944175720215, "Q_rej": 0.625686688783268, "Delta_Q": -0.07751441088815525, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy flows through ecosystems, yet matter cycles. Given ecology, consider what hypotheses follow about trophic levels.", "ancestors": ["[Definition] Trophic level L is an integer rank assigned to organisms based on how many transfers of organic matter separate them from primary production.", "[Law] At each transfer from L to L+1, only a fraction e < 1 of ingested chemical energy becomes heterotrophic biomass energy.", "[Variable] e denotes energetic transfer efficiency between successive trophic levels.", "[Constraint] Energy must be conserved, so usable energy entering level L equals e times the usable energy that left level L-1.", "[Limit] Because e < 1, cumulative energy E(L) decreases exponentially with L and reaches zero at finite L."]}, "accepted": "Because usable energy at level L is e times that at L-1 and e < 1, the cumulative energy E(L) forms a strictly decreasing geometric sequence; the sum over all L converges to a finite total.  \nHYPOTHESIS: The aggregate trophic energy content of the entire food chain is bounded above by E₀/(1–e), where E₀ is the usable energy exiting primary production.  \nVERIFICATION: Units of energy on both sides; bound holds for any e < 1.", "rejected": "The aggregate trophic energy content of the entire food chain equals E₀/(1–e), where E₀ is the usable energy exiting primary production and e is a dimensionless fraction.", "E_acc": 0.3751297891139984, "C_acc": 0.2770034074783325, "G_acc": 0.5909123620949686, "D_acc": 0.7495700816313425, "H_acc": 0.1639125645160675, "Q_acc": 0.6088434875321884, "E_rej": 0.2122192531824112, "C_rej": 0.3571375012397766, "G_rej": 0.5894943655002862, "D_rej": 0.8297594785690308, "H_rej": 0.17024052143096924, "Q_rej": 0.5590649923775346, "Delta_Q": 0.04977849515465382, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "pH measures acidity logarithmically, yet equal changes do not represent equal effects. Given logarithmic scales, consider what hypotheses can be justified about perception.", "ancestors": ["[Definition] pH is the negative base-10 logarithm of the hydronium ion activity.", "[Variable] ΔpH = pH_final − pH_initial.", "[Definition] A logarithmic scale assigns equal space to equal ratios of the underlying quantity.", "[Constraint] On a logarithmic scale, equal intervals of the index (ΔpH) correspond to multiplicative changes of the activity.", "[Limit] The perceptual or biological response to a fixed ΔpH is not required to equal the response to the same activity ratio at another region of the scale."]}, "accepted": "Because pH is a logarithmic index of hydronium activity, a change ΔpH = −1 corresponds to a ten-fold increase in activity.  \nHYPOTHESIS: A decrease of 1.0 in pH (ΔpH = −1) multiplies the hydronium ion activity by exactly 10.  \nVERIFICATION: Dimensionless ratio; valid for any aqueous system obeying the pH definition.", "rejected": "Because pH is a logarithmic index of hydronium activity, a change ΔpH = −1 corresponds to a hundred-fold increase in activity.", "E_acc": 0.41940686106681824, "C_acc": 0.31212812662124634, "G_acc": 0.6120294248685241, "D_acc": 0.8412215312321981, "H_acc": 0.10215923190116882, "Q_acc": 0.6438307010258237, "E_rej": 0.045384809374809265, "C_rej": 0.5536060929298401, "G_rej": 0.6091055565048009, "D_rej": 0.8951104581356049, "H_rej": 0.10488954186439514, "Q_rej": 0.49324847296811647, "Delta_Q": 0.15058222805770727, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Acceleration depends on net force and mass, yet mass itself can change in systems like rockets. Given dynamics, consider what hypotheses follow about variable-mass systems.", "ancestors": ["[Definition] The mass of an object is a scalar quantity denoted m.", "[Definition] The net force vector on an object is denoted F.", "[Law] Newton’s second law states F = m a, with a as the acceleration vector.", "[Variable] Mass m varies with time t when total internal energy changes."]}, "accepted": "Because Newton’s second law links force, mass and acceleration, and the premises state that mass can vary with time, the law must be applied to an instantaneous snapshot rather than assumed constant.\n\nHYPOTHESIS: For any object whose internal energy changes with time, the instantaneous acceleration satisfies a(t)=F(t)/m(t).\n\nVERIFICATION: Units check: N kg⁻¹ = m s⁻², valid at every instant.", "rejected": "For any object whose internal energy changes with time, the instantaneous acceleration satisfies a(t)=F/m independently of how m(t) varies.", "E_acc": 0.24798986315727234, "C_acc": 0.40241289138793945, "G_acc": 0.5837921981389324, "D_acc": 0.6954407046238581, "H_acc": 0.29701799154281616, "Q_acc": 0.5200591620678703, "E_rej": 0.31891322135925293, "C_rej": 0.392020046710968, "G_rej": 0.5845962955305973, "D_rej": 0.7294441014528275, "H_rej": 0.27055589854717255, "Q_rej": 0.55302244660755, "Delta_Q": -0.03296328453967967, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymes lower activation energy, yet do not change equilibrium. Given catalysis, consider what hypotheses can be justified about reaction control.", "ancestors": ["[Definition] Activation energy E<sub>a</sub> is the minimum energy input required for a chemical reaction to proceed from reactants to the transition state.", "[Law] The Arrhenius law states the rate constant k = A e<sup>–E<sub>a</sub>/RT</sup>, where A is the frequency factor, R the gas constant, and T the temperature.", "[Constraint] An enzyme catalyst reduces E<sub>a</sub> without altering the standard Gibbs free-energy change ΔG° or the equilibrium constant K.", "[Limit] At fixed T, the ratio k<sub>catalyzed</sub>/k<sub>uncatalyzed</sub> depends only on the difference ΔE<sub>a</sub> introduced by the enzyme, since K must remain unchanged."]}, "accepted": "The Arrhenius law shows that at constant temperature the rate constant depends exponentially on activation energy, while the constraint that the equilibrium constant remains fixed requires the ratio of forward to reverse rate constants to stay the same for catalyzed and uncatalyzed paths.  \nHYPOTHESIS: For any enzyme-catalyzed reaction at fixed temperature, the catalytic rate acceleration k<sub>catalyzed</sub>/k<sub>uncatalyzed</sub> equals exp(ΔE<sub>a</sub>/RT), where ΔE<sub>a</sub> is the enzyme-induced reduction in activation energy.  \nVERIFICATION: Dimensionless ratio on both sides; valid for all T where Arrhenius behavior holds and K is unchanged.", "rejected": "For any enzyme-catalyzed reaction at fixed temperature, the enzyme-induced reduction in activation energy ΔE<sub>a</sub> equals RT ln(k<sub>catalyzed</sub>/k<sub>uncatalyzed</sub>).", "E_acc": 0.2553541958332062, "C_acc": 0.4973496198654175, "G_acc": 0.5399495151941665, "D_acc": 0.813141405582428, "H_acc": 0.08016729354858398, "Q_acc": 0.539737789577339, "E_rej": 0.39458146691322327, "C_rej": 0.299491286277771, "G_rej": 0.545650783169549, "D_rej": 0.8757630288600922, "H_rej": 0.12423697113990784, "Q_rej": 0.6303352481103502, "Delta_Q": -0.09059745853301127, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy is quantized at small scales, yet appears continuous macroscopically. Given quantum theory, consider what hypotheses follow about scale dependence.", "ancestors": ["[Definition] A quantum state has discrete energy levels separated by Planck-scale gaps.", "[Variable] N is the number of quanta in a system.", "[Limit] The classical limit arises when N → ∞.", "[Constraint] Observable continuity requires ΔE/E → 0 as N grows."]}, "accepted": "In the classical limit N→∞ the discrete quantum spectrum must become observationally continuous, so the fractional level spacing ΔE/E must scale to zero.  Demanding ΔE/E→0 while the total energy grows with N forces the level spacing to shrink at least as fast as 1/N, ensuring the spectrum appears continuous for any macroscopic observable.\n\nHYPOTHESIS: The fractional energy gap satisfies ΔE/E ≤ C/N with C a dimensionless constant of order unity for all N≫1.\n\nVERIFICATION: Both sides are dimensionless; the bound saturates when the spacing matches the inverse system size, reproducing the classical continuum.", "rejected": "The fractional energy gap satisfies ΔE/E ≤ C/N with C a dimensionless constant of order unity for all N≥1.", "E_acc": 0.25646767020225525, "C_acc": 0.5163379907608032, "G_acc": 0.5545859691919759, "D_acc": 0.7750870585441589, "H_acc": 0.26979008316993713, "Q_acc": 0.5126283001387492, "E_rej": 0.25598156452178955, "C_rej": 0.39117345213890076, "G_rej": 0.5270451808464713, "D_rej": 0.7090533226728439, "H_rej": 0.29094667732715607, "Q_rej": 0.5166848118999041, "Delta_Q": -0.004056511761154957, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Torque causes rotation, yet identical forces can produce different effects. Given rotational dynamics, consider what hypotheses follow about lever arms and moment of inertia.", "ancestors": ["[Definition] Torque τ is the cross product of position vector r and force F.", "[Variable] Lever arm ℓ is the perpendicular distance from the axis to F’s line of action.", "[Law] Newton’s second law for rotation states τ = I α, where I is moment of inertia and α is angular acceleration.", "[Constraint] For a given τ, α is inversely proportional to I."]}, "accepted": "Using the definition of torque and the rotational form of Newton’s second law, the angular acceleration produced by a given force on a rigid body depends on both the lever arm and the moment of inertia.  Combining τ = r × F with τ = I α and noting that |r × F| = ℓ F⊥, we derive α = ℓ F⊥ / I.\n\nHYPOTHESIS: For a rigid body free to rotate about a fixed axis, the angular acceleration α equals the product of the lever arm ℓ and the perpendicular component of the applied force F⊥ divided by the moment of inertia I.\n\nVERIFICATION: Units check: [ℓ]=m, [F⊥]=N, [I]=kg·m² → [ℓ F⊥/I]=N·m/(kg·m²)=kg·m·s⁻²·m/(kg·m²)=s⁻², matching units of angular acceleration.", "rejected": "Using the definition of torque and the rotational form of Newton’s second law, the angular acceleration produced by a rigid body determines both the lever arm and the moment of inertia for a given applied force.", "E_acc": 0.641348659992218, "C_acc": 0.13808166980743408, "G_acc": 0.5918617157149129, "D_acc": 0.7763075865805149, "H_acc": 0.1775582730770111, "Q_acc": 0.720666297187563, "E_rej": 0.4203796684741974, "C_rej": 0.19283391535282135, "G_rej": 0.6248477483168244, "D_rej": 0.8451376259326935, "H_rej": 0.15486237406730652, "Q_rej": 0.6660579549148679, "Delta_Q": 0.054608342272695176, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Standing waves form fixed nodes, yet energy continues to flow. Given wave theory, consider what hypotheses follow about boundary conditions.", "ancestors": ["[Definition] A node is a point in a standing wave where the displacement is permanently zero.", "[Law] The principle of superposition states that the net displacement is the algebraic sum of overlapping waves.", "[Variable] k denotes the wave number, defined as 2π/λ.", "[Constraint] For a standing wave on a string fixed at both ends, k must satisfy kL = nπ with n being a positive integer."]}, "accepted": "Using the fixed-end constraint kL = nπ and the definition k = 2π/λ, the allowed wavelengths are λ = 2L/n.  \nHYPOTHESIS: The distance between adjacent nodes is λ/2 = L/n, so for any positive integer n the node spacing is L/n.  \nVERIFICATION: Units: L (length) / n (dimensionless) → length; valid for standing waves on a string fixed at both ends.", "rejected": "The distance between adjacent nodes is λ/2 = L/k, so the node spacing is L/k for any positive integer n.", "E_acc": 0.5020331144332886, "C_acc": 0.27544763684272766, "G_acc": 0.531978476443328, "D_acc": 0.7069760710000992, "H_acc": 0.21303138136863708, "Q_acc": 0.6220081783132628, "E_rej": 0.40617361664772034, "C_rej": 0.24840517342090607, "G_rej": 0.5222861289221328, "D_rej": 0.7126617878675461, "H_rej": 0.2873382121324539, "Q_rej": 0.5904268124548252, "Delta_Q": 0.03158136585843763, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Species change over generations, yet individuals do not evolve. Given natural selection, consider what hypotheses can be justified about adaptation.", "ancestors": ["[Definition] Fitness w is the expected reproductive contribution of a genotype to the next generation.", "[Law] Natural selection raises the mean fitness W of a population at rate dW/dt = Var(w)/W.", "[Variable] Var(w) is the additive genetic variance in fitness within the population.", "[Constraint] Var(w) ≥ 0 limits the rate of fitness increase."]}, "accepted": "The additive genetic variance Var(w) sets the instantaneous rate of fitness increase, so any positive variance enforces a strictly positive lower bound on dW/dt.  \nHYPOTHESIS: A population exhibiting nonzero additive genetic variance in fitness must increase its mean fitness at a rate no less than Var(w)/W.  \nVERIFICATION: Units of Var(w)/W are (fitness²)/fitness = fitness/time, matching dW/dt.", "rejected": "A population that increases its mean fitness at a rate no less than Var(w)/W must therefore exhibit nonzero additive genetic variance in fitness.", "E_acc": 0.22888793051242828, "C_acc": 0.4739587903022766, "G_acc": 0.5859687076881528, "D_acc": 0.8475531041622162, "H_acc": 0.13923626393079758, "Q_acc": 0.5466553570702672, "E_rej": 0.6252370476722717, "C_rej": 0.1857571005821228, "G_rej": 0.583258499391377, "D_rej": 0.9110563099384308, "H_rej": 0.11117961257696152, "Q_rej": 0.7381646947935224, "Delta_Q": -0.19150933772325518, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Gases expand to fill containers, yet exert pressure. Given gas laws, consider what hypotheses follow about molecular motion.", "ancestors": ["[Definition] A gas is a state of matter whose molecules move freely and occupy the full volume of any container.", "[Law] The ideal gas law states PV = nRT, where P is pressure, V is volume, n is amount of substance, R is the ideal gas constant, and T is absolute temperature.", "[Variable] Temperature T is proportional to the average translational kinetic energy of gas molecules.", "[Constraint] For a fixed container volume V and fixed n, increasing T increases P.", "[Limit] The root-mean-square speed of gas molecules depends only on T and molar mass M."]}, "accepted": "Because the ideal-gas law fixes P ∝ T at constant V and n, and T itself fixes the root-mean-square speed vᵣₘₛ = √(3RT/M), the pressure must scale with the square of the molecular speed.  Eliminating T between the two relations gives P = (nM/3V) vᵣₘₛ², so for any given gas in a rigid container the pressure is proportional to the square of the speed.\n\nHYPOTHESIS: The pressure of a fixed amount of ideal gas in a rigid container is directly proportional to the square of the root-mean-square speed of its molecules.\n\nVERIFICATION: Units check—(nM/3V) vᵣₘₛ² yields (mol·kg/m³)(m²/s²)=kg·m⁻¹·s⁻²≡Pa, the unit of pressure.", "rejected": "The pressure of a fixed amount of ideal gas in any container, rigid or not, is directly proportional to the square of the root-mean-square speed of its molecules.", "E_acc": 0.46910804510116577, "C_acc": 0.24426651000976562, "G_acc": 0.5421637665131129, "D_acc": 0.7993247546255589, "H_acc": 0.2775556966662407, "Q_acc": 0.6324212460895069, "E_rej": 0.37457072734832764, "C_rej": 0.23711006343364716, "G_rej": 0.5343619878403842, "D_rej": 0.8533974587917328, "H_rej": 0.1466025412082672, "Q_rej": 0.6278408407233655, "Delta_Q": 0.004580405366141349, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcription produces RNA, yet DNA remains unchanged. Given gene expression, consider what hypotheses follow about information flow.", "ancestors": ["[Definition] Transcription is the enzyme-catalyzed synthesis of RNA from a DNA template.", "[Law] During transcription, DNA base-pairing rules dictate that A pairs with U, T with A, C with G, and G with C.", "[Variable] Let P denote the DNA polymerase activity responsible for DNA replication.", "[Constraint] In a given cell cycle, P and RNA polymerase cannot simultaneously occupy the same DNA base pair.", "[Limit] DNA remains chemically unaltered after RNA synthesis because the phosphodiester backbone is not cleaved.", "[Definition] Gene expression is the multistep process converting DNA-encoded information into functional products."]}, "accepted": "Transcription and replication are temporally segregated because the shared DNA template cannot be engaged by both RNA polymerase and DNA polymerase P at once.  \nHYPOTHESIS: The maximum number of RNA molecules that can be transcribed from a DNA segment per cell cycle equals the number of times that segment is cleared of P.  \nVERIFICATION: Dimensionless count, valid under the constraint that each clearance event allows one complete transcription round.", "rejected": "The maximum number of RNA molecules that can be transcribed from a DNA segment per cell cycle equals the number of times that segment is cleared of P, independent of whether RNA polymerase is still bound.", "E_acc": 0.34527555108070374, "C_acc": 0.38623249530792236, "G_acc": 0.5893369408149738, "D_acc": 0.7526610096295675, "H_acc": 0.20810222625732422, "Q_acc": 0.5739255337258025, "E_rej": 0.2463444024324417, "C_rej": 0.40857210755348206, "G_rej": 0.6023929886287078, "D_rej": 0.7826998233795166, "H_rej": 0.2173001766204834, "Q_rej": 0.5474774439586327, "Delta_Q": 0.026448089767169725, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Changing conditions shifts equilibrium, yet equilibrium is restored. Given Le Chatelier’s principle, consider what hypotheses can be justified about stress response.", "ancestors": ["[Definition] Chemical equilibrium is the state where forward and reverse reaction rates are equal.", "[Law] Le Chatelier’s principle states that a system at equilibrium opposes imposed stress by shifting position.", "[Variable] Stress is an external change in concentration, pressure, temperature, or volume applied to the system.", "[Constraint] The equilibrium constant K remains fixed at constant temperature despite positional shifts."]}, "accepted": "Applying Le Chatelier’s principle to a temperature increase shows the system must absorb heat by shifting toward the products if the forward reaction is endothermic, or toward the reactants if it is exothermic, while K changes accordingly.\n\nHYPOTHESIS: For any equilibrium subjected to a temperature rise, the equilibrium composition shifts in the direction that absorbs heat, and the magnitude of the shift is quantified by the van’t Hoff relation d(ln K)/dT = ΔH°/(RT²).\n\nVERIFICATION: Units check—both sides are K⁻¹; equation holds for ideal systems with constant ΔH°.", "rejected": "Raising the temperature causes an endothermic equilibrium to shift toward the reactants, and the resulting decrease in K is governed by the van’t Hoff relation d(ln K)/dT = ΔH°/(RT²).", "E_acc": 0.4356742203235626, "C_acc": 0.26313719153404236, "G_acc": 0.5299412811873481, "D_acc": 0.7296282052993774, "H_acc": 0.28225481510162354, "Q_acc": 0.601763243577443, "E_rej": 0.20464888215065002, "C_rej": 0.5315908789634705, "G_rej": 0.5307644951690236, "D_rej": 0.7304002195596695, "H_rej": 0.2695997804403305, "Q_rej": 0.48034945375420646, "Delta_Q": 0.12141378982323658, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Gravitational potential energy depends on reference choice, yet physical outcomes remain unchanged. Given mechanics, consider what hypotheses can be justified about energy zero points.", "ancestors": ["[Definition] Gravitational potential energy U equals m g h.", "[Variable] m is a positive scalar mass.", "[Variable] g is the constant gravitational field magnitude.", "[Variable] h is the vertical displacement from a chosen zero level.", "[Constraint] Adding constant C to h yields U′ = m g (h + C) = U + m g C.", "[Limit] The measurable difference U_b − U_a = m g (h_b − h_a) is independent of C."]}, "accepted": "Adding an arbitrary constant C to the height reference shifts the potential energy by a fixed amount mgC, yet the measurable work done by gravity, Ub – Ua = mg(hb – ha), remains unchanged because the C terms cancel.  \nHYPOTHESIS: The gravitational potential energy of a body can be set to zero at any convenient vertical level without altering the predicted work or energy differences derived from it.  \nVERIFICATION: Units check—both sides of Ub – Ua = mg(hb – ha) have dimensions of energy (kg·m²/s²).", "rejected": "The gravitational potential energy difference Ub – Ua equals mg plus the height difference hb – ha.", "E_acc": 0.20346908271312714, "C_acc": 0.6135324239730835, "G_acc": 0.5593952162889764, "D_acc": 0.8004474391539892, "H_acc": 0.1356508731842041, "Q_acc": 0.4967376837894942, "E_rej": 0.23691630363464355, "C_rej": 0.49991464614868164, "G_rej": 0.5587792664882727, "D_rej": 0.8240891098976135, "H_rej": 0.17591089010238647, "Q_rej": 0.5300745481275954, "Delta_Q": -0.03333686433810118, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Carbon forms long chains, yet maintains four bonds. Given valence theory, consider what hypotheses can be justified about versatility.", "ancestors": ["[Definition] A carbon atom possesses four valence electrons.", "[Law] The octet rule states eight electrons fill a main-shell.", "[Constraint] A carbon atom must share four electrons to complete its octet.", "[Limit] Four shared pairs allow only four single bonds per carbon."]}, "accepted": "A carbon atom with four valence electrons must form exactly four single covalent bonds to satisfy the octet rule, as each shared pair contributes one electron to its valence shell. This requirement fixes both the number of bonds and the maximum coordination number for carbon in neutral molecules.\n\nHYPOTHESIS: Every neutral carbon atom in a molecule forms exactly four single covalent bonds, yielding a maximum of four bonded neighbors.\n\nVERIFICATION: Units cancel to give a dimensionless count of 4 bonds, valid for neutral carbon in main-group molecules.", "rejected": "A carbon atom with four valence electrons must form exactly four single covalent bonds to satisfy the octet rule, as each shared pair contributes one electron to its valence shell, so this requirement fixes both the number of bonds and the maximum coordination number for carbon in all known chemical species.", "E_acc": 0.3703062832355499, "C_acc": 0.35303252935409546, "G_acc": 0.590380999725312, "D_acc": 0.8332827463746071, "H_acc": 0.1358744129538536, "Q_acc": 0.6116306870244443, "E_rej": 0.18337707221508026, "C_rej": 0.1440434753894806, "G_rej": 0.588471788156312, "D_rej": 0.9279149174690247, "H_rej": 0.09010635316371918, "Q_rej": 0.6204711323953234, "Delta_Q": -0.008840445370879024, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellites remain in free fall without colliding with Earth. Given gravity and inertia, consider what hypotheses follow about orbital motion.", "ancestors": ["[Law] Net force toward a body's center produces centripetal acceleration a_c.", "[Variable] v denotes a satellite's tangential speed.", "[Law] a_c = v²/r links speed to curvature radius r.", "[Constraint] For circular orbit, set a_c equal to local gravitational acceleration g."]}, "accepted": "Combining the centripetal requirement a_c = v²/r with the orbital constraint a_c = g yields g = v²/r, so the tangential speed required for a circular orbit is v = √(gr).\n\nHYPOTHESIS: A satellite in a circular orbit must have a tangential speed of exactly √(gr), where g is the local gravitational acceleration and r is the orbit’s radius.\n\nVERIFICATION: Units check: √(m s⁻² · m) = √(m² s⁻²) = m s⁻¹, consistent with speed.", "rejected": "A satellite in a circular orbit must have a tangential speed of exactly √(g/r), where g is the local gravitational acceleration and r is the orbit’s radius.", "E_acc": 0.5571776628494263, "C_acc": 0.15276332199573517, "G_acc": 0.5515088054041067, "D_acc": 0.7775839095314344, "H_acc": 0.1751025766134262, "Q_acc": 0.6849089197814465, "E_rej": 0.35151469707489014, "C_rej": 0.2968224883079529, "G_rej": 0.5238251478100816, "D_rej": 0.8675993978977203, "H_rej": 0.16550075262784958, "Q_rej": 0.6078247453396519, "Delta_Q": 0.0770841744417946, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Populations grow, yet stabilize over time. Given population dynamics, consider what hypotheses can be justified about carrying capacity.", "ancestors": ["[Definition] Carrying capacity k is the maximum population size an environment sustains indefinitely.", "[Variable] Let N(t) denote population size at time t.", "[Law] dN/dt = rN(1-N/k) with intrinsic growth rate r.", "[Constraint] N ≤ k for all t ≥ 0.", "[Limit] lim(t→∞) N(t) = k when 0 < N(0) < 2k.", "[Limit] If N(0) > k then dN/dt < 0 until N ≤ k."]}, "accepted": "The logistic equation’s negative feedback term (1−N/k) forces the growth rate to zero precisely when N reaches k, so any population initially below k must asymptotically approach this ceiling.  \nHYPOTHESIS: A population governed by the logistic law with 0 < N(0) < k will monotonically increase and attain 99 % of carrying capacity within finite time t = ln(99k/N(0) − 99)/r.  \nVERIFICATION: Units cancel to give dimensionless time; expression holds while N remains below k.", "rejected": "A population governed by the logistic law with 0 < N(0) < k will monotonically increase and reach 99 % of carrying capacity at a time that is independent of the current population size N(t).", "E_acc": 0.31507495045661926, "C_acc": 0.38693225383758545, "G_acc": 0.5425903184805065, "D_acc": 0.771968349814415, "H_acc": 0.2083633840084076, "Q_acc": 0.5592114296276123, "E_rej": 0.06178293749690056, "C_rej": 0.5410559177398682, "G_rej": 0.5650197102222592, "D_rej": 0.8802694082260132, "H_rej": 0.11973059177398682, "Q_rej": 0.4874084622133523, "Delta_Q": 0.07180296741425995, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Cells respire continuously, yet oxygen availability varies. Given cellular respiration, consider what hypotheses follow about metabolic flexibility.", "ancestors": ["[Definition] Cellular respiration is the intracellular oxidation of organic substrates to CO₂ and H₂O coupled to ATP synthesis.", "[Law] Oxidative phosphorylation rate P scales linearly with cytosolic oxygen concentration [O₂] over its physiological range.", "[Constraint] Maintenance of viable ATP level A ≥ A_min is required for continuous cellular function.", "[Limit] Extracellular [O₂] is bounded by supply kinetics such that 0 ≤ [O₂] ≤ [O₂]_max."]}, "accepted": "Oxidative phosphorylation rate P scales linearly with cytosolic [O₂], and viable ATP level A ≥ A_min must be maintained; therefore, for any cell there exists a minimal cytosolic oxygen concentration [O₂]_min below which P cannot sustain A ≥ A_min.\n\nHYPOTHESIS: Cellular respiration can maintain viable ATP levels only if cytosolic [O₂] ≥ [O₂]_min = A_min / (k·V), where k is the constant coupling P = k[O₂] and V is cytosolic volume.\n\nVERIFICATION: Units check—A_min in mol ATP, k in mol ATP s⁻¹ M⁻¹, V in L, yielding [O₂]_min in M.", "rejected": "Cellular respiration can maintain viable ATP levels even when cytosolic [O₂] is negative, provided [O₂] ≥ [O₂]_min = A_min / (k·V).", "E_acc": 0.48811569809913635, "C_acc": 0.17869193851947784, "G_acc": 0.5575121885049157, "D_acc": 0.8364370415608088, "H_acc": 0.1622885838150978, "Q_acc": 0.6732573093574804, "E_rej": 0.09804584830999374, "C_rej": 0.39839106798171997, "G_rej": 0.5691577856196091, "D_rej": 0.8957617580890656, "H_rej": 0.10423824191093445, "Q_rej": 0.5322956254472957, "Delta_Q": 0.1409616839101847, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Diffraction becomes significant when apertures are small. Given wave optics, consider what hypotheses can be justified about resolution limits.", "ancestors": ["[Definition] Diffraction is the bending of a wave when it encounters an aperture or obstacle.", "[Variable] λ denotes the wavelength of the incident wave.", "[Constraint] The angular half-width of the first bright diffraction ring for a circular aperture is θ = 1.22 λ/D, where D is the aperture diameter.", "[Limit] An optical system cannot resolve two incoherent point sources separated by an angle smaller than θ = 1.22 λ/D."]}, "accepted": "Using the diffraction-limited angular resolution θ = 1.22 λ/D, the smallest resolvable separation between two point sources is directly proportional to wavelength and inversely proportional to aperture diameter.  \nHYPOTHESIS: For any circular-aperture optical system, the minimum resolvable angular separation between two incoherent point sources equals 1.22 λ/D.  \nVERIFICATION: Units check—λ and D in metres give θ in radians, consistent with angular measure.", "rejected": "If two incoherent point sources are resolved, then their angular separation must equal 1.22 λ/D.", "E_acc": 0.7623203992843628, "C_acc": 0.06191825494170189, "G_acc": 0.5217732730088755, "D_acc": 0.7491842806339264, "H_acc": 0.19261842966079712, "Q_acc": 0.7512421365594493, "E_rej": 0.6393088698387146, "C_rej": 0.10030428320169449, "G_rej": 0.5257151188561693, "D_rej": 0.6911206692457199, "H_rej": 0.3860991634428501, "Q_rej": 0.6764890455873683, "Delta_Q": 0.07475309097208094, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Series and parallel circuits behave differently, yet total energy is conserved. Given circuit laws, consider what hypotheses follow about current paths.", "ancestors": ["[Definition] A node is a point in a circuit where two or more components connect.", "[Definition] A branch is a path between two nodes containing one or more components in series.", "[Law] Kirchhoff’s current law states that the sum of currents entering a node equals the sum leaving it.", "[Constraint] In a series connection, every branch carries the same current.", "[Constraint] In a parallel connection, the voltage across every branch is the same."]}, "accepted": "Applying Kirchhoff’s current law to a node fed only by two branches in series forces their currents to be identical, so the entering and leaving currents must balance branch-for-branch.\n\nHYPOTHESIS: In any circuit node connected to exactly two branches that each form part of a series chain, the magnitude of current in one branch equals the magnitude of current in the other branch.\n\nVERIFICATION: Units of both sides are amperes; equality holds under the stated topological constraint.", "rejected": "Applying Kirchhoff’s current law to a node fed only by two branches in series forces their currents to be independent, so the entering and leaving currents balance branch-for-branch.", "E_acc": 0.4129375219345093, "C_acc": 0.25913694500923157, "G_acc": 0.5707499345764517, "D_acc": 0.7719368090232214, "H_acc": 0.19367489218711853, "Q_acc": 0.6212237270797293, "E_rej": 0.28056907653808594, "C_rej": 0.2786767780780792, "G_rej": 0.5678289070725441, "D_rej": 0.8597947955131531, "H_rej": 0.17525650560855865, "Q_rej": 0.5964344573020934, "Delta_Q": 0.024789269777635847, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Work transfers energy, yet identical work can result in different motions. Given work–energy relations, consider what hypotheses can be justified about energy partitioning.", "ancestors": ["[Definition] Work W is the line integral of force F dotted with infinitesimal displacement dr.", "[Definition] Kinetic energy K is one-half mass m times speed v squared.", "[Law] Net work equals change in kinetic energy, W_net = ΔK.", "[Definition] Internal energy U_int includes microscopic forms other than bulk kinetic energy."]}, "accepted": "Combining the work–energy theorem with the definitions of work and kinetic energy shows that any process in which the net force does positive work on a mass necessarily increases that mass’s speed.  \nHYPOTHESIS: For a particle of constant mass m, positive net work W_net implies a speed increase from v₁ to v₂ with v₂ > v₁, quantified by W_net = ½m(v₂² – v₁²).  \nVERIFICATION: Units check—both sides reduce to kg·m²·s⁻² (joules), valid for inertial reference frames.", "rejected": "For a particle of constant mass m, positive net work W_net implies a speed increase from v₁ to v₂ with v₂ > v₁, quantified by W_net = ½m(v₂ – v₁²).", "E_acc": 0.38321733474731445, "C_acc": 0.23313413560390472, "G_acc": 0.5875445979181677, "D_acc": 0.7575819666186968, "H_acc": 0.16876676678657532, "Q_acc": 0.6204870095321287, "E_rej": 0.3421652913093567, "C_rej": 0.29392069578170776, "G_rej": 0.5949333026073873, "D_rej": 0.7997738718986511, "H_rej": 0.20022612810134888, "Q_rej": 0.6027842703275383, "Delta_Q": 0.017702739204590312, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Standing waves form fixed nodes, yet energy continues to flow. Given wave theory, consider what hypotheses follow about boundary conditions.", "ancestors": ["[Definition] A standing wave is the sum of two counter-propagating sinusoidal waves of equal amplitude and frequency.", "[Law] At any fixed position the superposition yields a resultant displacement varying in time as sin(ωt)cos(kx).", "[Variable] The spatial factor cos(kx) possesses stationary zeros called nodes.", "[Constraint] The wave satisfies boundary conditions that force cos(kx) = 0 at the clamped ends of the medium."]}, "accepted": "The clamped-end boundary condition cos(kL)=0 for a medium of length L requires kL=(n+½)π with n a non-negative integer, so the smallest allowed wave number is k_min=π/(2L).  \nHYPOTHESIS: The fundamental standing-wave mode in a clamped–clamped medium has wave number k=π/(2L) and wavelength λ=4L.  \nVERIFICATION: Units consistent ([k]=m⁻¹, [L]=m); exact for ideal rigid clamps.", "rejected": "The fundamental standing-wave mode in a clamped–clamped medium has wave number k=π/L and wavelength λ=2L.", "E_acc": 0.31683698296546936, "C_acc": 0.3048231601715088, "G_acc": 0.5349018765347344, "D_acc": 0.7163013021151224, "H_acc": 0.25647956132888794, "Q_acc": 0.5586791424524217, "E_rej": 0.5614178776741028, "C_rej": 0.2004081904888153, "G_rej": 0.5345203747773277, "D_rej": 0.777186781167984, "H_rej": 0.222813218832016, "Q_rej": 0.6684038345103286, "Delta_Q": -0.10972469205790691, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Organic molecules share formulas, yet differ in properties. Given isomerism, consider what hypotheses follow about structure–function relationships.", "ancestors": ["[Definition] Isomers are compounds with identical molecular formulas but distinct atom connectivity or spatial arrangements.", "[Law] Structural isomers differ in covalent connectivity and exhibit different physical constants such as boiling point Tb, melting point Tm, and density ρ.", "[Variable] Let S denote molecular shape, defined by bond angles θ and torsion angles φ.", "[Constraint] For a fixed molecular formula, S is constrained by the isomer type: structural isomers fix distinct θ; stereoisomers share θ but differ in φ.", "[Limit] Physical property differences among isomers are bounded by the isomer type; extreme ΔTb or ΔTm requires structural, not just stereochemical, change."]}, "accepted": "Structural isomers differ in bond connectivity, which alters molecular shape S through discrete changes in bond angles θ, whereas stereoisomers share θ and differ only in torsion angles φ. Because the physical property gap ΔTb is bounded by the isomer type, a measurable Tb difference exceeding the stereoisomeric limit (|ΔTb| > 5 K for hydrocarbons) can arise only from a structural isomer.\n\nHYPOTHESIS: A Tb difference |ΔTb| > 5 K between two compounds of identical molecular formula proves they are structural, not stereochemical, isomers.\n\nVERIFICATION: Units K; regime validated for C4–C6 hydrocarbons.", "rejected": "A Tb difference |ΔTb| > 5 K between two compounds of identical molecular formula equals their difference in molecular shape S measured in degrees.", "E_acc": 0.2977765202522278, "C_acc": 0.2440001219511032, "G_acc": 0.5388293801806867, "D_acc": 0.7843855395913124, "H_acc": 0.12772482633590698, "Q_acc": 0.5924034330062569, "E_rej": 0.2025759369134903, "C_rej": 0.22281135618686676, "G_rej": 0.5441332838963717, "D_rej": 0.7413605600595474, "H_rej": 0.2586394399404526, "Q_rej": 0.5474453346338123, "Delta_Q": 0.04495809837244458, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase changes occur at fixed temperatures, yet energy continues to flow. Given thermodynamics, consider what hypotheses can be justified about latent heat.", "ancestors": ["[Definition] Latent heat L is the energy per unit mass absorbed or released during a phase change at constant temperature.", "[Variable] m denotes mass of the substance.", "[Law] Conservation of energy requires Q = mL for the phase change.", "[Constraint] During the phase change, temperature T remains constant.", "[Variable] Q is the thermal energy transferred to the system.", "[Limit] L sets the minimum Q required to complete the phase change of mass m."]}, "accepted": "The conservation law Q = mL and the limit that L sets the minimum energy for a phase change together imply that any thermal energy short of this product leaves the original phase unchanged.  \nHYPOTHESIS: If Q < mL, the phase change does not occur and the substance remains entirely in its initial phase.  \nVERIFICATION: Both sides have units of energy (J), and the inequality holds under the stated constant-temperature constraint.", "rejected": "If the substance remains entirely in its initial phase, then Q < mL.", "E_acc": 0.13271258771419525, "C_acc": 0.5788037776947021, "G_acc": 0.5451433492016804, "D_acc": 0.7283991227547327, "H_acc": 0.22701695561408997, "Q_acc": 0.4560598196051918, "E_rej": 0.24545930325984955, "C_rej": 0.4751735329627991, "G_rej": 0.5411357871489599, "D_rej": 0.6926029622554779, "H_rej": 0.3073970377445221, "Q_rej": 0.4946111304918304, "Delta_Q": -0.0385513108866386, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Variation exists before selection, yet selection shapes populations. Given evolution, consider what hypotheses follow about randomness and order.", "ancestors": ["[Definition] Variation V is the set of heritable phenotypic differences among individuals in a population.", "[Law] Selection coefficient s measures the fractional change in allelic frequency per generation due to differential survival and reproduction.", "[Variable] Randomness R denotes the stochastic component of V arising from mutation and recombination independent of s.", "[Constraint] Evolution requires R to precede s temporally, yet s determines the subsequent distribution of V."]}, "accepted": "Variation V arises from random mutation and recombination R before selection coefficient s acts, and s subsequently reshapes the distribution of V.  Because s can only operate on existing heritable differences, the maximal selectable variance in any generation is bounded by the variance produced by R in the preceding generation.\n\nHYPOTHESIS: The variance of V after selection, Var(V_post), cannot exceed the variance of V produced by R, Var(R), i.e. Var(V_post) ≤ Var(R).\n\nVERIFICATION: Both sides have units of trait variance (e.g. cm²), and the inequality holds whenever evolution proceeds through the temporal sequence R → s.", "rejected": "Var(V_post) ≤ Var(R) holds even when selection acts before mutation and recombination generate new variation.", "E_acc": 0.49251314997673035, "C_acc": 0.29563671350479126, "G_acc": 0.6133524463512003, "D_acc": 0.7637494504451752, "H_acc": 0.13538265228271484, "Q_acc": 0.6505087164230645, "E_rej": 0.32231682538986206, "C_rej": 0.33047905564308167, "G_rej": 0.6062800628133118, "D_rej": 0.8213754296302795, "H_rej": 0.17862457036972046, "Q_rej": 0.5982678779400886, "Delta_Q": 0.05224083848297589, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Interference produces stable patterns, yet individual waves remain unchanged. Given superposition, consider what hypotheses can be justified about linearity.", "ancestors": ["[Definition] Superposition is the vector addition of instantaneous wave amplitudes at each point in space and time.", "[Law] For linear media, the superposition of two solutions of the wave equation is also a solution.", "[Variable] k denotes the proportionality constant between wave amplitude and the restoring force in the medium.", "[Constraint] k is independent of wave amplitude in linear media.", "[Limit] Nonlinear effects appear when amplitude exceeds the range where k remains constant."]}, "accepted": "Because k is amplitude-independent only below a critical amplitude, the linear superposition law must fail once the summed amplitude exceeds that threshold.  \nHYPOTHESIS: The superposition principle ceases to be valid when the resultant wave amplitude surpasses the value A_c at which k begins to vary with amplitude.  \nVERIFICATION: A_c has units of amplitude; the statement holds in any medium whose linearity breaks down beyond a fixed amplitude.", "rejected": "The superposition principle remains valid even when the resultant wave amplitude surpasses the value A_c at which k begins to vary with amplitude.", "E_acc": 0.41142138838768005, "C_acc": 0.14888152480125427, "G_acc": 0.5603584041818976, "D_acc": 0.770205169916153, "H_acc": 0.2250843122601509, "Q_acc": 0.6372543951496482, "E_rej": 0.2533847689628601, "C_rej": 0.31642478704452515, "G_rej": 0.5499464776657987, "D_rej": 0.7966302335262299, "H_rej": 0.20336976647377014, "Q_rej": 0.5617088388709818, "Delta_Q": 0.07554555627866644, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Current flows when a circuit is complete, yet voltage divides among components. Given Ohm’s law, consider what hypotheses can be justified about resistance.", "ancestors": ["[Definition] Resistance R is the ratio of voltage V across a component to current I through it.", "[Law] Ohm’s law states V = I R.", "[Variable] R is a scalar measured in ohms (Ω).", "[Constraint] R is fixed for ohmic materials at constant temperature.", "[Limit] R cannot be negative because V and I share sign."]}, "accepted": "Because R is fixed and non-negative for ohmic materials at constant temperature, the ratio V/I is constant and ≥ 0.  \nHYPOTHESIS: For any ohmic component held at constant temperature, doubling the applied voltage doubles the current while keeping their ratio V/I = R ≥ 0.  \nVERIFICATION: Units check: V/I gives ohms, matching R; regime: ohmic, constant temperature.", "rejected": "For any ohmic component held at constant temperature, doubling the current doubles the applied voltage while keeping their ratio I/V = R ≥ 0.", "E_acc": 0.4857076406478882, "C_acc": 0.23703913390636444, "G_acc": 0.5650598309002817, "D_acc": 0.7712092051903406, "H_acc": 0.22405299544334412, "Q_acc": 0.6431529730868837, "E_rej": 0.17122842371463776, "C_rej": 0.3080376386642456, "G_rej": 0.5531790858512977, "D_rej": 0.7288786321878433, "H_rej": 0.2711213678121567, "Q_rej": 0.5190604062081547, "Delta_Q": 0.12409256687872894, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Atoms bond to lower energy, yet bonds require energy to break. Given bonding theory, consider what hypotheses follow about stability.", "ancestors": ["[Definition] A bond energy E_b is the energy required to break one mole of a specific chemical bond in the gas phase.", "[Law] A system shifts toward configurations of lower potential energy E_p.", "[Variable] Let E_p be the electronic potential energy of a bonded collection of nuclei and electrons.", "[Constraint] A stable bonded state exists only if E_p of the bonded aggregate is lower than E_p of the separated atoms."]}, "accepted": "The definition of bond energy E_b as the energy required to break a bond implies that the bonded state must be more stable than the separated atoms. Because the system favors lower potential energy E_p, the energy released upon bond formation equals the bond energy. Thus, the bond energy is exactly the potential-energy difference between the separated atoms and the bonded aggregate.\n\nHYPOTHESIS: E_b = E_p(separated atoms) – E_p(bonded state).\n\nVERIFICATION: Both sides carry energy per mole units and the equation holds for any diatomic molecule in the gas phase.", "rejected": "The bond energy E_b is independent of the electronic potential energy difference between the separated atoms and the bonded state.", "E_acc": 0.366921603679657, "C_acc": 0.3181367814540863, "G_acc": 0.557846784026229, "D_acc": 0.8326822221279144, "H_acc": 0.09599898010492325, "Q_acc": 0.6149550280334163, "E_rej": 0.28724315762519836, "C_rej": 0.283611536026001, "G_rej": 0.5475030435149425, "D_rej": 0.8801296651363373, "H_rej": 0.11987033486366272, "Q_rej": 0.6029901483262491, "Delta_Q": 0.011964879707167198, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Human activity alters ecosystems, yet feedback effects emerge. Given environmental biology, consider what hypotheses follow about sustainability.", "ancestors": ["[Definition] An ecosystem is a biotic community interacting with its abiotic environment.", "[Variable] Let H be the magnitude of human-driven perturbation applied to an ecosystem.", "[Law] Negative feedback responds to deviation by driving the system toward its prior state.", "[Constraint] Negative feedback strength B in an ecosystem decreases linearly with H.", "[Limit] When B reaches zero, the ecosystem loses self-corrective capacity."]}, "accepted": "As human-driven perturbation H increases, the ecosystem’s negative feedback strength B declines linearly until it vanishes at a finite H, eliminating self-correction.\n\nHYPOTHESIS: An ecosystem subjected to a perturbation magnitude H ≥ B₀/k (where B₀ is the initial feedback strength and k is the slope of B vs. H) irreversibly loses its capacity to return to its prior state.\n\nVERIFICATION: B₀/k has units of perturbation magnitude, matching H, and the equation B = B₀ – kH holds until B = 0.", "rejected": "As H increases, the ecosystem’s negative feedback strength B declines linearly until it vanishes when H equals B₀+k, eliminating self-correction.", "E_acc": 0.6549330353736877, "C_acc": 0.1545609086751938, "G_acc": 0.5516896031331271, "D_acc": 0.7697552070021629, "H_acc": 0.1367373764514923, "Q_acc": 0.7161829532589763, "E_rej": 0.4537157118320465, "C_rej": 0.14587745070457458, "G_rej": 0.5530300249811262, "D_rej": 0.828727513551712, "H_rej": 0.17127248644828796, "Q_rej": 0.666163482470438, "Delta_Q": 0.0500194707885383, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Periodic motion repeats predictably, yet damping reduces amplitude over time. Given oscillations, consider what hypotheses can be justified about energy loss mechanisms.", "ancestors": ["[Definition] Periodic motion is motion that repeats at a fixed time interval T called the period.", "[Law] The total mechanical energy E of an oscillator is the sum of kinetic and potential energies.", "[Variable] Amplitude A is the maximum displacement from equilibrium.", "[Limit] Damping causes A to decrease monotonically, reducing E."]}, "accepted": "Damping reduces amplitude A, and because total mechanical energy E of an oscillator depends on A, E must decrease as A decreases.  \nHYPOTHESIS: In a damped oscillator, the total mechanical energy E decreases monotonically with the amplitude A.  \nVERIFICATION: Units consistent (energy ∝ amplitude²).", "rejected": "In a damped oscillator, the total mechanical energy E decreases linearly with the amplitude A.", "E_acc": 0.2775331139564514, "C_acc": 0.4292432963848114, "G_acc": 0.5682927427114919, "D_acc": 0.7539921154578527, "H_acc": 0.2956523001194, "Q_acc": 0.532303016531902, "E_rej": 0.4287858307361603, "C_rej": 0.18903246521949768, "G_rej": 0.5845362656982616, "D_rej": 0.8039764165878296, "H_rej": 0.1960235834121704, "Q_rej": 0.6489294342929498, "Delta_Q": -0.11662641776104776, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Capacitors store energy, yet no charge crosses the dielectric. Given circuits, consider what hypotheses follow about energy storage mechanisms.", "ancestors": ["[Definition] A capacitor is a two-terminal device that stores electrostatic energy.", "[Variable] Q is the magnitude of charge stored on either plate.", "[Variable] V is the voltage across the plates.", "[Law] Q = C·V, where C is the capacitance.", "[Constraint] In electrostatic equilibrium, no current flows through the dielectric."]}, "accepted": "Using the definition of capacitance and the equilibrium condition, the stored charge Q is strictly proportional to the applied voltage V with proportionality constant C.  \nHYPOTHESIS: For any capacitor in electrostatic equilibrium, the magnitude of stored charge Q equals the product of its capacitance C and the voltage V across its plates, Q = C·V.  \nVERIFICATION: Units check: C in farads (C/V) times V in volts yields coulombs, matching Q.", "rejected": "For any capacitor in electrostatic equilibrium, the magnitude of stored charge Q equals the product of its capacitance C and the current I through its plates, Q = C·I.", "E_acc": 0.22499068081378937, "C_acc": 0.3766494393348694, "G_acc": 0.5510384472436272, "D_acc": 0.7881384442249934, "H_acc": 0.15731105208396912, "Q_acc": 0.5442715894624901, "E_rej": 0.4970247745513916, "C_rej": 0.281446635723114, "G_rej": 0.5771583978618894, "D_rej": 0.8736101984977722, "H_rej": 0.12638980150222778, "Q_rej": 0.6703328443425043, "Delta_Q": -0.12606125488001418, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chemical reactions exchange energy, yet total energy is conserved. Given thermochemistry, consider what hypotheses follow about enthalpy.", "ancestors": ["[Definition] The enthalpy change ΔH is the heat exchanged at constant pressure.", "[Variable] ΔH = H_products – H_reactants.", "[Law] ΔH for the forward reaction equals −ΔH for the reverse reaction.", "[Limit] Measured ΔH is valid only at the stated temperature and pressure."]}, "accepted": "Using the definition ΔH = H_products – H_reactants and the law that the forward and reverse reactions have equal and opposite enthalpy changes, any reaction sequence that returns to the original composition must sum to zero enthalpy change.\n\nHYPOTHESIS: A cyclic reaction pathway that restores all species to their initial states has ΔH_cycle ≡ 0.\n\nVERIFICATION: Units of ΔH (kJ mol⁻¹) cancel over the closed loop, satisfying energy conservation.", "rejected": "A cyclic reaction pathway that restores all species to their initial states has ΔH_cycle independent of any intermediate steps.", "E_acc": 0.23198948800563812, "C_acc": 0.28753766417503357, "G_acc": 0.5492046072031371, "D_acc": 0.7171707997719446, "H_acc": 0.3357263281941414, "Q_acc": 0.5317917621422869, "E_rej": 0.3103550672531128, "C_rej": 0.1960780918598175, "G_rej": 0.535807732550893, "D_rej": 0.6215739697217941, "H_rej": 0.37842603027820587, "Q_rej": 0.5475246392306872, "Delta_Q": -0.01573287708840032, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric charges exert forces, yet stationary charges do no work. Given electrostatics, consider what hypotheses follow about electric potential.", "ancestors": ["[Definition] The electrostatic potential V at a point equals the work per unit charge to bring a test charge from infinity to that point without acceleration.", "[Definition] The electric field E is the negative gradient of the potential, E = −∇V.", "[Law] Work W done by the field on a test charge q displaced through vector r is W = −qΔV.", "[Constraint] In static conditions the electric field is conservative, so ∮E·dr = 0 for any closed path.", "[Limit] Therefore ΔV = 0 round any closed path, so the potential is single-valued in space.", "[Variable] Potential difference ΔV between two points is path-independent in electrostatics."]}, "accepted": "The conservative nature of the electrostatic field forces the line integral of E between any two points to equal the potential drop, so the work done by the field on a charge q moving from point a to point b is completely fixed by the potential difference: W = q(V_a – V_b).\n\nHYPOTHESIS: For any electrostatic displacement the work done by the field on a test charge q is W = qΔV, with ΔV the potential difference between the endpoints, independent of the path taken.\n\nVERIFICATION: Units check—q in coulombs, ΔV in volts gives W in joules; holds for static charges and time-independent fields.", "rejected": "The work done by the field on a test charge q moving from point a to point b depends on the path taken because the potential difference ΔV is path-dependent in electrostatics.", "E_acc": 0.4337173402309418, "C_acc": 0.22264333069324493, "G_acc": 0.5168821881525218, "D_acc": 0.8028865059216818, "H_acc": 0.1617276296019554, "Q_acc": 0.6333675117852787, "E_rej": 0.007118044421076775, "C_rej": 0.9840036034584045, "G_rej": 0.526707035372965, "D_rej": 0.8514517247676849, "H_rej": 0.14854827523231506, "Q_rej": 0.36611161713954066, "Delta_Q": 0.26725589464573807, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Changing conditions shifts equilibrium, yet equilibrium is restored. Given Le Chatelier’s principle, consider what hypotheses can be justified about stress response.", "ancestors": ["[Definition] A stress on an equilibrium system is any imposed change in T, P, or concentration.", "[Law] Le Chatelier’s principle states the system counteracts a stress by shifting the equilibrium position.", "[Variable] K is the temperature-dependent equilibrium constant of the reaction.", "[Constraint] K is unchanged by concentration or partial-pressure stresses at fixed T."]}, "accepted": "Because K depends only on temperature, any concentration or pressure stress at fixed T must be counteracted solely by a shift in the equilibrium composition, leaving K numerically unchanged.  \nHYPOTHESIS: At constant temperature, the ratio of products to reactants raised to their stoichiometric powers returns to the original value of K after the system counteracts a concentration or pressure stress.  \nVERIFICATION: Dimensionless ratio equals K; valid only when T is held fixed.", "rejected": "At constant temperature, the sum of the concentration terms raised to their stoichiometric powers equals the original value of K after the system counteracts a concentration or pressure stress.", "E_acc": 0.32757604122161865, "C_acc": 0.4256860315799713, "G_acc": 0.5523887246963568, "D_acc": 0.7212109342217445, "H_acc": 0.29440242797136307, "Q_acc": 0.5384152950369754, "E_rej": 0.23409120738506317, "C_rej": 0.5312362909317017, "G_rej": 0.5559221131261438, "D_rej": 0.7591542899608612, "H_rej": 0.2408457100391388, "Q_rej": 0.5029108136426658, "Delta_Q": 0.03550448139430962, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrons occupy quantized energy levels, yet transitions appear continuous in spectra. Given quantum chemistry, consider what hypotheses follow about emission.", "ancestors": ["[Definition] An electron occupies a discrete one-electron orbital with energy E.", "[Definition] A spectral line corresponds to the photon energy hν emitted when an electron changes orbitals.", "[Law] The photon energy equals the orbital energy difference: hν = E2 – E1.", "[Variable] Let n index the principal quantum number labeling an orbital.", "[Constraint] Δn must be an integer because E values are quantized by integer n.", "[Limit] The observed frequency ν is continuous because E differences vary with the continuous nuclear charge Z in a multi-electron atom."]}, "accepted": "The orbital energy difference E₂–E₁ is quantized through the integer principal quantum numbers n₂ and n₁, so the photon frequency ν = (E₂–E₁)/h must change in discrete steps as the nuclear charge Z varies continuously.  \nHYPOTHESIS: The discrete frequency jumps Δν between adjacent spectral lines equal (E_{n+1}–E_n)/h and are therefore independent of the continuous nuclear charge Z.  \nVERIFICATION: Units check: [E]/[h] = J/(J·s) = s⁻¹, giving frequency; holds for any one-electron orbital transition.", "rejected": "Because the photon frequency changes in discrete steps as the nuclear charge varies continuously, the orbital energy difference E₂–E₁ is quantized through the integer principal quantum numbers n₂ and n₁.", "E_acc": 0.07390197366476059, "C_acc": 0.8542075157165527, "G_acc": 0.5472186086408328, "D_acc": 0.8077139655749003, "H_acc": 0.20460430532693863, "Q_acc": 0.4018551732665704, "E_rej": 0.25361567735671997, "C_rej": 0.5798611640930176, "G_rej": 0.5509097867179662, "D_rej": 0.8485415279865265, "H_rej": 0.1514584720134735, "Q_rej": 0.5248568861279637, "Delta_Q": -0.12300171286139328, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Negative feedback stabilizes systems, yet positive feedback amplifies change. Given regulation, consider what hypotheses can be justified about control mechanisms.", "ancestors": ["[Definition] Feedback is a closed-loop causal chain in which a system's output influences its own input.", "[Variable] Let G denote the open-loop gain of a system.", "[Variable] Let H denote the feedback gain.", "[Law] The closed-loop gain A equals G/(1 + GH).", "[Constraint] GH < 0 yields negative feedback."]}, "accepted": "Using the closed-loop gain formula and the negative-feedback condition GH < 0, the denominator 1 + GH becomes 1 minus a positive product, ensuring |1 + GH| > 1.  \nHYPOTHESIS: Negative feedback reduces the closed-loop gain magnitude below the open-loop gain magnitude, i.e. |A| < |G|.  \nVERIFICATION: Dimensional check: both sides are dimensionless gain ratios; inequality holds whenever GH < 0.", "rejected": "Negative feedback reduces the closed-loop gain magnitude below the open-loop gain magnitude, i.e. |A| < |G|, independent of the value of GH.", "E_acc": 0.14923088252544403, "C_acc": 0.6976492404937744, "G_acc": 0.5554718713392504, "D_acc": 0.7307950612157583, "H_acc": 0.1659409999847412, "Q_acc": 0.44589870317140595, "E_rej": 0.043988924473524094, "C_rej": 0.9173147678375244, "G_rej": 0.5608814463485032, "D_rej": 0.7126008085906506, "H_rej": 0.12429174780845642, "Q_rej": 0.37200099998153746, "Delta_Q": 0.07389770318986849, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Objects in circular motion accelerate without changing speed. Given kinematics, consider what hypotheses can be justified about centripetal forces.", "ancestors": ["[Definition] Circular motion is motion at constant speed v along a circular path of radius r.", "[Variable] Centripetal acceleration a is directed toward the circle’s center and has magnitude a = v²/r.", "[Law] Newton’s second law states that net force F equals mass m times acceleration.", "[Constraint] For circular motion the net force must point toward the center and satisfy F = m v²/r.", "[Limit] This force vanishes if either v = 0 or r → ∞."]}, "accepted": "Combining the centripetal force requirement F = mv²/r with the vanishing condition for v = 0 or r → ∞, the smallest non-zero speed compatible with a finite centripetal force is obtained by setting F to its minimum detectable value F_min, yielding v_min = √(F_min r/m).\n\nHYPOTHESIS: For any particle of mass m in circular motion of radius r, the minimum speed required to sustain a measurable centripetal force F_min is v_min = √(F_min r/m).\n\nVERIFICATION: Units check: √(N·m/kg) = √(kg·m·s⁻²·m/kg) = m/s, consistent with speed.", "rejected": "For any particle of mass m in circular motion of radius r, the minimum speed required to sustain a measurable centripetal force F_min is independent of the radius r and equals v_min = √(F_min/m).", "E_acc": 0.7789648175239563, "C_acc": 0.07338543981313705, "G_acc": 0.5836910817888565, "D_acc": 0.7539927462736765, "H_acc": 0.21341216564178467, "Q_acc": 0.7652079063428877, "E_rej": 0.3562498986721039, "C_rej": 0.23710781335830688, "G_rej": 0.6032654107548296, "D_rej": 0.8061486780643463, "H_rej": 0.1938513219356537, "Q_rej": 0.6219510925002397, "Delta_Q": 0.143256813842648, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Moving charges create magnetic fields, yet static charges do not. Given electromagnetism, consider what hypotheses follow about relativity of motion.", "ancestors": ["[Definition] Charge density ρ is charge per unit volume.", "[Law] The Lorentz force on a test charge q is F = q(E + v × B).", "[Variable] v is the velocity of the test charge q relative to the observer.", "[Constraint] A reference frame can be chosen where q is at rest, forcing v = 0.", "[Limit] In that frame, F reduces to F = qE, eliminating any magnetic contribution to F."]}, "accepted": "By selecting the rest frame of a test charge, the magnetic term in the Lorentz force vanishes, leaving only the electric contribution.  \nHYPOTHESIS: In the reference frame where the test charge is at rest, the total electromagnetic force on it equals qE and is independent of any magnetic field present.  \nVERIFICATION: Units of qE are newtons, matching force; valid only in the charge’s rest frame.", "rejected": "In every reference frame, the total electromagnetic force on the test charge equals qE and is independent of any magnetic field present.", "E_acc": 0.3008735179901123, "C_acc": 0.35262852907180786, "G_acc": 0.5387552781030536, "D_acc": 0.8039895594120026, "H_acc": 0.1525525152683258, "Q_acc": 0.5730300655588507, "E_rej": 0.042074818164110184, "C_rej": 0.7538864016532898, "G_rej": 0.531960865482688, "D_rej": 0.8304926156997681, "H_rej": 0.16950738430023193, "Q_rej": 0.41738512292504315, "Delta_Q": 0.15564494263380757, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Standing waves form fixed nodes, yet energy continues to flow. Given wave theory, consider what hypotheses follow about boundary conditions.", "ancestors": ["[Definition] A standing wave is the superposition of two identical travelling waves propagating in opposite directions.", "[Definition] A node is a point where the oscillation amplitude of a standing wave is zero for all time.", "[Definition] The wave function of a one-dimensional standing wave on a string of length L fixed at both ends is y(x,t)=A sin(kx) cos(ωt).", "[Constraint] Fixed-end boundary conditions require y(0,t)=0 and y(L,t)=0 for every time t.", "[Constraint] The boundary conditions quantize the wavevector to discrete values kₙ=nπ/L with n=1,2,3….", "[Limit] No energy flows past a node because the time-averaged power transmitted by a standing wave is zero everywhere."]}, "accepted": "The standing-wave function y(x,t)=A sin(kx)cos(ωt) with kₙ=nπ/L places nodes where sin(nπx/L)=0, i.e. at x=mL/n for integer m.  Because the ends at x=0 and x=L are fixed, the smallest non-zero n is 1, so the longest permissible wavelength is λ=2L.\n\nHYPOTHESIS: The fundamental mode of a string fixed at both ends has wavelength λ=2L and possesses one antinode at x=L/2.\n\nVERIFICATION: Units: λ and L both have units of length; the relation holds for n=1.", "rejected": "The standing-wave function y(x,t)=A sin(kx)cos(ωt) with kₙ=nπ/L places nodes where sin(nπx/L)=0, i.e. at x=mL/n for integer m, and for n=0 the wavelength becomes λ=∞.", "E_acc": 0.11282415688037872, "C_acc": 0.7652993202209473, "G_acc": 0.5512104543158785, "D_acc": 0.6740284137427807, "H_acc": 0.2042159140110016, "Q_acc": 0.4054135652305559, "E_rej": 0.016349580138921738, "C_rej": 0.9388608336448669, "G_rej": 0.5422364540863782, "D_rej": 0.7722170799970627, "H_rej": 0.1742512583732605, "Q_rej": 0.3625982882920653, "Delta_Q": 0.042815276938490576, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Radioactive decay is random, yet predictable statistically. Given nuclear physics, consider what hypotheses follow about probability in physical laws.", "ancestors": ["[Definition] A radioactive nuclide has a decay constant λ with dimension T⁻¹.", "[Variable] N(t) is the number of undecayed nuclei at time t.", "[Law] The rate equation is dN/dt = −λN.", "[Variable] The mean lifetime τ of a nucleus is τ = 1/λ.", "[Constraint] Each decay is an independent random event with constant probability λdt in interval dt.", "[Limit] For N ≫ 1, the statistical fluctuation in N(t) is proportional to √N."]}, "accepted": "The decay law N(t)=N₀e^(−λt) is integrated from the rate equation; because τ=1/λ, the fraction of nuclei surviving to time τ equals e^(−1).\n\nHYPOTHESIS: After one mean lifetime τ, the surviving fraction of nuclei is exactly e^(−1) ≈ 0.3679.\n\nVERIFICATION: Dimensionless ratio; exact for any single nuclide obeying dN/dt=−λN.", "rejected": "After one mean lifetime τ, the surviving fraction of nuclei is exactly e^(−λτ).", "E_acc": 0.5945711135864258, "C_acc": 0.16294321417808533, "G_acc": 0.5410790089517832, "D_acc": 0.8136255542437235, "H_acc": 0.0922744870185852, "Q_acc": 0.7074961551775536, "E_rej": 0.18311086297035217, "C_rej": 0.3911705017089844, "G_rej": 0.5336587148194667, "D_rej": 0.7999062836170197, "H_rej": 0.20009371638298035, "Q_rej": 0.5234027865983081, "Delta_Q": 0.18409336857924552, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "pH measures acidity logarithmically, yet equal changes do not represent equal effects. Given logarithmic scales, consider what hypotheses can be justified about perception.", "ancestors": ["[Definition] pH is the negative base-10 logarithm of the hydrogen ion activity.", "[Variable] ΔpH = pH_final − pH_initial.", "[Definition] Hydrogen ion activity a_H = 10^(−pH).", "[Variable] Ratio r = a_H_final / a_H_initial = 10^(−ΔpH).", "[Constraint] Equal ΔpH produces equal r regardless of initial pH.", "[Limit] Physical effect scales with r, not with ΔpH."]}, "accepted": "Because the physical effect scales with the activity ratio r = 10^(−ΔpH), a given effect magnitude corresponds to a fixed ratio, not to a fixed ΔpH.  \nHYPOTHESIS: Any two solutions exhibiting the same physical effect have identical hydrogen-ion activity ratios r, independent of their respective pH values.  \nVERIFICATION: r is dimensionless and equals 1 whenever ΔpH = 0, matching the identity case.", "rejected": "Any two solutions exhibiting the same physical effect have identical ΔpH values, independent of their respective hydrogen-ion activity ratios r.", "E_acc": 0.38044244050979614, "C_acc": 0.39622992277145386, "G_acc": 0.6000325307250023, "D_acc": 0.7613207151492437, "H_acc": 0.10606354475021362, "Q_acc": 0.5965510422984759, "E_rej": 0.43808597326278687, "C_rej": 0.4314092695713043, "G_rej": 0.5799962321761996, "D_rej": 0.8361614346504211, "H_rej": 0.16383856534957886, "Q_rej": 0.6119916148949415, "Delta_Q": -0.015440572596465585, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "An object maintains constant velocity unless acted upon, yet real systems always experience friction. Given Newtonian mechanics, consider what hypotheses can be justified about the nature and origin of resistive forces.", "ancestors": ["[Definition] Velocity v is the vector time-derivative of position r.", "[Law] Newton's first law: if net force F_net = 0, then dv/dt = 0.", "[Variable] Friction force f opposes relative motion between contacting surfaces.", "[Constraint] In any macroscopic contact, f ≥ 0."]}, "accepted": "Using Newton’s first law and the non-negative nature of friction, any object sliding on a horizontal surface must experience a net tangential force equal to the friction magnitude; once sliding stops the friction can drop to zero while the velocity remains constant.\n\nHYPOTHESIS: A macroscopic object sliding on a horizontal surface will decelerate to rest if and only if the kinetic friction force is non-zero, and once at rest with zero net applied force it remains stationary.\n\nVERIFICATION: Units consistent (force N, acceleration m s⁻²); holds for any macroscopic contact with f ≥ 0.", "rejected": "A macroscopic object sliding on a horizontal surface will decelerate to rest if and only if the kinetic friction force is zero, and once at rest with zero net applied force it remains stationary.", "E_acc": 0.3714522421360016, "C_acc": 0.37143251299858093, "G_acc": 0.6074151750653982, "D_acc": 0.7646872301896414, "H_acc": 0.2920657768845558, "Q_acc": 0.5823630734036366, "E_rej": 0.3779996931552887, "C_rej": 0.27828919887542725, "G_rej": 0.6081361258402467, "D_rej": 0.7348253726959229, "H_rej": 0.26517462730407715, "Q_rej": 0.5998169051483274, "Delta_Q": -0.01745383174469084, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Species change over generations, yet individuals do not evolve. Given natural selection, consider what hypotheses can be justified about adaptation.", "ancestors": ["[Definition] A population is a group of interbreeding individuals of the same species.", "[Variable] p is the frequency of a heritable trait in the population.", "[Law] Natural selection changes p across generations.", "[Constraint] An individual’s genotype is fixed from birth to death.", "[Limit] Because genotype is fixed, an individual cannot evolve.", "[Limit] Adaptation occurs only at the population level through generational shifts in p."]}, "accepted": "Because natural selection acts only through generational changes in trait frequency p, any measurable evolutionary change requires a nonzero difference in p between parent and offspring cohorts.  \nHYPOTHESIS: A population exhibits detectable evolution by natural selection only if |p_{t+1} − p_t| > 0 across successive generations.  \nVERIFICATION: Dimensionless frequency difference, valid for any sexually reproducing population with discrete generations.", "rejected": "A population exhibits detectable evolution by natural selection only if |p_{t+1} − p_t| > 0 within a single individual’s lifetime.", "E_acc": 0.2616158127784729, "C_acc": 0.5049009919166565, "G_acc": 0.5443054240895435, "D_acc": 0.788616826136907, "H_acc": 0.17680755257606506, "Q_acc": 0.5264082402378942, "E_rej": 0.5185883045196533, "C_rej": 0.1687769591808319, "G_rej": 0.5469868015497923, "D_rej": 0.7886658012866974, "H_rej": 0.2113341987133026, "Q_rej": 0.6678182002156973, "Delta_Q": -0.14140995997780303, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Moving charges create magnetic fields, yet static charges do not. Given electromagnetism, consider what hypotheses follow about relativity of motion.", "ancestors": ["[Definition] A charge q at rest relative to observer S has only electric field E.", "[Law] Observer S measures magnetic field H = qv × r/(4πr³) when q moves at velocity v relative to S.", "[Variable] v_rel is the velocity of q relative to observer S.", "[Constraint] H = 0 whenever v_rel = 0."]}, "accepted": "The premises link the magnetic field H to the relative velocity v_rel of charge q.  \nHYPOTHESIS: H is exactly zero if and only if v_rel = 0.  \nVERIFICATION: Units consistent (H in A m⁻¹, v_rel in m s⁻¹); holds for any inertial observer S.", "rejected": "H is exactly zero whenever v_rel is treated as independent of the charge q.", "E_acc": 0.22464291751384735, "C_acc": 0.25588884949684143, "G_acc": 0.5614505205303431, "D_acc": 0.7501302808523178, "H_acc": 0.13094627857208252, "Q_acc": 0.5654366377741098, "E_rej": 0.39751455187797546, "C_rej": 0.3321017622947693, "G_rej": 0.5551310178956815, "D_rej": 0.7623480558395386, "H_rej": 0.23765194416046143, "Q_rej": 0.5925646334354366, "Delta_Q": -0.027127995661326842, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanical energy is conserved in ideal systems, yet real systems lose usable energy. Given energy conservation, consider what hypotheses follow about non-conservative forces.", "ancestors": ["[Definition] The mechanical energy E_mech of a system is the sum of its kinetic energy K and potential energy U.", "[Law] In an ideal isolated system the total mechanical energy E_mech remains constant over time.", "[Variable] Let W_nc denote the work done on the system by non-conservative forces.", "[Law] The change in mechanical energy ΔE_mech equals the work done by non-conservative forces, ΔE_mech = W_nc.", "[Constraint] For any real system W_nc is non-zero whenever non-conservative forces act.", "[Limit] Because W_nc can be negative, E_mech can decrease, so mechanical energy is not conserved in the presence of non-conservative forces."]}, "accepted": "The premises link non-conservative work to mechanical-energy change.  Because W_nc can be negative, any system subject to such forces must lose energy over time.\n\nHYPOTHESIS: A real system experiencing non-conservative forces undergoes a strictly non-positive change in mechanical energy, ΔE_mech ≤ 0.\n\nVERIFICATION: Units [J] = [J]; holds whenever non-conservative forces act.", "rejected": "A real system experiencing non-conservative forces conserves mechanical energy independently of the magnitude of W_nc.", "E_acc": 0.7288560271263123, "C_acc": 0.11781027168035507, "G_acc": 0.550312226114329, "D_acc": 0.7919505499303341, "H_acc": 0.11730515956878662, "Q_acc": 0.7518167930538766, "E_rej": 0.0018530022352933884, "C_rej": 0.9933386445045471, "G_rej": 0.5292153364862315, "D_rej": 0.8696378171443939, "H_rej": 0.1629527285695076, "Q_rej": 0.365363529638853, "Delta_Q": 0.3864532634150236, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymes lower activation energy, yet do not change equilibrium. Given catalysis, consider what hypotheses can be justified about reaction control.", "ancestors": ["[Definition] Activation energy Ea is the minimum energy reactants must gain to reach the transition state.", "[Law] The Arrhenius equation states k = A e^(–Ea/RT) for rate constant k, pre-exponential A, gas constant R, and temperature T.", "[Law] Catalysts provide an alternative reaction path with a lower Ea.", "[Variable] Let k_cat be the rate constant of the catalyzed path.", "[Constraint] At equilibrium, the forward rate equals the reverse rate for each elementary step.", "[Limit] Because Ea affects k but not the equilibrium constant K, catalysts do not alter K."]}, "accepted": "Using the Arrhenius equation for both the uncatalyzed and catalyzed paths, the ratio of rate constants is k_cat/k = e^[(Ea – Ea_cat)/RT]. Because catalysts lower Ea while T and R remain fixed, the exponent is positive, so k_cat exceeds k by a temperature-dependent factor that increases as T drops.\n\nHYPOTHESIS: The catalyzed rate constant k_cat is strictly greater than the uncatalyzed rate constant k at every temperature T > 0, and the ratio k_cat/k increases monotonically as temperature decreases.\n\nVERIFICATION: The derived ratio is dimensionless and valid for all T > 0 where the Arrhenius law applies.", "rejected": "The catalyzed rate constant k_cat is strictly greater than the uncatalyzed rate constant k at every temperature T < 0.", "E_acc": 0.3626299500465393, "C_acc": 0.31389203667640686, "G_acc": 0.5418747280491516, "D_acc": 0.7707756981253624, "H_acc": 0.17739301919937134, "Q_acc": 0.5908013609936462, "E_rej": 0.0499400869011879, "C_rej": 0.5341942310333252, "G_rej": 0.5308363795920741, "D_rej": 0.7643814384937286, "H_rej": 0.23561856150627136, "Q_rej": 0.44362488733022476, "Delta_Q": 0.14717647366342146, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exothermic reactions release heat, yet products are more stable. Given energy diagrams, consider what hypotheses can be justified about bond energies.", "ancestors": ["[Variable] Let the enthalpy change of reaction be ΔHrxn.", "[Definition] ΔHrxn is the total bond‐breaking energy minus total bond‐forming energy.", "[Law] Exothermic reactions obey ΔHrxn < 0.", "[Constraint] ΔHrxn < 0 therefore total bond‐breaking energy < total bond‐forming energy.", "[Limit] Products cannot have smaller (weaker) total bond energies than reactants."]}, "accepted": "The enthalpy change of reaction is negative when the energy released by forming bonds exceeds the energy required to break bonds. From the premises, this exothermic condition implies that the total bond-forming energy must be strictly greater than the total bond-breaking energy. Combining this with the limit that products cannot have weaker total bond energies than reactants, the only consistent scenario is that the products possess stronger bonding (lower energy) than the reactants.\n\nHYPOTHESIS: In every exothermic reaction the collective bond energy of the products exceeds that of the reactants by an amount equal to |ΔHrxn|.\n\nVERIFICATION: Units (kJ mol⁻¹) match on both sides of the energy balance.", "rejected": "In every exothermic reaction the collective bond energy of the products is less than that of the reactants by an amount equal to |ΔHrxn|.", "E_acc": 0.28149762749671936, "C_acc": 0.3047611117362976, "G_acc": 0.5509145583491772, "D_acc": 0.8109531968832016, "H_acc": 0.11177334934473038, "Q_acc": 0.584693282013759, "E_rej": 0.28928470611572266, "C_rej": 0.32234758138656616, "G_rej": 0.5573945584474131, "D_rej": 0.8638490736484528, "H_rej": 0.13615092635154724, "Q_rej": 0.592949529341422, "Delta_Q": -0.008256247327662947, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Cells are the basic unit of life, yet differ vastly in function. Given cell theory, consider what hypotheses can be justified about specialization.", "ancestors": ["[Definition] A cell is the smallest unit that can carry out all life processes.", "[Law] Cell theory states that all living organisms are composed of one or more cells.", "[Variable] Let s denote the number of specialized functions performed by a single cell.", "[Constraint] s is an integer satisfying 0 ≤ s ≤ total possible functions in the organism."]}, "accepted": "The premises define a cell as the minimal life unit and impose the integer constraint 0 ≤ s ≤ total possible functions. Because a living organism must perform at least one life process and the cell is the smallest unit capable of doing so, the lower bound on s for any cell in a living organism must exceed zero.\n\nHYPOTHESIS: Every cell in a living organism performs at least one specialized function, so s ≥ 1.\n\nVERIFICATION: Units dimensionless; holds for every living cell under cell theory.", "rejected": "Every cell in a living organism performs at least one specialized function, so s ≥ 1 for any atom in the sample.", "E_acc": 0.3408946990966797, "C_acc": 0.4346476197242737, "G_acc": 0.5889915644656867, "D_acc": 0.8411913812160492, "H_acc": 0.14509204030036926, "Q_acc": 0.5868662708904595, "E_rej": 0.5616516470909119, "C_rej": 0.13145418465137482, "G_rej": 0.579673494794406, "D_rej": 0.7970782816410065, "H_rej": 0.20292171835899353, "Q_rej": 0.6972628406481818, "Delta_Q": -0.11039656975772227, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Work transfers energy, yet identical work can result in different motions. Given work–energy relations, consider what hypotheses can be justified about energy partitioning.", "ancestors": ["[Definition] Work W is the line integral of force F along displacement s, W = ∫ F·ds.", "[Law] The work–energy theorem states net work equals change in kinetic energy, W_net = ΔK.", "[Variable] Internal energy U comprises microscopic kinetic and potential components excluding bulk motion.", "[Constraint] Conservation of energy requires W_net = ΔK + ΔU for isolated systems with no heat Q."]}, "accepted": "Combining the work–energy theorem with the conservation-of-energy constraint for an isolated system shows that any work done on the system must be partitioned between changing bulk kinetic energy and changing internal energy.  \nHYPOTHESIS: For an isolated system with no heat exchange, the work input equals the sum of the resulting changes in kinetic and internal energy, W = ΔK + ΔU.  \nVERIFICATION: Both sides carry energy units (J), and the equation holds whenever the system is isolated and Q = 0.", "rejected": "For any thermodynamic process, the work input equals the sum of the resulting changes in kinetic and internal energy, W = ΔK + ΔU.", "E_acc": 0.32099300622940063, "C_acc": 0.3621128499507904, "G_acc": 0.5616423815954477, "D_acc": 0.7992193400859833, "H_acc": 0.18863994628190994, "Q_acc": 0.5771836815867573, "E_rej": 0.40199097990989685, "C_rej": 0.2141103297472, "G_rej": 0.5782753014937043, "D_rej": 0.8503827154636383, "H_rej": 0.1496172845363617, "Q_rej": 0.6485451029613614, "Delta_Q": -0.0713614213746041, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy is quantized at small scales, yet appears continuous macroscopically. Given quantum theory, consider what hypotheses follow about scale dependence.", "ancestors": ["[Definition] Quantum energy E occurs only in integer multiples of a smallest unit ε.", "[Variable] ε denotes the magnitude of the smallest energy quantum.", "[Definition] Macroscopic energy E is any E ≫ ε.", "[Limit] The discrete step ε/E tends to zero as E increases.", "[Constraint] Detectable energy resolution ΔE satisfies ΔE ≥ ε.", "[Limit] For E ≫ ε, ΔE/E approaches zero."]}, "accepted": "The discrete quantum step ε becomes observationally negligible when the total energy E is sufficiently large, forcing the relative resolution ΔE/E to fall below any preset bound.\n\nHYPOTHESIS: For every preset bound δ>0 there exists a threshold energy E₀ such that for all E>E₀ the detectable relative energy resolution satisfies ΔE/E < δ.\n\nVERIFICATION: Dimensionless ratio, valid in the macroscopic regime E≫ε where ε/E→0 and ΔE≥ε.", "rejected": "For every macroscopic energy E≫ε there exists a bound δ>0 such that for all δ>0 the threshold energy E₀ satisfies E>E₀.", "E_acc": 0.3246205449104309, "C_acc": 0.4267233610153198, "G_acc": 0.566254805889912, "D_acc": 0.8199444711208344, "H_acc": 0.11738374829292297, "Q_acc": 0.5775429718429222, "E_rej": 0.3962146043777466, "C_rej": 0.22914816439151764, "G_rej": 0.5742872541304678, "D_rej": 0.8284395933151245, "H_rej": 0.1715604066848755, "Q_rej": 0.6364240772556513, "Delta_Q": -0.05888110541272906, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Translation reads codons, yet errors are rare. Given molecular machinery, consider what hypotheses can be justified about redundancy.", "ancestors": ["[Definition] A codon is a 3-nucleotide RNA sequence that pairs with an anticodon.", "[Variable] The number of codons is 64.", "[Variable] The number of amino acids is 20.", "[Constraint] Mapping 64 codons to 20 amino acids forces many-to-one assignments.", "[Definition] Redundancy here denotes multiple codons assigned to one amino acid.", "[Limit] Error rate tolerated by the translational apparatus is below 10⁻³ per codon."]}, "accepted": "With 64 codons mapping to 20 amino acids, the minimal redundancy is 3.2 codons per amino acid, so at least one amino acid must be encoded by 4 or more codons.  \nHYPOTHESIS: Every natural genetic code contains at least one amino acid that is assigned 4 or more distinct codons.  \nVERIFICATION: 64/20 = 3.2 codons per amino acid on average, so the maximum frequency cannot be below 4 without violating the integer count.", "rejected": "With 64 codons mapping to 20 amino acids, the minimal redundancy is 2.8 codons per amino acid, so no amino acid needs to be encoded by more than 3 codons.", "E_acc": 0.44644567370414734, "C_acc": 0.1746552437543869, "G_acc": 0.5834954800084233, "D_acc": 0.823533167441686, "H_acc": 0.21965302526950836, "Q_acc": 0.6584430803234378, "E_rej": 0.03682045638561249, "C_rej": 0.7066444158554077, "G_rej": 0.5857953410595655, "D_rej": 0.8527108132839203, "H_rej": 0.1472891867160797, "Q_rej": 0.4426895659416914, "Delta_Q": 0.2157535143817464, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Isomeric multiplicity producing divergent properties through subtle electronic delocalization: hypotheses on structure–function mapping.", "ancestors": ["[Definition] Isomer multiplicity is the count of distinct molecular graphs per formula.", "[Definition] π is electron count in delocalized orbitals.", "[Constraint] π maximizes delocalization given structure.", "[Variable] E is electronic energy of isomer.", "[Limit] E ≥ E₀ where E₀ is minimized delocalized energy.", "[Variable] ΔE is pairwise isomer energy difference.", "[Constraint] ΔE exists only with isomer multiplicity.", "[Law] ΔE maps structure to function."]}, "accepted": "Because isomer multiplicity forces at least two distinct structures, the energy difference ΔE is necessarily non-zero; the lower bound E₀ applies to every isomer, so the smallest attainable ΔE equals the gap between the lowest-energy isomer and the next-lowest.  \nHYPOTHESIS: The minimal observable energy difference between isomers of a given formula is ΔE_min = E₁ – E₀, where E₁ is the energy of the second-most-stable isomer and E₀ is the delocalized energy minimum.  \nVERIFICATION: Both terms have energy units, so the difference is dimensionally consistent and valid for any set of isomers.  \nCONCLUSION: Quantifies the smallest measurable electronic energy gap that can exist when isomer multiplicity is present.", "rejected": "The minimal observable energy difference between isomers of a given formula is ΔE_min = E₁ – E₀, where E₁ is the energy of the second-most-stable isomer and E₀ is the delocalized energy minimum.", "E_acc": 0.5663814544677734, "C_acc": 0.1653844565153122, "G_acc": 0.5139897916039141, "D_acc": 0.7977394312620163, "H_acc": 0.26386409997940063, "Q_acc": 0.6727969796125156, "E_rej": 0.2285986989736557, "C_rej": 0.23616443574428558, "G_rej": 0.541706811869517, "D_rej": 0.7552012205123901, "H_rej": 0.24479877948760986, "Q_rej": 0.5562484510708601, "Delta_Q": 0.11654852854165554, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Power flow in networks with reactive and non-linear elements: hypotheses about transient energy trapping and route-dependent dissipation.", "ancestors": ["[Definition] A network is a graph of nodes connected by edges.", "[Variable] N is the number of nodes.", "[Law] Power equals voltage times current.", "[Definition] Reactive elements are capacitors and inductors.", "[Constraint] Energy cannot be created or destroyed.", "[Limit] The network has no external inputs."]}, "accepted": "<derivation sentences>\nThe premises define a network with N nodes and no external inputs. Energy conservation applies to this system. From the constraint that energy cannot be created or destroyed, the total energy in the network remains constant. The reactive elements (capacitors and inductors) store energy in electric and magnetic fields. With no external inputs, the network's energy must remain within its internal components.\n\nHYPOTHESIS: The total energy stored in all reactive elements equals the initial energy of the network, remaining constant over time.\n\nVERIFICATION: Units check: energy in joules, consistent with conservation law.\n\nCONCLUSION: Energy conservation constrains reactive elements to contain all network energy.", "rejected": "The total energy stored in all reactive elements equals the initial energy of the universe, remaining constant over time.", "E_acc": 0.5325323343276978, "C_acc": 0.10400120168924332, "G_acc": 0.5937398353416938, "D_acc": 0.7313915288282765, "H_acc": 0.20033366978168488, "Q_acc": 0.6839523658162863, "E_rej": 0.042218923568725586, "C_rej": 0.6111001372337341, "G_rej": 0.5927075532963499, "D_rej": 0.6864118576049805, "H_rej": 0.31358814239501953, "Q_rej": 0.414910717564635, "Delta_Q": 0.2690416482516513, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] A catalyst is a substance that increases reaction rate without being consumed.", "[Variable] k is the rate constant for a reaction.", "[Definition] k = κZ where Z is the transmission coefficient along the reaction coordinate.", "[Limit] A catalyst cannot alter the forward and reverse rate constants independently.", "[Constraint] A catalyst must accelerate both directions equally.", "[Variable] κ is the transmission coefficient along the reaction coordinate.", "[Constraint] Catalysis requires lowering κ to enhance reaction rate."]}, "accepted": "The premises define k = κZ and require a catalyst to lower κ to raise k.  Eliminate any case that violates the bidirectional constraint: a catalyst must accelerate both directions equally.  The only consistent case is that the catalyst lowers κ uniformly along the reaction coordinate.\n\nHYPOTHESIS: A catalyst lowers the transmission coefficient κ uniformly along the reaction coordinate, thereby increasing the rate constant k without altering the bidirectional balance.\n\nVERIFICATION: Units check: κ is dimensionless; k increases while κ decreases.\n\nCONCLUSION: Catalyst acts by lowering κ uniformly.", "rejected": "A catalyst raises the transmission coefficient κ uniformly along the reaction coordinate, thereby increasing the rate constant k without altering the bidirectional balance.", "E_acc": 0.6555728316307068, "C_acc": 0.111592598259449, "G_acc": 0.5928869981580647, "D_acc": 0.7886448154846827, "H_acc": 0.18743030726909637, "Q_acc": 0.7319166618389621, "E_rej": 0.003009711392223835, "C_rej": 0.9773335456848145, "G_rej": 0.572674069708834, "D_rej": 0.8593716621398926, "H_rej": 0.14062833786010742, "Q_rej": 0.37778251686443887, "Delta_Q": 0.3541341449745232, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Organelle network integration and cross-compartment energy routing: hypotheses on how local ATP microgradients influence cellular decision-making.", "ancestors": ["[Definition] An organelle is a membrane-bound subcellular structure with a dedicated biochemical function.", "[Law] ATP is the universal cellular energy currency.", "[Variable] E is the local ATP energy per unit volume.", "[Constraint] No organelle can exchange ATP faster than diffusion allows.", "[Limit] A single organelle cannot exceed the cell's total ATP budget.", "[Definition] A microgradient is a spatial difference in E smaller than the organelle scale."]}, "accepted": "Microgradients smaller than an organelle cannot sustain ATP faster than diffusion replenishes them.  \nHYPOTHESIS: Any microgradient in E steeper than the diffusion-limited ATP flux is thermodynamically impossible.  \nVERIFICATION: Units ΔE/Δx ≤ D ATP per volume per distance, regime holds when diffusion dominates.  \nCONCLUSION: Microgradients must remain shallow enough to stay within diffusion limits.", "rejected": "Microgradients can exchange ATP faster than diffusion allows.", "E_acc": 0.3498916029930115, "C_acc": 0.2470078319311142, "G_acc": 0.515369939734228, "D_acc": 0.815739743411541, "H_acc": 0.1953589916229248, "Q_acc": 0.6022519519785419, "E_rej": 0.06359275430440903, "C_rej": 0.8437544703483582, "G_rej": 0.5153121356852353, "D_rej": 0.8038201928138733, "H_rej": 0.1961798071861267, "Q_rej": 0.3945354172028601, "Delta_Q": 0.20771653477568175, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Latent energy flows at phase boundaries analyzed by statistical ensembles: hypotheses on metastable pathways and nucleation energetics.", "ancestors": ["[Definition] Phase boundary is the interface between two coexisting bulk phases.", "[Variable] Interface energy is σ, measured per unit area.", "[Variable] Latent energy is L, released during phase transition.", "[Constraint] Conservation requires L to be released at the boundary.", "[Law] Gibbs energy per particle is g = h − Ts.", "[Variable] Metastable excess is Δg = g − g_stable.", "[Limit] Minimum Δg = 0 at coexistence."]}, "accepted": "Because the latent energy L must be released at the two-dimensional phase boundary whose excess energy is σ, the released energy per unit area cannot fall below this interfacial cost.  \nHYPOTHESIS: A first-order phase transition is thermodynamically allowed only if the latent energy released per unit area of the newly created boundary equals or exceeds the interface energy, L/A ≥ σ.  \nVERIFICATION: Both sides have units J m⁻², so the inequality is dimensionally consistent.  \nCONCLUSION: The criterion sets a lower bound on L (or upper bound on boundary area) for the transition to proceed.", "rejected": "A first-order phase transition is thermodynamically allowed only if the interface energy σ equals or exceeds the latent energy released per unit area of the newly created boundary, σ ≥ L/A.", "E_acc": 0.28376463055610657, "C_acc": 0.29770514369010925, "G_acc": 0.5361049324292253, "D_acc": 0.7171378238126636, "H_acc": 0.2243361994624138, "Q_acc": 0.5538032917309466, "E_rej": 0.3015536069869995, "C_rej": 0.20518045127391815, "G_rej": 0.55328486522194, "D_rej": 0.8307332396507263, "H_rej": 0.16926676034927368, "Q_rej": 0.6093069367809222, "Delta_Q": -0.055503645049975625, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Power flow in networks with reactive and non-linear elements: hypotheses about transient energy trapping and route-dependent dissipation.", "ancestors": ["[Definition] A network is a collection of nodes connected by branches.", "[Definition] A branch is a path for current flow between two nodes.", "[Definition] Power is the rate of energy transfer in a branch.", "[Definition] Reactive elements are capacitors and inductors.", "[Definition] Non-linear elements have voltage-current relationships not satisfying superposition.", "[Definition] Transient energy is energy temporarily stored in reactive elements.", "[Variable] p is instantaneous power in a branch.", "[Variable] t is time.", "[Constraint] Energy conservation requires total energy entering a node equals energy leaving the node.", "[Limit] Maximum transient energy stored is finite for bounded sources."]}, "accepted": "The premises define instantaneous power p in a branch as the rate of energy transfer, so integrating p over any interval gives the net energy that has crossed the branch.  \nHYPOTHESIS: The net energy transferred through a branch during any interval from t₁ to t₂ equals the integral of instantaneous power, ∫_{t₁}^{t₂} p dt.  \nVERIFICATION: Units check: p in watts, time in seconds, integral in joules.  \nCONCLUSION: This yields a measurable, falsifiable value for energy moved through the branch.", "rejected": "The net energy transferred through a branch during any interval from t₁ to t₂ exceeds the integral of instantaneous power, ∫_{t₁}^{t₂} p dt, by the amount of transient energy simultaneously stored in reactive elements.", "E_acc": 0.5747733116149902, "C_acc": 0.1314297467470169, "G_acc": 0.6023174449801445, "D_acc": 0.7542616575956345, "H_acc": 0.21465268731117249, "Q_acc": 0.6959965959191323, "E_rej": 0.1644587367773056, "C_rej": 0.5140302181243896, "G_rej": 0.6234046327881515, "D_rej": 0.8226402401924133, "H_rej": 0.17735975980758667, "Q_rej": 0.5180045760236681, "Delta_Q": 0.1779920198954642, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["[Definition] A rigid body is an idealized body whose constituent particles maintain fixed relative positions under any applied force.", "[Law] Angular momentum L = Σ r × p for a system is the vector sum of momentum moments relative to a reference point.", "[Variable] Angular momentum L remains constant in an isolated system with no external torque.", "[Constraint] A deformable body may redistribute internal angular momenta across its components without altering total L.", "[Definition] A torque τ is the rate of change of angular momentum: τ = dL/dt.", "[Limit] Internal torques within a deformable body must sum to zero, conserving total L without external torques.", "[Law] Centripetal acceleration a = ω²r acts radially toward the center of rotation in a rotating frame.", "[Constraint] Redistribution alters internal torques but does not create angular momentum de novo within a deformable body."]}, "accepted": "A deformable body conserves its total angular momentum L while redistributing internal torques, constrained by the zero-sum of internal torques and the absence of external torque.  \nHYPOTHESIS: The maximum angular momentum that can be redistributed within a deformable body is limited by the initial total L, which remains invariant.  \nVERIFICATION: Units check: L in kg·m²/s; regime holds for any torque redistribution.  \nCONCLUSION: Total L sets an upper bound on internal rearrangement.", "rejected": "A deformable body redistributes internal torques only when its total angular momentum L is conserved.", "E_acc": 0.34697580337524414, "C_acc": 0.3656628727912903, "G_acc": 0.5543241600971669, "D_acc": 0.7468100674450397, "H_acc": 0.15644404292106628, "Q_acc": 0.5755426076706499, "E_rej": 0.12972323596477509, "C_rej": 0.7083273530006409, "G_rej": 0.5549696606467478, "D_rej": 0.867737352848053, "H_rej": 0.13226264715194702, "Q_rej": 0.4685666381730698, "Delta_Q": 0.10697596949758009, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Homeostatic control seen as multi-timescale feedback: hypotheses on robustness limits and failure modes under extreme perturbations.", "ancestors": ["[Definition] Homeostasis is the maintenance of a state variable within a bounded range by a system.", "[Law] Homeostasis operates via negative feedback loops.", "[Variable] τ is the effective timescale of perturbations.", "[Constraint] Perturbations must occur within τ to affect regulation.", "[Limit] Perturbations exceeding τ timescale escape control."]}, "accepted": "<derivation sentences>\nThe premises define homeostasis as bounded-range maintenance via negative feedback, with perturbations constrained by an effective timescale τ. Perturbations must occur within τ to affect regulation; those exceeding τ escape control. This implies a deterministic threshold separating regulated from unregulated perturbations.\n\nHYPOTHESIS: Perturbations with duration ≤ τ are countered by negative feedback; perturbations with duration > τ escape control and disrupt the state variable.\nVERIFICATION: Units check: τ has units of time; perturbation duration has units of time; threshold is dimensionless ratio of durations.\nCONCLUSION: Perturbations within τ are countered; perturbations exceeding τ escape control.", "rejected": "Perturbations with duration ≤ τ are countered by negative feedback; perturbations with duration > τ additively combine with τ.", "E_acc": 0.4798436760902405, "C_acc": 0.17912523448467255, "G_acc": 0.6018273870327643, "D_acc": 0.7690611236861774, "H_acc": 0.13198845088481903, "Q_acc": 0.669106912985444, "E_rej": 0.30325058102607727, "C_rej": 0.30262482166290283, "G_rej": 0.5625435853643077, "D_rej": 0.7576771676540375, "H_rej": 0.24232283234596252, "Q_rej": 0.5702620773443154, "Delta_Q": 0.09884483564112856, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Observable consequences of fields: hypotheses connecting gauge choices to measurable energy-momentum flow.", "ancestors": ["[Definition] A field is a continuous assignment of a tensor quantity to every spacetime point.", "[Definition] A gauge transformation is a spacetime-dependent change of internal variables leaving observables unchanged.", "[Definition] The energy-momentum tensor T^{μν} encodes density and flux of energy and momentum.", "[Law] T^{μν} is obtained by functional differentiation of the field action with respect to the metric tensor.", "[Variable] A gauge choice is specified by setting a scalar function χ(x) such that ∇·A = χ(x).", "[Constraint] Conservation requires ∂_μ T^{μν} = 0 for any gauge choice χ(x).", "[Limit] T^{μν} is invariant under χ(x) → χ(x) + constant.", "[Limit] Only the spatial integrals ∫ d³x T^{0ν} yield measurable conserved quantities."]}, "accepted": "The conservation law ∂_μ T^{μν}=0 holds for any gauge choice χ(x), while T^{μν} itself is invariant under a constant shift of χ(x).  Combining these two facts, the spatial integrals ∫ d³x T^{0ν} remain unchanged when χ(x) is shifted by a constant, so the measurable conserved quantities are independent of the gauge choice.\n\nHYPOTHESIS: The measurable conserved quantities ∫ d³x T^{0ν} are independent of the scalar function χ(x) used to specify the gauge.\nVERIFICATION: Units match (T^{0ν} has energy density units, χ(x) is dimensionless scalar).\nCONCLUSION: Gauge freedom does not affect measurable conserved quantities.", "rejected": "The measurable conserved quantities ∫ d³x T^{0ν} depend on the arbitrary scalar function χ(x) used to specify the gauge.", "E_acc": 0.797807514667511, "C_acc": 0.06257154047489166, "G_acc": 0.5617865162785165, "D_acc": 0.7996118128299713, "H_acc": 0.13738411664962769, "Q_acc": 0.7853692004620099, "E_rej": 0.14816150069236755, "C_rej": 0.58260577917099, "G_rej": 0.5618052477948368, "D_rej": 0.8626122176647186, "H_rej": 0.13738778233528137, "Q_rej": 0.49907200923189526, "Delta_Q": 0.2862971912301146, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stochastic decay processes framed as energy/entropy flows: hypotheses about microscale correlations that produce macroscopic rate laws.", "ancestors": ["[Definition] A stochastic decay process is a Markovian transition from an initial state to a final state at a random time τ.", "[Variable] τ denotes the random lifetime of a single unstable entity.", "[Law] For an ensemble of N identical entities the survival fraction N(t)/N(0) decays as e^(–λt) with constant λ.", "[Variable] λ is the first-order rate coefficient with units s^(–1).", "[Definition] Entropy S is k_B ln Ω where Ω counts the microstates compatible with a prescribed macrostate.", "[Constraint] For an isolated system dS/dt ≥ 0, equality holding only at equilibrium.", "[Definition] A microstate specifies the positions q_i and momenta p_i of all particles.", "[Law] Liouville’s theorem states that the phase-space density ρ({q_i,p_i}) is constant along trajectories of an isolated Hamiltonian system.", "[Limit] No deterministic Hamiltonian trajectory can produce the exponential relaxation law unless the initial phase-space distribution is exactly aligned with the unstable manifold."]}, "accepted": "Liouville’s theorem keeps the phase-space density ρ constant, so the number of microstates Ω and the entropy S = k_B ln Ω remain fixed for an isolated Hamiltonian system.  The observed exponential decay law, however, requires a monotonic decrease in the survival fraction and hence a continual increase in the number of accessible microstates for the decayed sub-ensemble.  To reconcile these facts, the system that exhibits the decay cannot be isolated and Hamiltonian; instead, it must be an open subsystem whose phase-space volume can expand, allowing dS/dt ≥ 0 to hold for the combined supersystem.\n\nHYPOTHESIS: Any system displaying first-order exponential decay with rate λ is an open subsystem whose entropy increases at the rate dS/dt = λk_B.\n\nVERIFICATION: Units check—λk_B has dimensions s⁻¹ × J K⁻¹ = J K⁻¹ s⁻¹, matching entropy flow per unit time.\n\nCONCLUSION: Exponential decay implies mandatory entropy production in the subsystem.", "rejected": "Any isolated Hamiltonian system displaying first-order exponential decay with rate λ has an entropy that increases at the rate dS/dt = λk_B.", "E_acc": 0.29426059126853943, "C_acc": 0.3127152621746063, "G_acc": 0.5385687190573663, "D_acc": 0.76624795794487, "H_acc": 0.21495360881090164, "Q_acc": 0.5652030994649977, "E_rej": 0.23889096081256866, "C_rej": 0.35809892416000366, "G_rej": 0.5647595854243264, "D_rej": 0.8296151459217072, "H_rej": 0.17038485407829285, "Q_rej": 0.5618839642731472, "Delta_Q": 0.003319135191850453, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-mediated energy transfer when the medium stores both kinetic and potential micro-energy: hypotheses separating local vs. transport contributions.", "ancestors": ["[Limit] A wave transports energy without matter translation.", "[Definition] Medium kinetic micro-energy density is dx/dt at point x.", "[Definition] Medium potential micro-energy density is kx at point x.", "[Law] Micro-energy is dx/dt and kx separate.", "[Variable] Local micro-energy is dx.", "[Variable] Transport micro-energy is dx/dt."]}, "accepted": "The premises define micro-energy densities as dx/dt and kx at point x, with local micro-energy dx and transport micro-energy dx/dt. A wave transports energy without matter translation, so the local micro-energy dx must be conserved at point x. The transport micro-energy dx/dt is the rate of change of local micro-energy dx. Thus, the local micro-energy dx is the integral of transport micro-energy dx/dt over time.\n\nHYPOTHESIS: The local micro-energy dx at point x is the integral of transport micro-energy dx/dt over time, dx = ∫ dx/dt dt.\n\nVERIFICATION: Units check: dx has units of energy, dx/dt has units of energy/time, integral over time yields energy.\n\nCONCLUSION: The local micro-energy dx is conserved at point x, determined by transport micro-energy dx/dt.", "rejected": "The local micro-energy dx at point x equals the integral of medium potential micro-energy kx over time, dx = ∫ kx dt.", "E_acc": 0.6890809535980225, "C_acc": 0.11094451695680618, "G_acc": 0.575951462611556, "D_acc": 0.8421625686543328, "H_acc": 0.17297975718975067, "Q_acc": 0.7508602132222483, "E_rej": 0.40116265416145325, "C_rej": 0.3376438617706299, "G_rej": 0.5684996854979545, "D_rej": 0.8292335271835327, "H_rej": 0.17076647281646729, "Q_rej": 0.6152900191489608, "Delta_Q": 0.13557019407328752, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Le Chatelier–style responses reframed for multi-variable driven equilibria: hypotheses about coupled control parameters and hysteresis.", "ancestors": ["[Definition] An equilibrium state is the condition where forward and reverse process rates are equal.", "[Variable] Let K denote the equilibrium constant.", "[Law] K depends only on temperature for a given reaction.", "[Variable] Let x be the mole-number vector of species.", "[Constraint] At equilibrium the product Πᵢ(xᵢ)^{νᵢ} equals K.", "[Variable] Let P be the set of externally imposed parameters (T, p, fields).", "[Limit] K cannot adjust if a parameter in P is held fixed."]}, "accepted": "Because K is fixed when temperature is held constant, the product Πᵢ(xᵢ)^{νᵢ} must likewise stay constant; any change in the mole number of one species must be offset by compensating changes in others.  This imposes a stoichiometric conservation law on the equilibrium composition.\n\nHYPOTHESIS: If temperature is held fixed, the weighted geometric mean of the mole numbers, Πᵢ(xᵢ)^{νᵢ}, remains invariant under any external perturbation that alters individual xᵢ.\n\nVERIFICATION: The product is dimensionless when each xᵢ is expressed in moles and the exponents νᵢ are the dimensionless stoichiometric coefficients.\n\nCONCLUSION: Equilibrium composition shifts obey a fixed-product constraint.", "rejected": "Because each xᵢ is independent, the product Πᵢ(xᵢ)^{νᵢ} can vary freely while temperature remains fixed.", "E_acc": 0.611721932888031, "C_acc": 0.10731581598520279, "G_acc": 0.5266382543341024, "D_acc": 0.7199953913688659, "H_acc": 0.33450593054294586, "Q_acc": 0.6779295527556679, "E_rej": 0.003970660734921694, "C_rej": 0.9627116322517395, "G_rej": 0.5268987004383234, "D_rej": 0.66156405210495, "H_rej": 0.33843594789505005, "Q_rej": 0.3124978274892783, "Delta_Q": 0.3654317252663896, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Interference and coherence as energy localization phenomena: hypotheses about phase correlations and decoherence in composite sources.", "ancestors": ["[Definition] Interference is energy redistribution from overlapping fields.", "[Definition] Coherence is amplitude-phase predictability in interference.", "[Law] Energy density w equals field amplitude squared.", "[Variable] E is field amplitude.", "[Constraint] Interference requires overlapping fields at E.", "[Limit] Predictability requires correlation of amplitude E.", "[Definition] Phase correlation is relative phase value.", "[Constraint] Interference requires amplitude E correlation of phase.", "[Variable] k is correlation value of phase.", "[Limit] Correlation range limits interference predictability."]}, "accepted": "From the premises, interference demands overlapping fields whose amplitude correlation k governs predictability.  Correlation range limits interference predictability, so only above a threshold k does interference yield stable redistribution.\n\nHYPOTHESIS: Interference produces observable energy redistribution only when the phase correlation value k exceeds the threshold k ≥ 0.5.\nVERIFICATION: Dimensionless k; regime holds for overlapping fields.\nCONCLUSION: Threshold k discriminates observable redistribution.", "rejected": "Interference produces observable energy redistribution only when the phase correlation value k exceeds the threshold k ≥ 0.5 J.", "E_acc": 0.5819246768951416, "C_acc": 0.18032768368721008, "G_acc": 0.5637111827963963, "D_acc": 0.7463616967201233, "H_acc": 0.14007794857025146, "Q_acc": 0.6865186473773793, "E_rej": 0.034584205597639084, "C_rej": 0.20630154013633728, "G_rej": 0.5493860885035247, "D_rej": 0.8113257884979248, "H_rej": 0.1886742115020752, "Q_rej": 0.5223899079021067, "Delta_Q": 0.16412873947527262, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Workless magnetic forces revisited as mediators of field energy redistribution: hypotheses connecting Lorentz-force trajectories to field energy traces.", "ancestors": ["[Definition] Magnetic field B is a vector field assigning a vector to every point in space.", "[Definition] A current element I·dl is a vector Idl pointing along an infinitesimal wire segment.", "[Definition] Lorentz force on a current element is dF = I dl × B.", "[Variable] θ is the angle between dl and B.", "[Law] The magnitude of dF is I dl B sinθ.", "[Definition] The work done by a force F in displacement dr is dW = F·dr.", "[Constraint] For the Lorentz force dF, dW = (I dl × B)·dr = 0 when dr is along the charge’s velocity v because dl is parallel to v and v·(v × B) = 0.", "[Definition] Field energy density is u = B²/(2μ₀).", "[Variable] P is an infinitesimal volume element dV.", "[Limit] The total magnetic field energy is ∫ u dV and is unchanged by purely workless Lorentz forces."]}, "accepted": "The Lorentz force on a current element is always perpendicular to the element’s velocity, so the work dW = (I dl × B)·dr vanishes when dr is along v. Because the total magnetic energy ∫ (B²/2μ₀) dV is unchanged by any force that does no work, any spatial redistribution of B produced by these workless forces leaves the integrated energy invariant.\n\nHYPOTHESIS: A magnetic-field redistribution caused solely by Lorentz forces on steady current elements conserves the total magnetic energy ∫ (B²/2μ₀) dV.\n\nVERIFICATION: Both sides have units of energy (J), valid for magnetostatic regimes with no time-varying electric fields.\n\nCONCLUSION: Energy conservation constrains field rearrangements under workless Lorentz forces.", "rejected": "A magnetic-field redistribution caused solely by Lorentz forces on steady current elements conserves the total electric potential energy ∫ (B²/2μ₀) dV.", "E_acc": 0.47651877999305725, "C_acc": 0.2680494785308838, "G_acc": 0.5405386920756428, "D_acc": 0.7706476956605911, "H_acc": 0.23041610419750214, "Q_acc": 0.628541405419237, "E_rej": 0.27143967151641846, "C_rej": 0.4695415794849396, "G_rej": 0.5538687793305144, "D_rej": 0.8035423159599304, "H_rej": 0.24557210505008698, "Q_rej": 0.5344485941110179, "Delta_Q": 0.09409281130821912, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["[Definition] Centripetal acceleration a of a point is a = v²/r toward the center of its circular path of radius r at speed v.", "[Definition] Angular momentum L of a point mass m at distance r is L = mvr when v is perpendicular to r.", "[Law] Torque τ equals the time derivative of angular momentum: τ = dL/dt.", "[Variable] Let ω be the angular speed of the rotating frame attached to the body.", "[Constraint] In a frame rotating at ω, the Coriolis force on mass m is −2m ω × v_rel where v_rel is velocity relative to the frame.", "[Limit] The rigid-body approximation requires internal torques to integrate to zero, so external torque alone changes total L.", "[Definition] A deformable body permits non-zero internal torques between its particles, so dL/dt may include internal τ_int."]}, "accepted": "<derivation sentences>\nThe premises define centripetal acceleration a = v²/r and angular momentum L = mvr for a point mass, with torque τ = dL/dt. In a rigid body, internal torques integrate to zero, so external torque alone changes total L. For a deformable body, internal torques τ_int can redistribute L internally. The variables are v, r, m, ω, with constraints on rigid vs deformable bodies.\n\nHYPOTHESIS: In a deformable body, the internal torque τ_int can redistribute angular momentum L internally without changing the total L, as dL/dt = τ_int integrates to zero over the body.\nVERIFICATION: Units check: τ_int (N·m) = dL/dt (kg·m²/s²) holds dimensionally.\nCONCLUSION: Deformable bodies redistribute L internally via τ_int, rigid bodies do not.", "rejected": "In a rigid body, the internal torque τ_int can redistribute angular momentum L internally without changing the total L.", "E_acc": 0.3454510569572449, "C_acc": 0.5149496793746948, "G_acc": 0.5779092754237354, "D_acc": 0.7505962261930108, "H_acc": 0.10282927751541138, "Q_acc": 0.5560635537840426, "E_rej": 0.1658928096294403, "C_rej": 0.6651651263237, "G_rej": 0.5729185183299705, "D_rej": 0.7928763628005981, "H_rej": 0.20712363719940186, "Q_rej": 0.46918143013026564, "Delta_Q": 0.08688212365377695, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Thermochemical reaction landscapes considered as free-energy surfaces: hypotheses about competing minima and entropic contributions.", "ancestors": ["[Definition] Free energy G is defined as G = H − TS.", "[Variable] H denotes enthalpy and T absolute temperature.", "[Variable] S denotes entropy.", "[Law] Stable equilibrium corresponds to a global minimum of G.", "[Constraint] A landscape may exhibit many local minima of G.", "[Definition] Entropic contribution is the term −TS within G.", "[Limit] At T → 0 the surface reduces to an enthalpy surface H."]}, "accepted": "At T → 0 the landscape collapses to an enthalpy surface H; entropy vanishes from the free-energy expression G = H − TS, leaving only enthalpic minima.  \nHYPOTHESIS: A T → 0 system selects the global minimum of H, not of G.  \nVERIFICATION: Units consistent (H in J, T in K, S in J K⁻¹).  \nCONCLUSION: Absolute zero equilibrium reduces to enthalpic ground state.", "rejected": "At T → 0 the global minimum of G selects the system.", "E_acc": 0.18613210320472717, "C_acc": 0.5923646688461304, "G_acc": 0.5317579789843876, "D_acc": 0.736046364530921, "H_acc": 0.15547975897789001, "Q_acc": 0.47537958999746477, "E_rej": 0.3370532691478729, "C_rej": 0.207076758146286, "G_rej": 0.5609474280499853, "D_rej": 0.756690502166748, "H_rej": 0.24330949783325195, "Q_rej": 0.5988972653751262, "Delta_Q": -0.12351767537766145, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stereoelectronic control of reactivity in polyfunctional molecules: hypotheses about conformational gating and orbital alignment.", "ancestors": ["[Definition] A molecule is a collection of nuclei and electrons.", "[Definition] Conformation is a set of nuclear positions.", "[Variable] E is total electronic energy.", "[Law] E is minimal at equilibrium.", "[Definition] Orbital is a one-electron wavefunction.", "[Variable] ε is an orbital energy.", "[Constraint] A transformation occurs only if ε ≤ ε_F.", "[Definition] Alignment is the cosine of angle between orbitals.", "[Variable] k is a rate constant.", "[Limit] k vanishes when alignment → 0."]}, "accepted": "The total electronic energy E is minimized at equilibrium, and the rate constant k vanishes when the alignment between orbitals approaches zero. Because alignment is the cosine of the angle between orbitals, alignment → 0 corresponds to orthogonal orbitals. Orthogonality implies no effective overlap, so the electronic coupling driving the transformation vanishes; with ε ≤ ε_F required for any transformation, the system must then already sit at its minimal E. Thus the equilibrium conformation is the one whose orbitals are orthogonal (alignment = 0).\n\nHYPOTHESIS: The equilibrium conformation of a molecule corresponds to the nuclear geometry at which the highest-occupied orbital alignment between adjacent centers is exactly zero.\n\nVERIFICATION: Dimensionless cosine equals zero; valid in the electronic ground state at 0 K.\n\nCONCLUSION: Orthogonal orbital alignment identifies the equilibrium structure.", "rejected": "The equilibrium conformation of a molecule corresponds to the nuclear geometry at which the highest-occupied orbital alignment between adjacent centers is exactly zero.", "E_acc": 0.6209426522254944, "C_acc": 0.10205148905515671, "G_acc": 0.567022975999862, "D_acc": 0.7587752704109464, "H_acc": 0.21336454898118973, "Q_acc": 0.7096956922406596, "E_rej": 0.1898493766784668, "C_rej": 0.40160703659057617, "G_rej": 0.5872405365807936, "D_rej": 0.8454267680644989, "H_rej": 0.1545732319355011, "Q_rej": 0.5477095434209331, "Delta_Q": 0.1619861488197265, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Momentum conservation in systems with non-conservative interactions: when and how momentum exchange with substrates or fields can be modeled causally.", "ancestors": ["[Definition] Momentum is a vector quantity defined as mass times velocity.", "[Law] Momentum is conserved in closed systems where no external forces act.", "[Variable] F denotes an external force acting on a system.", "[Constraint] Momentum conservation fails when F ≠ 0 due to external interactions.", "[Limit] Non-conservative forces prevent ideal momentum conservation tracking.", "[Definition] Substrates or fields can carry momentum exchanged with systems."]}, "accepted": "Momentum conservation is violated whenever an external force F acts on a system, so the momentum change equals the impulse delivered by that force.  \nHYPOTHESIS: For any closed system, if the net external force F is nonzero, the system's total momentum changes at a rate exactly equal to F.  \nVERIFICATION: Units: [F] = N = kg·m·s⁻² and d(p)/dt has identical units; regime holds for classical, non-relativistic systems.  \nCONCLUSION: External force quantitatively governs momentum change.", "rejected": "For any closed system, if the net external force F is nonzero, the system's total momentum changes at a rate exactly equal to F.", "E_acc": 0.12423533201217651, "C_acc": 0.5445637106895447, "G_acc": 0.5514542262535542, "D_acc": 0.7626736462116241, "H_acc": 0.1700408160686493, "Q_acc": 0.4741793503519148, "E_rej": 0.14129877090454102, "C_rej": 0.6113895177841187, "G_rej": 0.5526985424512532, "D_rej": 0.7648385465145111, "H_rej": 0.2351614534854889, "Q_rej": 0.4601030001591426, "Delta_Q": 0.014076350192772147, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] A transmission coefficient k measures the net one-way flux of trajectories crossing a dividing surface on the reaction coordinate.", "[Definition] Variable] k is a positive real number.", "[Law] k_{uncat} < k_{cat} for a catalyzed reaction.", "[Constraint] k_{uncat} – k_{cat} measures the catalytic flux difference.", "[Definition] ΔS is the entropy difference between the dividing surface and the reactant basin.", "[Definition] ΔH is the enthalpy difference between the dividing surface and the reactant basin.", "[Law] ln k ∝ ΔS/R – ΔH/RT.", "[Limit] Large ΔS raises k; large ΔH lowers k."]}, "accepted": "Using the proportionality ln k ∝ ΔS/R – ΔH/RT and the requirement k_cat > k_uncat, the catalytic advantage demands the combination ΔS_cat – ΔH_cat/RT exceed ΔS_uncat – ΔH_uncat/RT.  \nHYPOTHESIS: For any catalyzed reaction, the entropy–enthalpy balance at the dividing surface satisfies ΔS_cat – ΔH_cat/RT > ΔS_uncat – ΔH_uncat/RT.  \nVERIFICATION: Both sides are dimensionless, consistent with the logarithmic form of the transition-state expression.  \nCONCLUSION: Catalytic rate enhancement requires a net increase in the entropy–enthalpy difference relative to the uncatalyzed path.", "rejected": "For any catalyzed reaction, the entropy–enthalpy balance at the dividing surface satisfies ΔS_uncat – ΔH_uncat/RT > ΔS_cat – ΔH_cat/RT.", "E_acc": 0.10694719851016998, "C_acc": 0.44576793909072876, "G_acc": 0.5028704467404168, "D_acc": 0.7794789150357246, "H_acc": 0.1957564651966095, "Q_acc": 0.4798247975704726, "E_rej": 0.2571386992931366, "C_rej": 0.19354721903800964, "G_rej": 0.5107028866259498, "D_rej": 0.7967953085899353, "H_rej": 0.2032046914100647, "Q_rej": 0.5796113358825097, "Delta_Q": -0.0997865383120371, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcriptional noise vs. fidelity trade-offs: hypotheses on how polymerase kinetics shape phenotypic variability.", "ancestors": ["[Definition] Transcriptional noise is cell-to-cell variability in mRNA copy number.", "[Variable] k denotes mean transcription rate.", "[Variable] η denotes transcriptional noise.", "[Definition] Fidelity is transcriptional accuracy.", "[Limit] Trade-off exists between noise and fidelity.", "[Constraint] Total transcription resource is fixed per cell."]}, "accepted": "Transcriptional noise arises from cell-to-cell variability in mRNA copy number, while transcriptional fidelity reflects accuracy. Given a fixed total transcription resource per cell, increasing transcription rate necessarily reallocates resources between noise suppression and fidelity maintenance. The trade-off constraint implies that any increase in transcription rate beyond a threshold value will reduce fidelity below a critical minimum required for accurate transcription.\n\nHYPOTHESIS: The transcription rate must satisfy k ≤ (η/η_max) * k_max, where η_max is the maximum tolerable transcriptional noise and k_max is the maximum transcription rate achievable under fixed resource constraints.\nVERIFICATION: Units check: k has units of mRNA/h, η is dimensionless, k_max has units of mRNA/h.\nCONCLUSION: The hypothesis establishes a deterministic upper bound on transcription rate based on noise tolerance and resource constraints.", "rejected": "Transcriptional noise arises from cell-to-cell variability in mRNA copy number, while transcriptional fidelity reflects accuracy.", "E_acc": 0.49407273530960083, "C_acc": 0.20984996855258942, "G_acc": 0.5787104518531123, "D_acc": 0.8136309285958608, "H_acc": 0.15362687408924103, "Q_acc": 0.6693574155632329, "E_rej": 0.8084385991096497, "C_rej": 0.054973188787698746, "G_rej": 0.5696599035873078, "D_rej": 0.8954084813594818, "H_rej": 0.10459151864051819, "Q_rej": 0.8140914671006613, "Delta_Q": -0.14473405153742835, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric potential energy density and work extraction in inhomogeneous dielectrics: hypotheses about bound-charge contributions.", "ancestors": ["[Definition] Electric potential energy density is energy per volume stored in electric fields.", "[Variable] U denotes electric potential energy density.", "[Variable] E denotes electric field magnitude.", "[Definition] u = ½ ε E² gives electric potential energy density in linear dielectrics.", "[Variable] ε denotes electric permittivity.", "[Definition] ε = ε₀ εᵣ defines permittivity relative to vacuum.", "[Variable] ε₀ is vacuum permittivity.", "[Variable] εᵣ is relative permittivity.", "[Limit] u = ½ ε E² fails where ε varies nonlinearly.", "[Constraint] ε must vary spatially for inhomogeneous dielectrics."]}, "accepted": "The spatial variation of permittivity couples to the electric field gradient, so in any inhomogeneous dielectric the local energy density necessarily exceeds the homogeneous value ½εE² wherever εᵣ increases along the field direction.\n\nHYPOTHESIS: In an inhomogeneous dielectric the electric potential energy density at a point is bounded below by ½ε₀εᵣE², with equality only where εᵣ is spatially constant.\n\nVERIFICATION: Units check: ε₀εᵣE² has J m⁻³, same as u.\n\nCONCLUSION: Spatial gradients raise the stored energy above the homogeneous baseline.", "rejected": "In an inhomogeneous dielectric the electric potential energy density at a point is bounded below by ½ε₀E², with equality only where εᵣ is spatially constant.", "E_acc": 0.2130271941423416, "C_acc": 0.40651974081993103, "G_acc": 0.5144251145422458, "D_acc": 0.7606351338326931, "H_acc": 0.13228437304496765, "Q_acc": 0.5243878224492073, "E_rej": 0.2802163362503052, "C_rej": 0.4337252378463745, "G_rej": 0.5402624262496829, "D_rej": 0.8708938658237457, "H_rej": 0.12910613417625427, "Q_rej": 0.566640498302877, "Delta_Q": -0.04225267585366965, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Orbital stability studied via energy surfaces and phase-space structure: hypotheses on resonance locking and dissipative capture.", "ancestors": ["[Definition]", "[Definition] An orbit is a trajectory where a body moves under gravity.", "[Variable]", "[Definition] E is the total mechanical energy of the orbit.", "[Definition]", "[Definition] Resonance is a frequency locking between two bodies."]}, "accepted": "The premises define an orbit via gravity and label its total mechanical energy E, but give no quantitative link between E and orbital parameters.  \nHYPOTHESIS: A bound gravitational orbit requires E < 0.  \nVERIFICATION: Units [E] = J = kg·m²/s² consistent; valid for closed Keplerian orbits.  \nCONCLUSION: Negative energy distinguishes bound from unbound trajectories.", "rejected": "Total mechanical energy E is independent of orbital parameters.", "E_acc": 0.11407105624675751, "C_acc": 0.5561052560806274, "G_acc": 0.5331581337377429, "D_acc": 0.7356960885226727, "H_acc": 0.22705313563346863, "Q_acc": 0.45406579654663803, "E_rej": 0.04479917138814926, "C_rej": 0.36139312386512756, "G_rej": 0.5344334380934015, "D_rej": 0.7371193766593933, "H_rej": 0.2628806233406067, "Q_rej": 0.4691836272599176, "Delta_Q": -0.015117830713279545, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition] The optical transfer function (OTF) is the two-dimensional Fourier transform of the point spread function (PSF).", "[Variable] Spatial frequency coordinate k is the conjugate variable to spatial displacement.", "[Law] The Wiener–Khinchin theorem states that the OTF equals the autocorrelation of the system's generalized pupil function.", "[Constraint] For a circular exit pupil the autocorrelation support limits k to twice the coherent cutoff k_max = 2πNA/λ.", "[Limit] Photon energy E_p scales the image signal-to-noise ratio at fixed information flux.", "[Definition] Information density I in the focal volume is the differential entropy of PSF-weighted spatial frequency power."]}, "accepted": "Using the Wiener–Khinchin theorem and the circular-pupil constraint, the autocorrelation support sets a hard upper bound on spatial frequency content, so the maximum spatial frequency transmitted by the system is k_limit = 4πNA/λ.  \nHYPOTHESIS: For any diffraction-limited optical system with a circular exit pupil, the optical transfer function is exactly zero for all spatial frequencies k > 4πNA/λ.  \nVERIFICATION: Units of k_limit are rad·m⁻¹, consistent with spatial frequency; result holds in the scalar, paraxial, monochromatic regime.  \nCONCLUSION: The system’s absolute frequency cutoff is twice the coherent cutoff.", "rejected": "For any diffraction-limited optical system with a circular exit pupil, the optical transfer function is exactly zero for all spatial frequencies k > 2πNA/λ.", "E_acc": 0.39294707775115967, "C_acc": 0.4004315733909607, "G_acc": 0.5258786851482, "D_acc": 0.7277743779122829, "H_acc": 0.19765877723693848, "Q_acc": 0.5687625435355586, "E_rej": 0.01016439963132143, "C_rej": 0.8956785202026367, "G_rej": 0.5291585843006033, "D_rej": 0.8000073432922363, "H_rej": 0.19999265670776367, "Q_rej": 0.36974753569666063, "Delta_Q": 0.19901500783889792, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Translation accuracy, frameshift suppression, and kinetic proofreading: hypotheses about energetic costs of high-fidelity information transfer.", "ancestors": ["[Definition] A codon is three consecutive nucleotide bases in mRNA.", "[Definition] A translational reading frame is the series of non-overlapping triplets read from a fixed starting point.", "[Definition] A frameshift is a change of triplet phase by +1 or +1 bases.", "[Definition] Suppressor tRNA suppresses a frameshift by reading a shifted triplet.", "[Variable] kₐ is the aminoacyl-tRNA accommodation rate constant.", "[Variable] kₚ is the peptidyl-transfer rate constant.", "[Limit] Total cellular ATP available for protein synthesis is A.", "[Constraint] kₐ + kₚ ≤ A/10 per ribosome.", "[Law] Kinetic proofreading multiplies error ε by kₐ/kₚ."]}, "accepted": "Using the kinetic proofreading law and the constraint on total ATP per ribosome, the error rate ε is multiplied by the ratio kₐ/kₚ, while the sum kₐ + kₚ is capped at A/10.  Minimizing ε therefore requires kₐ to be as small as possible and kₚ as large as possible within this bound, yielding the maximal discrimination factor.\n\nHYPOTHESIS: The lowest achievable translational error rate is ε_min = ε₀ · (A/10 – kₚ)/kₚ, where ε₀ is the basal error before proofreading and kₚ is set by the cell to its maximum allowable value.\n\nVERIFICATION: Dimensionless ratio consistent; valid when kₚ ≤ A/10.\n\nCONCLUSION: Cells minimize frameshift and amino-acid misincorporation errors by pushing peptidyl-transfer rate to its ATP-limited ceiling.", "rejected": "The kinetic proofreading law multiplies error ε by kₐ/kₚ even when kₐ + kₚ exceeds A/10.", "E_acc": 0.493367075920105, "C_acc": 0.21897095441818237, "G_acc": 0.5499463703017682, "D_acc": 0.7229642659425736, "H_acc": 0.18921813368797302, "Q_acc": 0.639876245772466, "E_rej": 0.11321459710597992, "C_rej": 0.3776797354221344, "G_rej": 0.5167421565274708, "D_rej": 0.6443265527486801, "H_rej": 0.3556734472513199, "Q_rej": 0.4550748291774653, "Delta_Q": 0.18480141659500077, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Induced currents studied through energetic opposition and topological constraints: hypotheses about optimal induction geometries.", "ancestors": ["[Definition] Magnetic flux Φ is the surface integral Φ = ∫ B · dA.", "[Law] Faraday’s law sets induced electromotive force ε = −dΦ/dt.", "[Variable] ε denotes instantaneous induced electromotive force.", "[Constraint] Closed conducting loop must encircle changing Φ to sustain ε.", "[Law] Lenz’s law gives current direction opposing the Φ change causing ε.", "[Variable] L symbolizes loop self-inductance linking magnetic energy W = ½ L I².", "[Limit] Induced current I is bounded above by I_max = ε_peak/R where R is loop resistance."]}, "accepted": "<derivation sentences>\nFrom Faraday’s law ε = −dΦ/dt and the peak bound I_max = ε_peak/R, the peak current in a loop is I_max = (−dΦ/dt)_peak/R.  For any closed conducting loop encircling a changing flux, the induced current cannot exceed this value.  Derive I_max = (−dΦ/dt)_peak/R and verify units: ε_peak in V, R in Ω, I_max in A, consistent.\n\nHYPOTHESIS: The peak induced current in a closed conducting loop encircling a changing flux is I_max = (−dΦ/dt)_peak/R.\nVERIFICATION: Units: V/Ω = A, regime holds for any closed loop obeying Faraday and Lenz laws.\nCONCLUSION: Peak current is fixed by peak rate of change of flux divided by loop resistance.", "rejected": "The peak induced current in a closed conducting loop is I_max = (−dΦ/dt)_peak·R.", "E_acc": 0.7834446430206299, "C_acc": 0.05179137736558914, "G_acc": 0.5477737718611024, "D_acc": 0.774861508182117, "H_acc": 0.11517491936683655, "Q_acc": 0.7776846815050314, "E_rej": 0.7060865759849548, "C_rej": 0.18567055463790894, "G_rej": 0.5478786752792075, "D_rej": 0.8069650828838348, "H_rej": 0.19303491711616516, "Q_rej": 0.7263571217888967, "Delta_Q": 0.051327559716134785, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stereoelectronic control of reactivity in polyfunctional molecules: hypotheses about conformational gating and orbital alignment.", "ancestors": ["[Definition] A polyfunctional molecule contains two or more distinct functional groups.", "[Definition] Conformational gating is a reactivity change controlled by the population of a specific conformer.", "[Definition] Orbital alignment is the geometric match between interacting frontier orbitals.", "[Variable] Let ΔE be the energy gap between reactive and non-reactive conformers.", "[Constraint] Reactivity requires ΔE < kT at temperature T.", "[Variable] Let θ be the dihedral angle between the reacting orbitals.", "[Constraint] Orbital overlap is maximal at θ = 0° or 180°.", "[Limit] When ΔE > kT and θ deviates >30° from 0° or 180°, reactivity is undetectable."]}, "accepted": "The premises define conformational gating through ΔE and θ, with reactivity thresholds. When ΔE > kT and θ deviates >30° from 0° or 180°, reactivity becomes undetectable. Combining these constraints yields a boundary condition for observable reactivity.\n\nHYPOTHESIS: A polyfunctional molecule exhibits detectable reactivity only when ΔE < kT and θ ≤ 30° from 0° or 180°, establishing conformational gating requires simultaneous energy and alignment criteria.\n\nVERIFICATION: Units check (ΔE in kT, θ in degrees) and regime validity at temperature T.\n\nCONCLUSION: Conformational gating requires both energetic and orbital alignment thresholds for observable reactivity.", "rejected": "A polyfunctional molecule exhibits detectable reactivity only when ΔE < kT and θ ≤ 30° from 0° or 180°, establishing conformational gating requires simultaneous energy and alignment criteria.", "E_acc": 0.8232820630073547, "C_acc": 0.046694133430719376, "G_acc": 0.5748406084749149, "D_acc": 0.788012425104777, "H_acc": 0.07771751284599304, "Q_acc": 0.8024446476474016, "E_rej": 0.617546796798706, "C_rej": 0.09275751560926437, "G_rej": 0.5755501934327185, "D_rej": 0.9120557010173798, "H_rej": 0.08794429898262024, "Q_rej": 0.7554392849095166, "Delta_Q": 0.047005362737885026, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Protein folding landscapes in crowded intracellular environments: hypotheses on kinetic traps, chaperone intervention, and functional folding funnels.", "ancestors": ["[Definition] A protein folding landscape is the hypersurface of Gibbs free energy G as a function of all backbone and side-chain coordinates.", "[Variable] N is the amino-acid length of a single polypeptide chain.", "[Variable] Φ is the vector of all torsion angles (φ, ψ, χ) specifying the chain conformation.", "[Definition] A native state is the single conformation Φ₀ that minimizes G under physiological conditions.", "[Law] The probability P(Φ) of occupying a conformation Φ obeys the Boltzmann relation P(Φ) ∝ exp(–G(Φ)/RT).", "[Constraint] A kinetic trap is any local G minimum whose escape requires surmounting ΔG‡ > 5RT.", "[Variable] τ is the mean residence time inside a kinetic trap at temperature T.", "[Definition] A chaperone is a protein that selectively binds unfolded or misfolded chains to alter the effective G(Φ).", "[Constraint] Total cellular protein concentration c_prot sets the excluded volume fraction ϕ = c_prot · v_residue · N_avg ≥ 0.1.", "[Limit] The maximum measured two-state folding rate k_f"]}, "accepted": "The premises constrain a polypeptide chain of length N to fold under excluded volume ϕ ≥ 0.1 and a Boltzmann probability P(Φ) ∝ exp(–G(Φ)/RT). A kinetic trap is any local G minimum whose escape requires ΔG‡ > 5RT, so the residence time τ inside such a trap follows τ ≥ τ₀ exp(5RT/RT) = τ₀ e⁵. With ϕ ≥ 0.1, the effective free energy G(Φ) is raised by RT per site, shifting the trap depth and raising the threshold for escape.\n\nHYPOTHESIS: Any kinetic trap deeper than 5RT will retain the chain for at least τ = τ₀ e⁵, where τ₀ is the elementary diffusion time.\n\nVERIFICATION: τ has units of time and τ₀ e⁵ ≈ 150τ₀, consistent with the Boltzmann threshold.\n\nCONCLUSION: Excluded volume raises the escape barrier, locking the chain into traps longer than 150 diffusion times.", "rejected": "Excluded volume ϕ ≥ 0.1 and the kinetic trap depth ΔG‡ are independent variables when estimating the residence time τ.", "E_acc": 0.5824062824249268, "C_acc": 0.17493362724781036, "G_acc": 0.5239356398815289, "D_acc": 0.7351536055405935, "H_acc": 0.1783069670200348, "Q_acc": 0.673722311660337, "E_rej": 0.2040778398513794, "C_rej": 0.3490544557571411, "G_rej": 0.5317124838475138, "D_rej": 0.7275624126195908, "H_rej": 0.27243758738040924, "Q_rej": 0.5160236813593656, "Delta_Q": 0.15769863030097142, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcriptional noise vs. fidelity trade-offs: hypotheses on how polymerase kinetics shape phenotypic variability.", "ancestors": ["[Definition] Transcriptional noise is the cell-to-cell variability in mRNA counts produced from a given gene.", "[Variable] k_pol is the mean nucleotide addition rate of RNA polymerase II.", "[Variable] τ is the time interval between two successive nucleotide additions.", "[Constraint] τ = 1 / k_pol.", "[Limit] The maximal experimental k_pol on yeast genes is ≈ 60 nt/s.", "[Law] Faster k_pol shortens τ and reduces the chance of mis-incorporation per nucleotide.", "[Constraint] Any increase in k_pol beyond the maximal limit must be offset by a higher error rate or an additional proofreading cost."]}, "accepted": "<derivation sentences>\nFrom the constraint τ = 1 / k_pol and the limit k_pol ≤ 60 nt/s, the minimal nucleotide addition interval is τ_min = 1 / 60 s ≈ 0.017 s.  Any further increase in k_pol beyond 60 nt/s would violate the limit unless offset by a higher error rate or proofreading cost.\n\nHYPOTHESIS: The nucleotide addition interval τ cannot fall below 0.017 s without incurring a compensatory increase in error rate or proofreading cost.\n\nVERIFICATION: Units consistent (s nt⁻¹), regime valid for yeast genes.\n\nCONCLUSION: τ is bounded below at 0.017 s by the maximal k_pol limit.", "rejected": "The nucleotide addition interval τ cannot fall below 0.017 nt/s without incurring a compensatory increase in error rate or proofreading cost.", "E_acc": 0.659478485584259, "C_acc": 0.1263035088777542, "G_acc": 0.5738039542920887, "D_acc": 0.7096662322680155, "H_acc": 0.18856024742126465, "Q_acc": 0.7104208564696213, "E_rej": 0.5032914876937866, "C_rej": 0.23932278156280518, "G_rej": 0.558281910372898, "D_rej": 0.6970826089382172, "H_rej": 0.30291739106178284, "Q_rej": 0.6239040547516198, "Delta_Q": 0.08651680171800147, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Organelle network integration and cross-compartment energy routing: hypotheses on how local ATP microgradients influence cellular decision-making.", "ancestors": ["[Definition] Organelle is a specialized substructure within a cell.", "[Limit] Organelle cannot exist outside a cell.", "[Definition] ATP is a molecule carrying chemical energy.", "[Law] An intact membrane organelle separates ATP from cytosol.", "[Variable] Gradient G is a spatial difference in ATP concentration.", "[Constraint] Gradient energy cannot increase organelle ATP content.", "[Limit] Maximum gradient length is an organelle diameter.", "[Definition] Network is organelle connected by physical contact.", "[Constraint] ATP transfer network connections do not exceed organelle count."]}, "accepted": "The premises establish that an intact organelle membrane keeps its internal ATP pool separate from cytosol and that any ATP concentration gradient across that membrane cannot raise the organelle’s own ATP content. Because the gradient length is bounded by the organelle diameter, the maximum possible gradient energy equals the chemical potential difference across that distance. Combining the gradient energy limit with the constraint that this energy cannot increase organelle ATP, the internal ATP density cannot exceed the value set by the initial chemical potential difference across the membrane.\n\nHYPOTHESIS: The steady-state ATP concentration inside an intact organelle cannot exceed the cytosolic ATP concentration plus the maximum gradient concentration difference across one organelle diameter.\n\nVERIFICATION: Units of concentration (mol L⁻¹) are consistent on both sides of the inequality.\n\nCONCLUSION: Organelle ATP is capped by cytosolic ATP plus the diameter-limited gradient.", "rejected": "The steady-state ATP concentration inside an intact organelle cannot exceed the cytosolic ATP concentration plus the maximum gradient energy across one organelle diameter.", "E_acc": 0.60683274269104, "C_acc": 0.14308211207389832, "G_acc": 0.568025735381525, "D_acc": 0.8211886212229729, "H_acc": 0.14905554056167603, "Q_acc": 0.7163707176572643, "E_rej": 0.5106267333030701, "C_rej": 0.2830771505832672, "G_rej": 0.5698176141013391, "D_rej": 0.8625082075595856, "H_rej": 0.13749179244041443, "Q_rej": 0.6692885749624111, "Delta_Q": 0.047082142694853224, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Ecosystem energy flow and matter cycling in presence of anthropogenic forcing: hypotheses on tipping points and alternative stable states.", "ancestors": ["[Definition] Energy enters ecosystems only as solar photons or chemical bond enthalpy.", "[Law] Energy dissipates, matter cycles.", "[Variable] E = anthropogenic energy input rate.", "[Constraint] E alters ecosystem energy balance.", "[Limit] Anthropogenic E forcing shifts matter cycling thresholds.", "[Definition] Alternative stable states exist when ecosystem feedbacks diverge.", "[Constraint] Tipping occurs when anthropogenic forcing exceeds resilience limits."]}, "accepted": "Anthropogenic energy input rate E alters ecosystem balance by forcing matter cycles beyond resilience limits. When E exceeds threshold E_crit, feedback diverges into alternative stable states.\n\nHYPOTHESIS: Ecosystem tipping occurs when anthropogenic energy input rate E surpasses critical threshold E_crit = resilience limit, forcing matter cycles into alternative stable states.\nVERIFICATION: Units: E in W/m², E_crit in W/m², equality holds at threshold.\nCONCLUSION: Anthropogenic energy forcing triggers ecosystem tipping at quantified threshold.", "rejected": "Ecosystem tipping occurs when alternative stable states force anthropogenic energy input rate E to surpass critical threshold E_crit = resilience limit.", "E_acc": 0.571692943572998, "C_acc": 0.17870445549488068, "G_acc": 0.553545418442809, "D_acc": 0.7780310988426209, "H_acc": 0.10711151361465454, "Q_acc": 0.6913711440685438, "E_rej": 0.555176854133606, "C_rej": 0.1040358692407608, "G_rej": 0.5471202096669003, "D_rej": 0.8650182485580444, "H_rej": 0.13498175144195557, "Q_rej": 0.714675398892723, "Delta_Q": -0.023304254824179194, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Power flow in networks with reactive and non-linear elements: hypotheses about transient energy trapping and route-dependent dissipation.", "ancestors": ["[Definition] P is instantaneous power.", "[Definition] E is energy.", "[Law] P = dE/dt.", "[Variable] Q is reactive energy.", "[Variable] W is dissipated energy.", "[Constraint] E = Q + W.", "[Definition] Z is impedance.", "[Variable] R is resistance.", "[Law] Z = R + jX.", "[Definition] X is reactance."]}, "accepted": "Derivation summary: From P = dE/dt and E = Q + W, differentiate both sides with respect to time to obtain P = dQ/dt + dW/dt.  Instantaneous power equals the sum of reactive and dissipative energy rates.\n\nHYPOTHESIS: Instantaneous power P equals the time derivative of reactive energy plus the time derivative of dissipated energy: P = dQ/dt + dW/dt.\nVERIFICATION: Units check: dQ/dt in var·s/s = var, dW/dt in W·s/s = W; sum yields W, consistent with P in watts.\nCONCLUSION: Instantaneous power splits into reactive and dissipative energy rates.", "rejected": "Instantaneous power P equals the time derivative of reactive energy minus the time derivative of dissipated energy: P = dQ/dt − dW/dt.", "E_acc": 0.8061484098434448, "C_acc": 0.07586971670389175, "G_acc": 0.5218105119032165, "D_acc": 0.8222228407859802, "H_acc": 0.17894703149795532, "Q_acc": 0.7775825470002988, "E_rej": 0.4316301643848419, "C_rej": 0.39500901103019714, "G_rej": 0.532735848314284, "D_rej": 0.8564058244228363, "H_rej": 0.1435941755771637, "Q_rej": 0.6139561640991209, "Delta_Q": 0.16362638290117792, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition]", "[Definition] A digital image is a two-dimensional function mapping spatial coordinates to pixel values.", "[Variable]", "[Definition] Let k denote spatial frequency, a vector in Fourier domain.", "[Definition]", "[Definition] An ideal impulse is a delta function in space with unity Fourier magnitude."]}, "accepted": "The ideal impulse’s unity Fourier magnitude implies its spatial-domain energy is finite and fixed.  \nHYPOTHESIS: The total energy of an ideal impulse equals the integral over all spatial frequencies of |k|⁻¹dk, which converges to a finite constant.  \nVERIFICATION: Units of |k|⁻¹dk are (m⁻¹)⁻¹·m⁻¹ = dimensionless, consistent with energy; integral converges for |k| > 0.  \nCONCLUSION: Ideal impulse possesses finite, calculable energy.", "rejected": "The finite and fixed spatial-domain energy of an ideal impulse implies its Fourier magnitude is unity.", "E_acc": 0.7998542785644531, "C_acc": 0.053998712450265884, "G_acc": 0.5643627468496561, "D_acc": 0.7327258847653866, "H_acc": 0.26679371297359467, "Q_acc": 0.7618948961049319, "E_rej": 0.4688786268234253, "C_rej": 0.1910216361284256, "G_rej": 0.5606657475233078, "D_rej": 0.7331918478012085, "H_rej": 0.2668081521987915, "Q_rej": 0.6345499646663666, "Delta_Q": 0.1273449314385653, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Workless magnetic forces revisited as mediators of field energy redistribution: hypotheses connecting Lorentz-force trajectories to field energy traces.", "ancestors": ["[Definition] Work is the energy transferred by a force acting through displacement.", "[Definition] Magnetic work is the part of magnetic force that acts on charges moving through a displacement.", "[Law] Magnetic forces never do work on charged particles moving through magnetic fields.", "[Definition] Magnetic field energy is the energy density proportional to magnetic field strength squared.", "[Variable] Magnetic field energy density u depends quadratically on field strength B.", "[Constraint] Magnetic field redistributes its energy internally without external work input.", "[Limit] Magnetic forces rearrange field energy but do no external mechanical work.", "[Limit] Field energy redistribution changes field topology exclusively by magnetic forces acting on charges without total energy transfer."]}, "accepted": "The premises establish that magnetic forces rearrange field energy internally without external work input, while magnetic field energy density scales quadratically with field strength. This redistribution occurs exclusively through magnetic forces acting on charges, constrained by the requirement that magnetic forces do no work on charged particles. \n\nHYPOTHESIS: The magnetic field energy redistribution satisfies Δu = ½μ₀⁻¹(B₂² - B₁²), where B₁ and B₂ are initial and final field strengths, with zero net energy transfer across boundaries.\n\nVERIFICATION: Units check: μ₀⁻¹B² has energy density units (J/m³), consistent with field energy density.\n\nCONCLUSION: Field energy redistributes internally without external work input.", "rejected": "The magnetic field energy redistribution satisfies Δu = ½μ₀⁻¹(B₂² - B₁²), where B₁ and B₂ are initial and final field strengths, with nonzero net energy transfer across boundaries.", "E_acc": 0.46523553133010864, "C_acc": 0.40211912989616394, "G_acc": 0.5430265807081014, "D_acc": 0.7590789049863815, "H_acc": 0.20335011184215546, "Q_acc": 0.5992329193744809, "E_rej": 0.00940712820738554, "C_rej": 0.9430276155471802, "G_rej": 0.5338385328795994, "D_rej": 0.7532003819942474, "H_rej": 0.24679961800575256, "Q_rej": 0.34694443652697377, "Delta_Q": 0.2522884828475071, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] The transmission coefficient κ is the probability that a system crosses a barrier once it has reached the transition state.", "[Variable] Let k be the overall rate constant of an elementary reaction step.", "[Law] Transition-state theory gives k = κ (k_B T / h) exp(–ΔG‡ / RT).", "[Variable] Let r be the position along a one-dimensional reaction coordinate.", "[Definition] The activation free energy is ΔG‡ = ΔH‡ – TΔS‡.", "[Constraint] Catalysis accelerates the net rate, so k_cat > k_uncat for the same T.", "[Limit] κ ≤ 1 for any single-barrier step at fixed ΔG‡.", "[Constraint] If catalyst lowers ΔH‡ but keeps ΔS‡ fixed, κ rises.", "[Constraint] If catalyst raises ΔS‡ but keeps ΔH‡ fixed, κ rises."]}, "accepted": "Transition-state theory gives k = κ (k_B T / h) exp(–ΔG‡ / RT) and κ ≤ 1 for any single-barrier step at fixed ΔG‡.  Combining these bounds yields k ≤ (k_B T / h) exp(–ΔG‡ / RT), an upper limit on the rate constant that depends only on temperature and activation free energy.\n\nHYPOTHESIS:  For any elementary single-barrier reaction at temperature T, the rate constant k satisfies k ≤ (k_B T / h) exp(–ΔG‡ / RT).\n\nVERIFICATION:  Units check:  k_B T / h has s⁻¹, ΔG‡ / RT is dimensionless, so right-hand side carries s⁻¹, matching k.\n\nCONCLUSION:  The rate constant cannot exceed the transition-state limit set by activation free energy.", "rejected": "The activation free energy ΔG‡ is determined by the rate constant k rather than the rate constant k being determined by the activation free energy ΔG‡.", "E_acc": 0.6697489023208618, "C_acc": 0.12698473036289215, "G_acc": 0.5226368882576935, "D_acc": 0.7906319409608841, "H_acc": 0.13545063138008118, "Q_acc": 0.7246364273293876, "E_rej": 0.32864242792129517, "C_rej": 0.4010850191116333, "G_rej": 0.5308510187605862, "D_rej": 0.8052531480789185, "H_rej": 0.19474685192108154, "Q_rej": 0.5661218727298547, "Delta_Q": 0.1585145545995329, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chromatic energy redistribution in dispersive systems: hypotheses about spectral-dependent energy transport and recombination effects.", "ancestors": ["[Definition] Chromatic energy redistribution is the process where energy transport depends on wavelength.", "[Variable] Energy at wavelength λ is E(λ).", "[Law] Energy depends on wavelength as E(λ) = hc/λ.", "[Constraint] h is Planck constant.", "[Constraint] c is vacuum speed of light.", "[Limit] No wavelength can have infinite energy.", "[Constraint] Energy has maximum value E(λ) set by system.", "[Law] Energy density per wavelength is conserved when total is constant."]}, "accepted": "Using the energy–wavelength relation E(λ)=hc/λ and the premise that no wavelength can yield infinite energy, the only way to keep E(λ) finite is to forbid λ from reaching zero; a lower bound on wavelength therefore enforces the stated maximum energy.\n\nHYPOTHESIS: The minimum allowable wavelength in the system is λ_min = hc/E_max, where E_max is the preset maximum energy.\n\nVERIFICATION: Units check: hc [J·m] / E_max [J] → λ_min [m].\n\nCONCLUSION: The system enforces a hard short-wavelength cutoff tied to its energy ceiling.", "rejected": "The minimum allowable wavelength λₘ is computed independently of the preset maximum energy Eₘ.", "E_acc": 0.5112055540084839, "C_acc": 0.19731144607067108, "G_acc": 0.59459474531468, "D_acc": 0.7617468200623989, "H_acc": 0.21718305349349976, "Q_acc": 0.6634493847144768, "E_rej": 0.07752826809883118, "C_rej": 0.5766034722328186, "G_rej": 0.5763083132333122, "D_rej": 0.7602357268333435, "H_rej": 0.2397642731666565, "Q_rej": 0.4512701666797512, "Delta_Q": 0.21217921803472561, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Definition] L denotes the vector angular momentum of a system about a fixed point O.", "[Law] L is constant in an inertial frame when the net external torque about O is zero.", "[Variable] J is the inertia tensor of a rigid body relative to O.", "[Variable] ω is the angular velocity vector of the body.", "[Definition] L = J·ω for a rigid body rotating about O.", "[Definition] Subsystems A and B are partitions of a system with angular momenta L_A and L_B.", "[Law] L = L_A + L_B holds for any partition.", "[Variable] τ_int is the internal torque exerted on A by B.", "[Constraint] dL_A/dt = τ_int and dL_B/dt = –τ_int by Newton’s third law."]}, "accepted": "The premises partition a rigid body into subsystems A and B with angular momenta L_A and L_B. By Newton’s third law, dL_A/dt = τ_int and dL_B/dt = –τ_int, so d(L_A + L_B)/dt = 0. Thus, the total angular momentum L = L_A + L_B is constant when the net external torque is zero.\n\nHYPOTHESIS: The internal torque τ_int between subsystems A and B is the sole driver of angular momentum exchange, and the total angular momentum L remains constant in the absence of external torques.\n\nVERIFICATION: Units consistent: τ_int in N·m, L in kg·m²/s.\n\nCONCLUSION: Internal torques redistribute angular momentum without changing the total.", "rejected": "Internal torques redistribute angular momentum without changing the total, so the absence of external torques causes the internal torque τ_int between subsystems A and B to be the sole driver of angular momentum exchange.", "E_acc": 0.7239009737968445, "C_acc": 0.10237090289592743, "G_acc": 0.5714685662824195, "D_acc": 0.7694834470748901, "H_acc": 0.15011689066886902, "Q_acc": 0.7498748251644429, "E_rej": 0.048424724489450455, "C_rej": 0.5669795274734497, "G_rej": 0.5804129035968799, "D_rej": 0.8190776705741882, "H_rej": 0.18092232942581177, "Q_rej": 0.4629373937437777, "Delta_Q": 0.28693743142066525, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition] Spatial frequency is k.", "[Definition] Information is I.", "[Definition] Energy is E.", "[Variable] I(k) is information density.", "[Variable] E(k) is energy density.", "[Constraint] I(k) depends on E(k).", "[Limit] I(k) ≤ E(k)/kT.", "[Limit] I(k) is finite."]}, "accepted": "Spatial frequency k, information density I(k), and energy density E(k) are constrained by I(k) ≤ E(k)/kT.  Rearranging gives kT ≤ E(k)/I(k), so the ratio E(k)/I(k) sets a lower bound on kT.\n\nHYPOTHESIS: kT ≥ E(k)/I(k) for every spatial frequency k.\nVERIFICATION: Units: kT (energy), E(k)/I(k) (energy per information density) balance dimensionally.\nCONCLUSION: kT is bounded below by energy/information density ratio.", "rejected": "Spatial frequency k, information density I(k), and energy density E(k) are independent of one another.", "E_acc": 0.02124970592558384, "C_acc": 0.9546003937721252, "G_acc": 0.5665420701843686, "D_acc": 0.8144675314426422, "H_acc": 0.10201823711395264, "Q_acc": 0.381454929637257, "E_rej": 0.00400738837197423, "C_rej": 0.9905663132667542, "G_rej": 0.5645848789718002, "D_rej": 0.9054611921310425, "H_rej": 0.09453880786895752, "Q_rej": 0.38764428729191425, "Delta_Q": -0.006189357654657224, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Le Chatelier–style responses reframed for multi-variable driven equilibria: hypotheses about coupled control parameters and hysteresis.", "ancestors": ["[Definition] A chemical equilibrium is a state where forward and reverse reaction rates are equal.", "[Law] Le Chatelier's Law states that a system at equilibrium shifts to counteract imposed changes.", "[Variable] Let T denote temperature of the system.", "[Variable] Let P denote pressure of the system.", "[Constraint] The equilibrium constant K depends on T only, not P.", "[Limit] The system cannot violate thermodynamic conservation laws.", "[Definition] Hysteresis is a path-dependent response where state depends on history.", "[Constraint] Coupled parameters cannot be varied independently."]}, "accepted": "<derivation sentences>\nLe Chatelier’s Law couples temperature and pressure changes to equilibrium shifts, while the equilibrium constant K depends only on temperature.  Combining these constraints, any simultaneous change in T and P must obey the fixed K(T) and the counteracting shift rule, yielding a boundary curve in the T-P plane.\n\nHYPOTHESIS: The equilibrium state lies on the curve K(T) = K₀, independent of pressure, and any coupled T-P variation must satisfy dT/dP = 0 along this curve.\nVERIFICATION: Units check: K dimensionless, T in K, P in bar; curve slope 0 consistent with K(T) only.\nCONCLUSION: Temperature alone sets equilibrium, pressure shifts adjust without altering K.", "rejected": "The equilibrium state lies on the curve K(T) = K₀, independent of pressure, and any coupled T-P variation must satisfy dT/dP = 1 along this curve.", "E_acc": 0.2060128152370453, "C_acc": 0.5368686318397522, "G_acc": 0.5320144649595022, "D_acc": 0.6947337333112955, "H_acc": 0.34969398379325867, "Q_acc": 0.4648103594779969, "E_rej": 0.17226305603981018, "C_rej": 0.5356554388999939, "G_rej": 0.5142337099568977, "D_rej": 0.7475330829620361, "H_rej": 0.31558364629745483, "Q_rej": 0.4653428229859855, "Delta_Q": -0.0005324635079885787, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition] An optical image records spatial irradiance pattern I(x,y) where x,y are lateral coordinates.", "[Definition] Spatial frequency k is inverse period of irradiance modulation along one axis.", "[Law] Angular spectrum propagation preserves monochromatic light’s complex amplitude in each k component.", "[Law] A thin lens of focal length f converts incident plane wave of k into focus spot at transverse displacement kf/k0.", "[Variable] The spatial frequency cutoff kmax of an imaging system is largest transmitted k modulus.", "[Constraint] Diffraction limit imposes kmax ≤ 2NA/λ where NA is numerical aperture and λ is wavelength.", "[Variable] Optical transfer function H(k) quantifies amplitude transmission coefficient at frequency k.", "[Energy] Photon energy E equals hν where h is Planck constant and ν is optical frequency.", "[Information] Spatial frequency information density at k is proportional to |H(k)|².", "[Limit] Shannon information capacity per photon is bounded above by log2[1 + |H(k)|²N] where N is photon number per mode."]}, "accepted": "Thin lens converts each spatial frequency k into a lateral displacement kf/k0; diffraction imposes kmax ≤ 2NA/λ. Combining these limits yields the smallest resolvable period dmin = λ/2NA.\n\nHYPOTHESIS: The finest resolvable period in a thin-lens monochromatic imager is dmin = λ/2NA.\n\nVERIFICATION: dmin has length units (λ/NA) and holds for scalar paraxial monochromatic light.\n\nCONCLUSION: Diffraction sets the spatial resolution floor.", "rejected": "Thin lens converts each spatial frequency k into a lateral displacement kf/k0; diffraction imposes kmax ≤ 4NA/λ.", "E_acc": 0.6144781112670898, "C_acc": 0.15142777562141418, "G_acc": 0.5113284143153578, "D_acc": 0.7132237434387207, "H_acc": 0.2004450559616089, "Q_acc": 0.6789238042104989, "E_rej": 0.45478355884552, "C_rej": 0.24866759777069092, "G_rej": 0.5203476039459929, "D_rej": 0.8129233121871948, "H_rej": 0.18707668781280518, "Q_rej": 0.6346480625448749, "Delta_Q": 0.04427574166562398, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Isotopic mass effects on reaction energetics and zero-point energy: hypotheses about subtle kinetic discrimination and vibrational partitioning.", "ancestors": ["[Definition] Isotopologues are molecules differing only by the number of neutrons in one or more atoms.", "[Definition] Zero-point energy (ZPE) is the finite vibrational energy remaining at absolute zero temperature.", "[Variable] ZPE ≈ (1/2)hν where h is Planck’s constant and ν is the vibrational frequency.", "[Variable] ν depends inversely on the reduced mass μ of the vibrating atoms via ν = (1/2π)√(k/μ).", "[Constraint] Heavier isotopologues have larger μ and therefore lower ν and lower ZPE.", "[Law] The activation energy Ea is the energy difference between the reactant and transition-state ZPE levels.", "[Limit] The mass-dependent ZPE shift alters Ea and can therefore change the Arrhenius prefactor-based rate constant k."]}, "accepted": "Derivation summary: Heavier isotopologues increase reduced mass μ, lower vibrational frequency ν, and reduce zero-point energy ZPE. Activation energy Ea equals the ZPE gap between reactant and transition state. A heavier isotopologue lowers both ZPE levels, but the transition-state drop is larger, shrinking Ea. Arrhenius rate constant k increases exponentially with decreasing Ea.\n\nHYPOTHESIS: For any heavier isotopologue, the activation energy Ea decreases and the Arrhenius rate constant k increases.\nVERIFICATION: Units check: ZPE in joules, Ea in joules, k in s⁻¹.\nCONCLUSION: Heavier isotopologue lowers Ea and accelerates reaction.", "rejected": "Heavier isotopologues lower activation energy Ea and increase Arrhenius rate constant k at all pressures.", "E_acc": 0.537255048751831, "C_acc": 0.29638102650642395, "G_acc": 0.5594900103169493, "D_acc": 0.7660836141024318, "H_acc": 0.12627461552619934, "Q_acc": 0.6543875726555208, "E_rej": 0.14051325619220734, "C_rej": 0.3286011815071106, "G_rej": 0.5305413897731341, "D_rej": 0.7590094804763794, "H_rej": 0.2409905195236206, "Q_rej": 0.5102448626537808, "Delta_Q": 0.14414271000174006, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Topology-dependent current partitioning under dynamic boundary conditions: hypotheses on metastable current paths and energy bottlenecks.", "ancestors": ["[Definition] A graph G is a set V of vertices connected by edges E.", "[Definition] A boundary is a subset B of vertices designated as boundary nodes.", "[Definition] A path is a sequence of edges connecting two vertices.", "[Variable] k is a boundary node in B.", "[Variable] T is the set of all boundary nodes.", "[Constraint] Boundary nodes are fixed during analysis.", "[Limit] No edge connects boundary nodes directly.", "[Definition] A current is a function assigning real values to edges.", "[Law] Current conservation requires sum of currents into each vertex equals zero.", "[Limit] Metastable current paths exist only transiently on graphs."]}, "accepted": "Because every boundary node is fixed and no edge links two boundary nodes, any steady current into a boundary node must exit through interior vertices.  Current conservation therefore forces the net current across the cut separating B from the interior to vanish.\n\nHYPOTHESIS: The total current crossing any edge cut that separates the boundary set B from the rest of the graph is exactly zero.\n\nVERIFICATION: Sum over boundary nodes of (inflow − outflow) = 0 by conservation, and no direct B–B edges exist.\n\nCONCLUSION: Boundary inflow balances outflow via interior paths.", "rejected": "Because every boundary node is fixed and no edge links two boundary nodes, any steady current into a boundary node equals the sum of the resistances of the interior edges.", "E_acc": 0.4934343993663788, "C_acc": 0.197003573179245, "G_acc": 0.5426633451425005, "D_acc": 0.7777157187461853, "H_acc": 0.274819940328598, "Q_acc": 0.645223423918942, "E_rej": 0.2573736310005188, "C_rej": 0.3161754012107849, "G_rej": 0.534198839450255, "D_rej": 0.7940824329853058, "H_rej": 0.2059175670146942, "Q_rej": 0.5590415068436414, "Delta_Q": 0.08618191707530065, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Non-equilibrium steady states and detailed-balance breaking in driven chemical networks: hypotheses on emergent fluxes and cycle affinities.", "ancestors": ["[Definition] T denotes temperature.", "[Definition] k denotes rate constant.", "[Variable] P is probability.", "[Law] P obeys master equation.", "[Definition] J is probability current.", "[Constraint] J ≠ 0 implies non-equilibrium.", "[Variable] A is cycle affinity.", "[Definition] A is net force.", "[Limit] A = 0 at equilibrium.", "[Constraint] Forb A fixes J."]}, "accepted": "Because cycle affinity A fixes the probability current J and equilibrium requires A = 0, any non-zero J enforces a strictly positive lower bound on |A|.  \nHYPOTHESIS: A non-equilibrium steady state obeys |A| ≥ |J|/k.  \nVERIFICATION: Both sides have units of energy (kJ mol⁻¹) and the bound collapses to 0 when J = 0.  \nCONCLUSION: Affinity must exceed a J-proportional threshold whenever the system is out of equilibrium.", "rejected": "A non-equilibrium steady state obeys |A| ≥ |J|/k.", "E_acc": 0.17798368632793427, "C_acc": 0.44474536180496216, "G_acc": 0.5256230170295263, "D_acc": 0.7570042237639427, "H_acc": 0.26146378368139267, "Q_acc": 0.4948251033279424, "E_rej": 0.323151171207428, "C_rej": 0.3716750144958496, "G_rej": 0.5411982289515436, "D_rej": 0.7598998546600342, "H_rej": 0.24010014533996582, "Q_rej": 0.5588199506513775, "Delta_Q": -0.06399484732343508, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellite dynamics from an energy-momentum perspective: hypotheses about tidal dissipation, secular drift, and station-keeping energetics.", "ancestors": ["[Definition] E is mechanical energy.", "[Definition] p is linear momentum.", "[Law] E conserved when no work done.", "[Definition] J is angular momentum.", "[Law] J conserved when no torque.", "[Variable] W is work done.", "[Constraint] W = ΔE.", "[Limit] W ≥ 0.", "[Constraint] W = 0 implies ΔE = 0."]}, "accepted": "From the premises, mechanical energy E is linked to work W by W = ΔE, and W is non-negative.  \nHYPOTHESIS: Any system with W = 0 maintains constant mechanical energy, so Efinal = Einitial.  \nVERIFICATION: Units (J) match on both sides; valid when no work is done.  \nCONCLUSION: Zero work guarantees mechanical energy conservation.", "rejected": "Any system with constant mechanical energy has W = 0, so Efinal = Einitial.", "E_acc": 0.28267115354537964, "C_acc": 0.4124521315097809, "G_acc": 0.5322643518447876, "D_acc": 0.7780646197497845, "H_acc": 0.21084412932395935, "Q_acc": 0.5432923011481762, "E_rej": 0.27502867579460144, "C_rej": 0.4626311659812927, "G_rej": 0.5451723210513592, "D_rej": 0.7785539627075195, "H_rej": 0.22144603729248047, "Q_rej": 0.5325830225646496, "Delta_Q": 0.01070927858352655, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Ecosystem energy flow and matter cycling in presence of anthropogenic forcing: hypotheses on tipping points and alternative stable states.", "ancestors": ["[Definition] Gross primary production (P) is the rate of light energy fixation by autotrophs.", "[Law] The first law of thermodynamics states energy may alter form but is not created or destroyed.", "[Constraint] P sets the upper limit for energy entering all heterotrophic trophic levels.", "[Variable] Anthropogenic external energy input (E_A) is additional energy injected by human activities.", "[Law] System energy change equals P plus E_A minus respiration losses.", "[Variable] Tipping energy input (E_T) is the threshold E_A beyond which state change is initiated.", "[Constraint] When E_A exceeds E_T, the system is forced outside its historical energy envelope.", "[Limit] Beyond E_T, the original community structure cannot be recovered solely by ceasing E_A."]}, "accepted": "Derivation sentences  \nThe premises constrain that anthropogenic energy input E_A must not exceed the tipping threshold E_T, otherwise the system exits its historical envelope and the original community cannot be recovered.  \nHYPOTHESIS: Anthropogenic energy input E_A must remain below the tipping threshold E_T to prevent irreversible state change.  \nVERIFICATION: Units match (both E_A and E_T measured in energy per time).  \nCONCLUSION: Anthropogenic energy must be capped below the tipping threshold to avoid irreversible ecological change.", "rejected": "Anthropogenic energy input E_A must equal the tipping threshold E_T to prevent irreversible state change.", "E_acc": 0.91550213098526, "C_acc": 0.01902943104505539, "G_acc": 0.5751249645836651, "D_acc": 0.7556101232767105, "H_acc": 0.20068985223770142, "Q_acc": 0.816922785434872, "E_rej": 0.4584403336048126, "C_rej": 0.2702268064022064, "G_rej": 0.5493028678465635, "D_rej": 0.8438944220542908, "H_rej": 0.19513197243213654, "Q_rej": 0.6426129995379597, "Delta_Q": 0.17430978589691226, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Law] Angular momentum J is conserved in a closed system.", "[Definition] Subsystem A is a rigid body with angular momentum J_A.", "[Definition] Subsystem B is a rigid body with angular momentum J_B.", "[Variable] J_A is angular momentum of A.", "[Variable] J_B is angular momentum of B.", "[Law] J = J_A + J_B remains constant.", "[Definition] Internal torque τ_int is torque exchanged between A and B.", "[Limit] J_A and J_B can change only via τ_int.", "[Constraint] J_A + J_B = J at all times."]}, "accepted": "Internal variables: J_A, J_B, τ_int.  \nCases: (i) τ_int = 0 → J_A and J_B fixed; (ii) τ_int ≠ 0 → J_A and J_B vary oppositely.  \nEliminate: all cases conserve J_A + J_B = J.  \nDerive: |J_A| can differ from |J_B| only if τ_int ≠ 0; when τ_int = 0, |J_A| and |J_B| remain fixed.  \nHYPOTHESIS: Internal torque τ_int is zero if and only if the angular momenta of A and B remain constant.  \nVERIFICATION: τ_int = 0 implies dJ_A/dt = 0 and dJ_B/dt = 0.  \nCONCLUSION: Constancy of J_A and J_B diagnoses vanishing internal torque.", "rejected": "Internal torque τ_int is zero if and only if the angular momenta of A and B are independent.", "E_acc": 0.32700732350349426, "C_acc": 0.4723809063434601, "G_acc": 0.5707763587124646, "D_acc": 0.781684935092926, "H_acc": 0.14748471975326538, "Q_acc": 0.5593698025681079, "E_rej": 0.013937962241470814, "C_rej": 0.7807599306106567, "G_rej": 0.55010419129394, "D_rej": 0.7918002605438232, "H_rej": 0.20819973945617676, "Q_rej": 0.39559031897224495, "Delta_Q": 0.16377948359586292, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reaction rates viewed through rare-event statistics and transition-path ensembles: hypotheses about mechanistic multiplicity and dynamic bottlenecks.", "ancestors": ["[Definition] A reaction rate k is the probability that a reaction occurs per unit time.", "[Variable] E is the energy barrier height.", "[Law] k = A e^(-E/(kB T)) with kB Boltzmann constant and A frequency factor.", "[Definition] A transition path is a stochastic trajectory connecting reactant to product basin.", "[Variable] P is the probability a trajectory is a transition path.", "[Constraint] P = 1 only when trajectory joins reactant and product basins.", "[Limit] P → 0 when barrier height E → ∞ makes crossing exponentially rare.", "[Definition] A transition-path ensemble is the set of all transition paths.", "[Variable] N is the number of transition paths sampled.", "[Limit] N → ∞ is required for exact statistics of mechanistic multiplicity."]}, "accepted": "Transition paths vanish exponentially with barrier height; sampling must compensate.  \nHYPOTHESIS: A detectable transition-path ensemble requires N ≥ A e^(E/(kB T)) trajectories.  \nVERIFICATION: N dimensionless; holds when E/(kB T) ≫ 1.  \nCONCLUSION: Threshold quantifies sampling needed for mechanistic multiplicity.", "rejected": "Transition paths vanish linearly with barrier height; sampling must compensate.", "E_acc": 0.12952721118927002, "C_acc": 0.5918042659759521, "G_acc": 0.5320425077807158, "D_acc": 0.719590624794364, "H_acc": 0.222676582634449, "Q_acc": 0.4485562784131616, "E_rej": 0.025359174236655235, "C_rej": 0.7506136298179626, "G_rej": 0.5024389351601712, "D_rej": 0.7565235793590546, "H_rej": 0.3043455258011818, "Q_rej": 0.3788429766311311, "Delta_Q": 0.0697133017820305, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Protein folding landscapes in crowded intracellular environments: hypotheses on kinetic traps, chaperone intervention, and functional folding funnels.", "ancestors": ["[Definition] The protein folding landscape is a multidimensional surface whose axes are the conformational degrees of freedom and whose height is the Gibbs free energy G.", "[Variable] G(native) is the global minimum of G on this surface.", "[Variable] N is the native conformation corresponding to G(native).", "[Definition] A kinetic trap is a local minimum of G whose escape rate k_escape satisfies k_escape << 1 s⁻¹ at physiological temperature.", "[Constraint] Crowding adds excluded-volume interactions that raise G for expanded conformations.", "[Law] Microscopic reversibility requires that the forward flux into a trap equals the backward flux out when G is constant.", "[Variable] k_trap is the effective rate constant for entry into a kinetic trap.", "[Limit] The maximum k_escape from a trap of depth ΔG‡ is k_escape ≤ ν exp(−ΔG‡/RT), where ν ≈ 10⁶ s⁻¹.", "[Definition] A chaperone is a protein that binds transiently to non-native conformations and lowers their G."]}, "accepted": "Crowding raises the free energy of expanded conformations, steepening the landscape toward more compact states and thereby deepening the kinetic traps that lie along those compacting paths.  \nHYPOTHESIS: In a crowded cellular environment, every kinetic trap whose native-bound escape route requires chain expansion becomes deeper by at least ΔG_crowd ≈ 2 kcal mol⁻¹, reducing its escape rate below 10⁻³ s⁻¹.  \nVERIFICATION: ΔG_crowd has energy units; estimate uses RT≈0.6 kcal mol⁻¹ at 300 K and a conservative 3RT rise for excluded-volume.  \nCONCLUSION: Crowding traps are effectively irreversible on biological timescales.", "rejected": "In a crowded cellular environment, every kinetic trap whose native-bound escape route requires chain expansion becomes shallower by at least ΔG_crowd ≈ 2 kcal mol⁻¹, increasing its escape rate above 10³ s⁻¹.", "E_acc": 0.3087153434753418, "C_acc": 0.3541264533996582, "G_acc": 0.5518240290693939, "D_acc": 0.734950739890337, "H_acc": 0.16846543550491333, "Q_acc": 0.5622977226041258, "E_rej": 0.36699920892715454, "C_rej": 0.3274352252483368, "G_rej": 0.557850774464896, "D_rej": 0.8203004896640778, "H_rej": 0.17969951033592224, "Q_rej": 0.6022730194206815, "Delta_Q": -0.03997529681655565, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Thermochemical reaction landscapes considered as free-energy surfaces: hypotheses about competing minima and entropic contributions.", "ancestors": ["[Definition] G is Gibbs free energy.", "[Law] G = H - TS.", "[Variable] H is enthalpy.", "[Variable] T is temperature.", "[Variable] S is entropy.", "[Limit] G is minimized at equilibrium."]}, "accepted": "At equilibrium, G is minimized, so its temperature derivative at constant pressure must vanish.  \nHYPOTHESIS: The equilibrium temperature derivative of Gibbs free energy satisfies (∂G/∂T)_P = –S = 0.  \nVERIFICATION: Units consistent (J K⁻¹ = 0); holds only at the single T where G(T) is minimal.  \nCONCLUSION: Entropy must be zero at the temperature that minimizes G.", "rejected": "At equilibrium, the temperature derivative of Gibbs free energy satisfies (∂G/∂T)_P = –S, assuming entropy is independent of temperature.", "E_acc": 0.24108007550239563, "C_acc": 0.3532879054546356, "G_acc": 0.5485486225225031, "D_acc": 0.7679055854678154, "H_acc": 0.25171856582164764, "Q_acc": 0.5397854265756905, "E_rej": 0.19171559810638428, "C_rej": 0.31969600915908813, "G_rej": 0.5398577672895044, "D_rej": 0.7803283631801605, "H_rej": 0.21967163681983948, "Q_rej": 0.5356455400120467, "Delta_Q": 0.004139886563643835, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A lipid bilayer is a two-molecule-thick film of amphiphilic lipids forming a closed vesicle.", "[Variable] Let D denote the lateral diffusion coefficient of a lipid in the bilayer plane.", "[Law] Fick’s law states that the one-dimensional flux J along the bilayer is J = -D ∂c/∂x, where c is the local lipid concentration.", "[Constraint] Continuity requires that ∂c/∂t = -∂J/∂x, giving ∂c/∂t = D ∂²c/∂x².", "[Definition] A transient nano-domain is a local region where c exceeds the surrounding average by at least 20% for a lifetime τ > 10 ms.", "[Limit] The characteristic size L of such a nano-domain is bounded below by the membrane bending length κ/σ, where κ is the bending rigidity and σ is the membrane tension.", "[Constraint] Within the domain, lipid mobility remains described by the same D, so the domain evolution still obeys ∂c/∂t = D ∂²c/∂x²."]}, "accepted": "The transient nano-domain concentration profile evolves as a diffusive Gaussian whose width σ(t) = √(2Dt) must reach the membrane bending length κ/σ before the 10 ms lifetime expires.  \nHYPOTHESIS: A lipid nano-domain survives only if D ≥ (κ/σ)² / 20 ms.  \nVERIFICATION: units check—(κ/σ)² / 20 ms gives m² s⁻¹, matching diffusion coefficient.  \nCONCLUSION: Diffusion threshold sets minimal nano-domain lifetime.", "rejected": "The transient nano-domain concentration profile evolves as a diffusive Gaussian whose width σ(t) = √(2Dt) may shrink below the membrane bending length κ/σ after the 10 ms lifetime expires.", "E_acc": 0.41323623061180115, "C_acc": 0.27615755796432495, "G_acc": 0.49478314723819494, "D_acc": 0.7777080349624157, "H_acc": 0.1375218853354454, "Q_acc": 0.6094854054972529, "E_rej": 0.35552188754081726, "C_rej": 0.26134026050567627, "G_rej": 0.4981555488775484, "D_rej": 0.8490699529647827, "H_rej": 0.15093004703521729, "Q_rej": 0.6087406098260545, "Delta_Q": 0.0007447956711984505, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Photosynthetic energy conversion efficiency constrained by spectral and structural trade-offs: hypotheses about dynamic acclimation strategies.", "ancestors": ["[Definition] Photosynthesis is the biological conversion of light energy to chemical energy in chloroplasts.", "[Variable] η denotes the energy conversion efficiency of photosynthesis.", "[Variable] PPFD is the incident photosynthetic photon flux density in μmol photons m⁻² s⁻¹.", "[Variable] Φ denotes the spectral distribution function of PPFD across wavelengths 400–700 nm.", "[Constraint] η is directly proportional to the fraction of PPFD absorbed by photosynthetic pigments.", "[Constraint] Absorbed photons beyond the photosystem capacity are dissipated as heat or fluorescence.", "[Limit] The maximum quantum yield of photosynthesis is 0.125 mol C fixed per mol photons absorbed.", "[Constraint] Leaf architecture trades off maximal light absorption against self-shading and heat load."]}, "accepted": "<derivation sentences>\nThe premises link spectral PPFD distribution Φ to absorbed fraction, which scales η.  A leaf must therefore absorb only enough photons to match photosystem capacity, else excess quanta degrade quantum yield.  Derive the threshold PPFD* = 8 mol photons m⁻² s⁻¹ by dividing the maximum quantum yield 0.125 mol C mol⁻¹ into 1 mol photons, converting units via 10⁶ μmol mol⁻¹.\n\nHYPOTHESIS: Incident PPFD below 8 mol photons m⁻² s⁻¹ ensures absorbed quanta do not exceed photosystem capacity, preventing heat dissipation and maintaining quantum yield at 0.125 mol C fixed per mol photons absorbed.\nVERIFICATION: 8 mol photons m⁻² s⁻¹ equals 8×10⁶ μmol photons m⁻² s⁻¹, consistent with unit conversion and maximum quantum yield regime.\nCONCLUSION: Incident flux threshold protects quantum yield.", "rejected": "If incident PPFD stays below 8 mol photons m⁻² s⁻¹, absorbed quanta not exceed photosystem capacity prevent heat dissipation and maintain quantum yield at 0.125 mol C fixed per mol photons absorbed.", "E_acc": 0.6447135806083679, "C_acc": 0.07809890806674957, "G_acc": 0.5646423759753816, "D_acc": 0.7427011983735221, "H_acc": 0.1513274759054184, "Q_acc": 0.7241302598483993, "E_rej": 0.35057201981544495, "C_rej": 0.24227258563041687, "G_rej": 0.5631609337870032, "D_rej": 0.8355319499969482, "H_rej": 0.16446805000305176, "Q_rej": 0.6200088605750352, "Delta_Q": 0.10412139927336406, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Physical consequences of gravitational potential reference choices: hypotheses on energy barriers and bound-state classifications.", "ancestors": ["[Definition] Gravitational potential Φ is work per unit mass needed to bring test mass from infinity.", "[Variable] Φ(r) = scalar field at location r.", "[Constraint] Φ(∞) = 0 by boundary condition.", "[Law] Total mechanical energy E = K + U.", "[Variable] U = mΦ(r) is gravitational potential energy.", "[Limit] E < 0 defines bound state."]}, "accepted": "The gravitational potential Φ(r) is defined as the work per unit mass required to bring a test mass from infinity to position r, with Φ(∞) = 0. The gravitational potential energy U = mΦ(r) represents the potential energy of a test mass m in the gravitational field. For a bound state, the total mechanical energy E = K + U must be negative, where K is the kinetic energy of the test mass.\n\nHYPOTHESIS: A test mass m is gravitationally bound to a central mass if and only if its total mechanical energy E < 0, where E = K + mΦ(r).\n\nVERIFICATION: Units check: E has units of energy (kg·m²/s²), K has units of energy (kg·m²/s²), and mΦ(r) has units of energy (kg·m²/s²), consistent with the hypothesis.\n\nCONCLUSION: The test mass is gravitationally bound to the central mass.", "rejected": "A test mass m is gravitationally bound to a central mass if and only if its total mechanical energy E < 0, where E = K + m and K is treated as independent of Φ(r).", "E_acc": 0.40032443404197693, "C_acc": 0.2698836922645569, "G_acc": 0.5646770093590021, "D_acc": 0.8111229240894318, "H_acc": 0.10424003005027771, "Q_acc": 0.6308565754443407, "E_rej": 0.38689136505126953, "C_rej": 0.29095369577407837, "G_rej": 0.5589960015578461, "D_rej": 0.7912707030773163, "H_rej": 0.20872929692268372, "Q_rej": 0.6070570815953293, "Delta_Q": 0.023799493849011366, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Redox processes analyzed by Marcus theory extensions: hypotheses on solvent reorganization and coupled vibrational modes.", "ancestors": ["[Definition] Redox is electron transfer between species.", "[Definition] Solvent reorganization is solvent configuration change.", "[Law] Electron transfer requires solvent molecules rearrange.", "[Variable] E is total reorganization energy.", "[Variable] E_s is solvent reorganization energy.", "[Constraint] E equals E_s plus vibrational reorganization energy."]}, "accepted": "Electron transfer obliges the solvent shell to reorganize, so the solvent component of the reorganization energy must be non-zero.  \nHYPOTHESIS: Every redox event that obeys the stated mechanism satisfies E_s > 0.  \nVERIFICATION: Units of E_s are energy (J or eV); inequality holds whenever solvent is present.  \nCONCLUSION: Redox reactions require positive solvent reorganization energy.", "rejected": "Positive solvent reorganization energy implies redox reactions.", "E_acc": 0.31321489810943604, "C_acc": 0.37133297324180603, "G_acc": 0.574562955815054, "D_acc": 0.7808886840939522, "H_acc": 0.13587329536676407, "Q_acc": 0.5772008732295945, "E_rej": 0.3021944761276245, "C_rej": 0.29202955961227417, "G_rej": 0.5807825775409583, "D_rej": 0.8679849803447723, "H_rej": 0.13201501965522766, "Q_rej": 0.608804440527456, "Delta_Q": -0.03160356729786151, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Bond polarity and mixed-covalent character driven by orbital hybridization: hypotheses connecting spectral signatures to fractional charge transfer.", "ancestors": ["[Definition] A bond is polarity when electron density is unevenly shared between atoms.", "[Variable] Let χ represent electronegativity.", "[Law] Polarity increases with electronegativity difference.", "[Definition] Hybridization is the mixing of atomic orbitals.", "[Variable] Mixing ratio is the hybridization ratio.", "[Constraint] Hybridization controls polarity magnitude.", "[Limit] Polarity cannot exceed hybridization limit."]}, "accepted": "<derivation>\nFrom premises: polarity increases with electronegativity difference, hybridization controls polarity magnitude, polarity cannot exceed hybridization limit. Eliminate cases where polarity exceeds hybridization limit. Derive threshold: polarity magnitude bounded by hybridization limit.\n\nHYPOTHESIS: Polarity magnitude is bounded by hybridization limit.\nVERIFICATION: Units check: polarity magnitude dimensionless, hybridization limit dimensionless.\nCONCLUSION: Hybridization sets polarity maximum.", "rejected": "Hybridization limit is bounded by polarity magnitude.", "E_acc": 0.5898040533065796, "C_acc": 0.24805249273777008, "G_acc": 0.578917062463006, "D_acc": 0.7865584082901478, "H_acc": 0.12706881761550903, "Q_acc": 0.6877189298334998, "E_rej": 0.6264317631721497, "C_rej": 0.12742045521736145, "G_rej": 0.5816585690481588, "D_rej": 0.8104569315910339, "H_rej": 0.18954306840896606, "Q_rej": 0.7219142311951146, "Delta_Q": -0.03419530136161475, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellite dynamics from an energy-momentum perspective: hypotheses about tidal dissipation, secular drift, and station-keeping energetics.", "ancestors": ["[Definition] The specific mechanical energy ε of a satellite is ε = v²/2 − μ/r, where v is speed relative to the primary, μ is the gravitational parameter, and r is radial distance.", "[Definition] The specific relative angular momentum h of a satellite is h = r × v, where × denotes the vector cross product.", "[Law] In a two-body Keplerian orbit, ε and h are constant in the absence of non-conservative forces.", "[Variable] Tidal dissipation converts orbital mechanical energy into heat at a rate P_d.", "[Constraint] P_d ≥ 0 because dissipation cannot create mechanical energy.", "[Variable] secular drift Δa per orbit of the semi-major axis a satisfies Δa/a = −2P_d T_orbit/(μ m), where T_orbit is the orbital period and m is satellite mass.", "[Constraint] Station-keeping requires an external power input P_sk to counteract Δa such that P_sk ≥ P_d.", "[Limit] The onboard energy reservoir E batt imposes P_sk ≤ E batt/T_res, where T_res is the residual mission life."]}, "accepted": "Tidal dissipation converts orbital mechanical energy into heat at a rate P_d, station-keeping requires external power input P_sk to counteract Δa such that P_sk ≥ P_d, and onboard energy reservoir E batt imposes P_sk ≤ E batt/T_res. Combining these constraints yields P_d ≤ E batt/T_res.\n\nHYPOTHESIS: The onboard battery capacity limits the maximum sustainable tidal dissipation power to P_d ≤ E batt/T_res.\nVERIFICATION: Units check: P_d (W) ≤ E batt (J)/T_res (s) → W ≤ W.\nCONCLUSION: Battery capacity bounds tidal dissipation power.", "rejected": "The onboard battery capacity limits the maximum tidal dissipation power to P_d ≤ E batt/T_res, assuming tidal dissipation and battery capacity are independent variables.", "E_acc": 0.222446009516716, "C_acc": 0.6301199793815613, "G_acc": 0.5294937561848201, "D_acc": 0.7388004273176193, "H_acc": 0.1772860288619995, "Q_acc": 0.4766400407929905, "E_rej": 0.016522584483027458, "C_rej": 0.9477397203445435, "G_rej": 0.5393777945282636, "D_rej": 0.7576722800731659, "H_rej": 0.2423277199268341, "Q_rej": 0.3505860742036021, "Delta_Q": 0.1260539665893884, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A lipid bilayer is a two-layered molecular sheet that forms the continuous matrix of biological membranes.", "[Variable] D is the lateral diffusion coefficient of a membrane component.", "[Constraint] 10⁻² µm² s⁻¹ ≥ D ≥10⁻⁴ µm² s⁻¹ for phospholipids in vivo.", "[Definition] A nanodomain is a transient (τ <1 s) cluster of ≤100 lipids and proteins.", "[Law] Fick’s second law relates the local concentration to D and its second spatial derivative.", "[Variable] τ is the characteristic lifetime of a nanodomain.", "[Definition] Mesoscopic sorting is the spontaneous partitioning of components on 10–300 nm scales.", "[Constraint] The free-energy gain ΔG = kT sets the maximum size of a stable nanodomain."]}, "accepted": "The lateral diffusion coefficient D and nanodomain lifetime τ are linked by Fick’s second law; inserting the extreme values D = 10⁻² µm² s⁻¹ and τ = 1 s gives a characteristic diffusion length l = √(Dτ) ≈ 0.1 µm, so any nanodomain must dissolve before growing beyond this scale.\n\nHYPOTHESIS: A nanodomain in a lipid bilayer cannot exceed 0.1 µm in size before thermally dissolving.\n\nVERIFICATION: Units check: √(Dτ) = √(µm² s⁻¹ × s) = µm, consistent with mesoscopic sorting range 10–300 nm.\n\nCONCLUSION: Diffusion limits nanodomain size to 0.1 µm, setting the upper bound for mesoscale sorting.", "rejected": "A nanodomain in a lipid bilayer cannot exceed 0.1 µm in size after thermally dissolving.", "E_acc": 0.6633883118629456, "C_acc": 0.09843870997428894, "G_acc": 0.5026482891407795, "D_acc": 0.792054295539856, "H_acc": 0.1189655065536499, "Q_acc": 0.726372717844788, "E_rej": 0.17827627062797546, "C_rej": 0.5163516402244568, "G_rej": 0.5003160287706123, "D_rej": 0.8569540083408356, "H_rej": 0.14304599165916443, "Q_rej": 0.5073619613998744, "Delta_Q": 0.21901075644491352, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Induced currents studied through energetic opposition and topological constraints: hypotheses about optimal induction geometries.", "ancestors": ["[Definition] Magnetic flux Φ through a loop is the surface integral Φ = ∫ B · dA.", "[Law] Faraday's law states the induced emf ε equals the negative time rate of change of Φ, ε = –dΦ/dt.", "[Variable] Let L denote the self-inductance of the conducting loop.", "[Law] The self-induced emf equals –L dI/dt, opposing the change in current I.", "[Definition] Inductive energy stored in the loop is E = ½ L I².", "[Constraint] For a fixed cross-sectional wire length l, the loop geometry sets the minimum achievable L.", "[Limit] The minimal L is reached by maximizing the geometric mean distance between filament elements.", "[Constraint] Topology forbids simply connected planar loops from achieving the absolute lower bound for L given fixed l."]}, "accepted": "<derivation sentences>\nFrom the self-inductance L of a conducting loop with fixed wire length l, the minimal achievable L is constrained by the loop geometry. The absolute lower bound for L cannot be reached by simply connected planar loops due to topological limits. Thus, the minimal L must satisfy a lower threshold determined by the geometry and topology of the loop.\n\nHYPOTHESIS: The self-inductance L of a conducting loop with fixed wire length l is bounded below by a geometry-dependent threshold L_min(l) that cannot be achieved by simply connected planar loops.\n\nVERIFICATION: Units of L_min(l) are henries (H), consistent with self-inductance.\n\nCONCLUSION: The loop geometry imposes a fundamental lower limit on achievable self-inductance for fixed wire length.", "rejected": "The self-inductance L of a conducting loop with fixed wire length l can be bounded below by a geometry-dependent threshold L_min(l) that is achieved by simply connected planar loops.", "E_acc": 0.6901221871376038, "C_acc": 0.0930991992354393, "G_acc": 0.5289091915474273, "D_acc": 0.7702980781240123, "H_acc": 0.1539095863699913, "Q_acc": 0.732867311591482, "E_rej": 0.09555622935295105, "C_rej": 0.8367524147033691, "G_rej": 0.5354906106367707, "D_rej": 0.8665894567966461, "H_rej": 0.13341054320335388, "Q_rej": 0.4283913450315595, "Delta_Q": 0.3044759665599225, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Momentum conservation in systems with non-conservative interactions: when and how momentum exchange with substrates or fields can be modeled causally.", "ancestors": ["[Definition] A system is a collection of particles within a boundary.", "[Variable] B denotes the system boundary.", "[Variable] p denotes momentum.", "[Constraint] Total momentum p remains constant if no particle crosses B.", "[Definition] Non-conservative interaction means mechanical energy not conserved.", "[Constraint] Non-conservative interaction does not alter total momentum p."]}, "accepted": "Because non-conservative interactions leave total momentum p unchanged while they can change mechanical energy, any measurable energy loss in a system whose boundary B is never crossed must be traceable to such interactions without affecting the conserved value of p.\n\nHYPOTHESIS: In a system with impermeable boundary B, the fractional mechanical-energy loss ΔE/E equals the work done by non-conservative forces, while the total momentum p remains exactly equal to its initial value.\n\nVERIFICATION: Energy and work share units (joules), and momentum conservation holds for isolated systems regardless of energy dissipation.\n\nCONCLUSION: Energy loss identifies non-conservative action; momentum stays constant.", "rejected": "Because the conserved value of p is unaffected, any measurable energy loss traceable to non-conservative interactions leaves total momentum unchanged while altering mechanical energy.", "E_acc": 0.2822025716304779, "C_acc": 0.4514106810092926, "G_acc": 0.5446113300509751, "D_acc": 0.7859364487230778, "H_acc": 0.3069654554128647, "Q_acc": 0.529791645500809, "E_rej": 0.21470344066619873, "C_rej": 0.5722720623016357, "G_rej": 0.543440605327487, "D_rej": 0.7526059746742249, "H_rej": 0.24739402532577515, "Q_rej": 0.4844265332072973, "Delta_Q": 0.045365112293511756, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adaptation as navigations of rugged fitness landscapes with contingent historical constraints: hypotheses on predictability vs contingency.", "ancestors": ["[Definition] A fitness landscape is real-valued function F(g) mapping genotype g to reproductive fitness.", "[Variable] Genotype g ∈ {0,1}^L for sequence length L.", "[Variable] Rugged fitness landscape F has multiple local peaks.", "[Constraint] Historical genotype sequence g(0),…,g(t) constrains possible g(t+1).", "[Definition] Adaptation path A is sequence g(0),…,t where F(g(t)) increases.", "[Limit] Adaptation path cannot revisit g(t) already passed.", "[Constraint] Path A must start from ancestor g(0)."]}, "accepted": "The premises define a rugged fitness landscape over binary genotypes of length L, where adaptation paths must monotonically increase F(g) without revisiting any genotype. Given these constraints, the path must terminate when it reaches a local peak that is not the global maximum.\n\nHYPESIS: Every adaptation path A must terminate at a local peak of F(g) within at most 2^L steps.\nVERIFICATION: The path cannot revisit any genotype, so the maximum length is bounded by the total number of genotypes 2^L.\nCONCLUSION: The path must terminate at a local peak because it cannot increase further without revisiting genotypes.", "rejected": "Adaptation paths must terminate at a local peak of any real-valued function, regardless of whether the function is rugged or smooth.", "E_acc": 0.6219714283943176, "C_acc": 0.06985528022050858, "G_acc": 0.6017220994690433, "D_acc": 0.8137191653251648, "H_acc": 0.13831329345703125, "Q_acc": 0.7418772960873321, "E_rej": 0.052840933203697205, "C_rej": 0.5975619554519653, "G_rej": 0.5460484162831563, "D_rej": 0.76964470744133, "H_rej": 0.28794411569833755, "Q_rej": 0.43068410204577956, "Delta_Q": 0.31119319404155255, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A lipid membrane is a fluid two-dimensional continuum composed of amphiphilic bilayer.", "[Law] The membrane bending rigidity κ relates curvature energy E to mean curvature C by E = 2κ(C)^2.", "[Variable] The instantaneous local curvature C has unit m^{-1}.", "[Constraint] Total membrane area A remains constant at mesoscale.", "[Limit] Thermal fluctuation amplitude limits curvature amplitude to C ≤ 2kT/κ.", "[Definition] A nanodomain is a transient cluster of lipids spanning < 100 nm.", "[Variable] Domain lifetime τ depends on lipid mobility L and viscosity η by τ = L/6η.", "[Constraint] Each nanodomain must conserve lipid number during deformation.", "[Limit] Domain growth stops when boundary curvature diverging energy reaches thermal energy kT.", "[Law] Membrane permeability P decreases exponentially with increasing transient domain packing by δP/P = exp(-ΔE/kT)."]}, "accepted": "The membrane bending rigidity κ and thermal fluctuation amplitude limit C ≤ 2kT/κ together impose a lower bound on the curvature energy density that any transient nanodomain must overcome to deform the surrounding bilayer.  Derive the threshold: the boundary curvature energy density must exceed kT/πD² for a domain of diameter D ≈ 100 nm, otherwise thermal fluctuations suppress deformation.\n\nHYPOTHESIS: A nanodomain boundary curvature energy density threshold is 4kT/πD², below which thermal fluctuations dominate deformation.\n\nVERIFICATION: Units check: kT (J) / D² (m²) → J m⁻², consistent with curvature energy density.\n\nCONCLUSION: Thermal fluctuation suppresses nanodomain deformation when boundary curvature energy density falls below 4kT/πD².", "rejected": "A nanodomain boundary curvature energy density threshold is 4kT/πD², below which thermal fluctuations dominate deformation.", "E_acc": 0.5120116472244263, "C_acc": 0.212027445435524, "G_acc": 0.48682051300420426, "D_acc": 0.7941725879907608, "H_acc": 0.17205530405044556, "Q_acc": 0.6501910948741716, "E_rej": 0.15904977917671204, "C_rej": 0.24383965134620667, "G_rej": 0.496997802547412, "D_rej": 0.8285281956195831, "H_rej": 0.17147180438041687, "Q_rej": 0.5469050226791297, "Delta_Q": 0.10328607219504193, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellite dynamics from an energy-momentum perspective: hypotheses about tidal dissipation, secular drift, and station-keeping energetics.", "ancestors": ["[Limit] Energy cannot be created or destroyed.", "[Definition] Tidal dissipation is the conversion of kinetic energy into heat.", "[Variable] H is the heat generated by tidal dissipation.", "[Law] H increases as orbital energy decreases.", "[Constraint] H > 0 for any non-rigid body.", "[Limit] Total mechanical energy E = E kinetic + E potential decreases secularly."]}, "accepted": "Tidal dissipation converts kinetic energy into heat H, which increases as orbital energy decreases, while total mechanical energy E decreases secularly.  \nHYPOTHESIS: Any secular decrease in orbital energy must yield H ≥ 0, with H strictly positive for non-rigid bodies.  \nVERIFICATION: H has units of energy, consistent with premises; holds for any non-rigid body.  \nCONCLUSION: Tidal heat generation is secularly tied to orbital energy loss.", "rejected": "Tidal dissipation converts kinetic energy into heat H, which increases as orbital energy decreases, while total mechanical energy E remains constant.", "E_acc": 0.7194799184799194, "C_acc": 0.08665911853313446, "G_acc": 0.558474643919908, "D_acc": 0.7781831249594688, "H_acc": 0.11990975588560104, "Q_acc": 0.7538527300246642, "E_rej": 0.18238459527492523, "C_rej": 0.5630849599838257, "G_rej": 0.5533962976332987, "D_rej": 0.8878979980945587, "H_rej": 0.11210200190544128, "Q_rej": 0.5191470455407399, "Delta_Q": 0.23470568448392437, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Variable-mass systems analysed through momentum flux and energy bookkeeping: hypotheses about reactive thrust, internal energy change, and open-system invariants.", "ancestors": ["[Definition] System mass m(t) is the instantaneous sum of all contained mass.", "[Variable] u(Δm) is the speed of ejected mass Δm relative to the system.", "[Law] Newton’s second law for variable-mass systems states F = m dv/dt – u dm/dt.", "[Definition] The thrust term is T = u dm/dt.", "[Variable] P(t) = m v is the instantaneous system momentum.", "[Law] The open-system momentum rate is dP/dt = F + u dm/dt.", "[Definition] Specific internal energy e is the internal energy per unit mass.", "[Variable] dQ is the infinitesimal heat added to the system.", "[Law] The open-system energy rate is dE/dt = dQ/dt + Pext dx/dt + (e + u²/2) dm/dt.", "[Constraint] Total energy E = ½m v² + m e is conserved when F = 0 and dQ = 0 and u = 0."]}, "accepted": "The open-system momentum rate dP/dt = F + u dm/dt combines with the thrust term T = u dm/dt to yield dP/dt = F + T, showing that thrust augments the external force in changing momentum.\n\nHYPOTHESIS: Inertial thrust T = u dm/dt equals the mass expulsion term u dm/dt and represents the net force contribution from variable-mass ejection.\n\nVERIFICATION: Units [T] = kg·m/s² = N, consistent with thrust as force.\n\nCONCLUSION: Thrust quantifies the momentum flux from expelled mass.", "rejected": "The open-system momentum rate dP/dt = F – u dm/dt combines with the thrust term T = u dm/dt to yield dP/dt = F – T, showing that thrust counteracts the external force in changing momentum.", "E_acc": 0.3743017315864563, "C_acc": 0.37871435284614563, "G_acc": 0.5324944053427316, "D_acc": 0.7975795343518257, "H_acc": 0.16544407606124878, "Q_acc": 0.5860180292394943, "E_rej": 0.1858125627040863, "C_rej": 0.6313602328300476, "G_rej": 0.5411922804196365, "D_rej": 0.8345461487770081, "H_rej": 0.16545385122299194, "Q_rej": 0.4880740229622461, "Delta_Q": 0.0979440062772482, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Induced currents studied through energetic opposition and topological constraints: hypotheses about optimal induction geometries.", "ancestors": ["[Definition] Current is charge in motion.", "[Variable] Let I be the induced current.", "[Law] Lenz law: induced current opposes the change in flux.", "[Constraint] Topology constrains the available current paths.", "[Limit] B = E/(c²) limits the magnetic energy density.", "[Variable] Let η be the energetic opposition coefficient."]}, "accepted": "Lenz law requires the induced current to oppose the flux change, so the energetic cost of that opposition is set by the magnetic energy density limit B=E/c².  Combining this with the definition of current as moving charge yields a bound on how large the opposition coefficient η can become before the magnetic field saturates.\n\nHYPOTHESIS: The energetic opposition coefficient satisfies η ≤ E/(I c²), equality holding when the induced magnetic field reaches its energy-density limit.\n\nVERIFICATION: Units check: η (energy/charge²) = (J/C²); E/(I c²) = (J m⁻¹)/(A m s⁻²) = J C⁻².\n\nCONCLUSION: η is bounded by the field-energy ceiling, predicting a maximum measurable value for any induced-current geometry.", "rejected": "The energetic opposition coefficient η can exceed the magnetic energy-density limit E/c², violating the bound imposed by topology.", "E_acc": 0.2761489748954773, "C_acc": 0.41754356026649475, "G_acc": 0.5458571971394122, "D_acc": 0.7627388685941696, "H_acc": 0.14253082871437073, "Q_acc": 0.5468021106906236, "E_rej": 0.11987877637147903, "C_rej": 0.5510560870170593, "G_rej": 0.531942140951287, "D_rej": 0.7379123121500015, "H_rej": 0.2620876878499985, "Q_rej": 0.45351453734328967, "Delta_Q": 0.0932875733473339, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Protein folding landscapes in crowded intracellular environments: hypotheses on kinetic traps, chaperone intervention, and functional folding funnels.", "ancestors": ["[Definition] A protein is a polypeptide chain that folds into a native structure.", "[Definition] A folding funnel is a free-energy surface guiding polypept to the native state.", "[Variable] k is the rate constant for transitions between conformational states.", "[Law] k satisfies Arrhenius law k = A exp(−βΔF where β = 1/kT.", "[Constraint] ΔF is the free-energy difference between two conformational states.", "[Limit] In crowded environments, kinetic traps reduce effective folding rates.", "[Definition] A chaperone is a protein binds unfolded chains and prevents aggregation.", "[Constraint] Chaperone binding lowers local concentration of unfolded chains."]}, "accepted": "Derivation summary:\nThe Arrhenius law k = A exp(−βΔF) governs transitions between conformational states. In crowded environments, kinetic traps reduce effective folding rates. Chaperones lower unfolded chain concentration, altering local free-energy differences. Combining these, the rate constant k scales with local unfolded concentration c through k = A exp(−βΔF(c)). Differentiating with respect to c yields dk/dc = −βk dΔF/dc, establishing a measurable threshold.\n\nHYPOTHESIS: The rate constant for transitions between conformational states satisfies k ≤ A exp(−βΔF_min) where ΔF_min is the minimal free-energy difference achievable by chaperone binding.\nVERIFICATION: Units check: k (s⁻¹), A (s⁻¹), β (J⁻¹), ΔF_min (J) consistent with Arrhenius law.\nCONCLUSION: Chaperone binding sets an upper bound on folding transition rates.", "rejected": "The rate constant for transitions between conformational states satisfies k = A exp(−βΔF) where ΔF is the free-energy difference between two conformational states.", "E_acc": 0.8622480630874634, "C_acc": 0.026529377326369286, "G_acc": 0.4971116059459746, "D_acc": 0.6886678536732992, "H_acc": 0.16329741477966309, "Q_acc": 0.7741946939068536, "E_rej": 0.8413979411125183, "C_rej": 0.08390668779611588, "G_rej": 0.517008471331792, "D_rej": 0.6793655753135681, "H_rej": 0.3206344246864319, "Q_rej": 0.7428494116349612, "Delta_Q": 0.03134528227189237, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stereoelectronic control of reactivity in polyfunctional molecules: hypotheses about conformational gating and orbital alignment.", "ancestors": ["[Definition] Stereoelectronic control governs reactivity by orbital alignment geometry.", "[Definition] Conformational gating modulates reactivity through stereoelectronic control.", "[Variable] k denotes reaction rate.", "[Variable] T denotes temperature.", "[Variable] E denotes orbital alignment energy.", "[Constraint] Reactivity depends on orbital alignment geometry.", "[Constraint] Conformational gating requires stereoelectronic control."]}, "accepted": "By combining stereoelectronic control with conformational gating, the reaction rate k becomes a function of the orbital alignment energy E, which itself is modulated by temperature T through conformational population shifts.\n\nHYPOTHESIS: The reaction rate k increases monotonically with decreasing orbital alignment energy E, and the sensitivity dk/dE scales inversely with temperature T.\n\nVERIFICATION: Units consistent (k in s⁻¹, E in J, T in K); valid within the regime where conformational gating dominates the rate.\n\nCONCLUSION: Lower temperature amplifies rate sensitivity to orbital alignment.", "rejected": "By combining stereoelectronic control with conformational gating, the orbital alignment energy E becomes a function of the reaction rate k, which itself is modulated by temperature T through conformational population shifts.", "E_acc": 0.16267675161361694, "C_acc": 0.21506275236606598, "G_acc": 0.586453582936277, "D_acc": 0.8046206049621105, "H_acc": 0.11094498634338379, "Q_acc": 0.5729108139562111, "E_rej": 0.7613581418991089, "C_rej": 0.04984109848737717, "G_rej": 0.6024068543532243, "D_rej": 0.896931916475296, "H_rej": 0.10306808352470398, "Q_rej": 0.8080001686854908, "Delta_Q": -0.23508935472927972, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chromatic energy redistribution in dispersive systems: hypotheses about spectral-dependent energy transport and recombination effects.", "ancestors": ["[Definition] Chromatic energy is the frequency-dependent energy content in a dispersive medium.", "[Law] Energy at frequency ω transports at group velocity v_g(ω).", "[Variable] E(ω) is density of chromatic energy per unit frequency.", "[Variable] v_g(ω) is group velocity at frequency ω.", "[Constraint] Total energy E satisfies ∫ E(ω)dω = E.", "[Limit] Energy cannot transport faster than v_g(ω) at each ω.", "[Variable] D(ω) is chromatic energy redistribution rate.", "[Law] Redistribution rate D(ω) equals ∂E(ω)/∂t."]}, "accepted": "Chromatic energy redistribution rate D(ω) equals the time derivative of the frequency-local energy density, D(ω)=∂E(ω)/∂t, and integrates to zero when the medium is isolated, ensuring no faster-than-v transport at any ω.\n\nHYPOTHESIS: The redistribution rate D(ω) satisfies ∫D(ω)dω=0, so faster-than-v transport is impossible at any frequency.\n\nVERIFICATION: Units of D(ω) are J s⁻¹ Hz⁻¹, consistent with ∂E(ω)/∂t.\n\nCONCLUSION: Redistribution preserves total energy without exceeding group velocity.", "rejected": "The redistribution rate D(ω) satisfies ∫D(ω)dω=0, so faster-than-v transport is impossible at any frequency.", "E_acc": 0.5891181826591492, "C_acc": 0.13212604820728302, "G_acc": 0.556731879041763, "D_acc": 0.791216816753149, "H_acc": 0.07445383071899414, "Q_acc": 0.7124546012433712, "E_rej": 0.03960740938782692, "C_rej": 0.8654127717018127, "G_rej": 0.5143242672784254, "D_rej": 0.7792001068592072, "H_rej": 0.22079989314079285, "Q_rej": 0.37542455398943275, "Delta_Q": 0.3370300472539385, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition] Spatial frequency k is the reciprocal of the spatial period in cycles per unit length.", "[Definition] The optical transfer function H(k) is the 2-D Fourier transform of the point-spread function.", "[Law] Conservation of energy requires the integral of |H(k)|² over all k to equal the total energy E incident on the detector.", "[Constraint] The passband K is the range of k for which |H(k)|² exceeds a specified threshold T.", "[Variable] The information density I(k) is given by the base-2 logarithm of the reciprocal noise power spectrum.", "[Limit] The maximum k imaged is bounded by the cutoff k_c = 2NA/λ where NA is the numerical aperture and λ is the wavelength."]}, "accepted": "The passband K is fixed by the threshold T applied to |H(k)|², while the maximum spatial frequency is capped at k_c = 2NA/λ.  Combining these bounds shows that the imaging system cannot convey spatial information beyond the smaller of the two limits.\n\nHYPOTHESIS: The effective spatial bandwidth is the intersection of the passband K and the interval [0, k_c], so the highest reliably imaged frequency is min(max(K), k_c).\n\nVERIFICATION: Both quantities have units of cycles per length and the inequality holds for any positive threshold T and optical parameters NA, λ.\n\nCONCLUSION: The usable resolution is strictly limited by whichever constraint—optical cutoff or detector threshold—is stricter.", "rejected": "The passband K is fixed by the threshold T applied to |H(k)|², while the maximum spatial frequency is capped at k_c = 2NA/λ, so every spatial frequency below k_c is always transmitted regardless of T.", "E_acc": 0.4269021153450012, "C_acc": 0.2252385914325714, "G_acc": 0.5238605596823618, "D_acc": 0.7683985382318497, "H_acc": 0.14393240213394165, "Q_acc": 0.6270814956864342, "E_rej": 0.07316112518310547, "C_rej": 0.7205225229263306, "G_rej": 0.5363394089508802, "D_rej": 0.8237356841564178, "H_rej": 0.2203303948044777, "Q_rej": 0.4278258121106774, "Delta_Q": 0.19925568357575685, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mutational robustness and network-level redundancy: hypotheses on how distributed regulation masks deleterious changes.", "ancestors": ["[Definition] A gene regulatory network is a graph whose nodes are genes and whose directed edges indicate regulation.", "[Definition] Robustness R is the probability that phenotype remains unchanged after a mutation.", "[Definition] Mutational robustness Rμ refers to R under genetic mutation.", "[Variable] n = number of distinct regulators targeting a gene.", "[Constraint] If n > 1, a single regulatory edge deletion leaves n – 1 inputs intact.", "[Law] Phenotype is a function P(G) of genotype G.", "[Definition] Neutrality N is the count of genotypes yielding identical P.", "[Law] Rμ = N / total possible genotypes.", "[Variable] k is the network’s average in-degree per node.", "[Limit] Rμ ≤ 1 with equality iff all mutations are neutral."]}, "accepted": "Using the constraint that a gene with n > 1 regulators retains n – 1 inputs after one edge deletion, the maximal mutational robustness for such a node occurs when every one-edge deletion leaves the phenotype unchanged, so the neutral set equals the number of genotypes differing by exactly one edge.  \nHYPOTHESIS: For any gene with in-degree n > 1, the mutational robustness against single-edge deletions satisfies Rμ ≤ (n – 1)/n, with equality iff all n possible single deletions are neutral.  \nVERIFICATION: Dimensionless ratio bounded by 1; valid for single-edge deletion regime.  \nCONCLUSION: Robustness is strictly limited by the number of redundant inputs.", "rejected": "For any gene with in-degree n > 1, mutational robustness Rμ is (n – 1)/n if and only if all n possible single deletions are neutral.", "E_acc": 0.3897307217121124, "C_acc": 0.33161401748657227, "G_acc": 0.5710517078405246, "D_acc": 0.7705603018403053, "H_acc": 0.14464408159255981, "Q_acc": 0.6044544067932293, "E_rej": 0.3672371506690979, "C_rej": 0.335320383310318, "G_rej": 0.5945870436262339, "D_rej": 0.8315137624740601, "H_rej": 0.16848623752593994, "Q_rej": 0.6114786060061306, "Delta_Q": -0.0070241992129013164, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Standing-wave energy balance and reactive power: hypotheses about node/anti-node energy exchange and boundary condition sensitivity.", "ancestors": ["[Definition] A standing wave is a wave pattern where incident and reflected waves interfere.", "[Law] Nodes are positions of zero amplitude interference; antinodes are maximum amplitude positions.", "[Variable] Incident energy E₍ᵢ can be represented as power density along transmission line.", "[Constraint] Energy conservation requires reflected power Pᵣ equals incident power Pᵢ in lossless medium.", "[Limit] Node energy density ρₙ must be zero due to destructive interference cancellation.", "[Definition] Reactive power Q represents oscillatory energy flow without net energy transfer.", "[Variable] Antinode energy density ρₐ equals maximum stored energy density in standing wave pattern.", "[Constraint] Boundary conditions determine reflection coefficient and node/antinode positions."]}, "accepted": "Derivation summary:  \nDestructive interference forces the node energy density to zero, while antinode density equals maximum stored energy. Energy conservation couples reflected power to incident power, so the reflected wave amplitude fixes the standing ratio.  \n\nHYPOTHESIS: The standing-wave energy density at any point is bounded by ρₐ ≥ ρ(x) ≥ 0, with equality at antinodes and nodes respectively.  \nVERIFICATION: Units check (energy per volume) and regime of validity for lossless medium.  \nCONCLUSION: Energy density extrema are fully determined by interference pattern.", "rejected": "The standing-wave energy density at any point is bounded by ρₐ ≥ ρ(x) ≥ 0, with equality at nodes and antinodes respectively.", "E_acc": 0.3143245577812195, "C_acc": 0.337008535861969, "G_acc": 0.5177494385279715, "D_acc": 0.7228678179283937, "H_acc": 0.15847153961658478, "Q_acc": 0.5591719574915867, "E_rej": 0.3612378239631653, "C_rej": 0.40570852160453796, "G_rej": 0.5166760885622352, "D_rej": 0.8305203020572662, "H_rej": 0.16947969794273376, "Q_rej": 0.579720951197669, "Delta_Q": -0.02054899370608232, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Variable-mass systems analysed through momentum flux and energy bookkeeping: hypotheses about reactive thrust, internal energy change, and open-system invariants.", "ancestors": ["[Definition] An open system is a region of space enclosed by an imaginary boundary across which matter can pass.", "[Variable] m(t) is the mass of the system at time t.", "[Constraint] The mass may change: m(t) is not constant.", "[Law] Newton's second law for open systems reads F = dp/dt.", "[Definition] p is the momentum of the system.", "[Variable] v is the velocity of the system.", "[Limit] No external force means F = 0.", "[Law] Conservation of momentum requires dp/dt = 0 when F = 0."]}, "accepted": "When the open system experiences no external force, its momentum remains constant over time.  \nHYPOTHESIS: If F = 0, then dp/dt = 0 and p remains constant.  \nVERIFICATION: Units: dp/dt has force units (N); p has kg·m/s; both consistent.  \nCONCLUSION: No external force implies momentum conservation.", "rejected": "If p remains constant, then F = 0 and dp/dt = 0.", "E_acc": 0.5169755816459656, "C_acc": 0.21070371568202972, "G_acc": 0.5337903153849766, "D_acc": 0.7370119877159595, "H_acc": 0.14446115493774414, "Q_acc": 0.6526662764837966, "E_rej": 0.32912182807922363, "C_rej": 0.3853012025356293, "G_rej": 0.5379443669226021, "D_rej": 0.6720442026853561, "H_rej": 0.32795579731464386, "Q_rej": 0.5308784421067685, "Delta_Q": 0.12178783437702811, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Gradual accumulation of complex systems explained via modular co-option and incremental functional shifts: hypotheses on feasible assembly paths.", "ancestors": ["[Definition] A module is a component that performs a discrete subfunction within a larger system.", "[Definition] Modular co-option is the process where a module is repurposed from one system to another.", "[Definition] Functional shift is the change in module or system function over time.", "[Definition] An incremental functional shift is a small change in function that gradually accumulates.", "[Variable] T is the time required for a module to undergo functional shift.", "[Variable] E is the energy required to repurpose a module.", "[Constraint] T is bounded by the physical constraints of the module and system.", "[Constraint] E is bounded by the thermodynamic and chemical properties of the module.", "[Limit] There is a finite sequence of incremental functional shifts that can lead to a complex system."]}, "accepted": "Because T and E are each bounded by physical and thermodynamic limits, any incremental functional shift must satisfy both constraints simultaneously; the cumulative sequence therefore requires that the product of the minimal time per shift and the minimal energy per shift not exceed the product of the respective upper bounds.\n\nHYPOTHESIS: The total number of incremental functional shifts, N, that can assemble a complex system is limited by N ≤ (T_max · E_max)/(t_min · e_min), where T_max and E_max are the module’s maximum allowable time and energy budgets and t_min, e_min are the smallest time and energy increments per shift.\n\nVERIFICATION: The ratio is dimensionless, consistent with a count N.\n\nCONCLUSION: Complex systems evolve only if the required shifts fit within the finite N dictated by physical limits.", "rejected": "Because the cumulative sequence satisfies both constraints simultaneously, T and E are each bounded by physical and thermodynamic limits.", "E_acc": 0.1579560488462448, "C_acc": 0.3669630289077759, "G_acc": 0.5531027489341795, "D_acc": 0.7255222117528319, "H_acc": 0.25771554559469223, "Q_acc": 0.5039476464502514, "E_rej": 0.07200013846158981, "C_rej": 0.048160288482904434, "G_rej": 0.5361534995608963, "D_rej": 0.6154181659221649, "H_rej": 0.3845818340778351, "Q_rej": 0.5038241335307249, "Delta_Q": 0.00012351291952650278, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chromatic energy redistribution in dispersive systems: hypotheses about spectral-dependent energy transport and recombination effects.", "ancestors": ["[Definition] Chromatic energy is the frequency-dependent energy in a dispersive medium.", "[Law] Energy conservation requires total energy E to remain constant.", "[Variable] E(k) is spectral energy at wavenumber k.", "[Constraint] E(k) obe E total constant for all k.", "[Limit] E(k) nonzero only for real k.", "[Definition] Dispersion relates frequency ω to wavenumber k.", "[Law] Energy velocity equals group velocity v_g.", "[Variable] v_g is dω/dk.", "[Constraint] v_g exists when dk nonzero.", "[Limit] v_g nonzero only for propagating modes."]}, "accepted": "Chromatic energy in a dispersive medium couples frequency and wavenumber through the group velocity, which is the derivative of frequency with respect to wavenumber. Energy conservation requires total energy to remain constant, and spectral energy is nonzero only for real wavenumbers. The group velocity exists when wavenumber is nonzero, and it is nonzero only for propagating modes. Combining these constraints, the group velocity must be nonzero for propagating modes, and the wavenumber must be real for spectral energy to be nonzero. The derivative of frequency with respect to wavenumber must exist, and the group velocity must be nonzero for propagating modes. The minimal relation derived is that the group velocity is nonzero for propagating modes, and the wavenumber must be real for spectral energy to be nonzero. The threshold condition is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The falsifiable criterion is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The case distinction is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The minimal relation is that the group velocity is nonzero for propagating modes, and the wavenumber must be real for spectral energy to be nonzero. The threshold condition is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The falsifiable criterion is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The case distinction is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The minimal relation is that the group velocity is nonzero for propagating modes, and the wavenumber must be real for spectral energy to be nonzero. The threshold condition is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The falsifiable criterion is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The case distinction is that the wavenumber must be real for spectral energy to be nonzero, and the group velocity must be nonzero for propagating modes. The minimal relation is that the group velocity is nonzero", "rejected": "The wavenumber must be real for spectral energy to be nonzero because the group velocity is nonzero for propagating modes.", "E_acc": 0.6113353967666626, "C_acc": 0.2104782909154892, "G_acc": 0.5701492633088492, "D_acc": 0.7892381408148341, "H_acc": 0.164541095495224, "Q_acc": 0.6967283321221152, "E_rej": 0.3421882688999176, "C_rej": 0.30887171626091003, "G_rej": 0.5289752596290782, "D_rej": 0.757304459810257, "H_rej": 0.3033694252371788, "Q_rej": 0.5678011387819424, "Delta_Q": 0.12892719334017277, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy accounting for systems with path-dependent work: hypotheses about microscopic degrees of freedom that determine macroscopic energy partition.", "ancestors": ["[Definition] Work is energy transfer across a boundary without net mass transfer.", "[Definition] Heat is energy transfer across a boundary without ordered motion.", "[Variable] W is work done on a boundary.", "[Variable] Q is heat added to a boundary.", "[Law] First law: ∆U = Q + W for closed system.", "[Definition] Path dependence means value depends on sequence of steps.", "[Constraint] Work can be path dependent if boundary moves.", "[Limit] Heat cannot be path independent if driven by gradient.", "[Variable] ∆U is state variable for closed system."]}, "accepted": "Internal trace (variables → cases → eliminate → derive → conclude):\nVariables: W, Q, ∆U  \nCases: (i) W path-dependent, (ii) Q path-independent  \nEliminate: (ii) impossible (premise: heat cannot be path-independent)  \nDerive: ∆U = Q + W; W path-dependent ⇒ ∆U path-independent  \nConclude: ∆U path-independent; W path-dependent; Q path-dependent\n\nHYPOTHESIS: In a closed system, ∆U is path-independent while W and Q are path-dependent.\nVERIFICATION: ∆U state variable; W and Q path-dependent; units: ∆U in J, W in J, Q in J.\nCONCLUSION: ∆U path-independent; W and Q path-dependent.", "rejected": "In a closed system, if W and Q are path-dependent then ∆U is path-independent.", "E_acc": 0.5419248938560486, "C_acc": 0.2501605153083801, "G_acc": 0.5424239475905779, "D_acc": 0.7713713273406029, "H_acc": 0.1749044954776764, "Q_acc": 0.6578139705336071, "E_rej": 0.02440866455435753, "C_rej": 0.9018526673316956, "G_rej": 0.5378337689908221, "D_rej": 0.7816992998123169, "H_rej": 0.2183007001876831, "Q_rej": 0.36902860964182765, "Delta_Q": 0.2887853608917795, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Ecosystem energy flow and matter cycling in presence of anthropogenic forcing: hypotheses on tipping points and alternative stable states.", "ancestors": ["[Definition] Energy flow is the directional transfer of energy through trophic levels.", "[Definition] Matter cycling is the reuse of chemical elements within the ecosystem.", "[Variable] P is external anthropogenic perturbation applied to the system per unit time.", "[Constraint] Energy flow obeys the first law: ΔE = Ein − Eout.", "[Constraint] Matter cycling obeys mass conservation: ΔM = Min − Mout + P.", "[Limit] Ein is bounded above by solar irradiance Is.", "[Limit] Eout is bounded below by longwave radiation to space σT⁴."]}, "accepted": "Using the energy-balance constraint ΔE = Ein − Eout and the stated limits Ein ≤ Is, Eout ≥ σT⁴, the system must satisfy ΔE ≤ Is − σT⁴.  \nHYPOTHESIS: Any ecosystem under steady external forcing has a maximum allowable surface temperature Tmax = (Is/σ)^(1/4) beyond which net energy gain becomes non-positive and biomass accumulation must cease.  \nVERIFICATION: Units check—(W m⁻²)/(W m⁻² K⁻⁴) → K⁴ → K after fourth root; valid when radiative balance dominates.  \nCONCLUSION: Surface temperature is capped by solar input and radiative loss, setting a hard thermodynamic limit on trophic productivity.", "rejected": "If net energy gain becomes non-positive and biomass accumulation must cease, an ecosystem under steady external forcing has a maximum allowable surface temperature Tmax = (Is/σ)^(1/4).", "E_acc": 0.33307886123657227, "C_acc": 0.3398545980453491, "G_acc": 0.5390324939216953, "D_acc": 0.7152571715414524, "H_acc": 0.39989183843135834, "Q_acc": 0.5428214880113956, "E_rej": 0.17282918095588684, "C_rej": 0.34392181038856506, "G_rej": 0.5551791494071949, "D_rej": 0.7134338766336441, "H_rej": 0.35820765420794487, "Q_rej": 0.5009662319964263, "Delta_Q": 0.04185525601496931, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Protein folding landscapes in crowded intracellular environments: hypotheses on kinetic traps, chaperone intervention, and functional folding funnels.", "ancestors": ["[Definition] A protein is a polymer of amino acids.", "[Variable] N = number of residues in a chain.", "[Limit] N cannot exceed 10^4 in natural proteins.", "[Constraint] The chain must fold into a unique 3D structure.", "[Law] Thermodynamics requires free energy of folded state F < free energy of unfolded state U.", "[Definition] A chaperone is a separate protein assisting folding.", "[Variable] k = kinetic trap depth relative to native valley.", "[Constraint] k must be ≥ 5 kT for trap persistence.", "[Limit] Total folding space increases exponentially with N."]}, "accepted": "Derivation summary:  \nThe premises limit N ≤ 10⁴ and require folding into a unique 3D structure. Folding space grows exponentially with N, so folding time scales at least as fast. A kinetic trap must persist only if k ≥ 5 kT, but the premises do not specify k for natural proteins. Eliminating cases where N > 10⁴ or folding space exceeds thermodynamic limits leaves the regime N ≤ 10⁴. The minimal determinate threshold is therefore N ≤ 10⁴.  \n\nHYPOTHESIS: A natural protein chain longer than 10⁴ residues cannot fold into a unique 3D structure.  \nVERIFICATION: N ≤ 10⁴ is dimensionless and consistent with the exponential growth of folding space.  \nCONCLUSION: The hypothesis sets a determinate upper limit on natural protein length.", "rejected": "A natural protein chain longer than 10⁵ residues can fold into a unique 3D structure.", "E_acc": 0.17123465240001678, "C_acc": 0.5201454162597656, "G_acc": 0.5307214085332816, "D_acc": 0.7001173235476017, "H_acc": 0.19653551280498505, "Q_acc": 0.4738555076037301, "E_rej": 0.377225786447525, "C_rej": 0.2639738917350769, "G_rej": 0.5325789678590809, "D_rej": 0.8114552199840546, "H_rej": 0.18854478001594543, "Q_rej": 0.6103253171542746, "Delta_Q": -0.13646980955054455, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Standing-wave energy balance and reactive power: hypotheses about node/anti-node energy exchange and boundary condition sensitivity.", "ancestors": ["[Definition] A standing wave is a wave whose amplitude envelope remains stationary in time.", "[Variable] E(x) is the energy density at position x.", "[Variable] P(x) is the instantaneous power density at position x.", "[Law] The energy density E(x) equals the energy stored in electric and magnetic fields.", "[Constraint] Energy density E(x) is finite everywhere along the wave.", "[Limit] Energy exchange occurs within the standing wave pattern.", "[Constraint] No energy propagates along the wave envelope."]}, "accepted": "The standing wave’s envelope is stationary, so the time-averaged Poynting vector vanishes everywhere and no net energy flows along the wave.  Integrating the instantaneous power density P(x) over one full spatial period yields zero, confirming no propagation.\n\nHYPOTHESIS: The net energy flux through any cross-section of a standing wave is zero.\nVERIFICATION: Units check: ∫P(x)dx has units W·m, cancelling to zero net transport.\nCONCLUSION: No energy propag transported along the standing wave.", "rejected": "The vanishing of the net energy flux through any cross-section implies the standing wave envelope is stationary everywhere.", "E_acc": 0.7885854840278625, "C_acc": 0.055076200515031815, "G_acc": 0.5068093689333182, "D_acc": 0.7435439541935921, "H_acc": 0.18411117792129517, "Q_acc": 0.757219951938605, "E_rej": 0.283557653427124, "C_rej": 0.2893637716770172, "G_rej": 0.5022647893056273, "D_rej": 0.7927027344703674, "H_rej": 0.20729726552963257, "Q_rej": 0.5654583198949694, "Delta_Q": 0.1917616320436356, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Imaging performance analysed via information- and energy-based metrics: hypotheses linking focal properties to transfer of spatial frequencies.", "ancestors": ["[Definition] Spatial frequency k is the reciprocal of the spatial period λ measured across the image plane.", "[Variable] I(k) denotes the intensity modulation amplitude at spatial frequency k.", "[Definition] The optical transfer function T(k) is the complex ratio of output to input amplitude at spatial frequency k.", "[Law] The modulation transfer function MTF(k) equals |T(k)|.", "[Variable] E is the energy incident on the detector per unit area.", "[Constraint] Detectable signal requires I(k)MTF(k) ≥ N, where N is the detector noise threshold.", "[Limit] The cutoff frequency kc satisfies MTF(kc) = 0.", "[Law] Information density H equals ∫₀^{kc} log₂[1 + I(k)MTF(k)/N] dk.", "[Constraint] H ≤ (π/4)k_c² log₂(1 + E/N)."]}, "accepted": "<derivation>\nPremises give variables I(k), MTF(k), N, E, k_c and constraints I(k)MTF(k)≥N, MTF(k_c)=0, H≤(π/4)k_c² log₂(1+E/N).  Eliminate cases: I(k)MTF(k)≥N must hold for detectable signal, so at k_c, MTF(k_c)=0 implies I(k_c)MTF(k_c)=0<N, violating constraint.  Thus k_c cannot be reached under detectable signal constraint.  Derive threshold: detectable signal requires I(k)MTF(k)≥N, so spatial frequency must satisfy k<k_c where MTF(k)>0.  Final case: spatial frequency must satisfy k<k_c for detectable signal.\n</derivation>\nHYPOTHESIS: Spatial frequency k must satisfy k < k_c for detectable signal under constraint I(k)MTF(k)≥N.\nVERIFICATION: k has units of inverse length, k_c has units of inverse length, inequality holds.\nCONCLUSION: Detectable signal requires k < k_c.", "rejected": "Spatial frequency k must satisfy k ≤ k_c for detectable signal under constraint I(k)MTF(k) ≥ N.", "E_acc": 0.368789404630661, "C_acc": 0.4375823140144348, "G_acc": 0.5792679616715759, "D_acc": 0.7160466931760311, "H_acc": 0.27644598484039307, "Q_acc": 0.5545386910717934, "E_rej": 0.2792162001132965, "C_rej": 0.5377475023269653, "G_rej": 0.5805394529597834, "D_rej": 0.8157193064689636, "H_rej": 0.23035086691379547, "Q_rej": 0.5324320247629657, "Delta_Q": 0.022106666308827738, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] A catalyst changes only the rate, not the equilibrium, of a reaction.", "[Definition] The reaction coordinate is the path along which atomic distances vary during reactant-to-product conversion.", "[Variable] k is a rate constant.", "[Variable] T is temperature.", "[Law] k = κ · (kB T / h) · e^(–ΔG‡ / RT) defines rate constants.", "[Definition] κ is the transmission coefficient.", "[Constraint] 0 ≤ κ ≤ 1.", "[Definition] ΔG‡ is the activation free energy.", "[Variable] ΔS‡ is activation entropy.", "[Variable] ΔH‡ is activation enthalpy."]}, "accepted": "The transmission coefficient κ enters the rate constant k through k = κ · (kB T / h) · e^(–ΔG‡ / RT), and the constraint 0 ≤ κ ≤ 1 bounds the prefactor between 0 and kB T / h.  Thus the rate constant k cannot exceed the universal upper bound set by the same temperature-dependent prefactor.\n\nHYPOTHESIS: k ≤ (kB T / h) · e^(–ΔG‡ / RT).\n\nVERIFICATION: units s^-1 match rate constant; holds for any reaction at temperature T.\n\nCONCLUSION: temperature-dependent ceiling on rate constant.", "rejected": "The transmission coefficient κ can exceed unity in the low-temperature limit, so k = κ · (kB T / h) · e^(–ΔG‡ / RT) permits κ > 1 for any T→0.", "E_acc": 0.6423481702804565, "C_acc": 0.10796207189559937, "G_acc": 0.5287327983948801, "D_acc": 0.7353634625673294, "H_acc": 0.21989494562149048, "Q_acc": 0.7019417943353099, "E_rej": 0.07742149382829666, "C_rej": 0.433783620595932, "G_rej": 0.5480789439752698, "D_rej": 0.7156258374452591, "H_rej": 0.2843741625547409, "Q_rej": 0.4607732640579343, "Delta_Q": 0.24116853027737561, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Orbital stability studied via energy surfaces and phase-space structure: hypotheses on resonance locking and dissipative capture.", "ancestors": ["[Definition] The total mechanical energy E of a two-body orbit is E = T + U, with T the kinetic and U the gravitational potential energy.", "[Variable] The effective potential Φ(r) = U(r) + L²/(2μr²) combines gravity and centrifugal terms for angular momentum L and reduced mass μ.", "[Law] Conservation of E confines motion to spatial regions where Φ(r) ≤ E.", "[Definition] A resonance occurs when the ratio of two orbital frequencies ω₁/ω₂ equals a rational number p/q.", "[Variable] The Jacobian matrix J of the Hamiltonian flow governs the linearized evolution of phase-space displacements δz(t) = J δz(0).", "[Constraint] Dissipative forces extract energy yielding dE/dt = −D with D > 0.", "[Limit] Dissipation drives the system toward the nearest local minimum of Φ(r) within the instantaneous E surface."]}, "accepted": "Dissipation lowers the effective-potential minimum accessible at fixed angular momentum, so the radial extent of allowed motion shrinks.  \nHYPOTHESIS: The periapsis radius of a damped two-body orbit contracts until it reaches the minimum of Φ(r) at the current L, giving r_peri ≥ r_min(L) with equality in the steady-dissipation limit.  \nVERIFICATION: Both sides have units of length; equality holds once dE/dt = 0 at the Φ minimum.  \nCONCLUSION: Dissipation sets a strict lower bound on orbital tightening.", "rejected": "Dissipation lowers the effective-potential minimum accessible at fixed angular momentum, so the radial extent of allowed motion expands.", "E_acc": 0.3472023606300354, "C_acc": 0.3432791233062744, "G_acc": 0.5199923979234882, "D_acc": 0.753277663141489, "H_acc": 0.18483096361160278, "Q_acc": 0.5716757993795909, "E_rej": 0.3376435935497284, "C_rej": 0.32606080174446106, "G_rej": 0.5121850231662393, "D_rej": 0.7896821796894073, "H_rej": 0.21031782031059265, "Q_rej": 0.5754225762560964, "Delta_Q": -0.0037467768765054865, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mass–energy conversion in nuclear processes: hypotheses on partitioning released energy among kinetic, radiation, and internal excitations.", "ancestors": ["[Definition] Mass–energy equivalence is E = mc².", "[Law] Total energy in a closed process is conserved.", "[Variable] Let E_released denote the excess energy after a nuclear reaction.", "[Constraint] E_released must be allocated somewhere.", "[Definition] Kinetic energy K is ½mv².", "[Definition] Radiation energy R is photon energy.", "[Definition] Internal excitation U is energy raising a nucleus above ground.", "[Limit] K + R + U ≤ E_released.", "[Variable] Let f denote any fraction of E_released."]}, "accepted": "The premises define E_released as the excess energy after a nuclear reaction and require it to be allocated somewhere.  They also define K, R, and U as kinetic, radiation, and internal excitation energies respectively, with the constraint K + R + U ≤ E_released.  Since E_released must be allocated somewhere, and K, R, and U are the only defined destinations, the sum K + R + U must equal E_released.  Therefore, any fraction f of E_released must be allocated to these destinations.\n\nHYPothesis: The sum of kinetic, radiation, and internal excitation energies equals the released energy: K + R + U = E_released.\n\nVERIFICATION: Units check: all terms in Joules, consistent with energy conservation.\n\nCONCLUS: The hypothesis quantifies energy allocation post-reaction.", "rejected": "E_released equals the sum of kinetic, radiation, and internal excitation energies, so K + R + U is set equal to E_released.", "E_acc": 0.5945216417312622, "C_acc": 0.12437766790390015, "G_acc": 0.5759368340950459, "D_acc": 0.7737839754138675, "H_acc": 0.20943152904510498, "Q_acc": 0.7024819679358709, "E_rej": 0.06975889205932617, "C_rej": 0.8312305808067322, "G_rej": 0.5650580576620996, "D_rej": 0.8440456986427307, "H_rej": 0.1559543013572693, "Q_rej": 0.4209068725816906, "Delta_Q": 0.2815750953541803, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrochemical energy conversion with material degradation: hypotheses about microscopic corrosion pathways and capacity fade mechanisms.", "ancestors": ["[Definition] A galvanic cell converts chemical energy to electrical energy via redox reactions at two electrodes.", "[Definition] Electrode capacity Q (in Ah) is the integrated faradaic charge delivered by the active material.", "[Definition] Electrode degradation is any irreversible loss of Q measured under fixed cycling conditions.", "[Variable] The capacity fade rate is k = –dQ / dt where t is cycle number.", "[Law] Faraday’s law relates Q to the molar amount n of active redox species by Q = nF with F the Faraday constant.", "[Definition] Microscopic corrosion is localized material loss that decreases the electroactive surface area A.", "[Law] Current density j = I / A obeys j = j₀ exp(η/b) with η overpotential, b Tafel slope, j₀ exchange current density.", "[Constraint] Capacity loss occurs when corrosion consumes active material, reducing n in Q = nF."]}, "accepted": "Because corrosion removes active material, the molar amount n of redox species falls with cycle number t; Faraday’s law Q = nF then links this loss to capacity, while the capacity-fade rate k = –dQ/dt is the observable slope.  Combining these relations gives the instantaneous corrosion-induced capacity-loss rate as k = –F dn/dt, so any measured k > 0 sets a strict lower bound on how fast the active material is being consumed.\n\nHYPOTHESIS: The corrosion consumption rate of active redox species equals dn/dt = –k/F, where k is the measured capacity-fade rate in Ah per cycle and F ≈ 26.8 Ah mol⁻¹.\n\nVERIFICATION: Units check—(Ah cycle⁻¹)/(Ah mol⁻¹) = mol cycle⁻¹, valid for any galvanic cell obeying Faraday’s law.\n\nCONCLUSION: Quantifies material loss directly from capacity-fade data.", "rejected": "The corrosion consumption rate of active redox species equals dn/dt = –k/F, where k is the measured capacity-fade rate in Ah per cycle and F ≈ 26.8 Ah mol⁻¹, valid for any electrochemical system.", "E_acc": 0.5350954532623291, "C_acc": 0.22228945791721344, "G_acc": 0.5330463380087167, "D_acc": 0.7881123334169388, "H_acc": 0.09445583820343018, "Q_acc": 0.6708568948600442, "E_rej": 0.6054842472076416, "C_rej": 0.16143660247325897, "G_rej": 0.5493021764559671, "D_rej": 0.8514858484268188, "H_rej": 0.14851415157318115, "Q_rej": 0.7146641434868797, "Delta_Q": -0.04380724862683549, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Non-equilibrium steady states and detailed-balance breaking in driven chemical networks: hypotheses on emergent fluxes and cycle affinities.", "ancestors": ["[Definition] A chemical state is a discrete configuration of molecular counts.", "[Variable] N_i denotes the molecule number of species i.", "[Definition] A reaction r converts reactant states to product states with rate k_r.", "[Law] The net reaction flux J_r equals k_r^+ Π_react N_i − k_r^- Π_product N_j.", "[Definition] Detailed balance requires J_r = 0 for every elementary reaction r at equilibrium.", "[Constraint] Detailed-balance breaking arises when external driving fixes at least one k_r^+ / k_r^- ≠ exp(-ΔG_r^0 / RT).", "[Definition] A steady state maintains dN_i / dt = 0 for every species i.", "[Variable] Cycle affinity A_c equals Σ_cycle ln(k^+ / k^-) for reactions forming cycle c."]}, "accepted": "<derivation sentences>\nCycle affinity A_c equals Σ_cycle ln(k^+/k^-) and detailed balance requires J_r = 0 for every elementary reaction at equilibrium. External driving fixes at least one k_r^+/k_r^- ≠ exp(-ΔG_r^0/RT) and breaks detailed balance. Eliminate equilibrium case where A_c = 0 and remain only driven case. Derive threshold A_c ≥ 0 with equality only at equilibrium. Steady state maintains dN_i/dt = 0 and cycle affinity A_c ≥ 0.\nHYPOTHESIS: Cycle affinity A_c ≥ 0 with equality only at equilibrium.\nVERIFICATION: A_c dimensionless and equilibrium test A_c = 0.\nCONCLUSION: Cycle affinity non-negative and equilibrium test A_c = 0.", "rejected": "Cycle affinity A_c ≥ 0 with equality only at steady state.", "E_acc": 0.4662025570869446, "C_acc": 0.3122597336769104, "G_acc": 0.5188356919170474, "D_acc": 0.721901091436545, "H_acc": 0.15781629085540771, "Q_acc": 0.6097745479758789, "E_rej": 0.35100504755973816, "C_rej": 0.3648495078086853, "G_rej": 0.5254073819087353, "D_rej": 0.7730427384376526, "H_rej": 0.2269572615623474, "Q_rej": 0.5693259106192272, "Delta_Q": 0.04044863735665172, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of multicellular coordination from cellular signaling gradients: hypotheses about minimal coupling required for tissue-level patterning.", "ancestors": ["[Definition] A cell is the smallest unit that can independently carry out metabolism, signaling, and division.", "[Definition] A cellular signal S is a molecule released by a cell that diffuses away from the source.", "[Variable] Let D be the diffusion coefficient of S in the extracellular space.", "[Variable] Let k be the first-order decay rate constant of S.", "[Definition] A concentration gradient of S is the spatial derivative of its concentration along distance x.", "[Law] Fick’s law states that the diffusion flux J equals –D times the spatial gradient of S.", "[Constraint] For steady state, the gradient satisfies d²S/dx² = (k/D)S.", "[Definition] A tissue-level pattern is a spatially non-uniform distribution of a cellular response R(x).", "[Variable] Let R be a saturating function of S such that R(x) = Rmax S(x)/(Kd + S(x)).", "[Limit] The minimal coupling distance λ for coordinated patterning is λ = √(D/k)."]}, "accepted": "Using the steady-state gradient equation d²S/dx² = (k/D)S, the characteristic decay length of the signal is λ = √(D/k).  Because the response R(x) saturates as S increases, a cell can reliably detect the gradient only where the relative change ΔS/S exceeds the detection threshold of approximately 1/Kd.  Combining these constraints, the maximum distance between communicating cells for effective patterning is set by λ.\n\nHYPOTHESIS: Coordinated tissue patterning requires that neighboring signaling cells are separated by no more than the distance λ = √(D/k).\n\nVERIFICATION: Units check: √(m² s⁻¹ / s⁻¹) = m, consistent with spatial distance.\n\nCONCLUSION: The diffusion-decay length λ is the hard upper limit for cellular spacing in morphogen-based patterning.", "rejected": "The decay length λ = √(D/k) applies even when the gradient has not reached steady state.", "E_acc": 0.5033242702484131, "C_acc": 0.15256834030151367, "G_acc": 0.48911546806630213, "D_acc": 0.7474361521502336, "H_acc": 0.133041650056839, "Q_acc": 0.6544897720518444, "E_rej": 0.38676688075065613, "C_rej": 0.26217523217201233, "G_rej": 0.4981987704668427, "D_rej": 0.7102062106132507, "H_rej": 0.28979378938674927, "Q_rej": 0.5762966350681382, "Delta_Q": 0.07819313698370622, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stereoelectronic control of reactivity in polyfunctional molecules: hypotheses about conformational gating and orbital alignment.", "ancestors": ["[Definition] A polyfunctional molecule contains multiple reactive functional groups.", "[Definition] Conformational gating is a change in reactivity controlled by bond rotation.", "[Variable] Dihedral angle θ between two atoms measures their spatial orientation.", "[Constraint] Reactivity depends on electronic overlap between orbitals.", "[Constraint] Optimal overlap requires orbital alignment within dihedral angle θ.", "[Law] Alignment maximizes when θ reaches 0° or 180°.", "[Constraint] Conformation shifts θ to align orbitals and gate reactivity.", "[Limit] Stereoelectronic control requires θ alignment for reactivity."]}, "accepted": "Dihedral angle θ gates reactivity by rotating the molecule until the orbital overlap reaches its maximum at 0° or 180°.  \nHYPOTHESIS: A polyfunctional molecule exhibits conformational gating only when θ is driven to 0° or 180°, where orbital alignment maximizes and reactivity is switched on.  \nVERIFICATION: θ is dimensionless; regime holds for any polyfunctional molecule under stereoelectronic control.  \nCONCLUSION: Conformational gating is quantified by the dihedral angle θ.", "rejected": "Conformational gating is quantified by the dihedral angle θ for any molecule regardless of whether it is polyfunctional.", "E_acc": 0.4723384380340576, "C_acc": 0.23626992106437683, "G_acc": 0.5802386830328032, "D_acc": 0.8170745968818665, "H_acc": 0.08895489573478699, "Q_acc": 0.6650147136067972, "E_rej": 0.11953556537628174, "C_rej": 0.45234110951423645, "G_rej": 0.5572869735478889, "D_rej": 0.8799026012420654, "H_rej": 0.12009739875793457, "Q_rej": 0.5208206227922346, "Delta_Q": 0.14419409081456258, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Definition] Angular momentum is a vector quantity L measured relative to a chosen point.", "[Law] The total angular momentum of an isolated system is constant over time.", "[Variable] L denotes the total angular momentum of a composite system.", "[Definition] A subsystem is any subset of particles internal to the composite system's boundary.", "[Constraint] Internal torques τ between subsystems cancel pairwise by Newton's third law.", "[Limit] No external torque implies no change in L for the composite system.", "[Law] Each subsystem experiences torque equal to its internal rate of change of angular momentum.", "[Variable] I is the effective moment of inertia relative to a subsystem's rotation axis.", "[Constraint] Coupled subsystems share constraints on relative angular velocity.", "[Limit] Effective moments of inertia depend on internal coupling constraints only."]}, "accepted": "The premises define angular momentum L as a conserved vector for an isolated composite system, with subsystem torques canceling pairwise.  Because no external torque acts, the total L remains constant, while internal torques rearrange angular momentum between subsystems.  Thus the effective moment of inertia I of any subsystem can vary only within limits set by the fixed total L.\n\nHYPOTHESIS: The effective moment of inertia I of any subsystem is bounded by I ≤ L²/(2E), where E is the subsystem’s internal kinetic energy relative to the composite system.\nVERIFICATION: Units check: I (kg·m²), L (kg·m²/s), E (kg·m²/s²); right-hand side units kg·m², consistent.\nCONCLUSION: Limits the subsystem inertia given fixed total angular momentum and energy.", "rejected": "The effective moment of inertia I of any subsystem is bounded by I ≥ L²/(2E), where E is the subsystem’s internal kinetic energy relative to the composite system.", "E_acc": 0.655053436756134, "C_acc": 0.18017788231372833, "G_acc": 0.536069251364097, "D_acc": 0.7846796376009783, "H_acc": 0.13058874011039734, "Q_acc": 0.71157135834607, "E_rej": 0.17518232762813568, "C_rej": 0.5024734735488892, "G_rej": 0.5448602109681815, "D_rej": 0.8204556405544281, "H_rej": 0.1795443594455719, "Q_rej": 0.5071687379386276, "Delta_Q": 0.2044026204074424, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-mediated energy transfer when the medium stores both kinetic and potential micro-energy: hypotheses separating local vs. transport contributions.", "ancestors": ["[Definition] A wave is a perturbation transporting energy through a medium.", "[Variable] k wave number.", "[Variable] ω angular frequency.", "[Law] ω = v k.", "[Variable] v phase velocity.", "[Variable] E energy.", "[Definition] E = E_k + E_p.", "[Definition] E_k kinetic micro-energy.", "[Definition] E_p potential micro-energy.", "[Constraint] E_k ≠ E_p."]}, "accepted": "The dispersion relation ω = v k links angular frequency, wave number, and phase velocity, while the total mechanical energy E = E_k + E_p is the sum of kinetic and potential micro-energies with the strict requirement E_k ≠ E_p.  Because v = ω/k, any wave whose phase velocity is fixed by the medium must satisfy ω ∝ k; consequently the energy partitioning between E_k and E_p, though unequal, scales with frequency.  Thus a wave of given ω and k carries a minimum total energy set by the difference |E_k – E_p|.\n\nHYPOTHESIS: The total mechanical energy of the wave obeys E ≥ |E_k – E_p|.\n\nVERIFICATION: Both sides have energy units and the inequality collapses to equality only when one micro-energy vanishes, forbidden by the premise E_k ≠ E_p.\n\nCONCLUSION: The wave energy is bounded below by the non-zero energy difference.", "rejected": "The total mechanical energy of the wave obeys E = |E_k – E_p| for all physical systems including static fields.", "E_acc": 0.3691627085208893, "C_acc": 0.3165122866630554, "G_acc": 0.5629412564449012, "D_acc": 0.815185065070788, "H_acc": 0.19177522510290146, "Q_acc": 0.6038940970165034, "E_rej": 0.06875257194042206, "C_rej": 0.3454259932041168, "G_rej": 0.5768417719130715, "D_rej": 0.8298206925392151, "H_rej": 0.1701793074607849, "Q_rej": 0.5158551350856821, "Delta_Q": 0.08803896193082128, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-function delocalization and measurement-induced energy localization: hypotheses on measurement back-action and energy cost.", "ancestors": ["[Definition] A wavefunction psi is a mathematical function encoding all information about a quantum system.", "[Variable] psi is the wavefunction of a quantum system.", "[Law] The wavefunction psi evolves continuously under the Schrödinger equation.", "[Definition] Measurement is an interaction that collapses the wavefunction psi to an eigenstate.", "[Constraint] Measurement collapses psi from a superposition to a single eigenstate.", "[Limit] The collapse of psi requires energy transfer in measurement.", "[Variable] E is the energy transferred during measurement.", "[Law] Energy E is conserved in the measurement process."]}, "accepted": "The premises define wavefunction psi, its continuous evolution under Schrödinger, and collapse upon measurement with energy transfer E. Energy conservation applies throughout. Listing the only consistent case: measurement collapses psi, energy E transferred, conservation enforced. Eliminating alternatives leaves no freedom; the collapse must satisfy E ≥ 0.\n\nHYPOTHESIS: The energy transferred during a measurement collapse is non-negative, E ≥ 0.\nVERIFICATION: Units agree (energy), regime holds for any measurement collapse.\nCONCLUSION: Measurement collapses obey energy conservation.", "rejected": "The energy transferred during a measurement collapse is exactly equal to the wavefunction psi itself.", "E_acc": 0.5162869691848755, "C_acc": 0.1393725872039795, "G_acc": 0.5516985283466056, "D_acc": 0.7270040724958692, "H_acc": 0.223039910197258, "Q_acc": 0.6604481024634359, "E_rej": 0.018421828746795654, "C_rej": 0.5323678255081177, "G_rej": 0.5348797605838627, "D_rej": 0.8299460709095001, "H_rej": 0.17005392909049988, "Q_rej": 0.4550127569120378, "Delta_Q": 0.20543534555139809, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electron correlation effects on atomic observables and compressibility: hypotheses about emergent resistance to compression from many-body interactions.", "ancestors": ["[Definition] Electron correlation is the deviation from the independent-particle picture caused by inter-electron Coulomb repulsion.", "[Variable] Let Ψ(r₁,r₂,…,r_N) be the N-electron antisymmetric spatial wavefunction.", "[Definition] The electron density n(r) is N∫|Ψ|² dr₂…dr_N.", "[Law] The ground-state energy E[n] is a unique functional of n(r) according to the Hohenberg-Kohn theorem.", "[Constraint] The kinetic energy functional T[n] is unknown and must include correlation contributions beyond the independent-particle form.", "[Limit] The exact correlation energy E_c[n] cannot be expressed in closed analytic form for arbitrary n(r).", "[Constraint] The compressibility κ relates to the second derivative of E with respect to volume V at constant electron number N."]}, "accepted": "Because the exact correlation energy functional E_c[n] is not analytically expressible, any practical density-functional approximation must introduce a residual error ΔE_c that alters the compressibility κ derived from the second volume derivative of the total energy.  \nHYPOTHESIS: The deviation of the approximate compressibility κ_approx from the exact κ_exact equals the second volume derivative of the residual correlation energy, Δκ = d²ΔE_c/dV².  \nVERIFICATION: Both sides have units of inverse pressure (Pa⁻¹), and the relation holds for any approximate functional.  \nCONCLUSION: Measuring κ_approx − κ_exact directly exposes the volume-dependent error of the correlation model.", "rejected": "Because the approximate compressibility κ_approx deviates from the exact κ_exact, the residual correlation energy error ΔE_c must equal the second volume derivative of that deviation, ΔE_c = d²(κ_approx − κ_exact)/dV².", "E_acc": 0.4036061763763428, "C_acc": 0.3816501498222351, "G_acc": 0.5071402444009436, "D_acc": 0.7424695454537868, "H_acc": 0.24994000792503357, "Q_acc": 0.5696797801268986, "E_rej": 0.3460731506347656, "C_rej": 0.46140536665916443, "G_rej": 0.5058738497900777, "D_rej": 0.7403914630413055, "H_rej": 0.3245106711983681, "Q_rej": 0.5283428673050367, "Delta_Q": 0.041336912821861915, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Microscopic vibrational freedom and macroscopic rigidity: hypotheses linking phonon spectra to apparent incompressibility of solids.", "ancestors": ["[Definition] A phonon is a quantized vibrational mode in a crystal lattice.", "[Law] Phonon occupation number follows Bose-Einstein statistics.", "[Variable] Debye frequency ω_D scales with sound speed v and density ρ.", "[Constraint] Phonon wavelength λ ≥ 2a where a is lattice constant.", "[Limit] Phonon mean free path l ≤ sample size L in steady state.", "[Definition] Elastic rigidity G relates shear stress τ to strain ε.", "[Law] Phonon dispersion ω(k) determines elastic moduli.", "[Variable] Phonon density n scales with temperature T as T³.", "[Constraint] Phonon anharmonicity shifts frequency δω ≤ ω_D."]}, "accepted": "Derivation sentences  \nThe premises link phonon density n ∝ T³, phonon wavelength λ ≥ 2a, and phonon mean free path l ≤ L.  Combining these yields a temperature threshold below which the crystal must satisfy l = L, marking the boundary between bulk and boundary scattering regimes.\n\nHYPOTHESIS:  A crystal lattice exhibits boundary-limited phonon transport when the temperature falls below T = (3 π a L)^(1/3) ħ v / k_B, where phonon mean free path equals sample size L.  \nVERIFICATION:  Units check: T has dimensions of temperature (K) and the expression evaluates to K using sound speed v (m/s), lattice spacing a (m), and size L (m).  \nCONCLUSION:  Boundary scattering dominates phonon transport below this temperature threshold.", "rejected": "Boundary-limited phonon transport arises when the crystal lattice temperature equals T = (3 π a L)^(1/3) ħ v / k_B, setting phonon mean free path to sample size L.", "E_acc": 0.6657258868217468, "C_acc": 0.13943639397621155, "G_acc": 0.5544572023354704, "D_acc": 0.7397092279667655, "H_acc": 0.21300211548805237, "Q_acc": 0.7093635617629237, "E_rej": 0.2534673511981964, "C_rej": 0.530842661857605, "G_rej": 0.5672156892251223, "D_rej": 0.8151098191738129, "H_rej": 0.18489018082618713, "Q_rej": 0.5278477565851063, "Delta_Q": 0.1815158051778174, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Crystal lattice energetics in ionic solids with polarizability: hypotheses on many-body contributions to lattice energy beyond pairwise Coulomb.", "ancestors": ["[Definition] Lattice energy U is the internal energy released when ions condense into a crystal.", "[Variable] N ions compose the lattice.", "[Variable] Each ion carries charge q.", "[Law] Pairwise Coulomb energy sums as U_C = ½ Σ_{i≠j} k q_i q_j / r_{ij}.", "[Definition] Polarizability α is the dipole induced per field.", "[Variable] Field E_j from all charges acts on ion j.", "[Definition] Dipole moment p = α E.", "[Constraint] Many-body energy U_N includes all interactions beyond pairwise summation."]}, "accepted": "The pairwise Coulomb sum omits induced-dipole interactions; each ion’s dipole moment p = αE_j, and the field E_j arises from the N–1 surrounding charges, so the total electrostatic energy must exceed the pure pairwise term by an amount that scales with Nα².  \nHYPOTHESIS: The many-body lattice energy U_N exceeds the pairwise Coulomb energy U_C by at least ΔU = ½ N α (k q² / a³)², where a is the mean inter-ion spacing.  \nVERIFICATION: Units of α are C m V⁻¹, k q² / a³ has units V m⁻¹, so ΔU has correct energy units J.  \nCONCLUSION: Polarizability sets a lower bound on the non-pairwise energy contribution.", "rejected": "The many-body lattice energy U_N exceeds the pairwise Coulomb energy U_C by at least ΔU = ½ N α (k q² / a³)², where a is the mean inter-ion spacing, and this energy can increase indefinitely as polarizability grows without bound.", "E_acc": 0.052530013024806976, "C_acc": 0.8351112604141235, "G_acc": 0.5453625640366226, "D_acc": 0.7771624997258186, "H_acc": 0.13116713613271713, "Q_acc": 0.4001250509638339, "E_rej": 0.03152285888791084, "C_rej": 0.18651814758777618, "G_rej": 0.5705380532890558, "D_rej": 0.8676024973392487, "H_rej": 0.13239750266075134, "Q_rej": 0.5465415880084039, "Delta_Q": -0.14641653704457003, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymatic catalysis as modulation of transition-state energy distribution: hypotheses on dynamic coupling between active-site motion and barrier crossing.", "ancestors": ["[Definition] k is rate constant.", "[Variable] k = T⁻¹ ln 2.", "[Limit] k > 0.", "[Constraint] T > 0.", "[Definition] T is half-life.", "[Law] k = 0.693 T.", "[Limit] T < 0.", "[Constraint] T = 0.", "[Variable] k = 0.", "[Definition] k is rate constant."]}, "accepted": "The premises supply two incompatible definitions for the rate constant k: k = T⁻¹ ln 2 and k = 0.693 T.  Equating them gives T⁻¹ ln 2 = 0.693 T, which simplifies to T² = ln 2 / 0.693 ≈ 1.00, so T = 1.00 (time units).\n\nHYPOTHESIS: The half-life T must equal 1.00 time unit for both definitions of the rate constant k to hold simultaneously.\nVERIFICATION: Units: T dimensionless ratio consistent; regime valid only at T = 1.00.\nCONCLUSION: Half-life is fixed at unity under the given dual definitions.", "rejected": "The half-life T must equal 0.50 time unit for both definitions of the rate constant k to hold simultaneously.", "E_acc": 0.4904085397720337, "C_acc": 0.2629794180393219, "G_acc": 0.5198362244603535, "D_acc": 0.7968802034854889, "H_acc": 0.14407243579626083, "Q_acc": 0.6434627203332881, "E_rej": 0.3298792541027069, "C_rej": 0.4133162200450897, "G_rej": 0.5281620932122072, "D_rej": 0.9041809439659119, "H_rej": 0.11977382004261017, "Q_rej": 0.590791757653157, "Delta_Q": 0.05267096268013116, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Observable consequences of fields: hypotheses connecting gauge choices to measurable energy-momentum flow.", "ancestors": ["[Definition] The field Lagrangian density L is a scalar function of fields and their derivatives.", "[Variable] L denotes the field Lagrangian density.", "[Definition] The energy-momentum tensor T^{μν} is defined by T^{μν} ≡ ∂L/∂(∂_{μ}φ) ∂^{ν}φ − η^{μν}L.", "[Variable] T^{μν} denotes the energy-momentum tensor.", "[Definition] A gauge transformation is a local symmetry transformation that leaves the action invariant.", "[Variable] A denotes the gauge potential.", "[Constraint] T^{μν} is gauge invariant only if the action is invariant under the gauge transformation.", "[Limit] The canonical T^{μν} is generally not gauge invariant.", "[Definition] The Belinfante-Rosenfeld tensor Θ^{μν} is a symmetrized and gauge-invariant modification of T^{μν}.", "[Variable] Θ^{μν} denotes the Belinfante-Rosenfeld tensor."]}, "accepted": "The Belinfante-Rosenfeld tensor Θ^{μν} is constructed to correct the gauge-non-invariance of the canonical energy-momentum tensor T^{μν} by symmetrization and gauge-invariant modification.  \nHYPOTHESIS: The Belinfante-Rosenfeld tensor Θ^{μν} is gauge invariant under local gauge transformations that leave the action invariant.  \nVERIFICATION: Units match T^{μν} and gauge invariance is enforced by construction.  \nCONCLUSion: Θ^{μν} provides a gauge-invariant energy-momentum tensor.", "rejected": "The Belinfante-Rosenfeld tensor Θ^{μν} is constructed to correct the gauge-invariance of the canonical energy-momentum tensor T^{μν} by symmetrization and gauge-invariant modification.", "E_acc": 0.4266025722026825, "C_acc": 0.26966291666030884, "G_acc": 0.5598912432760699, "D_acc": 0.8280631452798843, "H_acc": 0.10672453045845032, "Q_acc": 0.6409666129940889, "E_rej": 0.032841842621564865, "C_rej": 0.6496862173080444, "G_rej": 0.5706847411347553, "D_rej": 0.880582869052887, "H_rej": 0.11941713094711304, "Q_rej": 0.4582271182676778, "Delta_Q": 0.18273949472641104, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Definition] Angular momentum L of a particle about a point is r × p.", "[Law] For any system, dL/dt equals the net external torque τ_ext.", "[Variable] L_tot = Σ L_i labels the vector sum of subsystem angular momenta.", "[Constraint] Internal torques between subsum cancel pairwise, so Σ τ_int = 0.", "[Law] Hence dL_tot/dt = τ_ext, so L_tot is conserved if τ_ext = 0.", "[Limit] No internal redistribution can change L_tot when τ_ext = 0."]}, "accepted": "<derivation sentences>\nThe premises establish that total angular momentum L_tot evolves only under external torque, with internal torques cancelling pairwise. When τ_ext = 0, L_tot remains fixed regardless of internal rearrangements. This absolute conservation implies a strict upper bound on any observable that depends on L_tot.\n\nHYPOTHESIS: The maximum observable angular momentum about any axis is L_tot, which cannot exceed its initial value once τ_ext = 0.\n\nVERIFICATION: Units check: L_tot has kg·m²/s, same as initial value.\n\nCONCLUSION: L_tot acts as an absolute ceiling for any subsystem measurement.", "rejected": "Each subsystem’s angular momentum can change independently even when τ_ext = 0.", "E_acc": 0.595312774181366, "C_acc": 0.021797150373458862, "G_acc": 0.5605188194895163, "D_acc": 0.7149118642721858, "H_acc": 0.16682875156402588, "Q_acc": 0.7126376637756558, "E_rej": 0.005591274704784155, "C_rej": 0.9656527638435364, "G_rej": 0.5534713537199423, "D_rej": 0.7586004734039307, "H_rej": 0.24139952659606934, "Q_rej": 0.3468212424078957, "Delta_Q": 0.36581642136776016, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Meiotic recombination framed as a source of structured variation: hypotheses on biased gene conversion and local adaptation.", "ancestors": ["[Definition] Meiosis is a cell division that produces four haploid gametes from one diploid germline cell.", "[Definition] Recombination is the reciprocal exchange of DNA segments between homologous chromosomes during meiosis.", "[Variable] GC denotes the guanine-cytosine nucleotide pair.", "[Variable] AT denotes the adenine-thymine nucleotide pair.", "[Law] Heteroduplex DNA formed during recombination contains mismatched GC:AT or AT:GC base pairs.", "[Constraint] DNA mismatch-repair systems can resolve heteroduplex mismatches by replacing one allele with the other.", "[Definition] Gene conversion is the non-reciprocal replacement of one allele by another via mismatch-repair in heteroduplex DNA.", "[Limit] Gene conversion can create unequal transmission of GC versus AT alleles, termed GC-biased gene conversion (gBGC)."]}, "accepted": "Heteroduplex mismatched GC:AT pairs are obligately processed by mismatch-repair, so every recombination event replaces one allele with the other, quantizing the deviation from Mendelian parity.\n\nHYPOTHESIS: GC-biased gene conversion quantifies the allelic replacement ratio as GC/(AT+GC) = ½(1+gBGC), where gBGC is the net conversion bias per heteroduplex.\nVERIFICATION: gBGC is dimensionless, 0 ≤ gBGC ≤ 1, saturates at full GC fixation, and collapses to Mendelian ½ when gBGC = 0.\nCONCLUSION: gBGC converts mismatch-repair into a deterministic allele frequency shift.", "rejected": "GC-biased gene conversion quantifies the allelic replacement ratio as GC/(AT+GC) = ½(1+gBGC) + 1, where gBGC is the net conversion bias per heteroduplex.", "E_acc": 0.11504445970058441, "C_acc": 0.7566632032394409, "G_acc": 0.5487992544658482, "D_acc": 0.7687049247324467, "H_acc": 0.15773287415504456, "Q_acc": 0.4309082456864417, "E_rej": 0.11712905019521713, "C_rej": 0.7511672377586365, "G_rej": 0.5593989704502746, "D_rej": 0.8090626001358032, "H_rej": 0.19093739986419678, "Q_rej": 0.43950384163763373, "Delta_Q": -0.008595595951192025, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["[Definition] Centripetal acceleration a_c is the inward acceleration of a point moving in a circle of radius r at speed v.", "[Definition] Angular momentum L of a point particle is given by L = r × p where p is linear momentum.", "[Variable] Let Ω be the angular speed of the rotating reference frame about the common axis.", "[Law] In the rotating frame, a fictitious Coriolis force -2m Ω × v_rel acts on a mass m moving at velocity v_rel relative to the frame.", "[Constraint] The time derivative of L in inertial space equals the net torque τ_ext applied by external forces.", "[Limit] Internal tractions within a deformable body cannot create a net external torque τ_ext on the body."]}, "accepted": "The rotating frame introduces a Coriolis term that depends on the relative velocity; angular momentum evolution in that frame must balance the fictitious torque generated by the frame motion.\n\nHYPOTHESIS: The angular momentum of a point mass measured in the rotating frame changes at a rate equal to the fictitious torque −2m Ω × v_rel.\nVERIFICATION: Units check: Ω × v_rel has dimensions (rad s⁻¹)(m s⁻¹)=m s⁻², multiplying mass gives N, consistent with torque per unit length.\nCONCLUSION: Rotating-frame fictitious torque quantitatively governs angular-momentum evolution.", "rejected": "The angular momentum measured in the rotating frame changes at a rate equal to the fictitious torque −2m Ω × v_rel.", "E_acc": 0.5063652396202087, "C_acc": 0.13732007145881653, "G_acc": 0.5168953345855698, "D_acc": 0.761069405823946, "H_acc": 0.2694660797715187, "Q_acc": 0.6530918976990505, "E_rej": 0.41849246621131897, "C_rej": 0.194761261343956, "G_rej": 0.5371191019730759, "D_rej": 0.796138197183609, "H_rej": 0.203861802816391, "Q_rej": 0.6328607671443024, "Delta_Q": 0.020231130554748122, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Variable-mass systems analysed through momentum flux and energy bookkeeping: hypotheses about reactive thrust, internal energy change, and open-system invariants.", "ancestors": ["[Definition] A variable-mass system is an open system whose mass m changes with time.", "[Variable] m(t) is the instantaneous total mass at time t.", "[Variable] u is the exhaust velocity relative to the system.", "[Law] Newtonian momentum p equals mv.", "[Variable] dm is the mass ejected in time dt.", "[Definition] Momentum flux is the momentum crossing boundary per time.", "[Constraint] No external forces act on the system.", "[Limit] Special relativity effects are negligible.", "[Definition] Internal energy U is the energy of internal components."]}, "accepted": "Derivation summary:  \nThe open system ejects mass dm at relative velocity u while conserving momentum.  No external forces act, so the momentum change equals the momentum flux leaving the boundary.  Integrate over dt to obtain the instantaneous momentum change.\n\nHYPOTHESIS:  The momentum of a variable-mass system decreases at the rate dp/dt = –u(dm/dt), where u is the exhaust velocity and dm/dt is the mass-loss rate.\n\nVERIFICATION:  Units check:  u(dm/dt) has (m/s)(kg/s)=kg·m/s², matching force units, so dp/dt is momentum per second.\n\nCONCLUSION:  The system loses momentum linearly with its mass-loss rate, quantified by the exhaust velocity.", "rejected": "The momentum of a variable-mass system increases at the rate dp/dt = u(dm/dt), where u is the exhaust velocity and dm/dt is the mass-loss rate.", "E_acc": 0.5036677122116089, "C_acc": 0.22109884023666382, "G_acc": 0.5331246301939245, "D_acc": 0.7219957411289215, "H_acc": 0.2931678295135498, "Q_acc": 0.6285878369293642, "E_rej": 0.31428036093711853, "C_rej": 0.2530355155467987, "G_rej": 0.5605000326759182, "D_rej": 0.8128078877925873, "H_rej": 0.18719211220741272, "Q_rej": 0.5996193780447356, "Delta_Q": 0.028968458884628512, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Quantization at micro-scales vs. effective continuity macroscopically: hypotheses about coarse-graining and emergent classicality.", "ancestors": ["[Definition] A quantum state is a vector in a Hilbert space.", "[Variable] Let ℏ denote the reduced Planck constant.", "[Limit] The classical limit corresponds to ℏ → 0.", "[Law] Observable operators have discrete eigenvalues in a bounded system.", "[Variable] Let Δx be the position uncertainty of a quantum state.", "[Constraint] The inequality Δx Δp ≥ ℏ/2 relates position and momentum uncertainties.", "[Definition] Coarse-graining averages observables over a macroscopic cell of size L ≫ Δx.", "[Definition] The effective density operator is ρ_eff = (1/V) ∫_V ρ dV.", "[Limit] When L ≫ λ_th, the discrete eigenvalue spectrum becomes experimentally indistinguishable from a continuum."]}, "accepted": "When the coarse-graining cell L is expanded until L≫λ_th, the discrete eigenvalue spectrum becomes experimentally indistinguishable from a continuum, and the effective density operator ρ_eff converges to the classical density operator ρ_cl. Derive the threshold L≥λ_th, where λ_th is the thermal de Broglie wavelength, and the classical limit is achieved when ℏ→0.\n\nHYPOTHESIS: The classical limit is achieved when L≥λ_th, where λ_th is the thermal de Broglie wavelength, and the effective density operator ρ_eff converges to the classical density operator ρ_cl.\n\nVERIFICATION: Units check: L≫λ_th, where λ_th is the thermal de Brogl wavelength, and the classical limit is achieved when ℏ→0.\n\nCONCLUSION: The classical limit is achieved when L≥λ_th, where λ_th is the thermal de Brogl wavelength, and the effective density operator ρ_eff converges to the classical density operator ρ_cl.", "rejected": "The classical limit is achieved when L≥Δx, where Δx is the position uncertainty of a quantum state, and the effective density operator ρ_eff converges to the classical density operator ρ_cl.", "E_acc": 0.6077530980110168, "C_acc": 0.2061261683702469, "G_acc": 0.5433786601061001, "D_acc": 0.7544414520263671, "H_acc": 0.18732097744941711, "Q_acc": 0.6819326204108075, "E_rej": 0.3889797329902649, "C_rej": 0.357298344373703, "G_rej": 0.548040401248727, "D_rej": 0.8437095582485199, "H_rej": 0.1562904417514801, "Q_rej": 0.6079551987466403, "Delta_Q": 0.07397742166416721, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Epigenetic regulation as a tunable, heritable information layer: hypotheses on signal-dependent chromatin remodeling and memory retention.", "ancestors": ["[Definition] Epigenetic regulation is heritable gene expression without DNA sequence change.", "[Variable] Chromatin state is discrete gene accessibility level.", "[Variable] Epigenetic signal S controls chromatin state.", "[Variable] Epigenetic memory M stores past states.", "[Law] Signal-dependent remodeling uses S to set chromatin state.", "[Constraint] Signal must reach remodelers within cell volume.", "[Constraint] Memory retention needs chromatin state maintenance.", "[Limit] Epigenetic marks cannot alter DNA sequence.", "[Limit] Epigenetic memory M cannot override DNA mutations."]}, "accepted": "Epigenetic signal S must reach remodelers within the cell volume before chromatin state can be set, and memory M must retain that state without altering DNA sequence.  \nHYPOTHESIS: The minimal heritable gene expression threshold is the discrete chromatin state set by S once per cell cycle.  \nVERIFICATION: Units match discrete accessibility levels per cell cycle.  \nCONCLUSION: Epigenetic regulation quantizes gene accessibility.", "rejected": "Epigenetic signal S plus chromatin state equals discrete gene accessibility.", "E_acc": 0.5188013315200806, "C_acc": 0.2280530482530594, "G_acc": 0.6121491892263293, "D_acc": 0.7874217219650745, "H_acc": 0.1267029047012329, "Q_acc": 0.6772736815735698, "E_rej": 0.4209415912628174, "C_rej": 0.33445945382118225, "G_rej": 0.6235594907775521, "D_rej": 0.8375346660614014, "H_rej": 0.16246533393859863, "Q_rej": 0.6353628845885396, "Delta_Q": 0.041910796985030196, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Power flow in networks with reactive and non-linear elements: hypotheses about transient energy trapping and route-dependent dissipation.", "ancestors": ["[Definition] A sinusoidal steady-state phasor V has constant magnitude |V| and angle θ.", "[Variable] Let S = P + jQ denote complex power with P the real and Q the reactive part.", "[Law] Kirchhoff’s current law requires ΣI_in = ΣI_out at every node for each harmonic.", "[Constraint] Energy storage elements, L and C, make instantaneous power p(t) bidirectional and Q non-zero.", "[Variable] Define transient energy W_t(t) = ½L i_L² + ½C v_C².", "[Limit] For linear R-L-C segments, W_t decays ≤ exp(-2Rt/L) after any small disturbance.", "[Constraint] In a network with nonlinear v-i relations, W_t can be trapped in closed loops of L and C that contain no dissipative element."]}, "accepted": "<derivation sentences>\nThe premises constrain W_t(t) in linear R-L-C segments to decay no slower than exp(-2Rt/L), while nonlinear networks can trap W_t in loops without dissipative elements. This creates a boundary condition where dissipative elements determine the minimum decay rate.\n\nHYPOTHESIS: The trapped transient energy W_t in nonlinear L-C loops exceeds the decay threshold exp(-2Rt/L) when dissipative elements are absent, establishing exp(-2Rt/L) as the maximum decay rate for W_t in any network configuration.\n\nVERIFICATION: Units consistent (W_t in joules, R/L in s⁻¹, dimensionless exponential).\n\nCONCLUSION: Dissipative elements control transient energy decay boundaries.", "rejected": "The trapped transient energy W_t in nonlinear L-C loops decays faster than exp(-2Rt/L) when dissipative elements are absent, violating the decay lower bound.", "E_acc": 0.26475468277931213, "C_acc": 0.5204256176948547, "G_acc": 0.517673166905297, "D_acc": 0.720283484707276, "H_acc": 0.17599916458129883, "Q_acc": 0.5053326951592074, "E_rej": 0.231185644865036, "C_rej": 0.5609256029129028, "G_rej": 0.5170066673308611, "D_rej": 0.77506223320961, "H_rej": 0.22493776679039001, "Q_rej": 0.4930905763059855, "Delta_Q": 0.012242118853221906, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stochastic decay processes framed as energy/entropy flows: hypotheses about microscale correlations that produce macroscopic rate laws.", "ancestors": ["[Definition] Entropy is a measure of disorder in a thermodynamic system.", "[Law] The second law of thermodynamics states entropy increases in isolated systems.", "[Variable] k is the rate constant of decay processes.", "[Constraint] Energy flows must conserve total energy in stochastic processes.", "[Limit] Microscopic correlations cannot violate macroscopic thermodynamic laws.", "[Definition] Stochastic decay processes exhibit probabilistic behavior.", "[Law] Microscopic correlations produce emergent macroscopic rate laws.", "[Constraint] Energy/entropy flows must satisfy conservation laws."]}, "accepted": "Using the second-law requirement that entropy increases in isolated systems and the conservation of energy, any stochastic decay process must convert a non-zero fraction of the decay energy into entropy production.  \nHYPOTHESIS: The entropy increment ΔS for an isolated stochastic decay satisfies ΔS ≥ k ln 2, where k is the decay rate constant.  \nVERIFICATION: Both sides have entropy units (J K⁻¹) and the bound holds for any isolated system.  \nCONCLUSION: Sets a universal lower entropy threshold per stochastic decay event.", "rejected": "The entropy increment ΔS for an isolated stochastic decay satisfies ΔS ≥ k ln 2, where k is the decay rate constant.", "E_acc": 0.43580928444862366, "C_acc": 0.2700378894805908, "G_acc": 0.5454642574186437, "D_acc": 0.8051124885678291, "H_acc": 0.24765096604824066, "Q_acc": 0.6220854600309393, "E_rej": 0.4507884681224823, "C_rej": 0.19793066382408142, "G_rej": 0.5405768323107623, "D_rej": 0.8032970726490021, "H_rej": 0.19670292735099792, "Q_rej": 0.6447548959287815, "Delta_Q": -0.022669435897842205, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Crystal lattice energetics in ionic solids with polarizability: hypotheses on many-body contributions to lattice energy beyond pairwise Coulomb.", "ancestors": ["[Definition] An ionic solid is a crystal composed of cations and anions.", "[Definition] Lattice energy is the energy released when one mole of an ionic solid forms from separated ions.", "[Law] The pair attraction varies as the inverse of distance between two ions.", "[Variable] A polarizability α is defined for each ionic species.", "[Constraint] Only electrostatic forces act between ions in the pairwise model.", "[Definition] A multipole is a charge distribution beyond monopole.", "[Limit] The pairwise model does not account for multipoles induced by neighbors.", "[Constraint] The many-body energy correction depends on all ion positions."]}, "accepted": "The pairwise model treats ions as point charges interacting only through Coulomb attraction, so the lattice energy U is the sum over all ion pairs of (q_i q_j)/(4πε_0 r_ij).  \nBecause the premises restrict interactions to pairwise electrostatics and ignore neighbor-induced multipoles, this sum omits the many-body polarization energy ΔU_pol that scales with the ions’ polarizabilities α and the local field gradients.  \n\nHYPOTHESIS: The pairwise estimate of lattice energy systematically overestimates the true cohesive energy of an ionic solid by at least the total induced-polarization energy ΔU_pol = ½ Σ_i α_i |E_loc,i|².  \nVERIFICATION: Units check—α in C m² V⁻¹, E in V m⁻¹, product gives energy in joules per mole.  \nCONCLUSION: Correct pairwise lattice energies downward by including polarization terms.", "rejected": "The pairwise estimate of lattice energy assumes the polarization correction ΔU_pol is independent of the polarizabilities α.", "E_acc": 0.22645415365695953, "C_acc": 0.27262207865715027, "G_acc": 0.5218435673014028, "D_acc": 0.7601073235273361, "H_acc": 0.15050771832466125, "Q_acc": 0.5547512366989394, "E_rej": 0.01517726480960846, "C_rej": 0.9292592406272888, "G_rej": 0.531788979191333, "D_rej": 0.7556083798408508, "H_rej": 0.24439162015914917, "Q_rej": 0.35174164110794665, "Delta_Q": 0.2030095955909928, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Quantization at micro-scales vs. effective continuity macroscopically: hypotheses about coarse-graining and emergent classicality.", "ancestors": ["[Definition] Quantization denotes restriction of a physical quantity to discrete values.", "[Definition] A micro-state is the complete quantum specification of a system.", "[Definition] A macro-state is a set specification via coarse-grained macroscopic variables.", "[Variable] N labels the number of micro-states per macro-state.", "[Law] The number N is finite for bounded energy.", "[Variable] δx labels the minimal observable resolution of a position coordinate.", "[Constraint] The spacing between adjacent quantum levels must exceed δx to be individually distinguished.", "[Limit] The quantum level spacing scales inversely with system size.", "[Constraint] The macroscopic δx exceeds the quantum level spacing for large systems.", "[Limit] Consequently, adjacent quantum levels merge within experimental resolution."]}, "accepted": "For a macroscopic system whose size makes the quantum level spacing smaller than the minimal observable position resolution δx, the countable micro-states per macro-state, N, collapse into an effectively continuous set; consequently the macro-state entropy S=k ln N loses its discrete character and becomes a smooth function of the coarse-grained variables.  \nHYPOTHESIS: When the quantum level spacing falls below δx, the macroscopic entropy is continuous and obeys S=k ln(V/λ³) with λ=h/√(2πmkT).  \nVERIFICATION: λ has units of length, V/λ³ is dimensionless, and the formula holds in the thermodynamic limit where level spacing ≪ δx.  \nCONCLUSION: Macroscopic entropy becomes a continuous variable.", "rejected": "When the macroscopic entropy becomes a continuous variable, the quantum level spacing falls below δx.", "E_acc": 0.20175163447856903, "C_acc": 0.5035223960876465, "G_acc": 0.5508119039004669, "D_acc": 0.7732410691678524, "H_acc": 0.1474113166332245, "Q_acc": 0.5098904740763828, "E_rej": 0.031907375901937485, "C_rej": 0.5798057317733765, "G_rej": 0.5397395382160539, "D_rej": 0.788974404335022, "H_rej": 0.21102559566497803, "Q_rej": 0.43825129535962337, "Delta_Q": 0.0716391787167594, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Protein folding landscapes in crowded intracellular environments: hypotheses on kinetic traps, chaperone intervention, and functional folding funnels.", "ancestors": ["[Definition] A protein folding landscape is a surface in conformation space where every point assigns an energy E to a configuration.", "[Variable] E is the total effective energy of a protein conformation.", "[Variable] k is the folding rate constant.", "[Definition] A kinetic trap is a local energy minimum that impedes transition funnels.", "[Constraint] A local minimum must require activation energy higher than thermal fluctuation kT to exit.", "[Law] Energy surface shape determines kinetics of escape.", "[Limit] No single protein can lower activation energy needed to exit kinetic trap alone.", "[Definition] Chaperones exclude conformations from folding landscape.", "[Constraint] Chaperone exclusion reduces potential conformations by 50%.", "[Variable] c is the number of excluded conformations"]}, "accepted": "Chaperone exclusion halves the conformation space, so any kinetic trap that survives must lie in the remaining 50 % of the landscape; because the folding rate k scales with the number of accessible escape routes, eliminating half of the routes forces k to drop by at least the same fraction.\n\nHYPOTHESIS: Chaperone-mediated 50 % reduction of conformation space lowers the protein folding rate constant k by at least a factor of two.\n\nVERIFICATION: Dimensionless ratio k_after/k_before ≤ 0.5 follows directly from the 50 % reduction in accessible microstates.\n\nCONCLUSION: Chaperone action necessarily slows folding kinetics by ≥2-fold.", "rejected": "Chaperone-mediated 50 % reduction of conformation space lowers the protein folding rate constant k by at most a factor of two.", "E_acc": 0.7331265807151794, "C_acc": 0.05383560061454773, "G_acc": 0.49648883839836344, "D_acc": 0.7900062017142773, "H_acc": 0.14842477440834045, "Q_acc": 0.7516273846733385, "E_rej": 0.03214140981435776, "C_rej": 0.07914512604475021, "G_rej": 0.49700018751900643, "D_rej": 0.840719610452652, "H_rej": 0.15928038954734802, "Q_rej": 0.5454293183749542, "Delta_Q": 0.20619806629838422, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Gradual accumulation of complex systems explained via modular co-option and incremental functional shifts: hypotheses on feasible assembly paths.", "ancestors": ["[Definition] A module is a discrete functional unit composed of parts.", "[Definition] Co-option is the evolutionary reuse of a unit for a new function.", "[Law] Complexity can increase gradually through sequential additions.", "[Constraint] Each addition must minimally disrupt existing function.", "[Variable] Functional shift is denoted by ΔF per addition.", "[Limit] Maximum additions per step is finite and fixed.", "[Limit] Total additions cannot exceed system viability."]}, "accepted": "Sequential additions of modular parts under the co-option rule raise cumulative functional shift ΔF; because each step is bounded and viability imposes a ceiling, the total shift is capped.  \nHYPOTHESIS: The maximum attainable functional shift is ΔF_max = n_max · ΔF_step, where n_max is the largest integer satisfying n_max ≤ (Viability_limit / Disruption_per_step).  \nVERIFICATION: Dimensionless ratio on RHS matches dimensionless ΔF_max; holds when additions are uniform and disruptions additive.  \nCONCLUSION: Evolutionary reuse cannot produce arbitrary functional divergence.", "rejected": "Sequential additions of modular parts under the co-option rule raise cumulative functional shift ΔF; because each step is bounded and viability imposes a ceiling, the total shift is uncapped.", "E_acc": 0.28335538506507874, "C_acc": 0.46642836928367615, "G_acc": 0.5631795880326536, "D_acc": 0.7183563932776451, "H_acc": 0.20260217785835266, "Q_acc": 0.5277679201390129, "E_rej": 0.007134827319532633, "C_rej": 0.9732485413551331, "G_rej": 0.5657169121986954, "D_rej": 0.7737675905227661, "H_rej": 0.2262324094772339, "Q_rej": 0.35276439952140215, "Delta_Q": 0.1750035206176107, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electric potential energy density and work extraction in inhomogeneous dielectrics: hypotheses about bound-charge contributions.", "ancestors": ["[Definition] Electric field E is the force per unit charge.", "[Definition] Energy density u is energy per volume.", "[Law] Energy density u equals epsilon E squared over two.", "[Variable] epsilon is position-dependent static permeability.", "[Variable] Bound charge rho_b equals minus divergence of P.", "[Variable] P equals epsilon E minus epsilon naught E.", "[Constraint] Work extraction cannot create energy.", "[Limit] Local epsilon must remain positive."]}, "accepted": "The energy density u equals epsilon E squared over two, with epsilon position-dependent and locally positive. Bound charge rho_b equals minus divergence of P, where P equals epsilon E minus epsilon naught E. Combining these, rho_b equals minus divergence of (epsilon E minus epsilon naught E), which simplifies to minus divergence of epsilon E plus divergence of epsilon naught E. Since epsilon is position-dependent, divergence of epsilon E equals epsilon divergence of E plus E gradient of epsilon. Thus rho_b equals minus epsilon divergence of E minus E gradient of epsilon plus divergence of epsilon naught E. Divergence of epsilon naught E equals epsilon naught divergence of E, since epsilon naught is constant. Therefore rho_b equals minus epsilon divergence of E minus E gradient of epsilon plus epsilon naught divergence of E, which equals minus divergence of E (epsilon minus epsilon naught) minus E gradient of epsilon. This derived expression relates bound charge to electric field divergence and gradient.\n\nHYPOTHESIS: Bound charge rho_b equals minus divergence of E (epsilon minus epsilon naught) minus E gradient of epsilon.\nVERIFICATION: Units check: rho_b in C m^-3, divergence of E in V m^-2, epsilon in F m^-1, gradient of epsilon in F m^-2, E in V m^-1, consistent.\nCONCLUSION: Bound charge density derived from electric field divergence and gradient.", "rejected": "Bound charge rho_b equals minus divergence of E (epsilon minus epsilon naught) minus E gradient of epsilon, implying electric field divergence and gradient determine bound charge rather than bound charge determining electric field divergence and gradient.", "E_acc": 0.4954792261123657, "C_acc": 0.23333783447742462, "G_acc": 0.5643378579989076, "D_acc": 0.799571159211072, "H_acc": 0.14812591671943665, "Q_acc": 0.6599454127082771, "E_rej": 0.2729799151420593, "C_rej": 0.41192880272865295, "G_rej": 0.5600269532296807, "D_rej": 0.8051085472106934, "H_rej": 0.19489145278930664, "Q_rej": 0.5530461688060313, "Delta_Q": 0.10689924390224581, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcriptional noise vs. fidelity trade-offs: hypotheses on how polymerase kinetics shape phenotypic variability.", "ancestors": ["[Definition] Transcriptional noise is cell-to-cell variation in mRNA counts for a gene.", "[Definition] Fidelity is the probability that a transcript matches the coding sequence.", "[Definition] Polymerase speed v is the nucleotide addition rate during elongation.", "[Variable] Let τ be the elongation time from start to termination.", "[Law] τ = L / v, where L is the gene length in nucleotides.", "[Constraint] Higher v decreases τ.", "[Limit] Maximum v is set by the polymerase’s catalytic limit.", "[Variable] Let n be the mRNA copy number in one cell.", "[Constraint] n varies inversely with τ at constant transcription initiation rate."]}, "accepted": "Using the inverse relation between mRNA copy number n and elongation time τ, and the direct relation τ = L / v, we derive n ∝ v / L.  \nHYPOTHESIS: For a fixed gene length L, increasing polymerase speed v above the value that halves the basal elongation time will at least double the steady-state mRNA copy number n.  \nVERIFICATION: Units consistent (v [nt/s], L [nt], n dimensionless).  \nCONCLUSION: Raising polymerase speed predictably boosts transcriptional output.", "rejected": "For a fixed gene length L, increasing polymerase speed v above the value that halves the basal elongation time will raise the steady-state mRNA copy number n by exactly v².", "E_acc": 0.3442241847515106, "C_acc": 0.12714886665344238, "G_acc": 0.5926736609544605, "D_acc": 0.7585792522877455, "H_acc": 0.1426960527896881, "Q_acc": 0.6338184594642371, "E_rej": 0.03267873078584671, "C_rej": 0.379237562417984, "G_rej": 0.5983983692713082, "D_rej": 0.8396885991096497, "H_rej": 0.16031140089035034, "Q_rej": 0.5055423603393139, "Delta_Q": 0.12827609912492322, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exceptions to simple effective nuclear charge models attributed to multi-electron screening and exchange: hypotheses explaining localized irregularities.", "ancestors": ["[Definition] Effective nuclear charge Z_eff is the net positive charge attracting an electron after accounting for electron screening.", "[Definition] Electron screening reduces Z_eff by shielding outer electrons from nuclear charge.", "[Variable] Total electrons N minus proton count Z sets screening magnitude.", "[Constraint] Z_eff cannot exceed actual nuclear charge Z.", "[Limit] Z_eff never reaches zero for bound electrons in neutral atoms.", "[Constraint] Multi-electron interactions modify single-particle Z_eff predictions.", "[Definition] Exchange interaction alters orbital energies through antisymmetry requirement.", "[Variable] Spin alignment affects exchange contribution magnitude.", "[Limit] Z_eff models fail when correlation energy exceeds exchange screening."]}, "accepted": "Using the premise that total electrons N minus proton count Z sets screening magnitude and the constraint that Z_eff cannot exceed Z, the screening reduction must equal exactly N–Z when exchange and correlation are neglected.  \nHYPOTHESIS: In any multi-electron atom with N electrons and nuclear charge Z, the effective nuclear charge for an outer electron is Z_eff = Z – (N – 1) provided electron–electron correlation is negligible compared with exchange.  \nVERIFICATION: Dimensionless charge subtraction; valid for light to medium atoms where correlation energy < exchange splitting.  \nCONCLUSION: Outer-electron binding energies scale with Z – N + 1.", "rejected": "In any multi-electron atom with N electrons and nuclear charge Z, the effective nuclear charge for an outer electron is Z_eff = Z – N provided exchange and correlation contributions are treated as independent of electron count.", "E_acc": 0.23774823546409607, "C_acc": 0.438755065202713, "G_acc": 0.5542545588541543, "D_acc": 0.8170139826834202, "H_acc": 0.16353953629732132, "Q_acc": 0.541473212276469, "E_rej": 0.24352087080478668, "C_rej": 0.37424758076667786, "G_rej": 0.571629369049333, "D_rej": 0.869831770658493, "H_rej": 0.13016822934150696, "Q_rej": 0.573482150095515, "Delta_Q": -0.0320089378190459, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stochastic decay processes framed as energy/entropy flows: hypotheses about microscale correlations that produce macroscopic rate laws.", "ancestors": ["[Definition] A stochastic process is a collection of random variables indexed by time.", "[Variable] Each realization x(t) is a sample path of the process.", "[Definition] Entropy is S = k ln Ω with k a constant and Ω the multiplicity.", "[Law] The second law states ΔS ≥ 0 for isolated systems.", "[Constraint] Total energy E is conserved at every microscopic step.", "[Limit] Correlation vanishes beyond length ξ, above which variables are independent.", "[Constraint] The average decay rate equals Nk with N the number of channels.", "[Definition] Macroscopic linearity arises when ΔS is additive over subsystems."]}, "accepted": "The second law and the conserved microscopic energy together imply that any entropy-producing stochastic channel must compensate by exporting at least as much entropy to its surroundings.  \nHYPOTHESIS: An isolated system containing N independent stochastic channels each increasing its own entropy at rate k obeys dS/dt ≥ Nk, with equality when correlations vanish beyond ξ.  \nVERIFICATION: Units check—Nk gives entropy per time, matching dS/dt.  \nCONCLUSION: Entropy production scales linearly with channel number.", "rejected": "An isolated system containing N independent stochastic channels each increasing its own entropy at rate k obeys dS/dt = NkT, with equality when correlations vanish beyond ξ.", "E_acc": 0.41832780838012695, "C_acc": 0.21328085660934448, "G_acc": 0.5437650553067215, "D_acc": 0.7891336195170879, "H_acc": 0.23411616683006287, "Q_acc": 0.6260102894739248, "E_rej": 0.5091152191162109, "C_rej": 0.24805985391139984, "G_rej": 0.5583708975464106, "D_rej": 0.8142670392990112, "H_rej": 0.18573296070098877, "Q_rej": 0.6590768862515688, "Delta_Q": -0.03306659677764401, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A membrane is a lipid bilayer separating two aqueous phases.", "[Law] Fick's law states that flux J is proportional to concentration gradient.", "[Variable] D is the diffusion coefficient of a lipid molecule.", "[Constraint] D is measured at T above the bilayer's phase transition temperature.", "[Limit] D cannot exceed the value set by two-dimensional hard-disk collision rate.", "[Definition] A nano-domain is a transient cluster of lipids.", "[Variable] N is the number of lipids in a nano-domain.", "[Constraint] N is less than the total number of lipids in the membrane."]}, "accepted": "Using the diffusion coefficient D and the nano-domain size N, the two-dimensional collision frequency sets an upper bound on how fast lipids can join or leave a cluster.  \nHYPOTHESIS: The lifetime τ of a nano-domain satisfies τ ≥ (N – 1)/(4D) · √(πA₀), where A₀ is the mean area per lipid headgroup.  \nVERIFICATION: Units check: (dimensionless)/(cm² s⁻¹) · √(cm²) = s, consistent with lifetime.  \nCONCLUSION: Nano-domains persist for at least microseconds above the transition temperature.", "rejected": "The lifetime τ of a nano-domain satisfies τ ≥ (N – 1)/(4D) · √(πA₀), where A₀ is the mean area per lipid headgroup and N is treated as independent of D.", "E_acc": 0.3449711501598358, "C_acc": 0.1893726885318756, "G_acc": 0.47252233047038317, "D_acc": 0.7522689830511808, "H_acc": 0.2031818926334381, "Q_acc": 0.5902568807825446, "E_rej": 0.13513630628585815, "C_rej": 0.36138954758644104, "G_rej": 0.5025065213364238, "D_rej": 0.7853924632072449, "H_rej": 0.21460753679275513, "Q_rej": 0.5043820255979276, "Delta_Q": 0.08587485518461702, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Epigenetic regulation as a tunable, heritable information layer: hypotheses on signal-dependent chromatin remodeling and memory retention.", "ancestors": ["[Definition] An epigenetic mark is a chemical modification to DNA or histone proteins that alters gene expression without changing the DNA sequence.", "[Definition] Chromatin is the complex of DNA and histone proteins packaged inside the nucleus.", "[Definition] Chromatin remodeling is the repositioning or restructuring of nucleosomes to change DNA accessibility.", "[Variable] Let M denote the presence of an activating epigenetic mark.", "[Definition] A signal S is an external stimulus detected by a cell-sensing pathway.", "[Constraint] Enzymes that add or remove epigenetic marks require a specific substrate concentration [S] above threshold Km.", "[Law] The rate v of mark addition follows Michaelis-Menten kinetics: v = Vmax[S]/(Km + [S]).", "[Limit] Epigenetic marks persist through cell division only if maintenance enzymes re-establish them on newly synthesized DNA or histones.", "[Constraint] Histone-modifying enzymes can only act on nucleosomes where the target residue is solvent-accessible."]}, "accepted": "Derivation from premises: Michaelis-Menten kinetics constrain the rate v of mark addition to v = Vmax[S]/(Km + [S]).  Solving for [S] gives [S] = v Km /(Vmax – v).  To exceed any preset rate v, the substrate must exceed Km v /(Vmax – v).\n\nHYPOTHESIS: A chromatin-remodeling signal must raise substrate concentration above Km v /(Vmax – v) to drive activating mark addition faster than rate v.\nVERIFICATION: Units: [S] in mol/L, v in mol L⁻¹ s⁻¹, Km in mol/L, Vmax in mol L⁻¹ s⁻¹; both sides dimensionally consistent.\nCONCLUSION: Substrate threshold quantified for activating mark addition.", "rejected": "A chromatin-remodeling signal must raise substrate concentration to Km v /(Vmax – v) faster than rate v to drive activating mark addition.", "E_acc": 0.5998323559761047, "C_acc": 0.14883700013160706, "G_acc": 0.5561268408710021, "D_acc": 0.6937854140996933, "H_acc": 0.21955673396587372, "Q_acc": 0.6782090843640618, "E_rej": 0.21849887073040009, "C_rej": 0.28653883934020996, "G_rej": 0.561169430919108, "D_rej": 0.8719301521778107, "H_rej": 0.16008730977773666, "Q_rej": 0.578853078992688, "Delta_Q": 0.09935600537137379, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Refraction from conservation of photon momentum and phase velocity mismatch: hypotheses about anomalous dispersion regimes.", "ancestors": ["[Definition] A photon carries momentum p = ℏk.", "[Law] Conservation of momentum requires p_before = p_after.", "[Variable] Phase velocity v_p = ω/k.", "[Constraint] In refraction, photon momentum ℏk changes direction at boundary.", "[Limit] Conservation forbids abrupt jump in ℏk parallel to interface.", "[Definition] Anomalous dispersion occurs where v_p decreases with ω."]}, "accepted": "Momentum conservation at an interface fixes the component of the photon wave-vector parallel to the boundary, so any change in the perpendicular component must preserve the total wave-vector magnitude.  \nHYPOTHESIS: A photon entering a refractive medium acquires a perpendicular wave-vector component k⊥ = √(n²k₀² − k∥²), where k₀ is the vacuum wave-vector magnitude and k∥ is the conserved parallel component.  \nVERIFICATION: Units of k⊥ are m⁻¹, matching wave-vector dimensions, and the expression holds for n > 1 and k∥ ≤ nk₀.  \nCONCLUSION: Photon refraction direction is fully set by the conserved parallel momentum.", "rejected": "Momentum conservation at an interface allows the parallel component of the photon wave-vector to jump discontinuously across the boundary.", "E_acc": 0.3211630880832672, "C_acc": 0.4210503399372101, "G_acc": 0.5264341988950036, "D_acc": 0.76479072868824, "H_acc": 0.22735171020030975, "Q_acc": 0.5476486729341559, "E_rej": 0.008002270944416523, "C_rej": 0.9813174605369568, "G_rej": 0.5313615906052291, "D_rej": 0.8393946886062622, "H_rej": 0.1606053113937378, "Q_rej": 0.3642279138788581, "Delta_Q": 0.18342075905529776, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Latent energy flows at phase boundaries analyzed by statistical ensembles: hypotheses on metastable pathways and nucleation energetics.", "ancestors": ["[Definition] Latent energy L is the difference in molar internal energy across a phase boundary at fixed temperature T.", "[Definition] A statistical ensemble is a collection of microstates weighted by a probability distribution.", "[Variable] The partition function Z is the sum over microstates of exp(−βE) with β = 1/(kT).", "[Law] The ensemble average energy ⟨E⟩ equals −∂lnZ/∂β.", "[Constraint] At coexistence, the chemical potentials μα = μβ impose equal Gibbs free energy per particle.", "[Definition] Metastability denotes a local but not global minimum of the Gibbs free energy G(T,P,N).", "[Variable] The nucleation barrier ΔG* is the maximum excess Gibbs free energy for a critical cluster of radius r*.", "[Limit] The barrier height obeys ΔG* = 16πγ³/(3Δg²) with γ the interfacial tension and Δg the bulk driving force per volume.", "[Definition] The latent energy L equals Δg plus the interfacial and line energy densities integrated over the phase boundary."]}, "accepted": "The premises define latent energy L as the difference in molar internal energy across a phase boundary and relate it to the bulk driving force Δg plus interfacial contributions.  Combining the nucleation barrier ΔG* = 16πγ³/(3Δg²) with the definition L = Δg + surface terms yields a lower bound on L once the interfacial tension γ is specified.\n\nHYPOTHESIS: The latent energy L obeys L ≥ Δg = 4γ√(π/3ΔG*), equality holding at the critical nucleus.\nVERIFICATION: Units check: γ in J m⁻², ΔG* in J, Δg in J m⁻³, L in J m⁻³.\nCONCLUSION: L is bounded by measurable interfacial and nucleation parameters.", "rejected": "The latent energy L obeys L ≤ Δg = 4γ√(π/3ΔG*), equality holding at the critical nucleus.", "E_acc": 0.5813152194023132, "C_acc": 0.12288779765367508, "G_acc": 0.5516365765506634, "D_acc": 0.7385393798351287, "H_acc": 0.13905096054077148, "Q_acc": 0.6939471015130403, "E_rej": 0.34231606125831604, "C_rej": 0.3298630714416504, "G_rej": 0.5725673142005689, "D_rej": 0.7762362957000732, "H_rej": 0.22376370429992676, "Q_rej": 0.5841065556393006, "Delta_Q": 0.1098405458737397, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Proton activity and micro-solvation structure: hypotheses about site-specific dissociation strength and dynamic proton wires.", "ancestors": ["[Definition] A proton is H⁺.", "[Definition] Activity a equals effective concentration.", "[Variable] γ is the activity coefficient.", "[Law] a = γc with c the molar concentration.", "[Definition] A hydron is H₃O⁺.", "[Definition] A proton wire is a hydrogen-bonded chain that transfers H⁺.", "[Constraint] Each step in a proton wire requires an O–O distance ≤ 2.8 Å.", "[Variable] r is the donor–acceptor separation in the wire.", "[Limit] Proton transfer rate kₚ → 0 when r > 2.8 Å.", "[Variable] n is the number of intervening H₂O molecules in the wire."]}, "accepted": "The premises link proton transfer to the geometric constraint r ≤ 2.8 Å and identify n as the count of intervening water molecules along the wire.  Because each additional water extends the chain, the maximum donor–acceptor span that still satisfies r ≤ 2.8 Å sets an upper bound on n.\n\nHYPOTHESIS: A proton wire can contain at most one intervening water molecule while maintaining the ≤2.8 Å donor–acceptor separation required for non-zero proton transfer rate.\n\nVERIFICATION: For n = 1 the O–O–O span ≈ 5.6 Å, so the effective donor–acceptor r ≈ 2.8 Å, matching the limiting distance; larger n would exceed this limit.\n\nCONCLUSION: Proton wires longer than one water are geometrically forbidden under the 2.8 Å constraint.", "rejected": "A proton wire can contain at most two intervening water molecules while maintaining the ≤2.8 Å donor–acceptor separation required for non-zero proton transfer rate.", "E_acc": 0.5272525548934937, "C_acc": 0.16312909126281738, "G_acc": 0.5294208308623638, "D_acc": 0.7794000953435898, "H_acc": 0.19470444321632385, "Q_acc": 0.667843689135043, "E_rej": 0.015329123474657536, "C_rej": 0.15787069499492645, "G_rej": 0.5103823529789224, "D_rej": 0.8363445401191711, "H_rej": 0.16365545988082886, "Q_rej": 0.5260044306749478, "Delta_Q": 0.14183925846009515, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Topology-dependent current partitioning under dynamic boundary conditions: hypotheses on metastable current paths and energy bottlenecks.", "ancestors": ["[Definition] A current I is charge per unit time.", "[Definition] A metastable state is locally stable but globally unstable.", "[Definition] Energy E is a conserved quantity.", "[Variable] E is energy.", "[Constraint] E is bounded below.", "[Definition] A bottleneck is a local constriction limiting current.", "[Limit] Energy dissipation is non-negative.", "[Definition] Topology is the set of continuous properties under deformation.", "[Constraint] Current partition depends on topology."]}, "accepted": "Energy dissipation is non-negative and energy is bounded below, so any metastable state must satisfy a minimum-energy threshold relative to the bottleneck topology.  \nHYPOTHESIS: A metastable state constrained by a bottleneck obeys E ≥ E_min, where E_min is the lowest energy compatible with the bottleneck topology.  \nVERIFICATION: Units check: E_min has energy units, consistent with E.  \nCONCLUSION: Energy bounded below enforces a topology-dependent lower limit on metastable states.", "rejected": "A metastable state constrained by a bottleneck violates E ≥ E_min.", "E_acc": 0.41637569665908813, "C_acc": 0.2719898819923401, "G_acc": 0.5420034051473651, "D_acc": 0.7780501432716846, "H_acc": 0.23507144302129745, "Q_acc": 0.6110182979809385, "E_rej": 0.18659058213233948, "C_rej": 0.4001528024673462, "G_rej": 0.5492000199155882, "D_rej": 0.7912858128547668, "H_rej": 0.20871418714523315, "Q_rej": 0.5231723619857803, "Delta_Q": 0.08784593599515822, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of multicellular coordination from cellular signaling gradients: hypotheses about minimal coupling required for tissue-level patterning.", "ancestors": ["[Definition] A morphogen M is a diffusible molecule whose spatial gradient governs cell fate.", "[Law] Fickian diffusion yields ∇²M = (1/D) ∂M/∂t with diffusion constant D.", "[Variable] Let λ = √(D/γ) where γ is the first-order decay rate of M.", "[Limit] Steady-state gradient satisfies ∂M/∂t = 0.", "[Constraint] For two adjacent cells i and j, |M_i – M_j| ≤ ΔM_c to remain in same differentiation band.", "[Definition] Coupling strength k quantifies the rate at which adjacent cells synchronize internal states.", "[Constraint] Tissue-scale patterning requires k ≥ k_min(ΔM_c, λ)."]}, "accepted": "Steady-state diffusion-decay balance sets ∂M/∂t = 0, so Fickian law reduces to ∇²M = 0 and the gradient length is λ = √(D/γ).  Combining this with the tissue-scale requirement k ≥ k_min(ΔM_c, λ) gives the minimal coupling threshold k_min = ΔM_c / λ.\n\nHYPOTHESIS: The minimal inter-cell coupling strength required to maintain a differentiation band is k_min = ΔM_c / λ.\nVERIFICATION: Units [k_min] = (M/L) / L = M L⁻², consistent with coupling rate per area.\nCONCLUSION: Tissue-scale pattern fidelity is preserved when k ≥ ΔM_c / λ.", "rejected": "Steady-state diffusion-decay balance sets ∂M/∂t = 0, so Fickian law reduces to ∇²M = 0 and the gradient length is λ = √(D/γ), yielding k_min = ΔM_c + λ.", "E_acc": 0.5279558897018433, "C_acc": 0.2010960876941681, "G_acc": 0.49586675356840715, "D_acc": 0.7813034772872924, "H_acc": 0.09997609257698059, "Q_acc": 0.6636039862851613, "E_rej": 0.4294375479221344, "C_rej": 0.3194420337677002, "G_rej": 0.5381353741358907, "D_rej": 0.7591309249401093, "H_rej": 0.24086907505989075, "Q_rej": 0.6003092099323112, "Delta_Q": 0.06329477635285008, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Endocrine signaling as spatially distributed control with gain modulation: hypotheses about low-concentration amplification and receptor desensitization.", "ancestors": ["[Definition] Endocrine signaling is the release of hormones into the bloodstream to carry messages to distant target tissues.", "[Variable] Let E be the concentration of unbound hormone in the blood.", "[Variable] Let R be the number of free receptors on a target cell.", "[Limit] Receptor-ligand binding affinity has a finite dissociation constant Kd measured in concentration units."]}, "accepted": "<derivation sentences>\nWhen hormone concentration E and free receptor count R meet the binding affinity Kd, the fraction of occupied receptors equals E/(E+Kd), a dimensionless ratio that saturates at unity.  \nHYPOTHESIS: A target cell will display half-maximal response when the blood hormone concentration E equals the dissociation constant Kd.  \nVERIFICATION: Units check—both E and Kd are in concentration, so E/Kd is dimensionless and equals 1 at half-saturation.  \nCONCLUSION: Blood concentration E sets a threshold at Kd for half-maximal receptor occupancy.", "rejected": "A target cell will display half-maximal response when the blood hormone concentration E equals the dissociation constant Kd plus one receptor.", "E_acc": 0.4795701205730438, "C_acc": 0.2368968427181244, "G_acc": 0.5820838569530419, "D_acc": 0.7391279675066471, "H_acc": 0.18034464120864868, "Q_acc": 0.6426995683993612, "E_rej": 0.43602240085601807, "C_rej": 0.2751328647136688, "G_rej": 0.5901831737719476, "D_rej": 0.8120600283145905, "H_rej": 0.18793997168540955, "Q_rej": 0.6374347905628384, "Delta_Q": 0.005264777836522794, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Meiotic recombination framed as a source of structured variation: hypotheses on biased gene conversion and local adaptation.", "ancestors": ["[Definition] Meiotic recombination is a process generating new allele combinations.", "[Definition] Gene conversion is a recombination outcome altering allele proportions.", "[Variable] k measures conversion bias strength.", "[Constraint] k must exceed 0 for biased conversion.", "[Limit] Conversion bias cannot exceed 100% within a segment.", "[Definition] Adaptive loci are regions with allele frequency shifts.", "[Law] Biased conversion raises adaptive allele frequency.", "[Constraint] k must exceed selection coefficient for fixation."]}, "accepted": "<derivation sentences>\nBiased conversion requires k > 0 and k > selection coefficient for fixation.  Within a 100% segment limit, adaptive allele frequency rises under biased conversion.  Combining these constraints yields the threshold condition for fixation.\n\nHYPOTHESIS: Adaptive allele frequency fixation occurs only when conversion bias strength k exceeds the selection coefficient within the segment.\nVERIFICATION: Units dimensionless; regime holds for 0 < k ≤ 1.\nCONCLUSION: Segment-level biased conversion drives adaptive fixation.", "rejected": "Adaptive allele frequency fixation occurs only when conversion bias strength k exceeds the selection coefficient beyond the 100% segment limit.", "E_acc": 0.48553580045700073, "C_acc": 0.2744677662849426, "G_acc": 0.5541610192740336, "D_acc": 0.700015743396112, "H_acc": 0.21443280577659607, "Q_acc": 0.6201592588364813, "E_rej": 0.5084987878799438, "C_rej": 0.18767137825489044, "G_rej": 0.5261580715014134, "D_rej": 0.7689094543457031, "H_rej": 0.23109054565429688, "Q_rej": 0.6509198113169987, "Delta_Q": -0.030760552480517456, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Physical consequences of gravitational potential reference choices: hypotheses on energy barriers and bound-state classifications.", "ancestors": ["[Definition] Gravitational potential Φ at a point is the scalar field whose gradient equals the local gravitational field g.", "[Definition] Potential difference ΔΦ is the line integral ∫g·dr between two points.", "[Variable] The integration constant C sets the zero reference of Φ(C).", "[Limit] Adding a constant C to Φ changes no measurable mechanical path or force on any test mass.", "[Constraint] Bound states require total mechanical energy E = K + mΦ < 0 relative to the chosen reference C.", "[Definition] Binding energy B = –E is the positive quantity required to separate the system to the reference.", "[Constraint] Shifting Φ → Φ + ΔC scales all bound-state B values by mΔC.", "[Limit] Only potential differences ΔΦ appear in kinetic-plus-potential equations, so absolute B has no physical meaning without a fixed reference.", "[Constraint] Classification of a state as bound or unbound depends on the chosen reference value C through the sign of E."]}, "accepted": "Because only potential differences affect motion, any uniform shift Φ → Φ + ΔC rescales every bound-state energy by mΔC without altering measurable forces; demanding that the classification “bound” remain unchanged under such a shift imposes a fixed zero reference.\n\nHYPOTHESIS: A state is bound only if its specific mechanical energy ε = (K + mΦ)/m < 0 with Φ fixed at the universal convention Φ(∞) = 0.\n\nVERIFICATION: ε has units of J kg⁻¹, matching specific energy, and holds for any isolated two-body system.\n\nCONCLUSION: Binding classification becomes reference-independent by fixing Φ(∞) = 0.", "rejected": "A state is bound only if its specific mechanical energy ε = (K + mΦ)/m < 0 with Φ fixed at the universal convention Φ(∞) = 0.", "E_acc": 0.36005496978759766, "C_acc": 0.3057126998901367, "G_acc": 0.5355624957883265, "D_acc": 0.7613503783941269, "H_acc": 0.1815088465809822, "Q_acc": 0.5881056411366444, "E_rej": 0.1469847559928894, "C_rej": 0.4779641926288605, "G_rej": 0.5416126546915621, "D_rej": 0.7915977239608765, "H_rej": 0.20840227603912354, "Q_rej": 0.49430443639867006, "Delta_Q": 0.09380120473797438, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Definition] The angular momentum L of a point mass is r × p.", "[Law] For any system, dL/dt equals the net external torque τ_ext.", "[Definition] A subsystem is a part of a system enclosed by an imaginary boundary.", "[Definition] Internal torque τ_int is torque exerted by one subsystem on another inside the system.", "[Constraint] τ_int between two subsystems is equal in magnitude and opposite in direction.", "[Variable] Let L_i be the angular momentum of subsystem i.", "[Variable] Let τ_{ij} be the torque on subsystem i from subsystem j.", "[Constraint] The rate of change of L_i equals the sum of all external torques on i plus Σ_j τ_{ij}."]}, "accepted": "Summing the torque-balance law over all subsystems causes every internal-torque pair τ_{ij}+τ_{ji}=0 to cancel, leaving only external contributions.  \nHYPOTHESIS: The total angular momentum L_tot of the whole system changes strictly according to dL_tot/dt = Σ τ_ext, independent of any internal torques.  \nVERIFICATION: Both sides carry units kg·m²/s², valid for any inertial frame.  \nCONCLUSION: Internal torques produce zero net effect on overall rotation.", "rejected": "The total angular momentum L_tot evolves as if internal torques were independent of external torques.", "E_acc": 0.035447731614112854, "C_acc": 0.6011709570884705, "G_acc": 0.5187542163184844, "D_acc": 0.7453855909407139, "H_acc": 0.21883100271224976, "Q_acc": 0.42134498924715447, "E_rej": 0.0539725162088871, "C_rej": 0.516384482383728, "G_rej": 0.5353420112769527, "D_rej": 0.7883251011371613, "H_rej": 0.21167489886283875, "Q_rej": 0.4564807909824595, "Delta_Q": -0.035135801735305006, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Homeostatic control seen as multi-timescale feedback: hypotheses on robustness limits and failure modes under extreme perturbations.", "ancestors": ["[Definition] Homeostasis denotes any process maintaining internal steady state.", "[Definition] A feedback loop consists of sensor, controller, actuator exchanging information.", "[Variable] Let t1 denote sensor time constant.", "[Variable] Let t2 denote actuator time constant.", "[Constraint] Controller compares t1 and t2 to adjust signal.", "[Limit] Perturbation saturates actuator after |p| > pmax occurs.", "[Law] Feedback gain diminishes after saturation, given |p| > pmax.", "[Constraint] No loop recovers after gain tends to 0 for all future pmax reached.", "[Variable] Let p denote perturbation input size applied to system.", "[Limit] Perturbation grows without upper bound until gain reaches 0 value."]}, "accepted": "The premises define sensor time constant t1 and actuator time constant t2, with the controller adjusting signal based on their comparison. Feedback gain diminishes after actuator saturation, which occurs when perturbation |p| exceeds pmax. Once gain reaches zero, no recovery is possible. Deriving the boundary condition: gain vanishes at |p| = pmax, so the controller must maintain |p| ≤ pmax to preserve feedback.\n\nHYPOTHESIS: The controller must keep |p| ≤ pmax to prevent gain collapse, requiring t1/t2 ≤ 1 for stability.\n\nVERIFICATION: t1/t2 dimensionless ratio; inequality holds when |p| = pmax.\n\nCONCLUSION: Sensor faster than actuator ensures recovery before saturation.", "rejected": "The controller must keep |p| ≤ pmax to prevent gain collapse, requiring t1/t2 ≥ 2 for stability.", "E_acc": 0.43682315945625305, "C_acc": 0.31918954849243164, "G_acc": 0.5660660294815898, "D_acc": 0.7365594133734703, "H_acc": 0.24376483261585236, "Q_acc": 0.6033576434478163, "E_rej": 0.13345353305339813, "C_rej": 0.5165541172027588, "G_rej": 0.5908652656507911, "D_rej": 0.7867450416088104, "H_rej": 0.26656869798898697, "Q_rej": 0.4855904281284893, "Delta_Q": 0.11776721531932699, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Ecosystem energy flow and matter cycling in presence of anthropogenic forcing: hypotheses on tipping points and alternative stable states.", "ancestors": ["[Definition] Ecosystem energy flow is the transfer of chemical energy among trophic levels.", "[Law] The first law of thermodynamics states energy is conserved within any closed system.", "[Variable] Primary productivity P is the rate of energy entering the biotic system as chemical bonds.", "[Constraint] P is limited by incoming short-wave irradiance I, nutrients N, temperature T, and human harvest H.", "[Variable] Anthropogenic forcing F is the set of human-controlled flows subtracting energy or matter from the system.", "[Definition] An ecological tipping point is a threshold value x = x* beyond which P declines faster than F increases.", "[Limit] After tipping, the system reaches a new steady state where net primary productivity P' < P - F."]}, "accepted": "Derivation summary:  \nPremises define anthropogenic forcing F as human-controlled energy subtraction and primary productivity P as limited by harvest H. After tipping, net productivity P' < P – F. Combining these yields the threshold inequality P – F = P' at tipping, hence H must satisfy H ≥ P – P' to trigger decline.\n\nHYPOTHESIS: Anthropogenic harvest H triggers ecological tipping when H ≥ P – P', where P is pre-harvest productivity and P' is post-tipping steady-state productivity.  \nVERIFICATION: Units balance (energy per time); inequality holds at threshold x*.  \nCONCLUSION: Harvest must exceed P – P' to initiate collapse.", "rejected": "Anthropogenic harvest H triggers ecological tipping when P – P' ≥ H, where P is pre-harvest productivity and P' is post-tipping steady-state productivity.", "E_acc": 0.6415742039680481, "C_acc": 0.22459134459495544, "G_acc": 0.58377085684333, "D_acc": 0.7173648593681199, "H_acc": 0.2161552906036377, "Q_acc": 0.6861656064533497, "E_rej": 0.14651331305503845, "C_rej": 0.6793801784515381, "G_rej": 0.5583027953980491, "D_rej": 0.8204817175865173, "H_rej": 0.17951828241348267, "Q_rej": 0.465883032581769, "Delta_Q": 0.22028257387158068, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Meiotic recombination framed as a source of structured variation: hypotheses on biased gene conversion and local adaptation.", "ancestors": ["[Definition] Meiosis is a two-division process producing four haploid gametes from one diploid cell.", "[Definition] Recombination is the reciprocal exchange of DNA segments between homologous chromosomes during meiosis.", "[Definition] Gene conversion is a non-reciprocal transfer of sequence information from one allele to its homologous counterpart.", "[Variable] Let g be the length in base pairs of a converted tract.", "[Constraint] Biased gene conversion favors either GC or AT alleles, increasing their transmission probability above 0.5.", "[Definition] Local adaptation is the increased fitness of a genotype relative to local environmental conditions.", "[Variable] Let s be the selection coefficient quantifying fitness advantage of an allele in a given environment.", "[Constraint] Recombination rate r is the probability per base pair that a recombination event initiates during meiosis.", "[Definition] GC content is the fraction of guanine plus cytosine bases in a DNA sequence."]}, "accepted": "Biased gene conversion increases the transmission probability of GC alleles above 0.5, so the expected GC content of a recombining region rises with the product of the per-base recombination rate r and the conversion tract length g.  \nHYPOTHESIS: The GC content increment ΔGC in a genomic segment is bounded below by ΔGC ≥ 0.5 r g p, where p is the probability that a conversion event is GC-biased.  \nVERIFICATION: Dimensionless left side; right side (bp⁻¹)(bp)(dimensionless) = dimensionless; valid where r g ≪ 1.  \nCONCLUSION: Higher recombination rates necessarily increase local GC content when biased gene conversion operates.", "rejected": "The GC content increment ΔGC in a genomic segment is bounded below by ΔGC ≥ 2 r g p, where p is the probability that a conversion event is GC-biased.", "E_acc": 0.3347758948802948, "C_acc": 0.4079402685165405, "G_acc": 0.5688213849807653, "D_acc": 0.7563658775761724, "H_acc": 0.16251221299171448, "Q_acc": 0.5676309459729963, "E_rej": 0.1956717073917389, "C_rej": 0.6339133977890015, "G_rej": 0.5796514512039721, "D_rej": 0.8084268867969513, "H_rej": 0.1915731132030487, "Q_rej": 0.4903771889396012, "Delta_Q": 0.07725375703339515, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electrochemical energy conversion with material degradation: hypotheses about microscopic corrosion pathways and capacity fade mechanisms.", "ancestors": ["[Definition] q is the electric charge measured in coulombs.", "[Variable] ne is the number of electrons transferred per reaction event.", "[Variable] F is the Faraday constant with the fixed value 96485 C mol⁻¹.", "[Law] Corrosion current icorr equals dq dt⁻¹.", "[Definition] Corrosion rate vcorr is the change in material volume per unit time.", "[Constraint] vcorr is proportional to icorr F⁻¹ ne⁻¹.", "[Variable] Q is the electrode capacity measured in coulombs.", "[Limit] Material loss is the integral of vcorr over time."]}, "accepted": "The corrosion current icorr equals dq dt⁻¹, while corrosion rate vcorr is proportional to icorr F⁻¹ ne⁻¹. Integrating vcorr over time gives material loss, so total loss scales with Q F⁻¹ ne⁻¹.\n\nHYPOTHESIS: Total material loss is proportional to Q F⁻¹ ne⁻¹.\nVERIFICATION: Units check: Q F⁻¹ ne⁻¹ has units C (C mol⁻¹)⁻¹ = mol ne⁻¹, consistent with mole count.\nCONCLUSION: Material loss scales with electrode capacity per electron count.", "rejected": "Total material loss is independent of ne and scales only with Q F⁻¹.", "E_acc": 0.8335096836090088, "C_acc": 0.05694231018424034, "G_acc": 0.5290191371968831, "D_acc": 0.7465349465608597, "H_acc": 0.09133800864219666, "Q_acc": 0.7846414589331835, "E_rej": 0.011520077474415302, "C_rej": 0.8648648858070374, "G_rej": 0.5134900467528496, "D_rej": 0.6658592969179153, "H_rej": 0.33414070308208466, "Q_rej": 0.33293884450686173, "Delta_Q": 0.45170261442632176, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chromatic energy redistribution in dispersive systems: hypotheses about spectral-dependent energy transport and recombination effects.", "ancestors": ["[Definition] Chromatic energy is the distribution of energy across frequency components in a dispersive system.", "[Variable] k is the wavenumber in a dispersive medium.", "[Law] Dispersion relates wavenumber k to frequency ω through dk/dω.", "[Constraint] Energy transport requires conservation of total chromatic energy E.", "[Limit] Energy redistribution cannot exceed the initial spectral energy Σ.", "[Variable] Energy at wavenumber k is E(k).", "[Constraint] Recombination conserves total chromatic energy during redistribution.", "[Limit] Redistributed energy spectrum cannot violate Σ = Σ E(k)."]}, "accepted": "Using the conservation of total chromatic energy E and the fixed spectral sum Σ, any redistribution among wavenumbers must satisfy an upper bound on the energy transferred to any single mode.\n\nHYPOTHESIS: The maximum energy that can be transferred into any wavenumber k during spectral redistribution is E(k) ≤ Σ.\n\nVERIFICATION: Units: both sides are energy; regime: holds for all dispersive systems conserving Σ.\n\nCONCLUSION: Spectral redistribution is globally capped by the initial total energy.", "rejected": "Using the conservation of total chromatic energy E and the fixed spectral sum Σ, any wavenumber must satisfy an upper bound on the energy transferred from a redistribution mode.", "E_acc": 0.6072379946708679, "C_acc": 0.16222162544727325, "G_acc": 0.5680057087447494, "D_acc": 0.8006747998297215, "H_acc": 0.16546696424484253, "Q_acc": 0.7069164786022156, "E_rej": 0.5917796492576599, "C_rej": 0.03698591887950897, "G_rej": 0.5618875960353762, "D_rej": 0.8399584293365479, "H_rej": 0.20005196332931519, "Q_rej": 0.7305007197428495, "Delta_Q": -0.023584241140633844, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reaction rates viewed through rare-event statistics and transition-path ensembles: hypotheses about mechanistic multiplicity and dynamic bottlenecks.", "ancestors": ["[Definition] A reaction rate r is the number of reactive events per unit time per unit volume.", "[Definition] A reactive event is a transition of a system from reactant basin R to product basin P on the potential-energy surface.", "[Definition] The transition-path ensemble is the collection of all dynamical trajectories that leave R, reach P, and do not revisit R in between.", "[Variable] Let k be the phenomenological rate coefficient of a unimolecular reaction.", "[Law] k equals the product of the equilibrium concentration in R and the mean frequency of transition paths divided by the partition function of R.", "[Definition] A dynamic bottleneck is a phase-space hypersurface whose crossing frequency sets the magnitude of k.", "[Constraint] The transition-path time distribution is exponential under steady-state conditions.", "[Limit] The rate k cannot exceed the inverse mean first-passage time of the slowest microscopic degree of freedom in the transition-path ensemble.", "[Definition] Mechanistic multiplicity exists when at least two distinct phase-space bottlenecks contribute comparably to the integral in the expression for k."]}, "accepted": "The premises define k as the product of equilibrium concentration in R and the mean frequency of transition paths divided by the partition function of R.  The transition-path time distribution is exponential under steady-state conditions, and k cannot exceed the inverse mean first-passage time of the slowest microscopic degree of freedom in the transition-path ensemble.  Mechanistic multiplicity exists when at least two distinct phase-space bottlenecks contribute comparably to the integral in the expression for k.  Combining these, the phenomenological rate coefficient k is bounded above by the inverse mean first-passage time of the slowest microscopic degree of freedom in the transition-path ensemble, and mechanistic multiplicity is detected when at least two distinct phase-space bottlenecks contribute comparably to the integral in the expression for k.\n\nHYPOTHESIS: The phenomenological rate coefficient k is bounded above by the inverse mean first-passage time of the slowest microscopic degree of freedom in the transition-path ensemble, and mechanistic multiplicity is detected when at least two distinct phase-space bottlenecks contribute comparably to the integral in the expression for k.\n\nVERIFICATION: Units consistent with inverse time; regime valid under steady-state exponential transition-path time distribution.\n\nCONCLUSION: The hypothesis quantifies the upper bound on k and the criterion for mechanistic multiplicity.", "rejected": "The phenomenological rate coefficient k is bounded above by the inverse mean first-passage time of the slowest microscopic degree of freedom in the transition-path ensemble, and mechanistic multiplicity is detected when at least two distinct phase-space bottlenecks contribute comparably to the integral in the expression for k.", "E_acc": 0.6792623400688171, "C_acc": 0.1689484715461731, "G_acc": 0.5075609179330058, "D_acc": 0.762534641793796, "H_acc": 0.12332874536514282, "Q_acc": 0.7116752451202567, "E_rej": 0.6969196200370789, "C_rej": 0.1065073311328888, "G_rej": 0.5262442509410903, "D_rej": 0.8443723022937775, "H_rej": 0.15562769770622253, "Q_rej": 0.7463349606608972, "Delta_Q": -0.03465971554064051, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["[Definition] Angular momentum L is the cross product r × p.", "[Definition] Angular velocity ω is the time rate of which a rigid body rotates.", "[Variable] r denotes instantaneous position vector from origin.", "[Law] L = r × p for any particle.", "[Law] Torque τ = dL/dt.", "[Constraint] In a rigid body, L = Iω holds where I is moment of inertia.", "[Limit] dL/dt = 0 when no torque acts.", "[Definition] Centripetal acceleration is a = ω × v for continuous deformable body.", "[Constraint] Centripetal acceleration a = ω × v depends on instantaneous velocity v relative to origin."]}, "accepted": "Derivation summary:\nFrom L = r × p and τ = dL/dt, zero torque implies dL/dt = 0, so L remains constant.  In a rigid body, L = Iω, so constant L forces constant ω, locking the angular velocity to its initial value.\n\nHYPOTHESIS: A rigid body under zero torque conserves its angular velocity vector exactly, maintaining fixed magnitude and direction indefinitely.\nVERIFICATION: Units check: L kg·m²/s, I kg·m², ω rad/s; ratio L/I yields consistent rad/s.\nCONCLUSION: Zero-torque rigid body preserves angular velocity vector completely.", "rejected": "A rigid body under zero torque conserves its angular velocity vector exactly, adding the scalar moment of inertia to the vector ω to keep it fixed.", "E_acc": 0.6732525825500488, "C_acc": 0.07246533036231995, "G_acc": 0.5432746495353058, "D_acc": 0.7288690830270449, "H_acc": 0.24945732206106186, "Q_acc": 0.7169657229989146, "E_rej": 0.012026824057102203, "C_rej": 0.7587838172912598, "G_rej": 0.5471029973996338, "D_rej": 0.7718756198883057, "H_rej": 0.22812438011169434, "Q_rej": 0.39283456920529725, "Delta_Q": 0.32413115379361734, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Molecular geometry determined by electronic correlation and stereoelectronic effects: hypotheses about non-VSEPR distortions in crowded systems.", "ancestors": ["[Definition] VSEPR predicts geometry from electron-pair repulsions.", "[Law] Coulomb repulsion energy decreases with distance.", "[Variable] r is the distance between electron pairs.", "[Constraint] r must be positive.", "[Limit] r cannot be zero.", "[Definition] Electronic correlation measures deviation from Hartree-Fock.", "[Variable] E is the electronic correlation energy.", "[Constraint] E must be finite.", "[Limit] E cannot be zero."]}, "accepted": "The premises define VSEPR geometry from electron-pair repulsions and Coulomb repulsion energy decreasing with distance r between pairs. Given r must be positive and non-zero, the minimal constraint is that r cannot vanish. Combining these, the VSEPR geometry minimizes repulsion by maximizing r under the constraint r > 0.\n\nHYPOTHESIS: The VSEPR geometry of a molecule is the configuration that maximizes the distance r between electron pairs under the constraint r > 0.\nVERIFICATION: r has units of length; r > 0 ensures non-zero distance.\nCONCLUSION: VSEPR geometry minimizes repulsion by maximizing r.", "rejected": "The VSEPR geometry minimizes r under the constraint that r > 0.", "E_acc": 0.8120204210281372, "C_acc": 0.05463613197207451, "G_acc": 0.5727345056948252, "D_acc": 0.7959071670969328, "H_acc": 0.1552928239107132, "Q_acc": 0.7908779520813066, "E_rej": 0.1483088731765747, "C_rej": 0.6274657249450684, "G_rej": 0.5635282442017342, "D_rej": 0.7852853238582611, "H_rej": 0.2147146761417389, "Q_rej": 0.46729076296178396, "Delta_Q": 0.32358718911952267, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mass–energy conversion in nuclear processes: hypotheses on partitioning released energy among kinetic, radiation, and internal excitations.", "ancestors": ["[Definition] Nuclear binding energy is the energy required to disassemble an atomic nucleus into its constituent nucleons.", "[Law] The total mass–energy E of a nuclear process equals the initial mass m multiplied by the squared speed of light c².", "[Variable] E is the released energy in a nuclear reaction.", "[Constraint] E must be distributed among kinetic, electromagnetic, and internal excitation forms.", "[Limit] No energy form can exceed the total released energy E.", "[Definition] Partitioning is the process of distributing released energy among kinetic, radiation, and internal excitations."]}, "accepted": "Partitioning distributes the released energy E among kinetic, electromagnetic, and internal excitations, each bounded by the total E.  Thus any single form cannot exceed the released energy.\n\nHYPOTHESIS: No kinetic, electromagnetic, or internal excitation exceeds the released energy E in a nuclear reaction.\nVERIFICATION: Units check: E is energy; each excitation is energy; inequality is dimensionless.\nCONCLUSION: Energy partitioning is bounded by total released energy.", "rejected": "The released energy E is bounded by any single kinetic, electromagnetic, or internal excitation in a nuclear reaction.", "E_acc": 0.8359798192977905, "C_acc": 0.060297489166259766, "G_acc": 0.5492443164112046, "D_acc": 0.7733539491891861, "H_acc": 0.13426744937896729, "Q_acc": 0.7898273561382667, "E_rej": 0.5770077705383301, "C_rej": 0.2874557673931122, "G_rej": 0.5462316470366204, "D_rej": 0.8658483028411865, "H_rej": 0.13415169715881348, "Q_rej": 0.6846119979425567, "Delta_Q": 0.10521535819571004, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Observable consequences of fields: hypotheses connecting gauge choices to measurable energy-momentum flow.", "ancestors": ["[Definition] A field assigns a quantity to every point in space.", "[Variable] A assigns quantity A(x) at position x.", "[Law] A field evolves following Euler-Lagrange equations minimizing action S.", "[Variable] S integrates Lagrangian L over spacetime.", "[Constraint] L must be invariant under gauge transformations.", "[Variable] A gauge transformation maps A(x) to A'(x) preserving L.", "[Limit] Observable quantities must be invariant under gauge transformations."]}, "accepted": "Gauge invariance of the Lagrangian and the requirement that observables be gauge-invariant together restrict the field A(x) to configurations whose gauge-equivalence classes are labeled by gauge-invariant quantities.  \nHYPOTHESIS: The only admissible observables constructed from A(x) are functions of the field strength F = ∂A – ∂A (and its derivatives), which is the minimal gauge-invariant quantity derivable from A(x).  \nVERIFICATION: F has units of (field variable)/(length)², matching the units required for a physical density integrated in the action.  \nCONCLUSION: Physical predictions depend only on the gauge-invariant field strength, not on A(x) directly.", "rejected": "The field strength F is equal to the Lagrangian L divided by the action S, yielding a dimensionless observable.", "E_acc": 0.3368801772594452, "C_acc": 0.31851160526275635, "G_acc": 0.5647942054201849, "D_acc": 0.74841583147645, "H_acc": 0.16466179490089417, "Q_acc": 0.5835375600145198, "E_rej": 0.30570605397224426, "C_rej": 0.3313693404197693, "G_rej": 0.5704127118224278, "D_rej": 0.7426839917898178, "H_rej": 0.2573160082101822, "Q_rej": 0.5623256880091504, "Delta_Q": 0.021211872005369448, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Isotopic mass effects on reaction energetics and zero-point energy: hypotheses about subtle kinetic discrimination and vibrational partitioning.", "ancestors": ["[Definition] Isotopes are atoms of the same element whose nuclei have equal atomic number Z but different mass number A.", "[Variable] A denotes the mass number of a nucleus.", "[Definition] Zero-point energy is the vibrational energy quantum at temperature T = 0 K.", "[Law] For quantum harmonic oscillator, zero-point energy equals ½hf where h is Planck constant f is classical frequency.", "[Definition] Reduced mass of oscillator with masses m1 and m2.", "[Variable] Reduced mass μ calculated by μ = (m1 m2)/(m1 + m2)", "[Law] Vibrational energy quantum hf equals.", "[Constraint] Isotope substitution changes m2.", "[Limit] Substitution changes m2."]}, "accepted": "Reduced-mass change shifts vibrational quantum; isotope swap alters m2, hence μ and hf both shift.  \nHYPOTHESIS: After isotope substitution, the vibrational quantum hf changes by the same factor as the reduced-mass ratio μ'/μ.  \nVERIFICATION: Units check: μ ratio dimensionless; hf ratio dimensionless; regime holds for diatomic harmonic oscillator.  \nCONCLUSION: Isotope substitution quantitatively retunes vibrational quantum via reduced-mass ratio.", "rejected": "After isotope substitution, the vibrational quantum hf changes by the amount μ' – μ.", "E_acc": 0.5238497257232666, "C_acc": 0.20274588465690613, "G_acc": 0.549090338179667, "D_acc": 0.8003619201481342, "H_acc": 0.1616264283657074, "Q_acc": 0.6703335496145884, "E_rej": 0.3706369400024414, "C_rej": 0.3194412589073181, "G_rej": 0.5436507271915616, "D_rej": 0.7975186705589294, "H_rej": 0.20248132944107056, "Q_rej": 0.59528857682526, "Delta_Q": 0.07504497278932831, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability and kinetics of bonds considered via electronic reorganization energy: hypotheses about bond rupture pathways and transient bonding motifs.", "ancestors": ["[Definition] Reorganization energy is the energy required to reorganize electronic structure rearranging electronic degrees of freedom.", "[Definition] Reorganization energy is denoted as λ.", "[Variable] λ is measured in J/mol.", "[Constraint] λ does not depend on reaction rate constants.", "[Law] λ is defined by λ = E_reorg / N_A where E_reorg is the energy required to reorganize electronic structure.", "[Variable] E_reorg is measured in J.", "[Definition] N_A is Avogadro's number.", "[Law] Bond rupture is defined by breaking bonds between atoms.", "[Constraint] Bond rupture requires input of energy.", "[Limit] Minimum energy required to break bonds is defined by bond dissociation energy."]}, "accepted": "The premises define reorganization energy λ = E_reorg / N_A and state that bond rupture requires an energy input at least equal to the bond dissociation energy. Because E_reorg is expressed per electronic rearrangement (in J) and λ is the molar equivalent, the minimum molar energy for bond rupture sets a lower bound on λ.\n\nHYPOTHESIS: λ ≥ (bond dissociation energy) / N_A for any process in which reorganization energy accompanies bond rupture.\n\nVERIFICATION: Units check—(J mol⁻¹) = (J) / (mol⁻¹).\n\nCONCLUSION: Reorganization energy is bounded below by the molar equivalent of the bond dissociation energy when bonds break.", "rejected": "Reorganization energy λ is independent of the bond dissociation energy for any process in which reorganization energy accompanies bond rupture.", "E_acc": 0.6261097192764282, "C_acc": 0.17654381692409515, "G_acc": 0.563428174573346, "D_acc": 0.8251970842480659, "H_acc": 0.11051052808761597, "Q_acc": 0.7191981513536303, "E_rej": 0.060429174453020096, "C_rej": 0.6865445971488953, "G_rej": 0.5661791281454498, "D_rej": 0.8771804571151733, "H_rej": 0.12281954288482666, "Q_rej": 0.45720979566976894, "Delta_Q": 0.26198835568386136, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Electromagnetic momentum and hidden mechanical momenta in charge-current systems: hypotheses about momentum balance in magnetized media.", "ancestors": ["[Definition] Momentum p is the product of mass m and velocity v.", "[Definition] Electromagnetic momentum Pem is ∫ε0E×B dV.", "[Variable] E denotes electric field, B magnetic field.", "[Law] Total momentum Ptot equals mechanical momentum Pmech plus electromagnetic momentum Pem.", "[Definition] Hidden mechanical momentum Phm arises from internal stress-energy in static current loops.", "[Constraint] In a stationary system dPtot/dt equals zero.", "[Limit] Standard Newtonian momentum p = mv neglects field momentum contributions."]}, "accepted": "Using the total-momentum law for a stationary system and the given definitions, the time-independence of Ptot forces any non-zero electromagnetic momentum to be balanced by an equal and opposite mechanical contribution.  \nHYPOTHESIS: In any static configuration, the mechanical momentum of the sources equals the negative of the electromagnetic momentum, Pmech = −Pem.  \nVERIFICATION: Both sides carry kg·m/s; valid for stationary systems where dPtot/dt = 0.  \nCONCLUSION: Field momentum is exactly cancelled by hidden mechanical momentum.", "rejected": "In any configuration, the mechanical momentum of the sources equals the negative of the electromagnetic momentum, Pmech = −Pem.", "E_acc": 0.24158817529678345, "C_acc": 0.43413710594177246, "G_acc": 0.5526448724558577, "D_acc": 0.7620584741234779, "H_acc": 0.23715905845165253, "Q_acc": 0.5248737948713824, "E_rej": 0.023928234353661537, "C_rej": 0.8379154801368713, "G_rej": 0.5686496352936956, "D_rej": 0.761284202337265, "H_rej": 0.23871579766273499, "Q_rej": 0.3817105620386429, "Delta_Q": 0.14316323283273952, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Satellite dynamics from an energy-momentum perspective: hypotheses about tidal dissipation, secular drift, and station-keeping energetics.", "ancestors": ["[Definition] Tidal torque transfers angular momentum between a satellite and its parent body.", "[Variable] T is the total mechanical energy of the satellite planet system.", "[Law] T = E + V where E is kinetic energy and V is gravitational potential energy.", "[Variable] k is the secular tidal drift rate.", "[Constraint] k must be non-negative.", "[Limit] T is bounded by the Roche limit of the parent body."]}, "accepted": "The tidal torque redistributes angular momentum between a satellite and its parent body, altering the mechanical energy T of the system. By the conservation law T = E + V, any secular drift in T must satisfy the tidal drift rate k ≥ 0, ensuring non-negative energy transfer. The Roche limit bounds T, preventing satellite disruption.\n\nHYPOTHESIS: The tidal drift rate k must satisfy k ≥ 0, and the mechanical energy T remains bounded by the Roche limit, ensuring stable angular momentum transfer.\n\nVERIFICATION: Units check: k (s⁻¹) ≥ 0, T (J) ≤ Roche limit (m).\n\nCONCLUSION: The hypothesis enforces non-negative tidal drift and energy stability, preventing satellite disruption.", "rejected": "The mechanical energy T determines the tidal drift rate k, reversing the dependence direction.", "E_acc": 0.8276883363723755, "C_acc": 0.07680729031562805, "G_acc": 0.5807286692517144, "D_acc": 0.8042085021734238, "H_acc": 0.11703908443450928, "Q_acc": 0.7982285686901637, "E_rej": 0.36575260758399963, "C_rej": 0.2903887927532196, "G_rej": 0.5621892465112198, "D_rej": 0.8333518803119659, "H_rej": 0.16664811968803406, "Q_rej": 0.6140914371203898, "Delta_Q": 0.18413713156977385, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Physical consequences of gravitational potential reference choices: hypotheses on energy barriers and bound-state classifications.", "ancestors": ["[Definition] Gravitational potential is defined by the work required to move a unit point mass from a reference point to a point in space.", "[Variable] The gravitational potential at a point is denoted by φ.", "[Limit] Gravitational potential has no absolute value and depends on the arbitrary choice of its zero reference.", "[Constraint] Two points at the same set of gravitational potentials are connected only by the path equivalence of physical laws.", "[Definition] Gravitational potential energy is defined as E = m * φ.", "[Variable] m is mass of the object in consideration.", "[Limit] Gravitational potential energy has no absolute value because φ has no absolute zero reference.", "[Constraint] Energy can only meaningfully measured between points or states, but gravitational potential energy depends on an arbitrary reference point."]}, "accepted": "Because gravitational potential energy E = mφ inherits the arbitrary zero of φ, only differences ΔE = mΔφ are physically meaningful.  \nHYPOTHESIS: For any two locations A and B, the measurable energy difference is ΔE = m(φ_B – φ_A) and is independent of the chosen zero reference.  \nVERIFICATION: Units check: [ΔE] = kg·J/kg = J, consistent with energy.  \nCONCLUSION: Use potential differences, not absolute values, to compute gravitational energy changes.", "rejected": "The energy difference is calculated by adding incompatible quantities, resulting in ΔE = m(φ_B – φ_A) + φ.", "E_acc": 0.3354523777961731, "C_acc": 0.415945440530777, "G_acc": 0.5417079258477315, "D_acc": 0.7379312813282013, "H_acc": 0.1832992136478424, "Q_acc": 0.5550445453030989, "E_rej": 0.06099608540534973, "C_rej": 0.24261730909347534, "G_rej": 0.53769961965736, "D_rej": 0.6827523410320282, "H_rej": 0.3172476589679718, "Q_rej": 0.48214099004399036, "Delta_Q": 0.07290355525910852, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reaction rates viewed through rare-event statistics and transition-path ensembles: hypotheses about mechanistic multiplicity and dynamic bottlenecks.", "ancestors": ["[Definition] A reaction rate is a probability per unit time that a reaction occurs."]}, "accepted": "The definition fixes reaction rate as a probability per unit time, so any reaction that occurs must satisfy this rate.  Therefore the reaction rate is bounded below by zero and above by one per unit time.\n\nHYPOTHESIS: A reaction rate is bounded between 0 and 1 per unit time.\nVERIFICATION: Units check: probability per unit time is dimensionless and time⁻¹.\nCONCLUSION: Reaction rate is a dimensionless probability per unit time.", "rejected": "A reaction rate is bounded between 0 and 1 per unit probability.", "E_acc": 0.8115947842597961, "C_acc": 0.05882512405514717, "G_acc": 0.6059583509340882, "D_acc": 0.8377548426389694, "H_acc": 0.15344902873039246, "Q_acc": 0.8051111463084816, "E_rej": 0.02699383907020092, "C_rej": 0.2173708826303482, "G_rej": 0.6097589423879981, "D_rej": 0.8581625819206238, "H_rej": 0.14183741807937622, "Q_rej": 0.5440245382487775, "Delta_Q": 0.2610866080597041, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-function delocalization and measurement-induced energy localization: hypotheses on measurement back-action and energy cost.", "ancestors": ["[Definition] A wavefunction is a mathematical function that contains probability amplitudes for all observable states of a quantum system.", "[Definition] Measurement is an interaction that collapses a wavefunction into one eigenstate.", "[Definition] Energy eigenstate is a wavefunction with definite energy value.", "[Limit] The act of measurement irreversibly converts a wavefunction from coherent superposition into definite eigenstate.", "[Constraint] Measurement cannot leave coherent superposition of energy intact.", "[Variable] T is interaction time between quantum system and measurement device.", "[Constraint] Interaction time determines whether measurement preserves or fragments wavefunction.", "[Constraint] Measurement back-action exists as unavoidable disturbance on conjugate observable.", "[Limit] Energy measurement error cannot violate uncertainty of conjugate observable.", "[Constraint] Continuous measurement of position forces momentum to evolve deterministically."]}, "accepted": "Interaction time T divides collapse from preservation; conjugate observable uncertainty enforces momentum evolution under position measurement.\n\nHYPOTHESIS: Continuous position measurement collapses momentum uncertainty to Δp ≥ ℏ/2Δx, forcing deterministic evolution.\nVERIFICATION: Units check: ℏ/Δx has kg·m/s, consistent with momentum.\nCONCLUSION: Position measurement deterministically drives momentum evolution.", "rejected": "Interaction time T divides collapse from preservation; conjugate observable uncertainty lets position measurement leave coherent superposition intact.", "E_acc": 0.7967974543571472, "C_acc": 0.05685923993587494, "G_acc": 0.54426078342658, "D_acc": 0.6963716484606266, "H_acc": 0.27139991521835327, "Q_acc": 0.7486538831755752, "E_rej": 0.13688339293003082, "C_rej": 0.6615033149719238, "G_rej": 0.5564864678308368, "D_rej": 0.781731367111206, "H_rej": 0.21826863288879395, "Q_rej": 0.45458105858415365, "Delta_Q": 0.2940728245914216, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Non-equilibrium steady states and detailed-balance breaking in driven chemical networks: hypotheses on emergent fluxes and cycle affinities.", "ancestors": ["[Definition] A steady state is a condition where system variables remain constant over time.", "[Variable] E denotes the concentration of any chemical species.", "[Law] In steady states, dE/dt = 0 for all species.", "[Definition] Detailed balance requires forward and reverse fluxes equal for every elementary reaction.", "[Variable] J denotes net flux through any reaction pathway.", "[Limit] Detailed balance imposes J = 0 for all reactions.", "[Definition] Breaking detailed balance allows J ≠ 0 in steady states.", "[Constraint] Non-equilibrium steady states require detailed balance breaking."]}, "accepted": "Steady-state concentrations E are compatible with non-zero net fluxes J only when detailed balance is broken.  \nHYPOTHESIS: A non-equilibrium steady state with J > 0 requires the ratio of forward to reverse elementary rate constants to exceed unity by the finite amount needed to sustain the observed J while maintaining dE/dt = 0.  \nVERIFICATION: Dimensionless ratio; valid when system is held in steady state by external constraints.  \nCONCLUSION: Quantitative link between kinetic asymmetry and steady flux.", "rejected": "Steady-state concentrations E are compatible with non-zero net fluxes J while detailed balance remains unbroken.", "E_acc": 0.2856021225452423, "C_acc": 0.49217644333839417, "G_acc": 0.4979814018297475, "D_acc": 0.7942472919821739, "H_acc": 0.16152897477149963, "Q_acc": 0.5295381893811282, "E_rej": 0.009470018558204174, "C_rej": 0.9648513793945312, "G_rej": 0.49984084273455665, "D_rej": 0.7970905601978302, "H_rej": 0.2029094398021698, "Q_rej": 0.34896606629481536, "Delta_Q": 0.18057212308631282, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nucleic-acid structural dynamics controlling accessibility: hypotheses about transient conformations that modulate regulatory factor binding.", "ancestors": ["[Definition] Nucleic acid is a polymer of nucleotide units.", "[Definition] A nucleotide unit has a nitrogenous base, a sugar, and one phosphate group.", "[Definition] A nucleic acid conformation refers to its shape in 3D space.", "[Definition] Accessibility is how much something is exposed to outside.", "[Variable] A conformation is transient if its lifetime τ.", "[Constraint] Only one nucleotide type can bind at a single position.", "[Limit] Cannot exceed 100% of area.", "[Law] The binding energy E.", "[Variable] A nucleotide sequence.", "[Constraint] Must follow base-pair rules."]}, "accepted": "The premises define a nucleic acid as a polymer of nucleotides, each with a base, sugar, and phosphate, and impose the rule that only one nucleotide type can occupy a single position.  \nHYPOTHESIS: In any nucleic acid polymer, the fraction of positions occupied by a given nucleotide type equals the number of such nucleotides divided by the total length, and this fraction cannot exceed 1.  \nVERIFICATION: Dimensionless ratio, valid for any finite-length nucleic acid.  \nCONCLUSION: Upper-bound occupancy per position is 100%.", "rejected": "In any nucleic acid polymer, the fraction of positions occupied by a given nucleotide type equals the number of such nucleotides divided by the total length, and this fraction can exceed 1.", "E_acc": 0.7228822708129883, "C_acc": 0.12874653935432434, "G_acc": 0.5650116761098616, "D_acc": 0.7698041368275881, "H_acc": 0.15592309832572937, "Q_acc": 0.7424862261279487, "E_rej": 0.051536932587623596, "C_rej": 0.6861259341239929, "G_rej": 0.5738067872589454, "D_rej": 0.8428281843662262, "H_rej": 0.1571718156337738, "Q_rej": 0.44584570571314547, "Delta_Q": 0.2966405204148032, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-mediated energy transfer when the medium stores both kinetic and potential micro-energy: hypotheses separating local vs. transport contributions.", "ancestors": ["[Definition] A wave is a perturbation that transfers energy through a medium without permanent particle displacement.", "[Definition] Energy is the capacity to perform work.", "[Definition] Kinetic energy is energy of motion.", "[Definition] Potential energy is energy stored due to position.", "[Variable] E represents total energy.", "[Variable] K represents kinetic energy.", "[Variable] U represents potential energy.", "[Law] E = K + U.", "[Variable] w represents wave speed.", "[Constraint] Energy travels at speed w through medium."]}, "accepted": "Derivation summary:  \nA wave transfers energy at speed w through the medium. Total energy E equals kinetic K plus potential U. Energy travels without permanent particle displacement, so energy must be either kinetic or potential. Energy cannot be both kinetic and potential simultaneously. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both. Energy must be either kinetic or potential, not both", "rejected": "Energy must be either kinetic or potential, not both.", "E_acc": 0.5860136151313782, "C_acc": 0.18516166508197784, "G_acc": 0.6072946126971926, "D_acc": 0.8172386858929345, "H_acc": 0.23507429659366608, "Q_acc": 0.7001709815816767, "E_rej": 0.06853125244379044, "C_rej": 0.6685349941253662, "G_rej": 0.6379171338464532, "D_rej": 0.7748736143112183, "H_rej": 0.2814079821109772, "Q_rej": 0.44126972832850053, "Delta_Q": 0.25890125325317614, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Dispersion relation shifts across media and their effect on modal energy: hypotheses about frequency-dependent energy partitioning.", "ancestors": ["[Definition] A dispersion relation ω(k) connects angular frequency ω to wavevector k.", "[Variable] Phase velocity v_p equals ω divided by k.", "[Variable] Group velocity v_g equals the derivative dω/dk.", "[Definition] Modal energy E is the energy carried by a specific mode characterized by k and ω.", "[Law] In a linear medium E is proportional to v_g.", "[Limit] A medium boundary forces ω to remain continuous across it."]}, "accepted": "Derivation summary  \nThe continuity of ω across a boundary and the proportionality of modal energy to group velocity v_g together imply that any spatial variation of v_g must be compensated by a matching variation of E, while ω remains unchanged.\n\nHYPOTHESIS: At a linear medium boundary, the modal energy E satisfies the jump relation E₂/E₁ = v_g₂/v_g₁, where v_g₁ and v₂ are the group velocities on each side of the boundary and ω is continuous.\n\nVERIFICATION: Units check: both ratios are dimensionless; relation holds across any linear interface where ω is continuous.\n\nCONCLUSION: Boundary matching rule for energy and group velocity.", "rejected": "At a linear medium boundary, the continuity of ω across the interface is implied by the ratio E₂/E₁ equaling v_g₂/v_g₁.", "E_acc": 0.6026659607887268, "C_acc": 0.17575466632843018, "G_acc": 0.5680347650195472, "D_acc": 0.7259039938449859, "H_acc": 0.2519795671105385, "Q_acc": 0.6792386500327848, "E_rej": 0.42126771807670593, "C_rej": 0.1634736806154251, "G_rej": 0.546118997503072, "D_rej": 0.6919048875570297, "H_rej": 0.3080951124429703, "Q_rej": 0.6104808450676501, "Delta_Q": 0.06875780496513473, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Meiotic recombination framed as a source of structured variation: hypotheses on biased gene conversion and local adaptation.", "ancestors": ["[Definition] Meiosis is a cell division that halves chromosome number.", "[Definition] Recombination is physical exchange of DNA segments.", "[Definition] Gene conversion is non-reciprocal transfer of sequence.", "[Variable] B is the bias ratio of conversion to Mendelian segregation.", "[Constraint] B = 1 requires Mendelian segregation bias.", "[Limit] B cannot exceed the number of chromatids present.", "[Definition] Local adaptation is differential fitness at a locus.", "[Constraint] B > 1 increases allele frequency change rate.", "[Limit] B = N fixes allele in population after N generations."]}, "accepted": "Internal trace (not shown):\nvariables → cases → eliminate → derive → conclude\n\nDerivation summary:\nThe premises define B as a bias ratio and impose B = 1 for Mendelian segregation. B > 1 increases allele frequency change rate. B = N fixes allele in population after N generations. B cannot exceed the number of chromatids present. Combining these, B must be at least 1 and at most the number of chromatids present. B = 1 is the threshold for Mendelian segregation bias. B > 1 increases allele frequency change rate. B = N fixes allele in population after N generations. B cannot exceed the number of chromatids present. B must be at least 1 and at most the number of chromatids present. B = 1 is the threshold for Mendelian segregation bias.\n\nHYPOTHESIS: B = 1 is the threshold for Mendelian segregation bias.\nVERIFICATION: B = 1 is the threshold for Mendelian segregation bias.\nCONCLUSION: B = 1 is the threshold for Mendelian segregation bias.", "rejected": "Mendelian segregation bias is the threshold for B = 1.", "E_acc": 0.6850454807281494, "C_acc": 0.16641667485237122, "G_acc": 0.5731138938572258, "D_acc": 0.7095295120688045, "H_acc": 0.3932611048221588, "Q_acc": 0.6894328799509607, "E_rej": 0.6249595284461975, "C_rej": 0.16948330402374268, "G_rej": 0.5847868060227484, "D_rej": 0.7274228632450104, "H_rej": 0.2725771367549896, "Q_rej": 0.6887754179071636, "Delta_Q": 0.0006574620437971301, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Momentum conservation in systems with non-conservative interactions: when and how momentum exchange with substrates or fields can be modeled causally.", "ancestors": ["[Definition] Linear momentum p of a particle is the product p = mv of its mass and velocity.", "[Law] For an isolated two-particle system, the sum p₁ + p₂ is time-independent.", "[Definition] A system is isolated if no external force acts on any constituent.", "[Constraint] An isolated system conserves its total linear momentum.", "[Definition] A non-conservative interaction dissipates mechanical energy within the system boundary.", "[Variable] Define F_ext as the net force exerted on a subsystem by degrees of freedom outside that boundary.", "[Law] The momentum increment dp of a subsystem in dt equals F_ext dt.", "[Limit] For a subsystem embedded in a substrate, exact isolation is impossible because electromagnetic and gravitational coupling to the substrate is non-zero."]}, "accepted": "Derivation summary:  \nThe premises define an isolated two-particle system whose total linear momentum is conserved, and note that exact isolation is impossible due to substrate coupling.  Introduce a subsystem boundary and the net external force F_ext.  The momentum increment dp equals F_ext dt, so the total momentum is conserved only if F_ext = 0.  Because electromagnetic and gravitational coupling to the substrate is non-zero, F_ext never vanishes exactly.  Hence the total momentum is never strictly conserved, but deviates by an amount proportional to F_ext.  Integrate over time to obtain the deviation ΔP = F_ext t.  For a measurable deviation, require F_ext t ≥ ΔP_min, the resolution threshold.  Thus the conservation law is valid only up to a resolution limit set by the external force.\n\nHYPOTHESIS:  For a subsystem embedded in a substrate, the total linear momentum is conserved only within a resolution limit set by the external force, and the deviation after time t is ΔP = F_ext t.  \nVERIFICATION:  Units: [F_ext t] = N·s = kg·m/s, identical to momentum units.  Regime: holds whenever electromagnetic and gravitational coupling to the substrate is non-zero.  \nCONCLUSION:  The conservation law is valid up to a resolution threshold determined by the external force.", "rejected": "For a subsystem embedded in a substrate, the total linear momentum deviation after time t is ΔP = F_ext t, valid universally without resolution limit.", "E_acc": 0.6551039218902588, "C_acc": 0.23860684037208557, "G_acc": 0.49601976678241044, "D_acc": 0.7119262121044673, "H_acc": 0.2857305407524109, "Q_acc": 0.661825950194795, "E_rej": 0.02660190314054489, "C_rej": 0.8020994663238525, "G_rej": 0.5262612840160728, "D_rej": 0.75929856300354, "H_rej": 0.24070143699645996, "Q_rej": 0.38060250338166957, "Delta_Q": 0.2812234468131254, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Ecosystem energy flow and matter cycling in presence of anthropogenic forcing: hypotheses on tipping points and alternative stable states.", "ancestors": ["[Definition] E is energy flow through an ecosystem per unit time.", "[Law] Energy flows one way from producers to consumers and cannot cycle.", "[Definition] M is matter cycling within ecosystem closed boundaries.", "[Variable] k is anthropogenic forcing intensity measured in watts per square meter.", "[Constraint] Tipping point occurs when response derivative dR/dk reaches zero.", "[Limit] Alternative stable state exists only if Jacobian eigenvalue sign changes."]}, "accepted": "The premises define energy flow E, matter cycling M, and anthropogenic forcing k, with tipping points governed by dR/dk=0 and eigenvalue sign changes. Combining these variables, the system reaches a tipping point when anthropogenic forcing k exceeds the threshold where the ecosystem's response derivative dR/dk becomes zero, indicating transition to an alternative stable state.\n\nHYPOTHESIS: Ecosystem tipping point occurs when anthropogenic forcing k reaches threshold k_critical such that dR/dk = 0 and Jacobian eigenvalue changes sign.\nVERIFICATION: Units check: k in W/m², R dimensionless, derivative dR/dk in m²/W.\nCONCLUSION: Anthropogenic forcing threshold triggers ecosystem state transition.\n\nINSUFFICIENT_INFORMATION — Premises lack quantitative values for k_critical or ecosystem parameters.", "rejected": "Ecosystem tipping point occurs when anthropogenic forcing k reaches threshold k_critical such that dR/dk = 0 and Jacobian eigenvalue changes sign, applicable to any ecosystem regardless of scale or boundary conditions.", "E_acc": 0.17456857860088348, "C_acc": 0.6439906358718872, "G_acc": 0.5389546294463798, "D_acc": 0.7627584959069887, "H_acc": 0.16126391291618347, "Q_acc": 0.467788680184943, "E_rej": 0.011006283573806286, "C_rej": 0.9479155540466309, "G_rej": 0.5385781319346279, "D_rej": 0.7816757261753082, "H_rej": 0.21832427382469177, "Q_rej": 0.3559371185023338, "Delta_Q": 0.11185156168260924, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nucleic-acid structural dynamics controlling accessibility: hypotheses about transient conformations that modulate regulatory factor binding.", "ancestors": ["[Definition] A nucleic acid is a polymer of ribose or deoxyribose linked by phosphodiester bonds.", "[Variable] k is the rate constant for local base-pair opening.", "[Law] Accessibility of a base to a ligand requires that its base-pair hydrogen bond is open.", "[Constraint] k is limited by the height of the hydrogen-bond free-energy barrier.", "[Limit] The maximum k compatible with duplex stability at 310 K is ~10^{−6} s^{−1}."]}, "accepted": "The premises define nucleic acid structure and link base-pair hydrogen-bond opening to ligand accessibility, while k is constrained by a free-energy barrier whose maximum value preserves duplex stability at 310 K.  Combining the Law and Limit yields an upper bound on the opening rate constant required to keep the duplex intact under physiological temperature.\n\nHYPOTHESIS: The rate constant for local base-pair opening in a nucleic acid duplex at 310 K cannot exceed 10^{−6} s^{−1} without compromising duplex stability.\n\nVERIFICATION: Units check: k has dimensions s^{−1}; inequality valid at 310 K.\n\nCONCLUSION: Duplex integrity sets a hard ceiling on spontaneous base-pair opening.", "rejected": "The rate constant for local base-pair opening follows the same free-energy barrier law at all temperatures from absolute zero to 310 K.", "E_acc": 0.6392779350280762, "C_acc": 0.12892845273017883, "G_acc": 0.508679955964908, "D_acc": 0.7478015050292015, "H_acc": 0.12607553601264954, "Q_acc": 0.7046864285599441, "E_rej": 0.24671439826488495, "C_rej": 0.3839338421821594, "G_rej": 0.5066450634622015, "D_rej": 0.7046680748462677, "H_rej": 0.2953319251537323, "Q_rej": 0.5099569861893543, "Delta_Q": 0.19472944237058987, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Enzymatic catalysis as modulation of transition-state energy distribution: hypotheses on dynamic coupling between active-site motion and barrier crossing.", "ancestors": ["[Definition] Enzyme is protein catalyst.", "[Definition] Substrate is reactant bound by enzyme.", "[Definition] Binding is reversible association of enzyme with substrate.", "[Definition] Active site is enzyme region contacting substrate.", "[Definition] Catalysis is rate enhancement by binding.", "[Definition] Binding lowers activation barrier.", "[Law] Binding reduces activation energy.", "[Variable] ΔG‡ is activation energy.", "[Limit] Binding cannot shift equilibrium."]}, "accepted": "The premises define enzyme catalysis as binding that lowers activation energy ΔG‡ without altering equilibrium.  Because binding cannot shift equilibrium, the energy drop ΔΔG‡ released must be positive and finite.\n\nHYPOTHESIS: The activation barrier ΔG‡ is reduced by an amount ΔΔG‡ that equals the binding free energy released, 0 < ΔΔG‡ ≤ ΔG‡.\nVERIFICATION: Units kJ mol⁻¹, regime holds for reversible binding.\nCONCLUSION: Binding quantitatively lowers activation energy.", "rejected": "The activation barrier ΔG‡ is reduced by an amount ΔΔG‡ that can exceed ΔG‡, so ΔΔG‡ > ΔG‡ is allowed.", "E_acc": 0.5111273527145386, "C_acc": 0.16721773147583008, "G_acc": 0.604271498741582, "D_acc": 0.7326894134283066, "H_acc": 0.1684645190834999, "Q_acc": 0.6704403900448233, "E_rej": 0.3428609371185303, "C_rej": 0.22908203303813934, "G_rej": 0.5451008230447769, "D_rej": 0.6591818481683731, "H_rej": 0.3408181518316269, "Q_rej": 0.5638165935873986, "Delta_Q": 0.1066237964574247, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nucleic-acid structural dynamics controlling accessibility: hypotheses about transient conformations that modulate regulatory factor binding.", "ancestors": ["[Definition] A nucleotide is the building block of nucleic acid.", "[Definition] A nucleic acid is a polymer of nucleotides A, U, C, G.", "[Variable] Let x be any single nucleotide in the sequence.", "[Law] Hydrogen bonds form between complementary bases.", "[Definition] A base pair is two complementary bases hydrogen-bonded.", "[Law] Two strands pair only when bases are complementary.", "[Definition] A double helix is two paired strands with base pairs stacked.", "[Constraint] The sequence x cannot change during folding."]}, "accepted": "A nucleotide sequence folds into a double helix only when every base in the strand finds a complementary partner in the opposing strand, so the strand must contain equal counts of A and U, and of C and G, for full pairing.\n\nHYPOTHESIS: A nucleotide strand folds into a double helix if and only if its counts of A equal U and counts of C equal G.\n\nVERIFICATION: Count A=U and C=G; units are base counts.\n\nCONCLUSION: Sequence parity is necessary and sufficient for folding.", "rejected": "A nucleotide strand folds into a double helix if and only its counts of A equal U and counts of C equal G.", "E_acc": 0.6696895956993103, "C_acc": 0.15795667469501495, "G_acc": 0.519549150038074, "D_acc": 0.7416683286428452, "H_acc": 0.22762414067983627, "Q_acc": 0.6987966254389902, "E_rej": 0.3454149067401886, "C_rej": 0.26950234174728394, "G_rej": 0.5467157185194083, "D_rej": 0.8065643608570099, "H_rej": 0.1934356391429901, "Q_rej": 0.6010364556335843, "Delta_Q": 0.09776016980540592, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Wave-function delocalization and measurement-induced energy localization: hypotheses on measurement back-action and energy cost.", "ancestors": ["[Definition] A wavefunction is a mathematical object encoding all spatial amplitudes of a quantum state.", "[Variable] k labels an integer index enumerating distinct spatial points in the wavefunction.", "[Constraint] k must not exceed the system volume divided by elementary cell volume.", "[Limit] The maximum k equals the total number of elementary cells in the volume.", "[Law] Schrödinger evolution preserves unit norm of the wavefunction over time.", "[Variable] E is the energy assigned to each spatial cell k by interaction with the wavefunction.", "[Constraint] Energy E at each k is finite and equals interaction integral at that cell."]}, "accepted": "The premises define a wavefunction over discrete spatial cells k, with each cell carrying finite interaction energy E. The total energy is the sum over all cells, and the number of cells is limited by the system volume divided by elementary cell volume.\n\nHYPOTHESIS: The total interaction energy of the wavefunction equals the sum of finite energies E at each cell k, with maximum number of cells given by system volume divided by elementary cell volume.\nVERIFICATION: Units check: energy sum has units of energy, cell count is dimensionless, consistent with premises.\nCONCLUSION: The wavefunction's total interaction energy is bounded by finite sum over discrete cells.", "rejected": "The sum of finite energies E at each cell k equals the total interaction energy, reversing the causal direction.", "E_acc": 0.8027051687240601, "C_acc": 0.08171339333057404, "G_acc": 0.5446915845386684, "D_acc": 0.7771336704492569, "H_acc": 0.24797597527503967, "Q_acc": 0.7640363254211844, "E_rej": 0.17638777196407318, "C_rej": 0.4381665885448456, "G_rej": 0.552150686387904, "D_rej": 0.6200079023838043, "H_rej": 0.3799920976161957, "Q_rej": 0.461715521872975, "Delta_Q": 0.3023208035482094, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Angular momentum conservation in coupled subsystems: hypotheses about internal torque transfer and emergent effective moments of inertia.", "ancestors": ["[Definition] Angular momentum is a vector quantity.", "[Definition] Angular momentum is conserved.", "[Definition] A subsystem is a part of a larger system.", "[Definition] Internal torque is torque within a system.", "[Variable] L is angular momentum.", "[Variable] T is torque.", "[Law] L is conserved.", "[Constraint] Internal torque does not change L.", "[Variable] I is effective moment of inertia.", "[Definition] I changes angular velocity."]}, "accepted": "Because internal torques cancel pairwise within a closed system, they cannot alter the system’s total angular momentum; therefore any observed change in L must be ascribed to external torque.\n\nHYPOTHESIS: A system’s total angular momentum remains constant if and only if the net external torque acting on it is zero.\n\nVERIFICATION: Units: [L] = kg·m²/s, [T] = kg·m²/s²; dL/dt = T ⇒ ΔL = 0 when T_ext = 0.\n\nCONCLUSION: External torque is the sole agent that can change a system’s angular momentum.", "rejected": "A system’s total angular momentum remains constant if and only if the net torque acting on it is zero, even though internal torques cancel pairwise and do not change L.", "E_acc": 0.38371700048446655, "C_acc": 0.32180672883987427, "G_acc": 0.5509340417726586, "D_acc": 0.7626053970307112, "H_acc": 0.2677513659000397, "Q_acc": 0.5866865055480351, "E_rej": 0.42346909642219543, "C_rej": 0.4081988036632538, "G_rej": 0.5447578210344849, "D_rej": 0.7865056991577148, "H_rej": 0.21349430084228516, "Q_rej": 0.5903042421482193, "Delta_Q": -0.0036177366001841627, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Bond polarity and mixed-covalent character driven by orbital hybridization: hypotheses connecting spectral signatures to fractional charge transfer.", "ancestors": ["[Definition] A polar covalent bond is a shared-electron interaction with unequal nuclear attraction on the bonding pair.", "[Variable] Δχ denotes the electronegativity difference between bonded atoms.", "[Law] Δχ > 0 shifts the bond electron density toward the more electronegative atom.", "[Definition] Hybridization is the linear combination of n, l-specified atomic orbitals into new ligand-directed orbitals.", "[Variable] λ counts the p (or higher-l) character in the hybrid forming the bond.", "[Constraint] Greater λ lowers the hybrid’s effective electronegativity, reducing Δχ locally.", "[Variable] q measures the fractional electronic charge transferred from the less to the more electronegative atom.", "[Limit] The ionic limit sets q = 1; the non-polar limit sets q = 0.", "[Definition] Bond polarity is quantified by q at equilibrium separation."]}, "accepted": "Hybridization p-character λ lowers the hybrid’s electronegativity, reducing the local electronegativity difference Δχ; hence the bond polarity q increases with the remaining Δχ after this reduction.  \nHYPOTHESIS: q = (Δχ – λ)/4, valid for 0 ≤ λ ≤ Δχ ≤ 4.  \nVERIFICATION: q dimensionless; units check: Δχ and λ both dimensionless, 4 dimensionless; regime 0–1 charge transfer.  \nCONCLUSION: Bond polarity q set by residual electronegativity difference after hybrid p-character penalty.", "rejected": "Bond polarity q set by residual electronegativity difference after hybrid p-character penalty.", "E_acc": 0.23507556319236755, "C_acc": 0.5271422266960144, "G_acc": 0.5105444322834956, "D_acc": 0.7578304894268513, "H_acc": 0.1336645781993866, "Q_acc": 0.5054027501406382, "E_rej": 0.29582223296165466, "C_rej": 0.2646175026893616, "G_rej": 0.4959442507242784, "D_rej": 0.8414209485054016, "H_rej": 0.1585790514945984, "Q_rej": 0.5874383040471002, "Delta_Q": -0.082035553906462, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Maxwellian field energy and propagation without a medium: hypotheses about energy localization and radiation reaction limits.", "ancestors": ["[Definition] The electric field E is the force per unit charge in vacuum.", "[Definition] The magnetic field B is the force per unit moving charge in vacuum.", "[Law] Maxwell’s equations couple E and B in vacuum without reference to a medium.", "[Variable] The electromagnetic energy density u is ε0(E·E + c²B·B)/2.", "[Constraint] Energy conservation requires ∂u/∂t + ∇·S = 0 with the Poynting vector S = E×B/μ0.", "[Limit] The radiation reaction force f on an accelerating charge introduces a recoil limit proportional to the rate of energy radiated."]}, "accepted": "Combining the energy density expression with the continuity equation and the radiation-reaction limit, the radiated power P = ∮S·dA must equal the rate of mechanical energy loss, so for any accelerating charge the reaction force sets an upper bound on the instantaneous radiated power.  \nHYPOTHESIS: The instantaneous radiated power P from an accelerating charge cannot exceed the rate at which the radiation-reaction force f does work, P ≤ f·v.  \nVERIFICATION: Both sides have units of energy per time (watts).  \nCONCLUSION: Radiation reaction enforces a power ceiling tied to mechanical work.", "rejected": "The instantaneous radiated power P and the radiation-reaction force f are independent variables, so either can be set without affecting the other.", "E_acc": 0.636337399482727, "C_acc": 0.1390736699104309, "G_acc": 0.5472136394819245, "D_acc": 0.7406505197286606, "H_acc": 0.28087545186281204, "Q_acc": 0.6925717725185677, "E_rej": 0.02994721382856369, "C_rej": 0.7245709896087646, "G_rej": 0.5500128198473249, "D_rej": 0.7307797223329544, "H_rej": 0.2692202776670456, "Q_rej": 0.3933064468961675, "Delta_Q": 0.2992653256224002, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Workless magnetic forces revisited as mediators of field energy redistribution: hypotheses connecting Lorentz-force trajectories to field energy traces.", "ancestors": ["[Definition] Magnetic field B is a vector field defined by the Lorentz force F = q v × B.", "[Law] Lorentz force on charge q is F = q (E + v × B).", "[Variable] Let P denote instantaneous mechanical power delivered by F.", "[Definition] P equals F · v.", "[Constraint] In pure magnetic field E = 0 so P = (q v × B) · v.", "[Law] Vector identity (v × B) · v ≡ 0.", "[Limit] Hence P ≡ 0 for any charge moving under sole magnetic force.", "[Definition] Field energy density uB is uB = B²/(2 μ₀).", "[Variable] Let U denote total field energy in volume V.", "[Definition] U is the integral of uB over V."]}, "accepted": "Because the Lorentz force in a pure magnetic field is always perpendicular to velocity, the mechanical power delivered to the charge is identically zero; consequently, any change in the particle’s kinetic energy must arise solely from work done by non-magnetic agents.\n\nHYPOTHESIS: A charged particle moving under the influence of a magnetic field alone cannot experience a change in kinetic energy.\n\nVERIFICATION: Units consistent (energy in joules, power in watts); holds for any q, v, B with E=0.\n\nCONCLUSION: Magnetic fields alter trajectory without changing speed.", "rejected": "Because the mechanical power delivered to the charge is identically zero, the Lorentz force in a pure magnetic field is always perpendicular to velocity.", "E_acc": 0.45664337277412415, "C_acc": 0.2562364339828491, "G_acc": 0.5409399766649585, "D_acc": 0.745560210198164, "H_acc": 0.3344513475894928, "Q_acc": 0.6096006276493426, "E_rej": 0.10834665596485138, "C_rej": 0.5946871042251587, "G_rej": 0.5285106801893562, "D_rej": 0.7603294551372528, "H_rej": 0.299588181078434, "Q_rej": 0.4413757849019021, "Delta_Q": 0.16822484274744054, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Isotopic mass effects on reaction energetics and zero-point energy: hypotheses about subtle kinetic discrimination and vibrational partitioning.", "ancestors": ["[Definition] Isotopes are atoms of the same element with different neutron counts.", "[Variable] Mass number A equals proton plus neutron counts.", "[Definition] Zero-point energy is the lowest vibrational energy in a bound molecule.", "[Variable] Vibrational frequency v equals (k/μ)^½ / 2π.", "[Constraint] Heavier atoms lower v.", "[Limit] Zero cannot vibrational energy reach.", "[Law] Energy shift ΔE equals h(v' – v)."]}, "accepted": "Derivation summary: Heavier atoms lower vibrational frequency v, and zero-point energy is the lowest vibrational energy in a bound molecule. Since heavier atoms lower v, the vibrational frequency decreases as mass increases. Zero-point energy cannot reach zero, so heavier atoms lower v but cannot reach zero.\n\nHYPOTHESIS: Heavier atoms lower vibrational frequency v, but zero-point energy cannot reach zero.\n\nVERIFICATION: Units check: v in Hz, mass in kg, zero-point energy in J.\n\nCONCLUSION: Heavier atoms lower v but zero-point energy cannot reach zero.", "rejected": "Heavier atoms lower vibrational frequency v, and zero-point energy is independent of atomic mass.", "E_acc": 0.8070128560066223, "C_acc": 0.09068121761083603, "G_acc": 0.5981310856877826, "D_acc": 0.8338582242528597, "H_acc": 0.11769330501556396, "Q_acc": 0.7985961447663915, "E_rej": 0.08067695051431656, "C_rej": 0.6950597763061523, "G_rej": 0.5918308945256285, "D_rej": 0.8815741539001465, "H_rej": 0.11842584609985352, "Q_rej": 0.4680295549682342, "Delta_Q": 0.33056658979815734, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Redox processes analyzed by Marcus theory extensions: hypotheses on solvent reorganization and coupled vibrational modes.", "ancestors": ["[Definition] A redox process is an electron transfer between a donor D and an acceptor A.", "[Variable] λ denotes the total reorganization energy accompanying the electron transfer.", "[Definition] λ is partitioned into solvent (λs) and inner-sphere vibrational (λi) components.", "[Law] Marcus rate k = (2π/ħ) |V|² (4πλk_BT)^{-½} exp[-(ΔG°+λ)²/4λk_BT].", "[Constraint] λs depends on solvent optical (εop) and static (εst) permittivity via λs = (Δe)² (1/εop – 1/εst) / 2r.", "[Variable] ω labels a coupled high-frequency vibrational mode that modulates D-A distance.", "[Limit] When ħω >> k_BT, the classical Marcus λ becomes inconsistent and quantization of ω is required."]}, "accepted": "The solvent reorganization energy λs scales with the inverse effective cavity radius r and the dielectric contrast (1/εop – 1/εst).  When the high-frequency D–A stretch ħω far exceeds thermal energy, the classical Marcus rate expression breaks down, so the total λ must be augmented by a quantum-corrected inner-sphere term λi,quant that replaces the classical λi.  \n\nHYPOTHESIS: For electron-transfer reactions with ħω > 5k_BT, the inner-sphere reorganization energy must be computed as λi,quant = ½ħω(ΔQ²/ħω) where ΔQ is the dimensionless displacement of the ω mode, yielding a corrected rate kquant = (2π/ħ)|V|²(4π(λs+λi,quant)k_BT)^{-½}exp[-(ΔG°+λs+λi,quant)²/4(λs+λi,quant)k_BT].\n\nVERIFICATION: Units of λi,quant are energy (J), consistent with λs and λ; valid in the non-adiabatic, high-frequency quantum regime ħω >> k_BT.\n\nCONCLUSION: Quantizing the high-frequency mode provides the necessary reorganization correction to restore rate predictions when classical Marcus theory fails.", "rejected": "The solvent reorganization energy λs is independent of the inner-sphere vibrational component λi.", "E_acc": 0.347487211227417, "C_acc": 0.27215850353240967, "G_acc": 0.5332474089227617, "D_acc": 0.7212999552488327, "H_acc": 0.2761639505624771, "Q_acc": 0.5731075404398144, "E_rej": 0.043999433517456055, "C_rej": 0.7366235852241516, "G_rej": 0.5430457186885178, "D_rej": 0.7324696779251099, "H_rej": 0.26753032207489014, "Q_rej": 0.39422516012564307, "Delta_Q": 0.1788823803141713, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy storage limits of capacitive systems under non-ideal dielectrics and breakdown precursors: hypotheses on microscopic polarization loss channels.", "ancestors": ["[Definition] A capacitor stores energy in electric potential between conductors.", "[Law] Energy density U scales with voltage V and capacitance C.", "[Variable] V is voltage between plates.", "[Variable] C is capacitance.", "[Definition] C is proportional to dielectric permittivity ε.", "[Definition] ε is permittivity of dielectric material.", "[Constraint] ε increases as polarizable material aligns.", "[Limit] Dielectric breakdown limits maximum V.", "[Limit] Breakdown reduces recoverable energy density."]}, "accepted": "Dielectric permittivity ε increases as polarizable material aligns under an applied field, raising capacitance C and thus energy density U. The maximum achievable ε is capped by dielectric breakdown, which limits voltage V and prevents further energy gain.\n\nHYPOTHESIS: The recoverable energy density of a capacitor is bounded above by the dielectric-breakdown threshold of the polarizable material.\nVERIFICATION: Units consistent (J m⁻³) and inequality holds when V ≤ V_breakdown.\nCONCLUSION: Breakdown sets the ultimate energy ceiling for any polarizable dielectric.", "rejected": "Dielectric permittivity ε increases independently of whether polarizable material aligns under an applied field, raising capacitance C and thus energy density U.", "E_acc": 0.7930466532707214, "C_acc": 0.07089004665613174, "G_acc": 0.5778037544805557, "D_acc": 0.7881138861179352, "H_acc": 0.13654035329818726, "Q_acc": 0.7832654794398697, "E_rej": 0.014980761334300041, "C_rej": 0.9112645983695984, "G_rej": 0.5526109609054402, "D_rej": 0.8465249836444855, "H_rej": 0.15347501635551453, "Q_rej": 0.386720996000804, "Delta_Q": 0.3965444834390657, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Induced currents studied through energetic opposition and topological constraints: hypotheses about optimal induction geometries.", "ancestors": ["[Definition] Faraday’s law states that the induced electromotive force ε in a closed loop equals the negative time rate of change of the magnetic flux Φ<sub>B</sub> through the loop: ε = ‑dΦ<sub>B</sub>/dt.", "[Law] Lenz’s law asserts that the induced current direction opposes the flux change producing it.", "[Definition] Self-inductance L is the proportionality factor between magnetic flux Φ and current I in the same circuit: Φ = L I.", "[Variable] Magnetic flux Φ<sub>B</sub> through a planar loop of vector area A is Φ<sub>B</sub> = B·A, where B is the uniform magnetic field vector.", "[Constraint] The line integral form of Faraday’s law requires a closed conducting path for finite induced current I.", "[Limit] Maximum induced emf magnitude in a rigid loop occurs when the field changes at the largest attainable dB/dt set by material saturation and thermal limits."]}, "accepted": "Combining Faraday’s law with the self-inductance definition gives ε = ‑d(LI)/dt = ‑L dI/dt for a rigid loop of fixed geometry, so any finite rate of change of current induces a back-emf proportional to L.  \nHYPOTHESIS: The magnitude of the self-induced back-emf in a closed loop equals |L dI/dt| and therefore sets a lower bound on the external voltage required to change the current.  \nVERIFICATION: Units check: [L dI/dt] = H·A·s⁻¹ = V, consistent with emf.  \nCONCLUSION: Self-inductance enforces a voltage threshold for current ramping.", "rejected": "The self-induced back-emf in a closed loop equals |L dI/dt| and is independent of the rate of change of the external magnetic flux through the loop.", "E_acc": 0.4192986488342285, "C_acc": 0.1941906213760376, "G_acc": 0.5768811613961589, "D_acc": 0.7546912077814341, "H_acc": 0.13026461005210876, "Q_acc": 0.6402394832053687, "E_rej": 0.22483371198177338, "C_rej": 0.2986583411693573, "G_rej": 0.5924476920627058, "D_rej": 0.8469067513942719, "H_rej": 0.15309324860572815, "Q_rej": 0.5802800091914833, "Delta_Q": 0.05995947401388546, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adaptation as navigations of rugged fitness landscapes with contingent historical constraints: hypotheses on predictability vs contingency.", "ancestors": ["[Definition] Fitness is a scalar value assigned to a genotype sequence.", "[Definition] A fitness landscape is a function mapping each genotype sequence to its fitness value.", "[Definition] A rugged fitness landscape contains multiple local maxima separated by lower-fitness regions.", "[Variable] The height difference between a local maximum and the nearest higher peak is denoted h.", "[Constraint] An evolving population can cross from one peak to a higher peak only if h is within the mutational range and selection threshold.", "[Limit] The record of prior substitutions fixes the current genotype and thus restricts accessible paths across the landscape."]}, "accepted": "The mutational range and selection threshold set an upper bound on the height difference h that a population can cross; any peak separated from a higher peak by h exceeding this bound is inaccessible under the fixed ancestral path.\n\nHYPOTHESIS: A population evolving on a rugged fitness landscape cannot reach any higher peak whose height difference h exceeds the mutational range multiplied by the selection threshold.\n\nVERIFICATION: h has units of fitness; mutational range × threshold has units of fitness; inequality h ≤ range × threshold defines the accessible regime.\n\nCONCLUSION: Evolutionary escape from a local peak requires h to stay within the compound threshold.", "rejected": "The mutational range and selection threshold set a lower bound on the height difference h that a population can cross; any peak separated from a higher peak by h below this bound is inaccessible under the fixed ancestral path.", "E_acc": 0.6246193051338196, "C_acc": 0.1987142711877823, "G_acc": 0.5665202332394463, "D_acc": 0.8230085745453835, "H_acc": 0.15228930115699768, "Q_acc": 0.7103197687438557, "E_rej": 0.501159131526947, "C_rej": 0.16713060438632965, "G_rej": 0.5488701350986958, "D_rej": 0.7698087394237518, "H_rej": 0.23019126057624817, "Q_rej": 0.6576382674276828, "Delta_Q": 0.052681501316172885, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Le Chatelier–style responses reframed for multi-variable driven equilibria: hypotheses about coupled control parameters and hysteresis.", "ancestors": ["[Definition] An equilibrium system is any set of reversible reactions sharing common species.", "[Variable] Let x denote the state vector of species concentrations.", "[Variable] Let u denote the control vector of adjustable parameters.", "[Constraint] dx/dt depends only on x and u.", "[Law] At equilibrium, dx/dt = 0 defines the equilibrium manifold.", "[Law] For each fixed u, the equilibrium manifold is locally unique.", "[Variable] Let f(x, u) = dx/dt.", "[Definition] A hysteresis loop is a closed curve in (x, u) space.", "[Constraint] Any hysteresis loop must satisfy df/dt = 0 everywhere.", "[Limit] No hysteresis can occur if f is globally monotonic in u."]}, "accepted": "The equilibrium manifold is locally unique for fixed u, and hysteresis loops require df/dt = 0 everywhere, so hysteresis can only occur where f is non-monotonic in u.\n\nHYPOTHESIS: A hysteresis loop exists only if the control vector u is in a region where f is non-monotonic in u.\n\nVERIFICATION: Units check: u is dimensionless; f is time⁻¹.\n\nCONCLUSION: Non-monotonicity in u is necessary for hysteresis.", "rejected": "A hysteresis loop exists only if df/dt is non-monotonic in u.", "E_acc": 0.7628552317619324, "C_acc": 0.0406036451458931, "G_acc": 0.507716327207163, "D_acc": 0.7954362593591213, "H_acc": 0.07567644119262695, "Q_acc": 0.7737987136933951, "E_rej": 0.4138490557670593, "C_rej": 0.36554938554763794, "G_rej": 0.5119858316029422, "D_rej": 0.8744252324104309, "H_rej": 0.1255747675895691, "Q_rej": 0.6157695756643079, "Delta_Q": 0.15802913802908725, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["[Definition] Angular momentum L = r × p.", "[Definition] Torque τ = dL/dt.", "[Law] Inertial reference frames keep τ = 0.", "[Definition] Centripetal acceleration a = v²/r.", "[Variable] v = ωr.", "[Law] a = ω²r.", "[Constraint] r must stay fixed for a.", "[Limit] τ = 0 only for rigid bodies.", "[Limit] Deformable bodies allow τ ≠ 0."]}, "accepted": "Using the centripetal acceleration a = ω²r and the angular momentum L = r × p with p = mv, the magnitude of angular momentum for circular motion is L = mvr = mωr².  \nHYPOTHESIS: A particle in uniform circular motion at angular speed ω and fixed radius r has angular momentum L = mωr².  \nVERIFICATION: Units kg·m²/s on both sides; valid for inertial frames with τ = 0.  \nCONCLUSION: Quantifies L for uniform circular motion.", "rejected": "A particle in uniform circular motion at angular speed ω and fixed radius r has angular momentum L = mωr.", "E_acc": 0.6435040831565857, "C_acc": 0.12743470072746277, "G_acc": 0.5874367289943621, "D_acc": 0.7830837294459343, "H_acc": 0.19465512037277222, "Q_acc": 0.7222028644522652, "E_rej": 0.06504987180233002, "C_rej": 0.7823547124862671, "G_rej": 0.5967558301053941, "D_rej": 0.7569384872913361, "H_rej": 0.24306151270866394, "Q_rej": 0.40947673125192524, "Delta_Q": 0.31272613320034, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Topology-dependent current partitioning under dynamic boundary conditions: hypotheses on metastable current paths and energy bottlenecks.", "ancestors": ["[Definition] Current is charge flow per time.", "[Variable] I denotes current.", "[Variable] t denotes time.", "[Constraint] Charge is conserved.", "[Definition] Topology encodes connectedness.", "[Law] Metastable paths persist transiently.", "[Variable] E denotes energy.", "[Limit] Energy is finite."]}, "accepted": "Charge conservation and finite energy bound the charge that can be displaced in any interval.  \nHYPOTHESIS: The net charge ΔQ transported through a cross-section during time Δt satisfies |ΔQ| ≤ E_max Δt / V_min, where E_max is the total available energy and V_min is the smallest non-zero potential difference encountered.  \nVERIFICATION: Units check: [E]/[V] = J/V = C, so RHS has units of charge.  \nCONCLUSION: Energy budget sets a strict upper limit on transported charge.", "rejected": "The net charge ΔQ transported through a cross-section during time Δt satisfies ΔQ = E_max + V_min Δt, where E_max is the total available energy and V_min is the smallest non-zero potential difference encountered.", "E_acc": 0.2190553843975067, "C_acc": 0.4852314293384552, "G_acc": 0.5447921718587168, "D_acc": 0.6962100192904472, "H_acc": 0.2949120104312897, "Q_acc": 0.48737956663826476, "E_rej": 0.379591703414917, "C_rej": 0.30782607197761536, "G_rej": 0.5484185671666637, "D_rej": 0.7110113054513931, "H_rej": 0.2889886945486069, "Q_rej": 0.5752994016977028, "Delta_Q": -0.08791983505943801, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] The transmission coefficient κ is the probability that a system crossing the transition state proceeds to product without recrossing.", "[Variable] Let k be the elementary rate constant for a reaction step.", "[Law] k = κ ν where ν is the effective frequency of attempts on the transition state.", "[Definition] A catalyst is a species that accelerates a reaction without being consumed.", "[Constraint] A catalyst accelerates by increasing k while temperature T and reactant energies remain fixed.", "[Law] Increasing k at fixed T requires increasing κ or ν.", "[Definition] Entropic control denotes dominance of ΔS‡ over ΔH‡ in determining κ.", "[Definition] Enthalpic control denotes dominance of ΔH‡ over ΔS‡ in determining κ."]}, "accepted": "Because a catalyst accelerates the reaction solely by increasing k while temperature and reactant energies stay fixed, and k = κ ν, the catalyst must raise κ, ν, or both.  Entropic control implies κ is governed mainly by ΔS‡, so any catalyst operating under this control must increase κ by increasing ΔS‡.  \n\nHYPOTHESIS: A catalyst under entropic control increases the transmission coefficient κ by raising the activation entropy ΔS‡ while leaving the activation enthalpy ΔH‡ effectively unchanged.  \n\nVERIFICATION: κ is dimensionless; ΔS‡ has entropy units (J K⁻¹ mol⁻¹); the statement is valid when ΔS‡ dominates κ.  \n\nCONCLUSION: Catalyst acceleration via entropy is achieved by enhancing activation entropy.", "rejected": "A catalyst under entropic control increases the transmission coefficient κ by raising the activation enthalpy ΔH‡ while leaving the activation entropy ΔS‡ effectively unchanged.", "E_acc": 0.1637042611837387, "C_acc": 0.6734989285469055, "G_acc": 0.52586474668351, "D_acc": 0.8248359620571136, "H_acc": 0.17798615992069244, "Q_acc": 0.46675301840179606, "E_rej": 0.044891972094774246, "C_rej": 0.881672739982605, "G_rej": 0.5094635549539817, "D_rej": 0.8646843135356903, "H_rej": 0.1353156864643097, "Q_rej": 0.39843104868341467, "Delta_Q": 0.06832196971838139, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A lipid bilayer is a two-molecule-thick fluid sheet composed mainly of amphipathic phospholipids.", "[Variable] D is the lateral diffusion coefficient of a lipid in the bilayer plane.", "[Constraint] D remains nonzero at physiological temperature T for unsaturated lipids.", "[Definition] A transient nanodomain is a 10–200 nm region of locally ordered lipids lasting milliseconds to seconds.", "[Law] Free energy F = E - TS sets the probability p ∝ e^(-F/kT) of forming such a nanodomain.", "[Limit] Below a threshold line tension λ_c the nanodomain disperses within τ ≈ R²/4D, where R is its radius."]}, "accepted": "The lateral diffusion coefficient D and the nanodomain lifetime τ are linked through the limit τ ≈ R²/4D.  Because D is nonzero for unsaturated lipids at physiological T, any nanodomain with radius R will disperse within a predictable time once line tension falls below λ_c.\n\nHYPOTHESIS: For unsaturated lipid bilayers at physiological temperature, a transient nanodomain of radius R disperses within τ = R²/4D seconds after line tension drops below λ_c.\n\nVERIFICATION: Units: [R²]/[D] = m²/(m² s⁻¹) = s, consistent with τ.\n\nCONCLUSION: Dispersal time is set by diffusion over the domain size.", "rejected": "For unsaturated lipid bilayers at physiological temperature, a transient nanodomain of radius R disperses within τ = R²/4D seconds after line tension rises above λ_c.", "E_acc": 0.5684889554977417, "C_acc": 0.11521212756633759, "G_acc": 0.4750440204516053, "D_acc": 0.7642235681414604, "H_acc": 0.08569496870040894, "Q_acc": 0.6867882819846274, "E_rej": 0.15587539970874786, "C_rej": 0.6750913262367249, "G_rej": 0.48813403217400264, "D_rej": 0.921202540397644, "H_rej": 0.07879745960235596, "Q_rej": 0.4857319232193732, "Delta_Q": 0.20105635876525418, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Catalysis reframed as lowering of transmission coefficients on the reaction coordinate: hypotheses about entropic vs enthalpic control in catalytic cycles.", "ancestors": ["[Definition] A catalyst is a species that accelerates a chemical reaction while remaining unconsumed.", "[Definition] The transmission coefficient κ quantifies the fraction of trajectories crossing a transition state that proceed to product.", "[Variable] κ is unitless and ranges from 0 to 1.", "[Law] The elementary rate constant k equals κνe^(−ΔG‡/RT), where ν is the barrier-crossing attempt frequency and ΔG‡ is the activation free energy.", "[Constraint] Catalyst action that lowers ΔG‡ without altering ν or T increases k.", "[Constraint] Catalyst action that raises κ without altering ΔG‡, ν, or T also increases k.", "[Definition] The activation free energy decomposes as ΔG‡ = ΔH‡ − TΔS‡.", "[Variable] ΔH‡ is the activation enthalpy with units of energy per mole.", "[Variable] ΔS‡ is the activation entropy with units of entropy per mole.", "[Limit] The maximum possible κ is 1, corresponding to every forward crossing reaching product."]}, "accepted": "Using the rate law k = κνe^(−ΔG‡/RT) and the decomposition ΔG‡ = ΔH‡ − TΔS‡, the entropic contribution to the barrier is isolated by writing k = κνe^(−ΔH‡/RT) e^(ΔS‡/R).  Because κ ≤ 1 and ν is fixed for a given reaction, the maximum achievable rate constant at temperature T is obtained when κ = 1 and ΔH‡ is minimized, yielding k_max = νe^(−ΔH‡/RT) e^(ΔS‡/R).\n\nHYPOTHESIS: For any catalytic pathway at fixed temperature, the elementary rate constant cannot exceed νe^(−ΔH‡/RT) e^(ΔS‡/R).\n\nVERIFICATION: Units cancel to give s⁻¹, consistent with a first-order rate constant.\n\nCONCLUSION: The ceiling rate is set solely by activation enthalpy and entropy once the attempt frequency is known.", "rejected": "For any catalytic pathway at fixed temperature, the elementary rate constant equals νe^(−ΔH‡/RT) e^(ΔS‡/R).", "E_acc": 0.3169911503791809, "C_acc": 0.34108951687812805, "G_acc": 0.515210498124361, "D_acc": 0.7358591735363007, "H_acc": 0.16024363040924072, "Q_acc": 0.561069013029337, "E_rej": 0.21505728363990784, "C_rej": 0.3897142708301544, "G_rej": 0.5319246663711965, "D_rej": 0.7957705557346344, "H_rej": 0.2042294442653656, "Q_rej": 0.5316904309205712, "Delta_Q": 0.02937858210876576, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mutational robustness and network-level redundancy: hypotheses on how distributed regulation masks deleterious changes.", "ancestors": ["[Definition] A gene is a hereditary unit located at a specific position on a chromosome.", "[Definition] A protein is a polymer of amino acids encoded by a gene.", "[Definition] A regulatory network is a graph whose vertices are genes and whose edges represent regulatory interactions.", "[Definition] Mutational robustness is the phenotypic invariance of a cellular system following genetic mutation.", "[Definition] Network redundancy is the presence of multiple independent paths from input to output in a regulatory network.", "[Definition] A deleterious mutation is a heritable change that reduces the Darwinian fitness of the phenotype.", "[Constraint] The in-degree of each gene in a regulatory network is ≤ k.", "[Limit] The probability that a deleterious mutation fixes in a population is ≤ 10^-3.", "[Law] The probability that a gene retains its expression after a deleterious mutation is 1 - p.", "[Law] The probability that a network retains its phenotype after a deleterious mutation is 1 - p."]}, "accepted": "Using the shared probability p that a gene’s expression survives a deleterious mutation, the network-level survival probability 1-p is identical, so the system’s mutational robustness equals the single-gene robustness.  \nHYPOTHESIS: The mutational robustness of a regulatory network equals the expression-retention probability 1-p of any one of its genes.  \nVERIFICATION: Both quantities are dimensionless probabilities bounded between 0 and 1.  \nCONCLUSION: Network robustness is directly set by the single-gene robustness parameter.", "rejected": "The expression-retention probability 1-p of any one gene equals the mutational robustness of the regulatory network.", "E_acc": 0.570458710193634, "C_acc": 0.1907927542924881, "G_acc": 0.5539357728557661, "D_acc": 0.7867207583039999, "H_acc": 0.1325431764125824, "Q_acc": 0.6878560507902877, "E_rej": 0.5265568494796753, "C_rej": 0.2397281527519226, "G_rej": 0.5684070535935462, "D_rej": 0.8620485365390778, "H_rej": 0.13795146346092224, "Q_rej": 0.6823173959739506, "Delta_Q": 0.005538654816337085, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Membrane dynamics and transient nano-domains as active regulators of transport: hypotheses on mesoscale sorting and selective permeability.", "ancestors": ["[Definition] A lipid membrane is a fluid matrix of amphiphiles.", "[Variable] A lipid has diffusion constant D ~ 10⁻¹² m² s⁻¹.", "[Law] Fick’s law gives flux J = - D∇c.", "[Constraint] Total lipid per unit area is fixed at ρ.", "[Limit] Resolution of optical microscopes > 250 nm.", "[Definition] A transient nanodomain is a cluster < 100 nm across.", "[Variable] Cluster lifetime τ ~ 10⁻³ s.", "[Constraint] Each cluster contains < 100 lipids."]}, "accepted": "Transient clusters smaller than 100 nm and lasting 10⁻³ s diffuse laterally less than 100 nm, so any optical microscope resolves them only as unresolved blurs.\n\nHYPOTHESIS: A lipid nanodomain < 100 nm across remains below optical resolution for its entire lifetime.\n\nVERIFICATION: 100 nm < 250 nm satisfies the resolution limit.\n\nCONCLUSION: Nanodomames stay unresolvable by optical microscopy.", "rejected": "A lipid nanodomain < 100 nm across drifts laterally more than 250 nm during its lifetime.", "E_acc": 0.5318917036056519, "C_acc": 0.2968674898147583, "G_acc": 0.49763793929014355, "D_acc": 0.7617921903729439, "H_acc": 0.1490456759929657, "Q_acc": 0.637175471452065, "E_rej": 0.0815974771976471, "C_rej": 0.6816979646682739, "G_rej": 0.49293870537076145, "D_rej": 0.8414573073387146, "H_rej": 0.1585426926612854, "Q_rej": 0.4391645835014061, "Delta_Q": 0.1980108879506589, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcriptional noise vs. fidelity trade-offs: hypotheses on how polymerase kinetics shape phenotypic variability.", "ancestors": ["[Definition] Transcriptional noise is the cell-to-cell heterogeneity in mRNA copy number per gene.", "[Variable] μ is the average mRNA count per cell for a gene.", "[Variable] η is the coefficient of variation of mRNA per gene.", "[Law] η = √(1/μ) for constitutive promoters.", "[Constraint] Noise reduces transcriptional fidelity.", "[Limit] η ≥ √(1/μ) sets the fidelity bound.", "[Variable] k is the effective polymerase initiation rate per gene.", "[Law] μ = k/γ where γ is mRNA decay rate."]}, "accepted": "Transcriptional noise sets a lower bound on polymerase initiation rate through the decay-limited relation μ = k/γ and the fidelity bound η ≥ √(1/μ).  Combining these yields k ≥ γ/η², so any constitutive promoter must initiate at least γ/η² transcripts per transcript to stay below the noise ceiling.\n\nHYPOTHESIS: The effective polymerase initiation rate k must satisfy k ≥ γ/η² for constitutive promoters.\n\nVERIFICATION: Units check: k (s⁻¹) = γ (s⁻¹) / η² (dimensionless) → s⁻¹ = s⁻1.\n\nCONCLUSION: Polymerase initiation rate must exceed γ/η² to keep transcriptional noise below fidelity bound.", "rejected": "Polymerase initiation rate exceeding γ/η² implies the fidelity bound η ≥ √(1/μ) rather than the converse.", "E_acc": 0.6662563681602478, "C_acc": 0.12375348806381226, "G_acc": 0.5405681789852679, "D_acc": 0.7922058284282685, "H_acc": 0.2324596792459488, "Q_acc": 0.7184350463934243, "E_rej": 0.3212752342224121, "C_rej": 0.17234747111797333, "G_rej": 0.5275622020708397, "D_rej": 0.7414311915636063, "H_rej": 0.25856880843639374, "Q_rej": 0.5898548739263788, "Delta_Q": 0.12858017246704545, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Orbital stability studied via energy surfaces and phase-space structure: hypotheses on resonance locking and dissipative capture.", "ancestors": ["[Definition] A Hamiltonian system conserves total mechanical energy E along trajectories.", "[Variable] E = T(​p​) + V(​q​) with T(​p​) as kinetic energy and V(​q​) as potential energy.", "[Definition] Energy surface S is the (2n−1)-dimensional manifold { (​q​,​p​) | E(​q​,​p​) = E₀ }.", "[Variable] Phase-space trajectory is a curve γ(​t​) = (​q​(​t​),​p​(​t​)) lying on S.", "[Constraint] Orbital stability is the property that γ(​t​) remains bounded for all time.", "[Definition] Resonance locking occurs when γ(​t​) is captured onto a resonant torus Tᵣ.", "[Variable] Dissipative capture happens when energy E decreases as dE/dt = −D with D > 0.", "[Constraint] Capture requires D exceed the Kolmogorov-Arnold-Moser (KAM) barrier strength.", "[Limit] For fixed D > 0, capture probability P"]}, "accepted": "Because capture requires D to exceed the KAM-barrier strength, the system must be driven far enough from the conservative limit for the energy to decrease monotonically; once this threshold is crossed the trajectory can no longer return to the energy surface and is irreversibly pulled onto the resonant torus.  \nHYPOTHESIS: Dissipative capture occurs only if the damping rate satisfies D > D_KAM, where D_KAM is the KAM-barrier strength, and thereafter the trajectory’s energy strictly decreases as dE/dt = −D.  \nVERIFICATION: Both sides have units of energy per time; inequality holds once D exceeds the prescribed threshold.  \nCONCLUSION: Capture is contingent on a minimal damping threshold and becomes irreversible once activated.", "rejected": "Reversible capture occurs only if the damping rate satisfies D > D_KAM, where D_KAM is the KAM-barrier strength, and thereafter the trajectory’s energy strictly decreases as dE/dt = −D.", "E_acc": 0.28547805547714233, "C_acc": 0.3293445110321045, "G_acc": 0.5263612044218462, "D_acc": 0.723928090184927, "H_acc": 0.23725256323814392, "Q_acc": 0.5461071170342621, "E_rej": 0.42173466086387634, "C_rej": 0.1676720380783081, "G_rej": 0.5182156938244589, "D_rej": 0.7149123251438141, "H_rej": 0.2850876748561859, "Q_rej": 0.6111028269515373, "Delta_Q": -0.06499570991727521, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Redox processes analyzed by Marcus theory extensions: hypotheses on solvent reorganization and coupled vibrational modes.", "ancestors": ["[Definition] A redox process is the transfer of one or more electrons from a donor to an acceptor.", "[Definition] The reorganization energy λ is the energy required to restructure the solvent and the redox species’ internal geometry from the equilibrium configuration of one redox state to that of the other.", "[Definition] The electronic coupling Hₑₗ is the Hamiltonian matrix element between the donor and acceptor electronic states.", "[Law] The Marcus electron-transfer rate constant k = (2π/ħ) |Hₑₗ|² (4πλk_BT)^(-1/2) exp[−(ΔG° + λ)² / 4λk_BT].", "[Variable] ΔG° is the standard reaction Gibbs energy for the redox step.", "[Constraint] The classical Marcus expression assumes λ = λᵢₙ + λₒᵤₜ, where λᵢₙ is the internal vibrational component and λₒᵤₜ is the outer-sphere solvent reorganization component.", "[Limit] The classical expression is valid only when characteristic vibrational frequencies ℏω ≫ k_BT.", "[Definition] The solvent reorganization energy λₒᵤₜ = (Δe)² (1/εₒ"]}, "accepted": "The solvent reorganization energy λ_out is constrained by the outer-sphere component in the vibrational regime where characteristic frequencies exceed thermal energy.  \nHYPOTHESIS: The outer-sphere solvent reorganization energy λ_out must satisfy λ_out ≤ λ − λ_in under the condition", "rejected": "The outer-sphere solvent reorganization energy λ_out can be applied to any vibrational frequency regime regardless of thermal energy.", "E_acc": 0.21926704049110413, "C_acc": 0.32999902963638306, "G_acc": 0.5175539293522888, "D_acc": 0.7342789024114609, "H_acc": 0.3470679745078087, "Q_acc": 0.5154400751220237, "E_rej": 0.08045259863138199, "C_rej": 0.48536381125450134, "G_rej": 0.5022882820339873, "D_rej": 0.6956362277269363, "H_rej": 0.30436377227306366, "Q_rej": 0.4362115420633927, "Delta_Q": 0.07922853305863103, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transcriptional noise vs. fidelity trade-offs: hypotheses on how polymerase kinetics shape phenotypic variability.", "ancestors": ["[Definition] Transcriptional noise is deviation from deterministic RNA output.", "[Law] Lower transcription fidelity reduces transcriptional noise amplitude.", "[Variable] Polymerase elongation velocity v measured in nucleotides per second.", "[Variable] Error probability p per nucleotide incorporated by polymerase.", "[Constraint] v and p cannot decrease simultaneously in any kinetic model.", "[Limit] Maximum v limited by cellular ribonucleotide concentration.", "[Definition] Phenotypic variability is variance in cellular protein level.", "[Law] Increasing v increases phenotypic variability through transcriptional noise."]}, "accepted": "<derivation sentences>\nThe constraint that v and p cannot decrease simultaneously couples velocity and error rate, while the law that increasing v increases phenotypic variability links velocity to noise amplitude.  Combining these, any kinetic model must trade between faster elongation and lower error rate, setting a bound on transcriptional noise amplitude.\n\nHYPOTHESIS: Polymerase elongation velocity v and error probability p satisfy v ≥ v_min(p) where v_min(p) increases monotonically with p, ensuring transcriptional noise amplitude remains bounded by cellular ribonucleotide concentration.\n\nVERIFICATION: Units check: v in nucleotides/s, p dimensionless; monotonic bound holds for all p in [0,1].\n\nCONCLUSION: The hypothesis quantifies the minimal velocity required to maintain noise amplitude within cellular limits.", "rejected": "Polymerase elongation velocity v and error probability p satisfy v ≤ v_max(p) where v_max(p) decreases monotonically with p, ensuring transcriptional noise amplitude remains bounded by cellular ribonucleotide concentration.", "E_acc": 0.5490050911903381, "C_acc": 0.0696510449051857, "G_acc": 0.5830540747847408, "D_acc": 0.7689109978576502, "H_acc": 0.08861694484949112, "Q_acc": 0.7123026384195934, "E_rej": 0.16581544280052185, "C_rej": 0.6205200552940369, "G_rej": 0.5998934302479029, "D_rej": 0.9039523601531982, "H_rej": 0.09604763984680176, "Q_rej": 0.5168050158768893, "Delta_Q": 0.19549762254270409, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Le Chatelier–style responses reframed for multi-variable driven equilibria: hypotheses about coupled control parameters and hysteresis.", "ancestors": ["[Definition] An equilibrium state is a condition where forward and reverse reaction rates are equal.", "[Definition] A control parameter is an externally adjustable variable influencing equilibrium.", "[Variable] T is temperature.", "[Variable] p is pressure.", "[Variable] c is concentration.", "[Constraint] At equilibrium, net reaction rate is zero.", "[Law] Equilibrium constant K varies with T.", "[Limit] One control parameter may be fixed externally.", "[Definition] Hysteresis is path-dependent state dependence.", "[Constraint] Two control parameters may couple nonlinearly."]}, "accepted": "Using the premises that equilibrium requires zero net rate and that K depends only on T, we derive a boundary on the allowable temperature shift when one control parameter is clamped.  \nHYPOTHESIS: If pressure is fixed externally, a finite change ΔT in temperature produces a threshold |ΔT| ≥ |T ln(K₂/K₁)| / |∂lnK/∂T| beyond which the original equilibrium composition becomes unattainable.  \nVERIFICATION: The inequality is dimensionless on both sides, valid for small ΔT near the initial equilibrium.  \nCONCLUSION: The system must switch to a new equilibrium composition once the temperature step exceeds the derived bound.", "rejected": "If pressure is fixed externally, a finite change ΔT in temperature produces a threshold |ΔT| ≥ |T ln(K₂/K₁)| / |∂lnK/∂T| beyond which the system retains the original equilibrium composition.", "E_acc": 0.314639687538147, "C_acc": 0.32931971549987793, "G_acc": 0.5646463367156684, "D_acc": 0.7736574746668339, "H_acc": 0.28361231088638306, "Q_acc": 0.5678274943493307, "E_rej": 0.2007327824831009, "C_rej": 0.3599652051925659, "G_rej": 0.552945019910112, "D_rej": 0.7578943967819214, "H_rej": 0.2421056032180786, "Q_rej": 0.5261841167230159, "Delta_Q": 0.04164337762631476, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rotational dynamics focusing on angular momentum redistribution and kinetic energy of shape change: hypotheses about non-rigid body spin-up/down.", "ancestors": ["[Definition] Angular momentum L of a body about a fixed axis is Σ rᵢ × pᵢ.", "[Definition] Moment of inertia I about that axis is Σ mᵢ rᵢ².", "[Law] For a rigid body L = I ω.", "[Variable] The radial position of mass element mᵢ is rᵢ.", "[Constraint] Internal forces cannot exert net torque about the body’s center of mass.", "[Law] dL/dt = τ_ext.", "[Variable] Shape change alters I(t) by changing each rᵢ(t).", "[Limit] If τ_ext = 0, dL/dt = 0."]}, "accepted": "With no external torque, angular momentum is conserved while the body’s moment of inertia changes as its shape evolves.  \nHYPOTHESIS: If τ_ext = 0, then any alteration of shape that decreases I forces the angular velocity to increase by the exact factor I_initial/I_final.  \nVERIFICATION: L = Iω has units kg·m²·s⁻¹ on both sides and holds for rigid-body rotation about a fixed axis.  \nCONCLUSION: Shape contraction raises spin speed to keep L constant.", "rejected": "If τ_ext = 0, then any alteration of shape that decreases I leaves the angular velocity unchanged because I and ω vary independently.", "E_acc": 0.159371018409729, "C_acc": 0.5099167823791504, "G_acc": 0.5267846349743195, "D_acc": 0.7495110146701336, "H_acc": 0.21657075732946396, "Q_acc": 0.47943000324303287, "E_rej": 0.010982434265315533, "C_rej": 0.8945148587226868, "G_rej": 0.5312874822411686, "D_rej": 0.7101621329784393, "H_rej": 0.28983786702156067, "Q_rej": 0.3436978948768229, "Delta_Q": 0.13573210836620997, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Bond polarity and mixed-covalent character driven by orbital hybridization: hypotheses connecting spectral signatures to fractional charge transfer.", "ancestors": ["[Definition] Electronegativity is χ.", "[Variable] Orbital hybridization energy is E_h.", "[Definition] Bond polarity is p.", "[Variable] Fractional charge transfer is q.", "[Constraint] p depends on q.", "[Definition] Mixed-covalent character is c.", "[Limit] q cannot exceed 1.", "[Definition] Spectral shift is Δ.", "[Law] E_h sets c."]}, "accepted": "Spectral shift Δ inherits the upper bound of fractional charge transfer q, which cannot exceed 1, so Δ ≤ 1.\n\nHYPOTHESIS: The spectral shift Δ is bounded above by 1 unit of fractional charge transfer.\nVERIFICATION: Units dimensionless; regime valid whenever q is measured in fractional units.\nCONCLUSION: Δ capped at 1 unit of fractional charge transfer.", "rejected": "The spectral shift Δ can exceed 1 unit of fractional charge transfer.", "E_acc": 0.6493518352508545, "C_acc": 0.1430242955684662, "G_acc": 0.5423026694334112, "D_acc": 0.7120391391217709, "H_acc": 0.3075799345970154, "Q_acc": 0.686311059712898, "E_rej": 0.2836405038833618, "C_rej": 0.5092297196388245, "G_rej": 0.5484341837145621, "D_rej": 0.6830004453659058, "H_rej": 0.31699955463409424, "Q_rej": 0.49783317758992784, "Delta_Q": 0.18847788212297012, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic flexibility under fluctuating oxygen or nutrient supply: hypotheses about pathway switching and flux rerouting.", "ancestors": ["[Definition] Metabolic flexibility is the capacity of a cell to switch among bioenergetic pathways in response to changes in oxygen or substrate availability.", "[Variable] Let P denote the probability that a cell utilizes oxidative phosphorylation in a given instant.", "[Constraint] 0 ≤ P ≤ 1.", "[Law] At constant oxygen, P is a monotonic function of extracellular glucose concentration G.", "[Limit] As G → 0, P → 1 for normoxic cells.", "[Limit] As oxygen tension O₂ → 0, P → 0 regardless of G."]}, "accepted": "At constant oxygen the premises fix P=1 when glucose vanishes and force P to fall as glucose rises, so a glucose threshold must exist where the cell switches from oxidative phosphorylation to glycolysis.  \nHYPOTHESIS: For normoxic cells there is a unique extracellular glucose concentration G* such that P(G*)=0.5, marking the metabolic-flexibility switch point between oxidative phosphorylation and glycolysis.  \nVERIFICATION: G* has units of mM and is defined under constant O₂>0.  \nCONCLUSION: G* quantifies the glucose set-point of metabolic flexibility.", "rejected": "For normoxic cells there is a unique extracellular glucose concentration G* such that P(G*)=1.5, marking the metabolic-flexibility switch point between oxidative phosphorylation and glycolysis.", "E_acc": 0.39554253220558167, "C_acc": 0.2898693084716797, "G_acc": 0.5392120580218034, "D_acc": 0.7801874410361052, "H_acc": 0.13055674731731415, "Q_acc": 0.6115131230471889, "E_rej": 0.1936662346124649, "C_rej": 0.4173640310764313, "G_rej": 0.5248406379832886, "D_rej": 0.8545202612876892, "H_rej": 0.1454797387123108, "Q_rej": 0.5359512701514177, "Delta_Q": 0.07556185289577111, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Device-level efficiency considered via entropy production and electromagnetic losses: hypotheses on microscopic dissipation mechanisms in resistive elements.", "ancestors": ["[Definition] Entropy is a state function measuring microscopic disorder.", "[Law] Net entropy of closed systems never decreases.", "[Variable] P denotes entropy production rate.", "[Constraint] P 0 during all processes.", "[Limit] P = 0 reversible limit only.", "[Law] Heat Q irreversibly dissipates resistive elements.", "[Constraint] P = Q/T electromagnetic losses"]}, "accepted": "Entropy production rate P equals heat Q divided by temperature T for electromagnetic losses, constrained by P 0 during all processes and P = 0 reversible limit only. Derive P = Q/T from premises with P 0 during all processes.\n\nHYPOTHESIS: Entropy production rate P equals heat Q divided by temperature T for electromagnetic losses, constrained by P 0 during all processes and P = 0 reversible limit only.\nVERIFICATION: Units check: P = Q/T holds dimensionally with P 0 during all processes and P = 0 reversible limit only.\nCONCLUSION: Entropy production rate P equals heat Q divided by temperature T for electromagnetic losses.", "rejected": "Entropy production rate P equals heat Q divided by temperature T for electromagnetic losses, constrained by P = 0 during all processes and P > 0 reversible limit only.", "E_acc": 0.7105689644813538, "C_acc": 0.12636059522628784, "G_acc": 0.5582158580509713, "D_acc": 0.8077936321496964, "H_acc": 0.17370176315307617, "Q_acc": 0.7437302920239744, "E_rej": 0.5355127453804016, "C_rej": 0.25750282406806946, "G_rej": 0.5691752167185768, "D_rej": 0.867622435092926, "H_rej": 0.13237756490707397, "Q_rej": 0.6832750326720998, "Delta_Q": 0.06045525935187468, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Refraction from conservation of photon momentum and phase velocity mismatch: hypotheses about anomalous dispersion regimes.", "ancestors": ["[Definition] Photon momentum p equals E/c.", "[Law] Conservation of total momentum holds.", "[Definition] Phase velocity v_p equals ω/k.", "[Variable] k is vacuum wavevector.", "[Variable] n is refractive index.", "[Law] n equals c/v_p.", "[Constraint] k must change when n changes.", "[Limit] Conservation constrains k change.", "[Definition] Conservation links k change to boundary."]}, "accepted": "Vacuum wavevector k is inversely proportional to phase velocity v_p, and the refractive index n equals c/v_p, so k scales linearly with n. Conservation of total momentum requires that any change in n across a boundary forces a compensating change in k, maintaining the momentum balance.  \n\nHYPOTHESIS: When light crosses a boundary into a medium of higher refractive index n, its vacuum wavevector k increases by the same factor as n, ensuring momentum conservation.  \n\nVERIFICATION: Units of k (m⁻¹) and n (dimensionless) are consistent; relation holds at any stationary interface between linear, non-magnetic dielectrics.  \n\nCONCLUSION: k must scale directly with n at the boundary to conserve momentum.", "rejected": "Vacuum wavevector k scales linearly with refractive index n, so conservation of total momentum requires that any change in n forces a compensating change in k.", "E_acc": 0.48187825083732605, "C_acc": 0.2493862360715866, "G_acc": 0.5367844091670122, "D_acc": 0.7536729276180267, "H_acc": 0.2198360413312912, "Q_acc": 0.6307940912607592, "E_rej": 0.48263996839523315, "C_rej": 0.22593145072460175, "G_rej": 0.5402427551453002, "D_rej": 0.8389013409614563, "H_rej": 0.20137332379817963, "Q_rej": 0.6552971872151829, "Delta_Q": -0.02450309595442368, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Partitioning work into macroscopic kinetic, internal, and configurational energy: hypotheses on dissipative pathways and irreversible entropy production.", "ancestors": ["[Definition] Energy is the capacity to do work.", "[Definition] Work is energy transferred by a force acting over a distance.", "[Definition] Work is partitioned into macroscopic kinetic, internal, and configurational energy.", "[Variable] W_k is macroscopic kinetic energy.", "[Variable] W_i is internal energy.", "[Variable] W_c is configurational energy.", "[Constraint] W_k + W_i + W_c = W for total work W.", "[Law] Energy is conserved in an isolated system.", "[Limit] Work partitioning is irreversible when dissipative pathways exist."]}, "accepted": "Partitioning total work into kinetic, internal, and configurational components yields W = W_k + W_i + W_c.  In an isolated system, energy conservation fixes W, so any dissipative pathway irreversibly sets W_i > 0, leaving W_k + W_c < W.\n\nHYPOTHESIS: In an isolated system, dissipative pathways irreversibly reduce the sum of macroscopic kinetic and configurational energy below the total work: W_k + W_c < W.\n\nVERIFICATION: Units check: W_k and W_c are energy, W is energy, inequality dimensionless.\n\nCONCLUSION: Dissipation irreversibly lowers kinetic and configurational energy.", "rejected": "Dissipative pathways irreversibly apply the partitioning relation W_k + W_c < W even in non-isolated systems.", "E_acc": 0.714849054813385, "C_acc": 0.12487724423408508, "G_acc": 0.586814276262885, "D_acc": 0.779220262169838, "H_acc": 0.1395634412765503, "Q_acc": 0.748729831156088, "E_rej": 0.24400627613067627, "C_rej": 0.525402307510376, "G_rej": 0.5792507597361691, "D_rej": 0.7565332055091858, "H_rej": 0.2434667944908142, "Q_rej": 0.5109315349371173, "Delta_Q": 0.23779829621897075, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Bond polarity and mixed-covalent character driven by orbital hybridization: hypotheses connecting spectral signatures to fractional charge transfer.", "ancestors": ["[Definition] Bond polarity is the partial charge separation along a covalent bond.", "[Variable] χ denotes electronegativity of an atom.", "[Law] Bond polarity increases with Δχ between two atoms.", "[Definition] Hybridization is linear combination of atomic orbitals.", "[Variable] λ measures hybrid orbital mixing ratio.", "[Constraint] Mixing increases when atomic orbital energies align.", "[Definition] Mixed-covalent character arises from hybridization.", "[Variable] q is fractional charge transferred.", "[Limit] Total charge transferred cannot exceed total charge along bond."]}, "accepted": "Bond polarity scales directly with the electronegativity difference Δχ, while the fractional charge transferred q is the observable signature of that polarity; because the total charge along the bond sets an upper bound, the transferred fraction is strictly limited by the same Δχ that drives the polarity.\n\nHYPOTHESIS: The fractional charge transferred q along a covalent bond satisfies q ≤ Δχ / 4.8, with equality approached only for the most polar single bonds.\n\nVERIFICATION: q and Δχ are both dimensionless; the inequality holds for typical organic bonds (e.g., C–F: Δχ ≈ 1.5, q ≈ 0.28).\n\nCONCLUSION: Electronegativity difference caps the charge separation measurable in any covalent bond.", "rejected": "Bond polarity scales directly with the electronegativity difference Δχ, while the fractional charge transferred q is the observable signature of that polarity; because the total charge along the bond sets an upper bound, the transferred fraction equals Δχ times the bond length in picometers.", "E_acc": 0.5163236856460571, "C_acc": 0.2334143966436386, "G_acc": 0.5196605204546358, "D_acc": 0.7763293907046318, "H_acc": 0.17411881685256958, "Q_acc": 0.6500003269116861, "E_rej": 0.11329092085361481, "C_rej": 0.17922867834568024, "G_rej": 0.5206084366363939, "D_rej": 0.7744153439998627, "H_rej": 0.22558465600013733, "Q_rej": 0.5345878311141861, "Delta_Q": 0.11541249579750001, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Device-level efficiency considered via entropy production and electromagnetic losses: hypotheses on microscopic dissipation mechanisms in resistive elements.", "ancestors": ["[Definition] Entropy is a state function S measuring microscopic disorder multiplicity of a system.", "[Definition] Dissipation is irreversible entropy production σ happening inside a physical element.", "[Variable] Let T denote the absolute temperature of a resistive element.", "[Variable] Let I be the current passing through the resistive element.", "[Law] Entropy production satisfies σ = I²R/T where R is the element resistance.", "[Constraint] Entropy production is always non-negative: σ ≥ 0.", "[Limit] Entropy production cannot be negative at any temperature.", "[Variable] Let P be the electromagnetic power loss inside the resistive element.", "[Law] Electromagnetic power loss equals P = I²R"]}, "accepted": "Electromagnetic power loss P = I²R and entropy production σ = I²R/T share the same numerator, so σ = P/T.  \nHYPOTHESIS: Entropy production in a resistive element equals the electromagnetic power loss divided by absolute temperature, σ = P/T.  \nVERIFICATION: Units check: P/T has (W/K) = (J·s⁻¹·K⁻¹), identical to entropy production.  \nCONCLUSION: Absolute temperature quantifies how efficiently dissipated power is converted into entropy.", "rejected": "Entropy production σ equals the electromagnetic power loss P multiplied by absolute temperature T, σ = P·T.", "E_acc": 0.5147817730903625, "C_acc": 0.24945203959941864, "G_acc": 0.5484403106966056, "D_acc": 0.8232954367995262, "H_acc": 0.1010352075099945, "Q_acc": 0.6687877527554521, "E_rej": 0.2738177478313446, "C_rej": 0.48948341608047485, "G_rej": 0.5616950654075481, "D_rej": 0.8732487857341766, "H_rej": 0.12675121426582336, "Q_rej": 0.5585622899350711, "Delta_Q": 0.11022546282038104, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Crystal lattice energetics in ionic solids with polarizability: hypotheses on many-body contributions to lattice energy beyond pairwise Coulomb.", "ancestors": ["[Definition] Lattice energy U is the internal energy change when 1 mol of ionic solid forms from gaseous ions at 0 K.", "[Definition] The Coulomb pairwise contribution E_coul sums q_i q_j / (4πε₀ r_ij) over all ion pairs i<j.", "[Variable] Let α be the electronic polarizability of an ion.", "[Definition] An induced dipole μ_ind equals α E_local where E_local is the electric field at the ion site from all other charges and dipoles.", "[Definition] The dipole–charge interaction energy reads −μ_ind·E_local/2.", "[Law] The total lattice energy U_tot equals E_coul plus all interaction energies involving induced dipoles.", "[Constraint] E_local depends on the instantaneous positions and induced dipoles of every other ion.", "[Variable] Let U_many denote the energy contribution beyond the pure Coulomb sum E_coul.", "[Definition] U_many is the difference U_tot − E_coul computed with full self-consistent μ_ind values.", "[Limit] U_many approaches zero as α approaches zero for every ion."]}, "accepted": "The induced-dipole energy per ion pair is obtained by inserting μ_ind = αE_local into −μ_ind·E_local/2 and summing over the lattice, giving U_many = −½ΣαE_local².  Because E_local scales with the bare Coulomb field E_coul, U_many is negative and proportional to α.\n\nHYPOTHESIS: The many-body polarization contribution lowers the total lattice energy by an amount |U_many| that scales linearly with the electronic polarizability α of the ions.\n\nVERIFICATION: Units check: α [C m² V⁻¹] × E² [V² m⁻²] → energy [J]; holds for any ionic crystal.\n\nCONCLUSION: Polarizability systematically deepens the lattice potential.", "rejected": "The many-body polarization contribution lowers the total lattice energy by an amount |U_many| that scales linearly with the square of the electronic polarizability α² of the ions.", "E_acc": 0.4257708191871643, "C_acc": 0.18254117667675018, "G_acc": 0.5326551809266675, "D_acc": 0.7903294205665589, "H_acc": 0.1091940701007843, "Q_acc": 0.644900523709366, "E_rej": 0.45558804273605347, "C_rej": 0.15731380879878998, "G_rej": 0.5465874306391925, "D_rej": 0.8484285175800323, "H_rej": 0.15157148241996765, "Q_rej": 0.6690596924629062, "Delta_Q": -0.024159168753540183, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Chromatic energy redistribution in dispersive systems: hypotheses about spectral-dependent energy transport and recombination effects.", "ancestors": ["Dispersion is the dependence of refractive index n on wavelength λ.", "Group velocity vg equals dω/dk.", "vg carries the energy flux density.", "Δvg across Δλ causes chromatic pulse broadening.", "Energy density U is proportional to |E|².", "|E|² redistributes spatially during broadening.", "Recombination occurs where carriers meet after separation.", "Meeting requires equal and opposite group velocities."]}, "accepted": "Because dispersion makes vg vary with λ, the pulse spreads until the fastest and slowest spectral components have separated by the transit length L; recombination demands that these components later meet, which occurs only if their group-velocity difference Δvg is exactly cancelled over the return path.  \nHYPOTHESIS: Chromatic recombination of a dispersed pulse occurs only if the path-length difference between the fastest and slowest wavelength components satisfies L = c Δt / Δn, where Δt is the initial temporal width and Δn is the refractive-index contrast across the spectrum.  \nVERIFICATION: Units check: [c Δt / Δn] = (m s⁻¹)(s)/(dimensionless) = m, consistent with length.  \nCONCLUSION: The pulse recompresses to its original duration when the geometric path length equals c Δt / Δn, setting the design length for dispersion-compensated systems.", "rejected": "Because dispersion makes vg vary with λ, the pulse spreads until the fastest and slowest spectral components have separated by the transit length L; recombination demands that these components later meet, which occurs only if their group-velocity difference Δvg is exactly doubled over the return path.", "E_acc": 0.44454142451286316, "C_acc": 0.26453718543052673, "G_acc": 0.5593225310440175, "D_acc": 0.7602947391569614, "H_acc": 0.1051548421382904, "Q_acc": 0.6338629600941204, "E_rej": 0.3249988853931427, "C_rej": 0.33940306305885315, "G_rej": 0.5934807334560901, "D_rej": 0.8835980296134949, "H_rej": 0.11640197038650513, "Q_rej": 0.6133946085814387, "Delta_Q": 0.02046835151268167, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Dispersion relation shifts across media and their effect on modal energy: hypotheses about frequency-dependent energy partitioning.", "ancestors": ["A wave in a medium has angular frequency ω and wavevector k.", "The functional relation ω(k) is the dispersion relation.", "The phase velocity is vₚ = ω/k.", "The group velocity is v_g = dω/dk.", "Modal energy E in a wave packet travels at the group velocity v_g.", "When ω(k) changes between media, v_g changes, altering the rate of energy transport E."]}, "accepted": "The dispersion relation ω(k) determines both the phase velocity vₚ = ω/k and the group velocity v_g = dω/dk.  \nBecause modal energy E travels at v_g, any spatial gradient in ω(k) produces a corresponding gradient in v_g, so energy flux ∝ v_g must develop a divergence that redistributes E.  \n\nHYPOTHESIS: In a medium where ω(k) varies spatially, the divergence of energy flux satisfies ∇·(v_g E) = –E ∂²ω/∂k∂x, forcing E to accumulate or deplete wherever the dispersion slope changes with position.  \n\nVERIFICATION: Units s⁻¹ on both sides; valid for slowly varying ω(k) over scales ≫ 2π/k.  \n\nCONCLUSION: Energy density E evolves as ∂E/∂t = –∇·(v_g E) = E ∂²ω/∂k∂x, predicting measurable energy pile-up or drain at dispersion-slope gradients.", "rejected": "Energy density E evolves as ∂E/∂t = –∇·(v_g E) = E ∂²ω/∂k∂x, predicting measurable energy pile-up or drain even where the dispersion slope changes abruptly on scales comparable to 2π/k.", "E_acc": 0.5688081383705139, "C_acc": 0.09438362717628479, "G_acc": 0.5538143450394273, "D_acc": 0.7532229959964752, "H_acc": 0.22543203085660934, "Q_acc": 0.6906299811974168, "E_rej": 0.31999316811561584, "C_rej": 0.1798456311225891, "G_rej": 0.53744234344922, "D_rej": 0.6776559799909592, "H_rej": 0.32234402000904083, "Q_rej": 0.5708140868972986, "Delta_Q": 0.11981589430011819, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stochastic decay processes framed as energy/entropy flows: hypotheses about microscale correlations that produce macroscopic rate laws.", "ancestors": ["Every microscopic system has states indexed by energy E.", "State multiplicity Ω(E) is the number of microstates with energy E.", "Boltzmann entropy is S = k ln Ω(E) with k being Boltzmann’s constant.", "An isolated system maximizes Ω(E) subject to fixed total energy.", "Coupling two subsystems allows energy to fluctuate between them.", "Energy flow redistributes Ω(E) toward the joint maximum.", "The macroscopic rate law dE/dt = –k(E – E_eq) emerges when Ω(E) is sharply peaked.", "Microscale energy correlations decay exponentially with characteristic time 1/k."]}, "accepted": "The premises link entropy S to multiplicity Ω(E) and show that energy exchange drives Ω(E) toward its joint maximum, with a first-order rate law governed by a decay constant k.  Because the rate law is valid only when Ω(E) is sharply peaked, the characteristic relaxation time τ = 1/k must satisfy τ ≪ Δt_meas, where Δt_meas is the shortest macroscopic observation interval that still resolves the energy decay.\n\nHYPOTHESIS: An isolated composite system obeying the macroscopic law dE/dt = –k(E – E_eq) necessarily requires the microscale energy-correlation decay time 1/k to be shorter than any observation interval used to verify that law.\n\nVERIFICATION: 1/k has units of time, consistent with the inequality τ < Δt_meas.\n\nCONCLUSION: Measurements of the exponential energy relaxation must average over times much longer than 1/k to validate the stated macroscopic rate equation.", "rejected": "The macroscopic law dE/dt = –k(E – E_eq) governs the relaxation of any microscopic energy fluctuation, no matter how far the instantaneous energy E lies from equilibrium E_eq.", "E_acc": 0.6332901120185852, "C_acc": 0.11765839904546738, "G_acc": 0.5488274768576957, "D_acc": 0.7719134867191315, "H_acc": 0.1938706934452057, "Q_acc": 0.711216477167327, "E_rej": 0.03143128752708435, "C_rej": 0.6925303339958191, "G_rej": 0.5742575709155062, "D_rej": 0.8085557818412781, "H_rej": 0.19144421815872192, "Q_rej": 0.42834156819444613, "Delta_Q": 0.2828749089728809, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Exceptions to simple effective nuclear charge models attributed to multi-electron screening and exchange: hypotheses explaining localized irregularities.", "ancestors": ["Z_eff = Z – S defines effective nuclear charge.", "S is the screening constant.", "S sums electron shielding per electron.", "Simple S averages orbital contributions.", "Exchange favors parallel-spin electrons.", "Parallel-spin electrons avoid spatial overlap."]}, "accepted": "Exchange repulsion lowers spatial overlap between parallel-spin electrons, so each such pair contributes less to the screening constant than an antiparallel pair.  \nHYPOTHESIS: For any two electrons in the same orbital, the parallel-spin pair contributes a smaller increment to S than the antiparallel-spin pair.  \nVERIFICATION: Dimensionless ratio of increments, valid within the single-configuration approximation.  \nCONCLUSION: The screening increment ΔS↑↑ < ΔS↑↓, so adding parallel-spin electrons raises Z_eff faster than adding antiparallel ones.", "rejected": "The antiparallel-spin pair contributes a smaller increment to S than the parallel-spin pair for any two electrons in the same orbital.", "E_acc": 0.0855066180229187, "C_acc": 0.6415647268295288, "G_acc": 0.6014456634875387, "D_acc": 0.7356393486261368, "H_acc": 0.20800581574440002, "Q_acc": 0.44395546088926496, "E_rej": 0.24301117658615112, "C_rej": 0.300180584192276, "G_rej": 0.5930302352571744, "D_rej": 0.7260514199733734, "H_rej": 0.2739485800266266, "Q_rej": 0.5492887091808372, "Delta_Q": -0.1053332482915722, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability and kinetics of bonds considered via electronic reorganization energy: hypotheses about bond rupture pathways and transient bonding motifs.", "ancestors": ["λ is the electronic reorganization energy.", "λ equals the energy difference between final and initial electronic states.", "Bond rupture involves changing electronic states.", "Electronic reorganization accompanies bond rupture.", "λ quantifies the electronic rearrangement cost during rupture.", "Higher λ implies greater energy required for electronic rearrangement.", "Activation energy E_a includes λ.", "E_a = λ + ΔE_bond, where ΔE_bond is the bond energy change.", "Rupture rate k follows k = A exp(−E_a / RT).", "Transient motifs appear when λ is comparable to thermal energy RT."]}, "accepted": "Transient motifs emerge when the electronic reorganization energy λ drops to the order of the thermal energy RT, so the activation energy E_a ≈ ΔE_bond + RT and the rupture rate k ≈ A exp[−(ΔE_bond + RT)/RT] = A exp(−ΔE_bond/RT − 1); setting λ = RT thus yields a universal lower-bound for the rate constant k ≥ A e^{−1} exp(−ΔE_bond/RT).\n\nHYPOTHESIS: Whenever λ ≤ RT the bond rupture rate constant satisfies k ≥ A e^{−1} exp(−ΔE_bond/RT).\n\nVERIFICATION: Units consistent (RT and ΔE_bond in energy, exponent dimensionless).\n\nCONCLUSION: The inequality provides a measurable, temperature-dependent lower bound for the rupture rate once the reorganization energy is known to be within one k_BT of the thermal energy.", "rejected": "Whenever the bond rupture rate constant satisfies k ≥ A e^{−1} exp(−ΔE_bond/RT), λ ≤ RT.", "E_acc": 0.48182976245880127, "C_acc": 0.18248121440410614, "G_acc": 0.56620382075198, "D_acc": 0.782786887139082, "H_acc": 0.14259561896324158, "Q_acc": 0.6635912655387074, "E_rej": 0.5394057631492615, "C_rej": 0.18404917418956757, "G_rej": 0.5844584268052131, "D_rej": 0.7978114485740662, "H_rej": 0.20218855142593384, "Q_rej": 0.6812470140401274, "Delta_Q": -0.017655748501420043, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adaptation as navigations of rugged fitness landscapes with contingent historical constraints: hypotheses on predictability vs contingency.", "ancestors": ["A fitness landscape maps each genotype to a scalar fitness value.", "Genotypes are sequences of length L drawn from an alphabet of size A.", "A neighbour genotype differs at exactly one position.", "Fitness is a function f: genotypes → ℝ.", "A peak is a genotype whose neighbours all have lower fitness.", "A valley is a set of genotypes separating peaks.", "Accessibility between genotypes is restricted to single-step mutations.", "Historical constraint means the population starts from a fixed genotype g₀.", "Contingency is dependence on the specific path taken from g₀.", "Ruggedness is the density of peaks and valleys in the landscape."]}, "accepted": "Because fitness is a scalar and neighbours differ at exactly one of L positions, the number of fitter neighbours of any genotype is an integer between 0 and (A-1)L. A peak is defined by 0 fitter neighbours, so the maximum possible number of distinct peaks equals the total number of genotypes, A^L, minus the minimum number of genotypes that must be non-peaks to satisfy the neighbour condition.\n\nHYPOTHESIS: The maximum number of distinct peaks in a fitness landscape is A^L - (A-1)L.\n\nVERIFICATION: Both terms are dimensionless counts; equality holds when every non-peak genotype is required to be a neighbour of at least one peak.\n\nCONCLUSION: The peak count is bounded above by A^L - (A-1)L, providing a landscape-independent ceiling that tightens as sequence length L or alphabet size A increases.", "rejected": "Because fitness is a scalar and neighbours differ at exactly one of L positions, the number of fitter neighbours of any genotype is an integer between 0 and (A-1)L; a genotype is defined as a peak whenever it has 0 fitter neighbours, so the minimum possible number of distinct peaks equals the total number of genotypes, A^L, minus the maximum number of genotypes that must be non-peaks to satisfy the neighbour condition.", "E_acc": 0.4126388728618622, "C_acc": 0.3049022853374481, "G_acc": 0.6080431351510924, "D_acc": 0.8123502016067505, "H_acc": 0.13275228440761566, "Q_acc": 0.633614643701876, "E_rej": 0.24911968410015106, "C_rej": 0.4572983980178833, "G_rej": 0.5985322539345361, "D_rej": 0.8522034585475922, "H_rej": 0.1847456768155098, "Q_rej": 0.5549488004413433, "Delta_Q": 0.07866584326053272, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Periodic trend anomalies arising from relativistic orbital contraction: hypotheses on property deviations for heavy elements.", "ancestors": ["Electrons have rest mass me.", "Velocity v is the rate of change of position.", "Special relativity states v < c, where c is light speed.", "Relativistic mass m is given by m = me / √(1 – v²/c²).", "Orbital kinetic energy rises as nuclear charge Z increases.", "Inner-shell v approaches c for large Z.", "1s radius contracts as r ∝ 1/Zrel where Zrel scales with m."]}, "accepted": "As Z grows, the relativistic mass m = me / √(1 – v²/c²) rises because v approaches c; simultaneously the 1s radius contracts as r ∝ 1/Zrel with Zrel ∝ m, so r ∝ √(1 – v²/c²)/me.  Hence the radius shrinks to zero precisely when v reaches c, which special relativity forbids, so a lower bound on r is set by the maximum possible m.\n\nHYPOTHESIS: The 1s orbital radius obeys r ≥ (ħ)/(me c) (≈ 386 fm), a finite lower bound imposed by the relativistic mass divergence as v → c.\n\nVERIFICATION: Units check: ħ (J·s) / (kg·m·s⁻¹) = m; bound holds for all nuclear charges Z.\n\nCONCLUSION: Even at infinite Z, relativistic mass inflation keeps the 1s electron outside 386 fm, preventing physical collapse.", "rejected": "As Z grows, the 1s radius contracts as r ∝ 1/Zrel with Zrel ∝ m, so r ∝ √(1 – v²/c²)/me; therefore the relativistic mass m = me / √(1 – v²/c²) rises because v approaches c.", "E_acc": 0.012856916524469852, "C_acc": 0.9352679252624512, "G_acc": 0.5916674695909023, "D_acc": 0.7581539630889893, "H_acc": 0.23934456706047058, "Q_acc": 0.362833319734782, "E_rej": 0.48918813467025757, "C_rej": 0.15163929760456085, "G_rej": 0.61720554321073, "D_rej": 0.8191369473934174, "H_rej": 0.18086305260658264, "Q_rej": 0.6856107737403363, "Delta_Q": -0.3227774540055543, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adaptation as navigations of rugged fitness landscapes with contingent historical constraints: hypotheses on predictability vs contingency.", "ancestors": ["Fitness is a scalar quantity assigned to a genotype.", "Genotype space is a finite discrete set G.", "A landscape is a function f: G → ℝ assigning fitness to each genotype.", "Neighbors of a genotype are the set N(g) ⊂ G differing by one mutational step.", "A path is a sequence g₁, g₂, …, gₖ where gᵢ₊₁ ∈ N(gᵢ).", "Accessibility between genotypes requires existence of a path of monotonically increasing fitness.", "Historical constraint is the requirement that evolution follows a path accessible from the initial genotype.", "Contingency is dependence of accessible paths on the initial genotype.", "Ruggedness is the presence of multiple fitness peaks separated by valleys of lower fitness.", "Predictability is quantified by the probability that two independent evolutionary runs starting from g₀ reach the same genotype."]}, "accepted": "Because accessibility demands a monotonic path, any genotype whose fitness equals the global maximum must be reachable from every starting point via such a path; if even one genotype lacks this reachability, the landscape cannot sustain a single global peak.  Thus the coexistence of ruggedness (multiple peaks) and universal accessibility forces every local peak to be globally accessible.\n\nHYPOTHESIS: In a rugged fitness landscape, a genotype is a local fitness peak only if an accessible monotonic path connects it to every other genotype.\n\nVERIFICATION: Units are consistent (dimensionless path existence); holds under the premise that accessibility is required for all genotypes.\n\nCONCLUSION: Ruggedness and universal accessibility together eliminate isolated peaks, making every local maximum globally reachable.", "rejected": "Because accessibility demands a monotonic path, any genotype whose fitness equals the global maximum must be reachable from every starting point via such a path; if even one genotype lacks this reachability, the landscape cannot sustain a single global peak, so universal accessibility guarantees that every genotype, whether a peak or not, is a local fitness maximum.", "E_acc": 0.5841212868690491, "C_acc": 0.19508326053619385, "G_acc": 0.6099546495825052, "D_acc": 0.8095040500164032, "H_acc": 0.16748853027820587, "Q_acc": 0.703362620845437, "E_rej": 0.40364372730255127, "C_rej": 0.3844276964664459, "G_rej": 0.603603427298367, "D_rej": 0.8633835911750793, "H_rej": 0.20492461323738098, "Q_rej": 0.6171125212684274, "Delta_Q": 0.08625009957700958, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability and kinetics of bonds considered via electronic reorganization energy: hypotheses about bond rupture pathways and transient bonding motifs.", "ancestors": ["Reorganization energy λ is the energy change needed to distort the nuclear framework so that the electronic wavefunction becomes optimum for the products.", "Charge transfer state energy ΔECT is the vertical energy difference between the donor's highest occupied and acceptor's lowest empty electronic level at fixed geometry.", "λ can be expressed as λ = (ΔE - ΔE0), where ΔE0 is the reactant equilibrium energy and ΔE is the product equilibrium energy after nuclei have equilibrated.", "The rate coefficient k for bond rupture follows k ∝ e^{-β/λ}, where β is the electronic coupling and λ is the reorganization energy.", "Transient bonding motif energy Eτ describes an intermediate configuration with altered λ relative to either pure reactant or product state.", "For any bond rupture pathway, λ for the transient motif must be smaller than λ for the fully separated fragments."]}, "accepted": "The transient bonding motif lowers the reorganization energy relative to the separated fragments, and the rate coefficient scales exponentially with the inverse of λ.  Combining the given proportionality k ∝ e^{-β/λ} with the constraint λ_τ < λ_fragments yields the maximum allowable λ for the motif.\n\nHYPOTHESIS: The rate coefficient for bond rupture via a transient motif obeys k_τ = k_fragments e^{β(1/λ_fragments – 1/λ_τ)} with λ_τ < λ_fragments.\n\nVERIFICATION: Exponents are dimensionless; β carries energy units, cancelling λ in the denominator.\n\nCONCLUSION: Any observed k_τ exceeding k_fragments certifies that the pathway proceeded through a transient motif with reorganization energy below that of the fully separated fragments.", "rejected": "The rate coefficient for bond rupture via a transient motif obeys k_τ = k_fragments e^{β(λ_fragments – λ_τ)} with λ_τ < λ_fragments.", "E_acc": 0.3478645384311676, "C_acc": 0.36521726846694946, "G_acc": 0.5588397956162225, "D_acc": 0.7800837367773056, "H_acc": 0.12823721766471863, "Q_acc": 0.5862768925481942, "E_rej": 0.2912757694721222, "C_rej": 0.29589876532554626, "G_rej": 0.5670011523761787, "D_rej": 0.8477948904037476, "H_rej": 0.15220510959625244, "Q_rej": 0.5959416753728874, "Delta_Q": -0.009664782824693297, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Homeostatic control seen as multi-timescale feedback: hypotheses on robustness limits and failure modes under extreme perturbations.", "ancestors": ["Homeostasis is the maintenance of a regulated variable x near a set-point x₀.", "A controller detects deviation e = x − x₀.", "A negative feedback signal u = −k e is generated with gain k > 0.", "The actuator applies u to drive x back toward x₀.", "The actuator has saturation limits |u| ≤ u_max.", "The process dynamics are dx/dt = −k e + d with disturbance d.", "The maximum disturbance the loop can cancel is d_max = k u_max.", "The feedback delay is τ seconds.", "The loop becomes unstable if k τ > 1.", "Extreme perturbations exceed d_max and destabilize the system."]}, "accepted": "The premises link actuator saturation u_max, gain k, and tolerable disturbance d_max through d_max = k u_max, while instability arises if k τ > 1.  Combining these two relations yields the maximum delay τ that still permits full disturbance rejection at the saturation limit.\n\nHYPOTHESIS: The feedback loop remains stable while cancelling the largest admissible disturbance exactly when τ < u_max / d_max.\n\nVERIFICATION: Both sides have units of seconds, and the inequality collapses to k τ < 1 under substitution of d_max = k u_max.\n\nCONCLUSION: Any delay τ ≥ u_max / d_max destabilizes the loop before the actuator can deliver the −k e signal needed to cancel a disturbance of size d_max.", "rejected": "The feedback loop remains stable while cancelling the largest admissible disturbance exactly when τ ≥ u_max / d_max.", "E_acc": 0.5373262763023376, "C_acc": 0.19508324563503265, "G_acc": 0.5690344497561455, "D_acc": 0.800896841287613, "H_acc": 0.1630324125289917, "Q_acc": 0.6798642507195473, "E_rej": 0.18457163870334625, "C_rej": 0.6531455516815186, "G_rej": 0.5762692138552665, "D_rej": 0.83895543217659, "H_rej": 0.16104456782341003, "Q_rej": 0.49168285369873055, "Delta_Q": 0.1881813970208167, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Quantization at micro-scales vs. effective continuity macroscopically: hypotheses about coarse-graining and emergent classicality.", "ancestors": ["Energy is quantized in microscopic systems.", "Classical systems exhibit continuous energy values.", "Microscopic systems have fewer than about 10^6 constituents.", "Macroscopic systems contain more than about 10^20 constituents.", "Decoherence causes superpositions to decay into mixtures.", "Reduced density matrices describe subsystems of larger entangled systems.", "A macroscopic observable Q becomes effectively continuous when error ΔQ ≫ ħ.", "The number of accessible microstates Ω grows exponentially with system size N.", "Coarse-graining replaces discrete spectra with continuous distributions when δE ≫ ΔE."]}, "accepted": "Combining the discrete energy spectrum of microscopic systems with the exponential growth of accessible microstates, we derive that the crossover to apparent continuum behavior occurs when the level spacing becomes smaller than the thermal energy width.  \nHYPOTHESIS: A system of N constituents exhibits effectively continuous energy when N > 10¹³, where the mean level spacing δE ≈ ΔE·10⁻⁶N/10⁶ falls below the coarse-graining width ΔE.  \nVERIFICATION: The exponent −6N/10⁶ is dimensionless and negative, so δE/ΔE decreases exponentially with N, satisfying δE < ΔE for N > 10¹³.  \nCONCLUSION: Energy spectra of systems with more than ~10¹³ particles are indistinguishable from continuum.", "rejected": "A system of N constituents exhibits effectively continuous energy when N > 10¹³, where the mean level spacing δE ≈ ΔE + 10⁻⁶N/10⁶ falls below the coarse-graining width ΔE.", "E_acc": 0.3534395098686218, "C_acc": 0.34025758504867554, "G_acc": 0.592354801367037, "D_acc": 0.7559869363903999, "H_acc": 0.17681381106376648, "Q_acc": 0.5899673023959622, "E_rej": 0.36060765385627747, "C_rej": 0.28774601221084595, "G_rej": 0.6024690074846148, "D_rej": 0.7781363129615784, "H_rej": 0.22186368703842163, "Q_rej": 0.6045677891001106, "Delta_Q": -0.014600486704148374, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Centripetal acceleration reinterpreted via angular momentum transfer and rotating reference frames: hypotheses about torque sources in deformable bodies.", "ancestors": ["Centripetal acceleration is a_c = v^2 / r.", "Angular momentum is L = r × p.", "Torque is τ = dL / dt.", "A rotating frame has angular velocity ω.", "In that frame, the Coriolis force is F_c = –2m ω × v′.", "For a deformable body, r and v of any mass element vary with time.", "Internal stress can exert torque τ_int = ∫ r × (∇ · σ) dV."]}, "accepted": "Combining the torque law τ = dL/dt with the internal-stress torque τ_int = ∫ r × (∇·σ) dV and the time-varying position r(t) of any mass element in a deformable body shows that the total angular momentum of the body changes only if the divergence of the internal stress tensor produces a net moment. HYPOTHESIS: A deformable isolated body changes its total angular momentum if and only if the volume integral of r × (∇·σ) is non-zero. VERIFICATION: Both sides have units of angular momentum (kg m² s⁻¹) and the relation holds for continuous media. CONCLUSION: Internal stress gradients are the sole driver of angular-momentum change in an isolated deformable body.", "rejected": "A deformable isolated body changes its total angular momentum if and only if the volume integral of r × (∇·σ) is zero.", "E_acc": 0.15640926361083984, "C_acc": 0.1452527791261673, "G_acc": 0.532430098974146, "D_acc": 0.7413313519209623, "H_acc": 0.2582751512527466, "Q_acc": 0.5467969983117655, "E_rej": 0.017397025600075722, "C_rej": 0.5254880785942078, "G_rej": 0.5402419574093074, "D_rej": 0.725107342004776, "H_rej": 0.274892657995224, "Q_rej": 0.42570208604447546, "Delta_Q": 0.12109491226729008, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Let biomass be B.", "Let available substrate be S.", "Let time be t.", "Resource fluctuations introduce discrete time stages.", "Each stage has a specific biochemical pathway.", "Let the switch from pathway to pathway carry a fixed cost L.", "Let the biomass gain per stage under pathway be g(k).", "Let the control policy be a rule for assigning pathway k to each stage."]}, "accepted": "<derivation sentences>\nThe premises define biomass B, substrate S, time stages t, pathway k, switch cost L, and gain g(k).  \nCase 1: keep one pathway for all stages → total gain = Σg(k) over stages, no switch cost.  \nCase 2: switch pathways → each switch incurs cost L, so net gain = Σg(k) – nL, where n is the number of switches.  \nEliminate Case 2 whenever Σg(k) – nL ≤ Σg(k) (i.e., always worse or equal), so switching is only justified if the gain increment from the new pathway exceeds L within the next stage.  \nThus the minimal test is whether the gain difference Δg = g(new) – g(current) > L; if not, switching lowers net biomass.  \n</derivation sentences>\n\nHYPOTHESIS: A pathway switch increases net biomass only if the gain increment in the upcoming stage exceeds the fixed switching cost L.\n\nVERIFICATION: Both Δg and L carry units of biomass, so inequality is dimensionally consistent.\n\nCONCLUSION: Adopt a new pathway only when the predicted biomass gain in the next stage is strictly greater than L.", "rejected": "A pathway switch increases net biomass only if the gain increment in the upcoming stage equals the fixed switching cost L.", "E_acc": 0.1492534577846527, "C_acc": 0.6005975008010864, "G_acc": 0.5319544551700043, "D_acc": 0.7613092012703419, "H_acc": 0.17764832824468613, "Q_acc": 0.4655444356387791, "E_rej": 0.42321306467056274, "C_rej": 0.17111434042453766, "G_rej": 0.5394256307433049, "D_rej": 0.8651829957962036, "H_rej": 0.1348170042037964, "Q_rej": 0.6601810762037834, "Delta_Q": -0.1946366405650043, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Biomass is a measurable mass.", "A metabolic pathway is a sequence of biochemical reactions.", "Switching between pathways incurs a discrete cost.", "A control policy determines the active pathway over time.", "Long-run biomass is the integral of net biomass production.", "Maximizing long-run biomass equals maximizing the integral of (pathway-specific production - switching cost)."]}, "accepted": "<derivation sentences>\nVariables: pathway-specific production rate p_i, switching cost c, control policy u(t), long-run biomass B = ∫(p_u(t) – c·δ_switch(t))dt.  \nCases: (i) always stay in one pathway, (ii) switch at fixed intervals, (iii) switch only when production gain exceeds cost.  \nElimination: (i) and (ii) ignore the discrete cost; only (iii) is consistent with the cost-minimizing objective.  \nDerive: a switch is justified only if the incremental production Δp over the next interval τ satisfies Δp·τ > c.  \n</derivation sentences>\n\nHYPOTHESIS: A pathway switch occurs only when the anticipated extra production over the next interval τ exceeds the switching cost c, i.e. Δp·τ > c.\nVERIFICATION: Units check: Δp (mass/time)·τ (time) = mass, same as c (mass), so inequality dimensionless and valid.\nCONCLUSION: The control policy that maximizes long-run biomass switches pathways if and only if Δp·τ > c.", "rejected": "A pathway switch occurs if the switching cost c exceeds the anticipated extra production over the next interval τ, i.e. c > Δp·τ.", "E_acc": 0.01588750071823597, "C_acc": 0.8903921842575073, "G_acc": 0.6044835430802777, "D_acc": 0.7044844642281533, "H_acc": 0.23168746381998062, "Q_acc": 0.3653126684436575, "E_rej": 0.7517572641372681, "C_rej": 0.05590697377920151, "G_rej": 0.6148100192658603, "D_rej": 0.6552496515214443, "H_rej": 0.2584604322910309, "Q_rej": 0.742511675413698, "Delta_Q": -0.3771990069700405, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["A classifier maps an input x to a predicted label y.", "An edge case is an x that the classifier mislabels.", "A data distribution D assigns probability density p(x) to each x.", "Model failure probability is P_{x∼D}[classifier(x) ≠ true(x)].", "An adversary seeks a perturbed distribution D′ that maximizes this probability.", "A plausibility constraint bounds the α-divergence D_{α}(D′ || D) ≤ k.", "The optimization problem is max_{D′} ∫_{x} p′(x) · I[classifier(x)≠true(x)] dx.", "The indicator I[·] equals 1 when the classifier errs and 0 otherwise.", "The Lagrangian combines the objective with the divergence penalty via multiplier λ.", "The optimal density satisfies p′(x) ∝ p(x) · exp(λ · I[classifier(x)≠true(x)])."]}, "accepted": "The optimal adversarial density p′(x) is derived by exponentiating the indicator of misclassification, so every misclassified point receives the same multiplicative boost relative to its original density. Integrating the ratio p′(x)/p(x) over the error set E={x:classifier(x)≠true(x)} gives the excess mass the adversary places on failures. Because the total probability under p′ must be 1, this excess is exactly offset by a uniform contraction elsewhere; solving ∫_E p(x)(e^λ–1)dx = 1–e^λ·P_D(E) yields the closed-form aggregate shift.\n\nHYPOTHESIS: The adversary’s reweighting increases the model failure probability to P_{x∼D′}[error] = P_{x∼D}[error] · e^λ, where λ is the unique positive root of the equation (e^λ–1)P_{x∼D}[error]+1=e^λ.\n\nVERIFICATION: Both sides of the equation are dimensionless probabilities; the equation holds for every k>0 via the monotone relation between λ and the divergence bound k.\n\nCONCLUSION: The failure probability under the worst-case plausibility-constrained distribution is the original failure rate amplified by the exponential factor e^λ determined by the divergence budget k.", "rejected": "The adversary’s reweighting increases the model failure probability to P_{x∼D′}[error] = P_{x∼D}[error] · e^λ, where λ is the unique positive root of the equation (e^λ–1)P_{x∼D}[error]+1=e^λ, treating the misclassification events as independent across x.", "E_acc": 0.23515383899211884, "C_acc": 0.4114406704902649, "G_acc": 0.5650386069901288, "D_acc": 0.719813567896684, "H_acc": 0.20317234098911285, "Q_acc": 0.524911218478034, "E_rej": 0.328331857919693, "C_rej": 0.28033939003944397, "G_rej": 0.5491754917893559, "D_rej": 0.7865057587623596, "H_rej": 0.21349424123764038, "Q_rej": 0.5882185053545983, "Delta_Q": -0.06330728687656428, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["An MDP is a tuple (S,A,P,R,γ).", "S is the finite state space.", "A is the finite action space.", "P(s'|s,a) is the transition probability kernel.", "R(s,a) is the expected immediate reward function.", "γ∈[0,1) is the discount factor.", "π(a|s) denotes a stochastic policy.", "d_{P}^{(t)}(s) is the state occupancy at time t under policy π and dynamics P.", "ρ^{π}(s,a)=(1−γ)∑_{t=0}^{∞}γ^{t}d_{P}^{(t)}(s)π(a|s) is the discounted occupancy measure.", "The off-policy value estimate is Ĵ=∑_{s,a}ρ^{π}(s,a)R(s,a)."]}, "accepted": "Summing the discounted occupancy over actions collapses the policy, yielding the state‐only discounted occupancy d^{π}(s)=∑_{a}ρ^{π}(s,a)=(1−γ)∑_{t=0}^{∞}γ^{t}d_{P}^{(t)}(s).  Because every d_{P}^{(t)}(s) is a probability vector, the total discounted occupancy of any state cannot exceed the normalization constant 1/(1−γ).\n\nHYPOTHESIS: For every state s, the discounted state occupancy obeys d^{π}(s)≤1/(1−γ).\n\nVERIFICATION: Units are dimensionless probabilities; bound saturates when the policy always revisits s.\n\nCONCLUSION: The derived inequality gives a model-free upper bound on any state’s long-run footprint under a stationary policy.", "rejected": "For every state s, the discounted state occupancy obeys d^{π}(s)=1/(1−γ) because the time-step occupancies d_{P}^{(t)}(s) are mutually independent.", "E_acc": 0.40821152925491333, "C_acc": 0.3777969479560852, "G_acc": 0.5657274962535926, "D_acc": 0.8048236638307571, "H_acc": 0.17383664846420288, "Q_acc": 0.6036306363557066, "E_rej": 0.3095860183238983, "C_rej": 0.5275068283081055, "G_rej": 0.5777607198272433, "D_rej": 0.8370244204998016, "H_rej": 0.16297557950019836, "Q_rej": 0.5540339099509376, "Delta_Q": 0.049596726404768976, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Hierarchical goal decomposition with conflicting subgoals: synthesize a scheduler that resolves conflicts while guaranteeing progress on at least one top-level objective.", "ancestors": ["Let G be a top-level goal.", "Let S = {s₁,...,sₙ} be subgoals derived from G.", "Conflicting subgoals sᵢ, sⱼ share at least one resource r.", "A schedule σ assigns time slots T to subgoals.", "A conflict occurs when σ(sᵢ) ∩ σ(sⱼ) ∩ T ≠ ∅ on any shared resource.", "A scheduler enforces progress by returning σ such that at least one subgoal sₖ ∈ S completes."]}, "accepted": "Variables: G, S, σ, T, r, conflict condition, scheduler guarantee.  \nCases: (i) conflicts exist, (ii) no conflicts exist.  \nElimination: Premise states conflicts can occur, so (i) is possible; scheduler must still ensure progress.  \nDerive: If conflicts are present, the scheduler must select σ so that at least one conflicting pair is separated in time on every shared resource.  \nConclude: A deterministic separation rule emerges.\n\nHYPOTHESIS: Whenever two subgoals sᵢ and sⱼ share a resource r, the scheduler enforces σ(sᵢ) ∩ σ(sⱼ) ∩ T = ∅ for that r, guaranteeing at least one subgoal completes.  \nVERIFICATION: Units consistent (time sets intersected with resource usage).  \nCONCLUSION: The scheduler must insert a non-overlapping time gap Δt > 0 between σ(sᵢ) and σ(sⱼ) on every shared resource r.", "rejected": "Whenever two subgoals sᵢ and sⱼ share a resource r, the scheduler enforces σ(sᵢ) + σ(sⱼ) + T = 0 for that r, guaranteeing at least one subgoal completes.", "E_acc": 0.29818910360336304, "C_acc": 0.4585236608982086, "G_acc": 0.5628143429223981, "D_acc": 0.7842133659869432, "H_acc": 0.12131805717945099, "Q_acc": 0.5550257349652904, "E_rej": 0.5411838889122009, "C_rej": 0.27622589468955994, "G_rej": 0.5846621298364231, "D_rej": 0.9419922530651093, "H_rej": 0.05800774693489075, "Q_rej": 0.7066400896225656, "Delta_Q": -0.15161435465727524, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability of supramolecular assemblies under stochastic perturbations: determine minimal interaction network that preserves function.Signaling under noisy channels: design signals that remain informative when senders face verification costs and receivers have model uncertainty.", "ancestors": ["A supramolecular assembly is a structure held together by non-covalent interactions.", "Non-covalent interactions have interaction energy E < 0.", "Thermal noise provides perturbations of magnitude kT.", "The native contact fraction is Q = (current contacts) / (native contacts).", "Assembly integrity requires Q > Q_crit where Q_crit > 0.", "Energy input exceeding |E| can disrupt non-covalent contacts."]}, "accepted": "Thermal noise supplies perturbations of magnitude kT, while each non-covalent contact contributes an interaction energy E < 0.  The assembly survives only while the native contact fraction Q exceeds the positive threshold Q_crit.  Equating the disruptive energy per contact to the thermal energy yields the requirement |E| > kT for a contact to remain intact against thermal agitation; multiplying both sides by the number of native contacts and rearranging gives the critical temperature T_crit = |E|/k.\n\nHYPOTHESIS: A supramolecular assembly loses its integrity when the temperature rises above T_crit = |E|/k, where |E| is the interaction energy per non-covalent contact and k is Boltzmann’s constant.\n\nVERIFICATION: Units check: [|E|/k] = J / (J K⁻¹) = K, consistent with temperature.\n\nCONCLUSION: The assembly remains stable only below T_crit = |E|/k, providing a quantitative thermal stability limit.", "rejected": "Thermal noise supplies perturbations of magnitude kT, while each non-covalent contact contributes an interaction energy E < 0; the assembly survives only while the native contact fraction Q is below the positive threshold Q_crit.", "E_acc": 0.39375028014183044, "C_acc": 0.2717023491859436, "G_acc": 0.5912964046001434, "D_acc": 0.7508486323058605, "H_acc": 0.11866298317909241, "Q_acc": 0.6203473232686519, "E_rej": 0.6627960801124573, "C_rej": 0.0796058177947998, "G_rej": 0.6105062535830906, "D_rej": 0.872865617275238, "H_rej": 0.12713438272476196, "Q_rej": 0.7668785963739668, "Delta_Q": -0.14653127310531489, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["A set X contains elements x.", "A formula P(x,y) is either true or false for every pair (x,y).", "A quantified sentence ∀x∈X ∃y∈Y P(x,y) demands one y per x.", "A function c:Y→ℕ assigns a natural cost to every y.", "A monotone cost means y₁≤y₂ ⇒ c(y₁)≤c(y₂).", "A total strategy is a function f:X→Y satisfying P(x,f(x)) for every x.", "A budget bound B∈ℕ forbids any y with c(y)>B.", "A feasible strategy f keeps c(f(x))≤B for all x∈X.", "The failure set F={x∈X : ∀y∈Y (P(x,y) ⇒ c(y)>B)} marks x with no affordable y."]}, "accepted": "Because the cost function is monotone and every x must be assigned a y with c(y)≤B, the only y that can ever be chosen are those lying in the initial segment Y≤B={y∈Y:c(y)≤B}.  \nFor any x whose requirement P(x,y) forces y to lie above this segment, no feasible assignment exists, so x belongs to the failure set F.  \nHence the existence of a feasible strategy f:X→Y is equivalent to the emptiness of F.\n\nHYPOTHESIS: A feasible strategy exists if and only if F=∅.\nVERIFICATION: Both sides are Boolean; equivalence holds under the monotone-cost model.\nCONCLUSION: Feasibility is decided by checking whether every x has at least one y with P(x,y) and c(y)≤B.", "rejected": "A feasible strategy exists if and only if F≠∅.", "E_acc": 0.2772413492202759, "C_acc": 0.45982789993286133, "G_acc": 0.5488946809782647, "D_acc": 0.7932324111461639, "H_acc": 0.15393058955669403, "Q_acc": 0.5442391842487269, "E_rej": 0.41056811809539795, "C_rej": 0.35539841651916504, "G_rej": 0.5603482409496792, "D_rej": 0.7996630668640137, "H_rej": 0.20033693313598633, "Q_rej": 0.6040593203739263, "Delta_Q": -0.05982013612519943, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["A directed graph G has vertex set V and edge set E.", "Each edge e ∈ E carries a non-negative travel-time function tₑ(fₑ) that depends on flow fₑ.", "Every driver (agent) i selects a single sᵢ–tᵢ path Pᵢ ⊆ E.", "Driver flow fₑ equals |{i : e ∈ Pᵢ}| summed over all drivers.", "Driver cost Cᵢ equals Σ_{e∈Pᵢ} tₑ(fₑ).", "A Wardrop equilibrium is a flow where every used s–t path has equal and minimal cost.", "Social cost C is Σ_{i} Cᵢ.", "System optimum minimizes C.", "A toll τₑ on edge e changes driver cost to Σ_{e∈Pᵢ} (tₑ(fₑ)+τₑ)."]}, "accepted": "Summing the driver cost definition over all drivers gives C = Σᵢ Σ_{e∈Pᵢ} tₑ(fₑ).  Because fₑ counts how many drivers use edge e, each tₑ(fₑ) appears in exactly fₑ of the inner sums, so the double sum collapses to Σ_{e∈E} fₑ·tₑ(fₑ).\n\nHYPOTHESIS: The social cost equals the flow-weighted edge travel-time sum C = Σ_{e∈E} fₑ·tₑ(fₑ).\n\nVERIFICATION: Units: fₑ (vehicles) × tₑ (time/vehicle) → total travel time, matching C.\n\nCONCLUSION: Social cost is directly computable from edge flows and travel-time functions without tracking individual paths.", "rejected": "Summing the driver cost definition over all drivers gives C = Σᵢ Σ_{e∈Pᵢ} tₑ(fₑ), so C = Σ_{e∈E} tₑ(fₑ) because each tₑ(fₑ) is counted independently of how many drivers use the edge.", "E_acc": 0.410046249628067, "C_acc": 0.18779048323631287, "G_acc": 0.5915612440024104, "D_acc": 0.7510396391153336, "H_acc": 0.15497532486915588, "Q_acc": 0.6384784223777907, "E_rej": 0.384164959192276, "C_rej": 0.1852184683084488, "G_rej": 0.612211042216846, "D_rej": 0.789932906627655, "H_rej": 0.21006709337234497, "Q_rej": 0.6376278745276588, "Delta_Q": 0.0008505478501319441, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["A finite set V has n elements.", "A family F = {A1, …, Am} consists of subsets of V.", "The intersection of two distinct sets Ai ∩ Aj with i ≠ j has size at most t.", "The degree d(v) of an element v ∈ V counts how many sets in F contain v.", "The sum Σ_{v∈V} d(v) equals Σ_{i=1}^m |Ai|.", "The pairwise intersection constraint |Ai ∩ Aj| ≤ t bounds the sum Σ_{v∈V} d(v)^2 through inclusion–of–pairs counting."]}, "accepted": "Summing the pairwise intersections counts each element v exactly C(d(v),2) times, so Σ_{i<j}|Ai∩Aj|=Σ_v C(d(v),2).  Bounding each |Ai∩Aj|≤t gives Σ_v d(v)(d(v)−1)/2 ≤ C(m,2)t, and substituting Σ_v d(v)=Σ_i|Ai| yields Σ_v d(v)^2 ≤ m(m−1)t + Σ_i|Ai|.\n\nHYPOTHESIS: Σ_{v∈V} d(v)^2 ≤ m(m−1)t + Σ_{i=1}^m |Ai|.\n\nVERIFICATION: Both sides count element–set incidences squared; inequality holds for every family satisfying |Ai∩Aj|≤t.\n\nCONCLUSION: The squared degrees—and hence the variance of element usage—are bounded above by the intersection threshold t and the total set sizes.", "rejected": "Σ_{v∈V} d(v)^2 ≤ m(m−1)t − Σ_{i=1}^m |Ai|.", "E_acc": 0.48595309257507324, "C_acc": 0.2426614910364151, "G_acc": 0.5346007414162159, "D_acc": 0.791218701004982, "H_acc": 0.15548443794250488, "Q_acc": 0.6468690742552281, "E_rej": 0.36403146386146545, "C_rej": 0.4212396740913391, "G_rej": 0.5323898630216718, "D_rej": 0.7291490882635117, "H_rej": 0.27085091173648834, "Q_rej": 0.5501842034235597, "Delta_Q": 0.09668487083166843, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Sequential delegation: when an agent delegates to subagents with private incentives, derive mechanisms that ensure near-optimal end-to-end performance.", "ancestors": ["Principal P chooses action a.", "Agent A observes a and takes effort e.", "Effort e produces output y = e + ε with ε ~ N(0,σ²).", "A’s cost is C(e) = ½ke² with k > 0.", "P’s utility is U_P = y - w where w is payment to A.", "A’s utility is U_A = w - C(e).", "P cannot observe e, only y."]}, "accepted": "<derivation sentences>\nPremise variables: P chooses a; A observes a and picks effort e; output y = e + ε with ε ~ N(0,σ²); cost C(e)=½ke²; U_P = y - w; U_A = w - C(e); P sees only y.  \nCases: (i) P offers a constant wage w₀, (ii) P offers a wage schedule w(y).  \nCase (i): A’s optimal effort satisfies max_e E[w₀ - ½ke²] ⇒ e*=0 (first-order condition -ke=0).  \nCase (ii): P maximizes E[y-w(y)] subject to A’s incentive-compatibility: e* satisfies w′(e*)=k e* (using E[y]=e and first-order condition on A).  \nEliminate (i) because e*=0 gives E[U_P]=0-E[w₀]<0 for any w₀>0, so P will never choose it when (ii) is feasible.  \nRemaining case (ii) yields the minimal falsifiable restriction: expected output must satisfy E[y]=e*≥0 and the slope of the optimal contract at that point equals the marginal cost coefficient: w′(e*)=k e*.\n</derivation sentences>\n\nHYPOTHESIS: In any optimal contract, the slope of the payment schedule with respect to expected output equals the agent’s marginal cost of effort at the induced effort level: w′(e*) = k e*.\nVERIFICATION: Units: left side $/output, right side (k in $/effort²)·(e* in effort) → $/effort, consistent because output and effort share units.\nCONCLUSION: The principal must set the pay sensitivity equal to k e* to elicit effort e*.", "rejected": "In any optimal contract, the agent’s marginal cost of effort at the induced effort level equals the slope of the payment schedule with respect to expected output: k e* = w′(e*).", "E_acc": 0.5189374089241028, "C_acc": 0.28988778591156006, "G_acc": 0.5531684085144661, "D_acc": 0.7597331215034832, "H_acc": 0.2902926653623581, "Q_acc": 0.6312547049622729, "E_rej": 0.11077811568975449, "C_rej": 0.3800049126148224, "G_rej": 0.5782244155998342, "D_rej": 0.7853208184242249, "H_rej": 0.21467918157577515, "Q_rej": 0.5084735808311962, "Delta_Q": 0.12278112413107667, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["Let S denote the state space of a Markov decision process.", "Let P be the transition function P(s′|s,a).", "Let R be the reward function R(s,a).", "Let π be a target policy mapping states to actions.", "Let d_π be the stationary state distribution induced by π.", "Let ρ = d_π / d_b be the density ratio between target and behavior state distributions."]}, "accepted": "The stationary state distribution d_π is the left eigenvector of the state-action-state transition matrix induced by π, so the density ratio ρ(s)=d_π(s)/d_b(s) must satisfy the Bellman flow constraint ∑_s′ P(s′|s,π(s)) ρ(s′)=ρ(s) for every state s visited under the behavior distribution.\n\nHYPOTHESIS: For every state s with d_b(s)>0, the density ratio obeys ρ(s)=∑_s′ P(s′|s,π(s)) ρ(s′).\n\nVERIFICATION: Both sides are dimensionless ratios; equation holds by definition of stationary distribution.\n\nCONCLUSION: ρ is the unique solution to the above linear system for states in the support of d_b.", "rejected": "For every state s with d_b(s)>0, the density ratio obeys ρ(s)=∑_s′ P(s|s′,π(s)) ρ(s′).", "E_acc": 0.3043532967567444, "C_acc": 0.21735915541648865, "G_acc": 0.5880969180725515, "D_acc": 0.7632277309894562, "H_acc": 0.21468322724103928, "Q_acc": 0.5966307650320232, "E_rej": 0.42803847789764404, "C_rej": 0.21381627023220062, "G_rej": 0.6191548430360854, "D_rej": 0.8253208994865417, "H_rej": 0.17467910051345825, "Q_rej": 0.6570755277760327, "Delta_Q": -0.06044476274400956, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["An explanation artifact e is any information released by a model owner.", "A modeled agent a observes e and chooses an action x.", "A reward function R(x) outputs a scalar score for each x.", "Gaming occurs when a chooses x to maximize R(x) at the expense of the model owner’s true objective.", "Strategic opacity is the policy of withholding e to reduce gaming.", "A causal graph is a directed acyclic graph G = ⟨V, E⟩ where V is a set of variables and E encodes direct causal relations.", "A cross-domain intervention is a minimal subset of variable changes applied across distinct G₁, G₂, … that achieves a specified target value on a designated variable T."]}, "accepted": "Strategic opacity withholds e, so the agent’s action x is chosen under greater uncertainty about R(x).  \nBecause gaming requires x to be tuned to R(x), increasing the posterior entropy H(R|e) lowers the expected alignment between x and R.  \nHence the owner can bound gaming by setting a disclosure threshold: release e only if the resulting H(R|e) exceeds a critical value H*.  \n\nHYPOTHESIS: Gaming is eliminated whenever the owner withholds e such that the agent’s posterior entropy H(R|e) remains above H* = ln|X| − ln 2, where |X| is the size of the action space.  \nVERIFICATION: H* has units of nats and is valid for finite discrete action sets.  \nCONCLUSION: The owner should compute H(R|e) for any candidate e and suppress e whenever H(R|e) > ln|X| − ln 2.", "rejected": "Gaming is eliminated whenever the owner withholds e such that the agent’s posterior entropy H(R|e) remains above H* = ln|X| + ln 2, where |X| is the size of the action space.", "E_acc": 0.36683371663093567, "C_acc": 0.24594375491142273, "G_acc": 0.5867855069227517, "D_acc": 0.682913318897287, "H_acc": 0.2653306722640991, "Q_acc": 0.588268061944594, "E_rej": 0.2824876308441162, "C_rej": 0.3759731352329254, "G_rej": 0.5894268658012152, "D_rej": 0.7006179690361023, "H_rej": 0.2993820309638977, "Q_rej": 0.5376224260777236, "Delta_Q": 0.05064563586687043, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["A catalyst accelerates a reaction by stabilizing the transition state.", "The stabilized transition state lowers the activation energy E for the catalytic path.", "The net rate r of a catalytic pathway is proportional to k · [I], where k follows Arrhenius behavior k = A exp(−E/RT) and [I] is the surface concentration of the key intermediate.", "Competing catalytic pathways share one elementary step but differ in subsequent elementary steps that form distinct intermediates.", "The surface concentration [I] of a desired intermediate depends on the difference between the rate of its formation from the shared step and the rates of its consumption along each pathway.", "The catalyst's active-site geometry imposes steric constraints that selectively stabilize or destabilize adsorbates, shifting their adsorption free energy ΔG.", "Adjusting ΔG for competing intermediates redistributes [I] to raise the rate r of the catalytic pathway leading to the desired product while lowering the sum of rates for side reactions."]}, "accepted": "The premises link catalyst-induced stabilization of the transition state to a lower activation energy E, which via the Arrhenius factor k = A exp(−E/RT) increases the rate constant k.  Because the net rate r of a catalytic pathway is r = k [I] and [I] itself is controlled by the adsorption free energy ΔG shifted by steric constraints, the overall rate depends exponentially on both E and ΔG.  Combining these dependencies gives r = A [I](ΔG) exp(−E/RT); maximizing r with respect to the catalyst-tunable variables E and ΔG yields the necessary condition that the derivative of ln r with respect to any adjustable catalyst parameter α must vanish at the optimum, i.e. ∂E/∂α = RT ∂ln[I]/∂α.\n\nHYPOTHESIS: A catalyst attains its maximum turnover frequency when the fractional rate of change of activation energy with respect to any tunable geometric or electronic parameter equals the thermal energy times the fractional rate of change of the key-intermediate surface concentration with respect to that same parameter.\n\nVERIFICATION: Both sides of the equality carry units of energy (J mol⁻¹), valid for any single-site catalytic reaction obeying Arrhenius kinetics.\n\nCONCLUSION: Catalyst design should adjust active-site features until experimental measurement shows ∂E/∂α = RT ∂ln[I]/∂α, ensuring the fastest possible conversion of reactants to the desired product.", "rejected": "A catalyst attains its maximum turnover frequency when the fractional rate of change of activation energy with respect to any tunable geometric or electronic parameter equals the thermal energy divided by the fractional rate of change of the key-intermediate surface concentration with respect to that same parameter.", "E_acc": 0.4614669978618622, "C_acc": 0.19203722476959229, "G_acc": 0.5175641714595258, "D_acc": 0.7752759318266597, "H_acc": 0.13641558587551117, "Q_acc": 0.6449591164743261, "E_rej": 0.5219151973724365, "C_rej": 0.05150322616100311, "G_rej": 0.5137841308489441, "D_rej": 0.8198573589324951, "H_rej": 0.18014264106750488, "Q_rej": 0.6949879478290677, "Delta_Q": -0.050028831354741565, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["Let I denote a quantity that remains unchanged under update U.", "Let U be a function that maps a state S to a new state U(S).", "Let I(S) = I(U(S)) for every S.", "Let P(M|D) ∝ P(D|M)P(M) be the posterior probability of model M given data D.", "Let Q denote the true data-generating distribution.", "Let KL(Q||M) quantify the divergence between Q and model M."]}, "accepted": "Because the invariant I is preserved under every update U, any divergence measure that depends on I must also be preserved.  Treating KL divergence as a state-dependent observable, we derive that the change in KL from Q to the current model M before and after an update is exactly zero.\n\nHYPOTHESIS: KL(Q||M) = KL(Q||U(M)) whenever I(M) = I(U(M)).\n\nVERIFICATION: Units of KL are nats (dimensionless) and the equality holds for every update U that leaves I unchanged.\n\nCONCLUSION: The KL divergence between the true distribution Q and model M remains constant across any update that preserves the invariant I, so model improvement efforts must target quantities outside I to reduce divergence.", "rejected": "KL(Q||U(M)) = KL(Q||M) only if I(M) = I(U(M)).", "E_acc": 0.282532662153244, "C_acc": 0.29082807898521423, "G_acc": 0.5782631809512774, "D_acc": 0.7755089461803436, "H_acc": 0.194857656955719, "Q_acc": 0.5778628425796828, "E_rej": 0.30515462160110474, "C_rej": 0.26588428020477295, "G_rej": 0.5886108626921972, "D_rej": 0.6879857331514359, "H_rej": 0.31201426684856415, "Q_rej": 0.562487422923247, "Delta_Q": 0.01537541965643574, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["A proposition B is a set of truth values {T, F}.", "A proposition C is a set of truth values {T, F}.", "The statement “A implies B unless C” gives a truth function f of A, B, C.", "f equals T if either C is T or B is T; otherwise f equals F.", "The state of C is given by a truth function g of B.", "g equals T if B is T and equals F otherwise.", "The pair (B, C) forms the state vector s."]}, "accepted": "The premises define f(A,B,C)=T iff C=T or B=T, and g(B)=C with g=T exactly when B=T.  Hence C always equals B, so f reduces to T precisely when B is T.  Thus the truth of the compound statement is decided solely by B.\n\nHYPOTHESIS: The statement “A implies B unless C” is true exactly when B is true, independent of A.\n\nVERIFICATION: Direct substitution of C=B into f gives f=T ⇔ B=T, holding for every A∈{T,F}.\n\nCONCLUSION: B alone controls the truth value of the entire statement, so evaluating B suffices to determine f.", "rejected": "The statement “A implies B unless C” is true exactly when A is true, independent of B.", "E_acc": 0.19454698264598846, "C_acc": 0.5904533863067627, "G_acc": 0.5849333895991246, "D_acc": 0.7572615693012873, "H_acc": 0.26084035634994507, "Q_acc": 0.48262837367753186, "E_rej": 0.007585751824080944, "C_rej": 0.943891167640686, "G_rej": 0.5609422088600695, "D_rej": 0.7898613810539246, "H_rej": 0.21013861894607544, "Q_rej": 0.36264434810727836, "Delta_Q": 0.1199840255702535, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["A population is a finite set of individuals.", "Each individual expresses one strategy i from a discrete set S.", "The state x is the vector of strategy frequencies summing to 1.", "The payoff to strategy i is πᵢ(x).", "Fitness fᵢ(x) equals πᵢ(x).", "An ESS x* satisfies fᵢ(x*) ≥ fⱼ(x*) for all i in support of x* and for any invader strategy j at arbitrarily small frequency ε.", "A mutation introduces a new strategy k at frequency μ, shifting x to x' and altering all πᵢ(x')."]}, "accepted": "Because fitness equals payoff and an ESS forces every resident strategy to enjoy a fitness no lower than that of any rare invader, the post-mutation payoffs must preserve this ranking.  After the mutation shifts the state to x′, the fitness of any resident strategy i that remains in the support of the original ESS satisfies fᵢ(x′) ≥ fₖ(x′) for the mutant k; otherwise the ESS condition would be violated once the perturbation vanishes.\n\nHYPOTHESIS: For any ESS x* and an introduced mutant strategy k at frequency μ→0, the fitness of every resident strategy i in the support of x* after the mutation satisfies fᵢ(x′) ≥ fₖ(x′).\n\nVERIFICATION: Both sides carry units of fitness (payoff), and the inequality holds in the μ→0 limit where x′→x*.\n\nCONCLUSION: Resident strategies retain a post-entry fitness advantage, preventing the mutant from invading and preserving ESS stability.", "rejected": "For any ESS x* and an introduced mutant strategy k at frequency μ→0, the fitness of every resident strategy i in the support of x* after the mutation satisfies fᵢ(x′) ≥ fₖ(x′) even when μ is large.", "E_acc": 0.49472904205322266, "C_acc": 0.15555265545845032, "G_acc": 0.5790962632745504, "D_acc": 0.8175433516502381, "H_acc": 0.18086551129817963, "Q_acc": 0.6785495533794166, "E_rej": 0.0641237422823906, "C_rej": 0.5831795930862427, "G_rej": 0.601466026689325, "D_rej": 0.8862248361110687, "H_rej": 0.11377516388893127, "Q_rej": 0.48876186023865426, "Delta_Q": 0.18978769314076233, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Paradoxes from self-reference: formalize a system where an agent's utility depends on predictions of its own future actions and derive consistency constraints.", "ancestors": ["A set \\( X \\) contains agent \\( A \\).", "Time is indexed by non-negative integers \\( t \\).", "A history \\( h_t \\in H_t \\) records all actions up to \\( t \\).", "The agent chooses an action \\( a_t \\in \\mathcal{A} \\) at each \\( t \\).", "A predictor \\( P \\) outputs belief \\( p_t \\in \\Delta(\\mathcal{A}) \\) about \\( a_t \\).", "The agent's utility at \\( t \\) is \\( u_t(a_t, p_t) \\in \\mathbb{R} \\).", "The agent's total utility is \\( U = \\sum_{k=t}^{\\infty} \\delta^{k-t} u_k(a_k, p_k) \\) with \\( \\delta \\in [0,1) \\).", "A history \\( h_t \\) is consistent only if \\( p_k(a_k) > 0 \\) for every earlier \\( k < t \\)."]}, "accepted": "The consistency rule forces every realized action to have positive predicted probability, so the predictor never assigns zero to the event that actually occurs.  Because the agent’s instantaneous utility depends on the predictor’s belief, any action that would drive the predictor’s belief to zero is excluded from the feasible set at every step.  Therefore the agent’s choice set is restricted to actions whose minimal predicted probability is bounded away from zero.\n\nHYPOTHESIS: For every t, the agent selects an action a_t satisfying p_t(a_t) ≥ min_{a∈A} p_t(a) > 0.\n\nVERIFICATION: Probability is dimensionless and the inequality holds for every history consistent with the premises.\n\nCONCLUSION: The agent never chooses an action that the predictor deems impossible, so the support of p_t covers the actual action path.", "rejected": "The agent’s choice set is restricted to actions whose minimal predicted probability is bounded away from zero, therefore any action that would drive the predictor’s belief to zero is excluded from the feasible set at every step.", "E_acc": 0.3723973333835602, "C_acc": 0.2621113657951355, "G_acc": 0.5567358366097324, "D_acc": 0.755238709350427, "H_acc": 0.21491548418998718, "Q_acc": 0.6002002876290742, "E_rej": 0.26565977931022644, "C_rej": 0.2803794741630554, "G_rej": 0.5189422488911077, "D_rej": 0.755641758441925, "H_rej": 0.24435824155807495, "Q_rej": 0.5541030162712559, "Delta_Q": 0.04609727135781827, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase coexistence with finite-size effects: derive corrections to bulk phase diagrams for nanostructured assemblies and predict hysteresis.", "ancestors": ["Phase coexistence occurs when two distinct phases share a boundary at equilibrium.", "A phase is a homogeneous region of matter with uniform intensive properties.", "Boundary energy per unit area is γ.", "Total boundary area is A.", "Total boundary energy is E_b = γA.", "Volume is V.", "Characteristic length is L, so V ∝ L³ and A ∝ L².", "Ratio E_b/(kT) scales as γL²/(kT), where k is Boltzmann constant and T is temperature.", "Bulk free energy scales with V, so ΔG_bulk ∝ L³.", "Finite-size free-energy correction is ΔG_fs = γA = γcL² with geometric factor c > 0."]}, "accepted": "The premises give the finite-size correction to the free energy as ΔG_fs = γA = γcL² and the bulk free-energy change as ΔG_bulk ∝ L³.  Dividing the two yields ΔG_fs/ΔG_bulk ∝ γcL²/(ρL³) = γc/(ρL), where ρ is the proportionality constant for the bulk term.  Because this ratio scales inversely with L, there is a critical length below which the surface term dominates.\n\nHYPOTHESIS: Phase coexistence is thermodynamically stable only for systems larger than the critical length L_c = γc/ρ, where below L_c the finite-size correction outweighs the bulk free-energy gain.\n\nVERIFICATION: L_c has units of length (m), consistent with γ (J m⁻²), c (dimensionless), and ρ (J m⁻³).\n\nCONCLUSION: Systems smaller than L_c = γc/ρ cannot sustain stable phase coexistence because the boundary energy penalty exceeds the bulk free-energy benefit.", "rejected": "Phase coexistence is thermodynamically stable only for systems smaller than the critical length L_c = γc/ρ, where above L_c the finite-size correction outweighs the bulk free-energy gain.", "E_acc": 0.5489552617073059, "C_acc": 0.19526895880699158, "G_acc": 0.5439908347907476, "D_acc": 0.7708527718981107, "H_acc": 0.1335335373878479, "Q_acc": 0.6752481543497804, "E_rej": 0.12339791655540466, "C_rej": 0.24635322391986847, "G_rej": 0.5416116081178188, "D_rej": 0.8767295777797699, "H_rej": 0.1232704222202301, "Q_rej": 0.5590899251401424, "Delta_Q": 0.11615822920963792, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["VERTEX-COVER is the problem of choosing a minimum-cardinality set C ⊆ V such that every edge of an undirected graph G = (V,E) is incident to at least one vertex in C.", "Let x_v ∈ {0,1} indicate whether vertex v is chosen for C.", "The integer program min Σ_{v∈V} x_v subject to x_u + x_v ≥ 1 for every {u,v}∈E and x_v ∈ {0,1} for every v∈V exactly encodes VERTEX-COVER.", "Its linear-programming relaxation replaces each integrality constraint x_v ∈ {0,1} by 0 ≤ x_v ≤ 1.", "For the complete graph K_n with n ≥ 2, the optimal integer value is n − 1.", "For K_n the fractional solution x_v = 1/2 for every v∈V is feasible and attains objective value n/2.", "The integrality gap of this relaxation is the supremum of the ratio integer optimum / fractional optimum over all instances."]}, "accepted": "For K_n the integer optimum is n − 1 and the fractional optimum is n/2, so their ratio is (n − 1)/(n/2) = 2 − 2/n.  \nTaking the supremum over all n ≥ 2 gives 2, and no graph family in the premises exceeds this ratio.\n\nHYPOTHESIS: The integrality gap of the vertex-cover LP relaxation equals 2.\n\nVERIFICATION: Ratio is dimensionless and supremum is attained in the limit n → ∞.\n\nCONCLUSION: The worst-case performance gap between integer and fractional optimums is exactly a factor of 2.", "rejected": "For K_n the integer optimum is n − 1 and the fractional optimum is n/2, so their ratio is (n − 1)/(n/2) = 2 − 2/n, and this ratio is independent of the choice of n ≥ 2.", "E_acc": 0.32873794436454773, "C_acc": 0.2577047646045685, "G_acc": 0.5520528114866465, "D_acc": 0.7072282776236534, "H_acc": 0.12065765261650085, "Q_acc": 0.5868708829488606, "E_rej": 0.13842903077602386, "C_rej": 0.5345204472541809, "G_rej": 0.5348341384669766, "D_rej": 0.7319976687431335, "H_rej": 0.26800233125686646, "Q_rej": 0.46119074809830635, "Delta_Q": 0.12568013485055424, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multiscale pattern formation: given local interaction rules, deduce which global patterns are possible and which require fine-tuning of parameters.", "ancestors": ["Local interaction rules are functions that map the state of a neighborhood to the next state of a cell.", "A neighborhood N is the set of cells within a fixed distance r of a given cell.", "A local state s_i(t) is the discrete value of cell i at time t.", "A global pattern is the array of all local states {s_i(t)} across the lattice.", "A parameter set P is the collection of numeric constants inside the local rules.", "A pattern class C is the set of global patterns sharing a specified symmetry or density.", "A pattern is possible if at least one P drives the system into C from typical initial conditions.", "A pattern requires fine-tuning if the volume of suitable P in parameter space has measure zero.", "Measure zero is defined as Lebesgue measure less than any ε > 0."]}, "accepted": "Local interaction rules map neighborhood states to the next cell state, and a pattern class C is reachable only if the parameter set P occupies a non-zero volume in parameter space. Because “requires fine-tuning” is defined as that volume having Lebesgue measure zero, any C that is possible must lie in the complement of this measure-zero set. Hence the collection of possible pattern classes is restricted to those whose compatible P sets have strictly positive measure.\n\nHYPOTHESIS: A pattern class C is possible only if the Lebesgue measure of its compatible parameter set P is strictly greater than zero.\n\nVERIFICATION: Units consistent (measure is dimensionless); holds for any lattice size and rule radius.\n\nCONCLUSION: Pattern-class possibility is equivalent to μ(P)>0, eliminating all finely-tuned classes.", "rejected": "A pattern class C is possible if the Lebesgue measure of its compatible parameter set P is strictly greater than zero.", "E_acc": 0.2786058783531189, "C_acc": 0.4610558748245239, "G_acc": 0.5603073996358684, "D_acc": 0.7312605256835619, "H_acc": 0.13693030923604965, "Q_acc": 0.535991142681312, "E_rej": 0.1948213428258896, "C_rej": 0.7077668309211731, "G_rej": 0.5604455337992736, "D_rej": 0.7546798884868622, "H_rej": 0.24532011151313782, "Q_rej": 0.4553861099694456, "Delta_Q": 0.08060503271186636, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["A proof is a finite sequence of formulas each derived from axioms or preceding formulas.", "An invariant is a formula that is derivable after every formula in the sequence.", "A destructive update is a rule that replaces a set of formulas with a new set.", "Bayesian updating maps a prior probability measure to a posterior via the likelihood function.", "Model misspecification means the data-generating distribution is excluded from the considered family.", "Posterior concentration refers to the posterior measure assigning its limiting mass to a subset."]}, "accepted": "<derivation sentences>\nPremise variables: proof sequence, invariant, destructive update, Bayesian updating, model misspecification, posterior concentration.\nCase exploration:\n1. Proof sequence with invariant preserved under destructive update.\n2. Bayesian updating under misspecification with posterior concentration.\n3. Interaction: destructive update alters the considered family of distributions.\nElimination: Case 1 lacks probabilistic content; Case 2 is directly supported by premises; Case 3 extends minimally by linking update rule to family alteration.\nDerive: Under model misspecification, the posterior cannot concentrate on the true parameter; destructive update that removes neighborhoods of the data-generating distribution prevents even approximate concentration.\n</derivation sentences>\n\nHYPOTHESIS: If a destructive update removes every distribution within ε total-variation distance of the data-generating measure, the posterior probability assigned to the remaining set converges to 1 as sample size n→∞.\nVERIFICATION: Units dimensionless (probability), regime holds under misspecification and ε>0 fixed.\nCONCLUSION: The update enforces posterior concentration on the least-incompatible surviving distributions, yielding a falsifiable ε-threshold for model revision.", "rejected": "If a destructive update removes every distribution within ε total-variation distance of the data-generating measure, the posterior probability assigned to the remaining set equals ε·n as sample size n→∞.", "E_acc": 0.6702910661697388, "C_acc": 0.16743382811546326, "G_acc": 0.5712137725204229, "D_acc": 0.6907470356673002, "H_acc": 0.13801497220993042, "Q_acc": 0.7061912186443806, "E_rej": 0.12999558448791504, "C_rej": 0.12032889574766159, "G_rej": 0.5619610494177323, "D_rej": 0.7853769361972809, "H_rej": 0.21462306380271912, "Q_rej": 0.562938186939573, "Delta_Q": 0.14325303170480763, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["A symbolic expression is a finite tree of operators and operands.", "An equivalence relation ~ partitions expressions into equivalence classes.", "A rewrite rule is a pair (L, R) of expressions with L ~ R.", "A certificate is a machine-checkable object that attests L ~ R.", "A certificate system C maps every valid rule (L, R) to certificate c.", "A verifier V(c, L, R) outputs true iff c attests L ~ R in C."]}, "accepted": "Because every rewrite rule (L,R) is required to satisfy L~R, the certificate system C must assign to that rule at least one certificate c that the verifier V accepts.  \nWith V(c,L,R)=true as the acceptance condition, the number of distinct certificates returned by C for any given rule is lower-bounded by 1.\n\nHYPOTHESIS: For every valid rewrite rule (L,R), the certificate system C outputs at least one certificate c such that V(c,L,R)=true.\n\nVERIFICATION: Counting argument—minimum cardinality 1 per rule.\n\nCONCLUSION: C is complete in the sense that no valid rule is left without an accepted certificate.", "rejected": "For every valid rewrite rule (L,R), the certificate system C outputs at least one certificate c such that V(c,L,R)=false.", "E_acc": 0.3602934777736664, "C_acc": 0.09790883213281631, "G_acc": 0.5713679995387793, "D_acc": 0.7483069717884063, "H_acc": 0.32814275473356247, "Q_acc": 0.6196269956976176, "E_rej": 0.07719513028860092, "C_rej": 0.8308076858520508, "G_rej": 0.5716821444220841, "D_rej": 0.7617218792438507, "H_rej": 0.2382781207561493, "Q_rej": 0.39984999457374215, "Delta_Q": 0.21977700112387544, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Measurement back-action trade-offs: quantify how much information gain about an observable forces disturbance on its incompatible conjugates.Information flow in regulatory networks: identify motifs that guarantee robust signal propagation despite stochastic expression and component failure.", "ancestors": ["A quantum observable is represented by a Hermitian operator A.", "A conjugate observable to A is an operator B satisfying [A,B]≠0.", "The Robertson uncertainty relation gives ΔA ΔB ≥|⟨[A,B]⟩|/2.", "A measurement of A with outcome a collapses the state to an eigenstate |a⟩ of A.", "The post-measurement state |a⟩ is not an eigenstate of B unless [A,B]=0.", "The disturbance of B is quantified by the change in its variance from pre- to post-measurement.", "Let G be the information gain about A, defined as the decrease in Shannon entropy H(A).", "The measurement back-action cost is the increase in H(B) induced by the A-measurement.", "For any measurement, G>0 implies ΔH(B)≥k|⟨[A,B]⟩| with k a positive constant."]}, "accepted": "The premises link information gain G about A to a lower bound on the entropy jump ΔH(B) via the commutator expectation.  Inserting the Robertson bound |⟨[A,B]⟩|/2 ≤ ΔA ΔB into the back-action inequality ΔH(B) ≥ k|⟨[A,B]⟩| gives ΔH(B) ≥ 2k ΔA ΔB.  Rearranging yields a state-independent trade-off between the two variances once G>0.\n\nHYPOTHESIS: Any measurement that yields non-zero information G about A enforces the lower bound ΔA ΔB ≥ ΔH(B)/(2k).\n\nVERIFICATION: Both sides have units of action (J·s), matching the commutator; valid whenever G>0.\n\nCONCLUSION: The product of conjugate uncertainties is bounded below by the entropy increase in B scaled by the fixed constant 2k.", "rejected": "Any measurement that yields non-zero information G about A enforces the lower bound ΔA ΔB ≥ ΔH(B)/(2k) even when the commutator expectation vanishes.", "E_acc": 0.29883745312690735, "C_acc": 0.48872387409210205, "G_acc": 0.5456609669407564, "D_acc": 0.726712055504322, "H_acc": 0.15161040425300598, "Q_acc": 0.531220025183367, "E_rej": 0.29304951429367065, "C_rej": 0.40248629450798035, "G_rej": 0.5411185796505639, "D_rej": 0.8115853071212769, "H_rej": 0.18841469287872314, "Q_rej": 0.559116903453001, "Delta_Q": -0.02789687826963405, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["Premise: A symbolic expression E is a finite syntax tree over operators and atoms.", "Premise: An equivalence relation ≡ partitions expressions into equivalence classes.", "Premise: A simplifier S maps E to an expression S(E) such that S(E) ≡ E.", "Premise: A certificate C is a datum reconstructible by a verifier V.", "Premise: A rewrite step is a triple (L, R, σ) where σ instantiates variables of L and R.", "Premise: A certificate chain is a finite sequence of rewrite steps from E to S(E).", "Premise: A verifier V accepts C if every rewrite step in C is an instance of an axiom in a fixed set A."]}, "accepted": "Because every rewrite step in a certificate chain must instantiate an axiom of A and the chain is finite, the number of distinct axiom instances that can appear in any valid certificate is bounded above by the length of that chain.  \nHYPOTHESIS: The maximum number of distinct axiom instances usable in a certificate chain for any expression E is exactly the length of the chain.  \nVERIFICATION: Unitless count; holds for every finite chain.  \nCONCLUSION: A verifier needs only to store |chain| axiom instances to check any given certificate.", "rejected": "Because the number of distinct axiom instances that can appear in any valid certificate is bounded above by the length of that chain, every rewrite step in a certificate chain must instantiate an axiom of A and the chain is finite.", "E_acc": 0.4214572012424469, "C_acc": 0.29303795099258423, "G_acc": 0.5323807448148727, "D_acc": 0.7631486020982265, "H_acc": 0.28749242424964905, "Q_acc": 0.5981861971318722, "E_rej": 0.6379739046096802, "C_rej": 0.04618401080369949, "G_rej": 0.5463784895837307, "D_rej": 0.7382402271032333, "H_rej": 0.32719971612095833, "Q_rej": 0.7063591409474611, "Delta_Q": -0.10817294381558895, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["A set X contains n distinct elements.", "A partition P of X is a set of non-empty disjoint subsets of X whose union is X.", "Let P have k subsets denoted P1,…,Pk.", "An operation f maps each Pi to an output space Y.", "A task T is a function from the k-tuple (f(P1),…,f(Pk)) to Y.", "Let G be the set of all finite sequences o=(o1,…,om) with each oj drawn from Y.", "A composition rule c is a function that maps each o∈G to a value in Y.", "Given any partition P and any f, a novel task Tnew is specified by a composition rule c applied to the sequence yielded by f on P."]}, "accepted": "The premises define a partition P of n elements into k non-empty blocks, an operation f that maps each block to a value in Y, and a composition rule c that collapses any finite sequence of Y-values into a single Y-value.  Because every partition has at least one block (k ≥ 1) and each block is non-empty, the shortest possible sequence that c can receive is the single-element sequence (f(P1)).  Consequently, the rule c must assign a definite Y-value to every one-element sequence; otherwise the novel task Tnew would be undefined for the coarsest partition k = 1.\n\nHYPOTHESIS: For every y ∈ Y, c((y)) = y.\nVERIFICATION: Units consistent (both sides in Y); holds for k = 1 partition.\nCONCLUSION: The composition rule c acts as the identity on one-element sequences, ensuring Tnew is always defined.", "rejected": "For every y ∈ Y, y = c((y)).", "E_acc": 0.6011074781417847, "C_acc": 0.19499537348747253, "G_acc": 0.5380448026407976, "D_acc": 0.7452995528777441, "H_acc": 0.21085157990455627, "Q_acc": 0.6769168818582936, "E_rej": 0.6756091117858887, "C_rej": 0.13718555867671967, "G_rej": 0.5252698801923543, "D_rej": 0.6862843185663223, "H_rej": 0.3137156814336777, "Q_rej": 0.6861848934087903, "Delta_Q": -0.009268011550496724, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Biomass B is measured in grams.", "Metabolic rate r is measured in grams per hour.", "Resource supply R(t) varies in time.", "Pathway P is discrete state index i ∈ {1, 2}.", "r is function of P and R, written r(P, R).", "Switching actions change i.", "Switching incurs fixed cost k in grams.", "Elapsed switching time is Tsw in hours.", "Gain rate during switching is zero.", "Control policy is sequence of i values."]}, "accepted": "Because switching incurs a fixed biomass cost k while the gain rate is zero for the duration Tsw, the organism must forfeit exactly k grams during every switch.  Hence the average biomass loss per switch is k, and any control policy that performs a switch necessarily reduces the cumulative biomass by this amount.\n\nHYPOTHESIS: Each discrete switch between pathway states decreases the organism’s biomass by exactly k grams.\n\nVERIFICATION: Units consistent (k in grams, biomass in grams).\n\nCONCLUSION: The cumulative biomass cost of a control policy equals the number of switches multiplied by k.", "rejected": "The organism’s biomass decreases by exactly k grams only if a discrete switch between pathway states occurs.", "E_acc": 0.757093608379364, "C_acc": 0.07869245111942291, "G_acc": 0.5992880766279995, "D_acc": 0.8263005673885345, "H_acc": 0.15742171555757523, "Q_acc": 0.780765149537474, "E_rej": 0.055785711854696274, "C_rej": 0.6358855366706848, "G_rej": 0.5920778319705278, "D_rej": 0.8170843422412872, "H_rej": 0.18291565775871277, "Q_rej": 0.45309947528876365, "Delta_Q": 0.32766567424871035, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["Let X be a real-valued random variable with distribution P.", "The tail probability at threshold t is p_t = P(X > t).", "An empirical estimator of p_t from n i.i.d. samples {x_i} is p̂_t = (1/n) Σ_{i=1}^n 𝟙{x_i > t}.", "Rare-event estimation requires small p_t and large t.", "An adversarial sampler draws x_i from a biased proposal Q instead of P.", "The importance weight for each x_i is w_i = P(x_i)/Q(x_i).", "The importance-weighted tail estimator is p̃_t = (1/n) Σ_{i=1}^n w_i · 𝟙{x_i > t}."]}, "accepted": "<derivation sentences>\nThe premises define two estimators for the tail probability p_t: the empirical estimator p̂_t and the importance-weighted estimator p̃_t. Both are sample averages over n i.i.d. observations, but p̃_t uses importance weights w_i = P(x_i)/Q(x_i) to correct for sampling from a biased proposal Q. To compare their variances, we examine the second moments. For p̂_t, the variance is Var[p̂_t] = (1/n) p_t (1 - p_t). For p̃_t, the variance is Var[p̃_t] = (1/n) Var_Q[w · 𝟙{X > t}], where the expectation is under Q. Expanding this: Var_Q[w · 𝟙{X > t}] = E_Q[(w · 𝟙{X > t})^2] - (E_Q[w · 𝟙{X > t}])^2. The second term is p_t^2 since E_Q[w · 𝟙{X > t}] = p_t. The first term is E_Q[w^2 · 𝟙{X > t}] = E_P[w · 𝟙{X > t}] = E_P[w | X > t] · p_t. Thus, Var[p̃_t] = (1/n) (E_P[w | X > t] · p_t - p_t^2) = (1/n) p_t (E_P[w | X > t] - p_t). The variance reduction condition Var[p̃_t] < Var[p̂_t] simplifies to E_P[w | X > t] < 1. This is achievable when Q concentrates mass on the tail region, making w small for X > t.\n</derivation sentences>\n\nHYPOTHESIS: The importance-weighted estimator p̃_t achieves lower variance than the empirical estimator p̂_t if and only if the conditional expectation of the importance weight over the tail region satisfies E_P[w | X > t] < 1.\n\nVERIFICATION: Units: E_P[w | X > t] is dimensionless; inequality holds when Q over-weights the tail.\n\nCONCLUSION: Use p̃_t instead of p̂_t whenever the biased sampler Q assigns higher density to the tail region than P, ensuring E_P[w | X > t] < 1 and thus Var[p̃_t] < Var[p̂_t].", "rejected": "The importance-weighted estimator p̃_t achieves lower variance than the empirical estimator p̂_t if and only if the conditional expectation of the importance weight over the tail region satisfies E_Q[w | X > t] < 1.", "E_acc": 0.5446366667747498, "C_acc": 0.1894518882036209, "G_acc": 0.5358113092370331, "D_acc": 0.6775558768388104, "H_acc": 0.17502814531326294, "Q_acc": 0.6506712450755431, "E_rej": 0.23731426894664764, "C_rej": 0.4924527108669281, "G_rej": 0.5443115599337034, "D_rej": 0.8448137640953064, "H_rej": 0.1551862359046936, "Q_rej": 0.5350101797259413, "Delta_Q": 0.11566106534960174, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["A set of agents N shares an undirected graph G = (V, E).", "Each agent i ∈ N chooses one sᵢ–tᵢ path in G.", "Each edge e ∈ E has a non-negative congestion cost cₑ(ℓₑ), where ℓₑ is edge load.", "ℓₑ = |{i : e is on i's chosen path}|.", "A routing profile P is a multiset {pᵢ}ᵢ∈N of chosen paths.", "The cost of profile P is W(P) = Σᵢ Σ_{e ∈ pᵢ} cₑ(ℓₑ)."]}, "accepted": "Summing the individual contributions gives the total congestion cost.  \nBecause every edge e is counted in exactly ℓₑ paths, the double sum over agents and their edges collapses to a single sum over edges weighted by load:\n\nΣᵢ Σ_{e∈pᵢ} cₑ(ℓₑ) = Σ_{e∈E} ℓₑ cₑ(ℓₑ).\n\nHYPOTHESIS: The total cost of any routing profile equals W(P)=Σ_{e∈E} ℓₑ cₑ(ℓₑ).\n\nVERIFICATION: Units: ℓₑ (dimensionless count) × cₑ (cost units) → cost units, summed over edges gives total cost.\n\nCONCLUSION: Total cost is exactly the load-weighted sum of edge congestion costs.", "rejected": "The total cost of any routing profile equals W(P)=Σ_{e∈E} cₑ(ℓₑ).", "E_acc": 0.6464169025421143, "C_acc": 0.12948064506053925, "G_acc": 0.5864070768335036, "D_acc": 0.7782627791166306, "H_acc": 0.11974799633026123, "Q_acc": 0.7289881133075272, "E_rej": 0.6746464967727661, "C_rej": 0.13525116443634033, "G_rej": 0.5871025699057749, "D_rej": 0.8584246933460236, "H_rej": 0.14157530665397644, "Q_rej": 0.7502916381295238, "Delta_Q": -0.0213035248219966, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Biomass B is measured as dry cell mass per liter.", "Resource supply R(t) > 0 is time-dependent.", "Uptake rate v(R) saturates at v_max.", "Internal carbon A₁ is measured in grams of carbon per cell.", "Catalytic rate k governs the flow A₁ → B.", "Flow A₁ → B stops below a threshold s₀.", "Switching flux Φ incurs a cost ΔB < 0.", "Time τ is the system clock in hours.", "Long-run biomass B̄ is the time-average of B(t) over T → ∞."]}, "accepted": "Because the catalytic flow A₁→B is inactive while A₁<s₀, the biomass production rate is zero in that regime; integrating this halt over any interval where A₁ remains below s₀ shows that the long-run average biomass B̄ is strictly bounded by the fraction of time that A₁ exceeds s₀.  \nHYPOTHESIS: The long-run biomass average satisfies B̄ ≤ v_max·(fraction of τ with A₁≥s₀)/k.  \nVERIFICATION: Units (g L⁻¹) on both sides; inequality holds whenever the internal carbon threshold governs the reaction.  \nCONCLUSION: B̄ is quantitately capped by the relative uptime of the A₁→B pathway.", "rejected": "The long-run biomass average satisfies B̄ ≥ v_max·(fraction of τ with A₁≥s₀)/k.", "E_acc": 0.4175383746623993, "C_acc": 0.25627583265304565, "G_acc": 0.5654278710135259, "D_acc": 0.7768432423472404, "H_acc": 0.17058542370796204, "Q_acc": 0.6254020261694677, "E_rej": 0.19049102067947388, "C_rej": 0.21883904933929443, "G_rej": 0.5648102490813471, "D_rej": 0.8248035609722137, "H_rej": 0.17519643902778625, "Q_rej": 0.5737826144439169, "Delta_Q": 0.051619411725550846, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["H is a finite set of competing hypotheses.", "C is a finite set of candidate experiments.", "c(e) is the positive real cost of experiment e in C.", "P(h) is the prior probability of hypothesis h in H.", "P(h | e) is the posterior probability of h after executing experiment e.", "The information gain of e is the reduction in entropy of H from prior to posterior.", "A selection strategy chooses e* in C that maximizes the ratio of information gain to cost."]}, "accepted": "The premises define a cost-weighted information-gain ratio for every candidate experiment. Because entropy is non-negative and costs are strictly positive, this ratio is bounded below by zero and above by the finite maximum of (log₂|H|)/c_min, where |H| is the number of hypotheses and c_min is the smallest cost in C. Hence the maximizing experiment e* always satisfies a simple inequality.\n\nHYPOTHESIS: The selected experiment e* satisfies IG(e*)/c(e*) ≥ (log₂|H|)/c_max, where IG(e*) is its information gain in bits and c_max is the largest cost in C.\n\nVERIFICATION: Both sides have units of bits per unit cost; inequality holds for any non-degenerate prior.\n\nCONCLUSION: Any experiment whose cost exceeds c_max must deliver at least (log₂|H|)/c_max bits of information per unit cost to be selectable.", "rejected": "The selected experiment e* satisfies IG(e*)/c(e*) ≥ (log₂|C|)/c_max, where IG(e*) is its information gain in bits and c_max is the largest cost in C.", "E_acc": 0.3566230237483978, "C_acc": 0.19847001135349274, "G_acc": 0.5516016773763113, "D_acc": 0.7880747069915136, "H_acc": 0.2661229223012924, "Q_acc": 0.6086158894972566, "E_rej": 0.5024009943008423, "C_rej": 0.11459221690893173, "G_rej": 0.5588381451088935, "D_rej": 0.811199814081192, "H_rej": 0.18880018591880798, "Q_rej": 0.6829294281546028, "Delta_Q": -0.07431353865734613, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy bookkeeping in non-Markovian environments: propose a consistent definition of work/heat when the bath stores long-lived correlations.", "ancestors": ["The system Hamiltonian H_sys is a time-independent operator on the system Hilbert space.", "The bath Hamiltonian H_bath is a time-independent operator on the bath Hilbert space.", "The composite density operator ρ(t) acts on the tensor product space H_sys ⊗ H_bath.", "The global Hamiltonian H(t) = H_sys + H_bath + V(t) includes apossibly time-dependent interaction V(t).", "The total von Neumann entropy S(t) = −Tr[ρ(t) ln ρ(t)] is defined for the composite state.", "The global state evolves unitarily under H(t) via ρ(t) = U(t,0) ρ(0) U†(t,0).", "The mutual information I(t) = S_sys(t) + S_bath(t) − S(t) quantifies correlations between subsystem states.", "The internal system energy E_sys(t) = Tr[ρ_sys(t) H_sys] is a partial trace quantity."]}, "accepted": "The global von Neumann entropy S(t) is conserved under the unitary evolution generated by the possibly time-dependent Hamiltonian H(t), because the von Neumann entropy of any density operator is invariant under unitary conjugation.  \nHYPOTHESIS: The total von Neumann entropy S(t) is constant for all times t.  \nVERIFICATION: Units of S(t) are dimensionless; result holds for any unitary evolution on H_sys ⊗ H_bath.  \nCONCLUSION: S(t) = S(0) for every t, providing a strict entropy conservation law for the composite system.", "rejected": "The global von Neumann entropy S(t) is conserved under the unitary evolution generated by the possibly time-dependent Hamiltonian H(t), because the von Neumann entropy of any density operator is invariant under unitary conjugation.", "E_acc": 0.3446349799633026, "C_acc": 0.344758540391922, "G_acc": 0.5849156675394624, "D_acc": 0.7790476903319359, "H_acc": 0.1446901261806488, "Q_acc": 0.5927624448668212, "E_rej": 0.22520402073860168, "C_rej": 0.4673652946949005, "G_rej": 0.5708597972989082, "D_rej": 0.8374215960502625, "H_rej": 0.16257840394973755, "Q_rej": 0.5394865855574609, "Delta_Q": 0.053275859309360296, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["P is a binary predicate on a domain D.", "∀x∈D ∃y∈D P(x,y) holds.", "A cost function c: D×D → ℕ is monotone in its second argument.", "A strategy is a total function f: D → D satisfying ∀x P(x,f(x)).", "The cost of f at x is c(x,f(x)).", "A feasible strategy satisfies ∃k∈ℕ ∀x c(x,f(x)) ≤ k."]}, "accepted": "The premises guarantee that for every element x a strategy image y=f(x) exists, and the cost c(x,f(x)) is a natural number.  Because the set of natural numbers is well-ordered, every non-empty subset has a least element; hence for each x the set {c(x,y) | P(x,y)} has a minimum.  Selecting for each x a minimizer y_x yields a strategy whose pointwise cost is this minimum, so the function x ↦ min{c(x,y) | P(x,y)} is well-defined and finite-valued.\n\nHYPOTHESIS: For every x∈D the quantity m(x)=min{c(x,y) | y∈D and P(x,y)} exists and satisfies m(x)≤c(x,f(x)) for every strategy f.\n\nVERIFICATION: Units: both sides are natural numbers; regime: universal over all strategies.\n\nCONCLUSION: The pointwise minimum cost m(x) provides a universal lower bound for the cost of any strategy at x.", "rejected": "For every x∈D the quantity m(x)=min{c(x,y) | y∈D and P(x,y)} exists and satisfies m(x)+k=c(x,f(x)) for every strategy f and some fixed k∈ℕ.", "E_acc": 0.45875972509384155, "C_acc": 0.2265917956829071, "G_acc": 0.5752102744299918, "D_acc": 0.7782230911155542, "H_acc": 0.15551958233118057, "Q_acc": 0.6474442732675622, "E_rej": 0.5819076895713806, "C_rej": 0.1557633876800537, "G_rej": 0.582486025756225, "D_rej": 0.8565210998058319, "H_rej": 0.1434789001941681, "Q_rej": 0.7168731644283981, "Delta_Q": -0.06942889116083595, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["Let G=(V,E) be an undirected graph.", "Let w:E→ℤ≥0 assign each edge a non-negative integer weight.", "A cut is a partition (S,V\\S) with ∅≠S⊂V.", "The weight of a cut is ∑_{e∈δ(S)} w(e), where δ(S) is the set of edges with exactly one endpoint in S.", "The Max-Cut problem seeks a cut of maximum weight.", "Max-Cut is NP-hard.", "For each edge e∈E introduce variable x_e∈[0,1].", "For each cycle C⊆E and each F⊆C with |F| odd, add constraint ∑_{e∈F}x_e − ∑_{e∈C\\F}x_e ≤ |F|−1.", "Maximize ∑_{e∈E} w(e)x_e over these constraints.", "This linear program has integrality gap 2−ε for every ε>0."]}, "accepted": "The linear program relaxes the binary edge-selection variables to the interval [0,1] and enforces cycle-parity inequalities that any integral cut must satisfy. Because the integrality gap is 2−ε, the optimum fractional value is at least half the maximum cut weight and can be arbitrarily close to twice the weight of the best integral cut.\n\nHYPOTHESIS: The fractional optimum of the given linear program is at least half the weight of the maximum cut and can be as large as (2−ε) times that weight for every ε>0.\n\nVERIFICATION: Units consistent (both sides in edge-weight units), regime holds for every undirected graph with non-negative weights.\n\nCONCLUSION: The LP provides a polynomial-time 2-approximation for Max-Cut, and this ratio is tight.", "rejected": "The fractional optimum of the given linear program is at most half the weight of the maximum cut and can be as small as (2−ε) times that weight for every ε>0.", "E_acc": 0.4829740822315216, "C_acc": 0.1417488306760788, "G_acc": 0.5604432155378163, "D_acc": 0.7678761631250381, "H_acc": 0.1536393165588379, "Q_acc": 0.6668424026109279, "E_rej": 0.46333616971969604, "C_rej": 0.22993263602256775, "G_rej": 0.5758817213354632, "D_rej": 0.8167324364185333, "H_rej": 0.18326756358146667, "Q_rej": 0.653210398904048, "Delta_Q": 0.013632003706879892, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["A population is a finite set of individuals.", "Each individual adopts a strategy drawn from a discrete set S.", "The frequency of strategy i in the population is denoted p_i.", "The vector p = (p_i) satisfies Σ p_i = 1 and p_i ≥ 0 for all i.", "A payoff matrix A = (a_{ij}) gives the payoff to strategy i against j.", "The expected payoff to strategy i is f_i(p) = Σ_j a_{ij} p_j.", "The average population payoff is φ(p) = Σ_i p_i f_i(p).", "A strategy i is an ESS if for every mutant strategy m at small frequency ε, f_i(p(ε)) > f_m(p(ε)).", "The post-entry frequencies are p_i(ε) = (1 − ε) and p_m(ε) = ε with others reduced proportionally.", "A novel strategy enters by mutation at rate μ per reproduction event."]}, "accepted": "Deriving the invasion barrier for an ESS: when a rare mutant m enters, the post-entry frequencies become p_i(ε)=(1−ε)p_i for all resident strategies and p_m(ε)=ε.  The ESS condition requires f_i(p(ε))>f_m(p(ε)) for every ε below a critical threshold ε*.  Expanding both sides to first order in ε and using the linearity of payoffs gives the inequality Σ_j a_{ij}p_j − Σ_j a_{mj}p_j > ε[Σ_j(a_{ij}−a_{mj})p_j − (f_i(p)−f_m(p))].  Solving for the largest ε that preserves the strict inequality yields ε*= (f_i(p)−f_m(p))/(f_i(p)−f_m(p)+Σ_j(a_{mj}−a_{ij})p_j).\n\nHYPOTHESIS: A strategy i that is an ESS has a minimal invasion barrier ε* = (f_i(p) − f_m(p)) / (f_i(p) − f_m(p) + Σ_j (a_{mj} − a_{ij}) p_j) below which any rare mutant m cannot increase.\n\nVERIFICATION: ε* is dimensionless and valid whenever the denominator is positive, ensuring 0<ε*≤1.\n\nCONCLUSION: Population-genetic management can maintain ESS i by keeping mutant inflow below ε* per generation.", "rejected": "A strategy i that is an ESS has a minimal invasion barrier ε* = (f_i(p) − f_m(p)) / (f_i(p) − f_m(p) + Σ_j (a_{mj} − a_{ij}) p_j) plus the scalar 0.1.", "E_acc": 0.41806674003601074, "C_acc": 0.23515664041042328, "G_acc": 0.5585490986704826, "D_acc": 0.7095089347234794, "H_acc": 0.14577540755271912, "Q_acc": 0.6174227598522392, "E_rej": 0.29984158277511597, "C_rej": 0.21462717652320862, "G_rej": 0.5464597365644295, "D_rej": 0.7586180567741394, "H_rej": 0.2413819432258606, "Q_rej": 0.5839044038730208, "Delta_Q": 0.03351835597921837, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transport-limited reactivity: when diffusion and surface reaction couple nonlinearly, identify regimes where modifying transport is more effective than altering surface chemistry.", "ancestors": ["Diffusion is molecular transport driven by concentration gradients.", "Surface reaction converts species at an interface.", "The diffusion coefficient is denoted D.", "The surface reaction rate constant is denoted k.", "The Damköhler number Da is defined as Da = kL/D, where L is a characteristic length.", "Da compares the rate of surface reaction to the rate of diffusion.", "When Da ≫ 1, the process is diffusion-limited.", "When Da ≪ 1, the process is reaction-limited.", "In diffusion-limited regimes, the overall rate is governed by D.", "In reaction-limited regimes, the overall rate is governed by k."]}, "accepted": "The Damköhler number Da = kL/D separates two asymptotic regimes. When Da exceeds unity, diffusion is the slower, rate-controlling step; when Da is below unity, the surface reaction is slower and thus controls the overall rate. The crossover between these regimes occurs precisely at Da = 1, where the characteristic diffusion time L²/D equals the characteristic reaction time 1/k.\n\nHYPOTHESIS: The overall rate switches from reaction control to diffusion control at the critical Damköhler number Da = 1.\n\nVERIFICATION: Da is dimensionless; the equality marks the point where diffusion and reaction timescales are equal.\n\nCONCLUSION: For any system with given k, L, D, compute Da; if Da > 1, increasing D will increase the overall rate, whereas if Da < 1, increasing k will increase the overall rate.", "rejected": "The overall rate switches from diffusion control to reaction control at the critical Damköhler number Da = 1.", "E_acc": 0.25088948011398315, "C_acc": 0.5617905259132385, "G_acc": 0.5770346916979179, "D_acc": 0.8090631614128748, "H_acc": 0.10694482922554016, "Q_acc": 0.5294338265511518, "E_rej": 0.5567542314529419, "C_rej": 0.10253967344760895, "G_rej": 0.5539287502760999, "D_rej": 0.8475434482097626, "H_rej": 0.15245655179023743, "Q_rej": 0.7115671192645097, "Delta_Q": -0.18213329271335787, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["Let O be the evidence set that is known to be true.", "Let R be a finite set of rules that transforms antecedents into consequents.", "A hypothesis h is a subset of the consequents of R that contains every member of O.", "The explanatory assumptions of h are the antecedent statements of R required to deduce h.", "Let k(h) equal the count of assumptions required to derive h from R.", "Let R be perturbed by replacing any one consequent with a newly observed one and record the fraction of prior hypotheses that remain derivable."]}, "accepted": "The premises define k(h) as the count of antecedent assumptions required to derive a hypothesis h from the rule set R.  When R is perturbed by replacing any single consequent with a newly observed one, the fraction of prior hypotheses that remain derivable is recorded.  Because every hypothesis must contain the evidence set O, any perturbation that removes or alters a consequent appearing in O forces every prior h to be re-derived; the minimal assumption count for any such re-derived hypothesis cannot be less than k(h)−1, since at least one antecedent used before may no longer apply.\n\nHYPOTHESIS: After a single consequent perturbation that affects O, every re-derived hypothesis requires at least k(h)−1 assumptions.\n\nVERIFICATION: Units are dimensionless counts; regime is finite rule systems with |R|≥2.\n\nCONCLUSION: The perturbation lowers the minimum assumption count by at most one, establishing k(h)−1 as the new derivational floor.", "rejected": "After a single consequent perturbation that affects O, every re-derived hypothesis requires at most k(h)−1 assumptions.", "E_acc": 0.708816647529602, "C_acc": 0.1035909429192543, "G_acc": 0.5444370202720166, "D_acc": 0.8063511252403259, "H_acc": 0.1873275339603424, "Q_acc": 0.7433516813814641, "E_rej": 0.6207208633422852, "C_rej": 0.07709187269210815, "G_rej": 0.5332441084086895, "D_rej": 0.7946420311927795, "H_rej": 0.20535796880722046, "Q_rej": 0.7158393155038357, "Delta_Q": 0.027512365877628397, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Measurement back-action trade-offs: quantify how much information gain about an observable forces disturbance on its incompatible conjugates.Information flow in regulatory networks: identify motifs that guarantee robust signal propagation despite stochastic expression and component failure.", "ancestors": ["The commutator [A,B]=AB-BA quantifies operator incompatibility.", "When [A,B]≠0, eigenstates of A are superpositions of B-eigenstates.", "A projective measurement of A with outcome a_i collapses the state to |a_i⟩.", "The post-measureture state |a_i⟩ carries no definite B-eigenvalue.", "Consequently, the B distribution after an A-measurement is generally broader.", "The mean squared change in B, ΔB², obeys ΔA ΔB ≥ ½|⟨[A,B]⟩|.", "Hence gaining information about A (reducing ΔA) can increase ΔB.", "This increase in ΔB quantifies the measurement back-action on conjugate observable B."]}, "accepted": "The premises link information gain in A to back-action on B via the uncertainty relation ΔA ΔB ≥ ½|⟨[A,B]⟩|.  Shrinking ΔA to ε forces ΔB to at least ½|⟨[A,B]⟩|/ε, so the mean-squared change in B scales inversely with the squared A-resolution.\n\nHYPOTHESIS: For any non-commuting pair (A,B), reducing the post-measurement uncertainty in A to ε sets a lower bound ΔB ≥ ½|⟨[A,B]⟩|/ε on the resulting B-spread.\n\nVERIFICATION: Units consistent: [ΔB]=[B], [ε]=[A], [⟨[A,B]⟩]=[A][B], so rhs units match; valid for arbitrary ε>0.\n\nCONCLUSION: The inverse proportionality ε⁻¹ quantifies the minimal back-action cost of sharpening A.", "rejected": "For any non-commuting pair (A,B), reducing the post-measurement uncertainty in A to ε sets a lower bound ΔB ≤ ½|⟨[A,B]⟩|/ε on the resulting B-spread.", "E_acc": 0.48689767718315125, "C_acc": 0.20148032903671265, "G_acc": 0.5856355768628418, "D_acc": 0.7330738365650177, "H_acc": 0.2145964652299881, "Q_acc": 0.6480554735101759, "E_rej": 0.3994585871696472, "C_rej": 0.24014556407928467, "G_rej": 0.5756057382095605, "D_rej": 0.7946279644966125, "H_rej": 0.20537203550338745, "Q_rej": 0.6253180003259331, "Delta_Q": 0.022737473184242796, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["∀x ∃y P(x,y) is a first-order sentence with unary universal and existential quantifiers.", "Let f(x)=y denote the Skolem function such that P(x, f(x)) holds for every x.", "Define a monotone cost function c(y) with c(y₁) ≤ c(y₂) if y₁ ≤ y₂ in some order.", "For any input x, the resource cost to obtain y is measured by c(f(x)).", "By monotonicity, any larger requirement z ≥ f(x) satisfies c(f(x)) ≤ c(z).", "Feasibility here means c(f(x)) ≤ T(x) for a given explicit resource bound T(x)."]}, "accepted": "The premises guarantee for every x a minimal witness y = f(x) satisfying P(x, f(x)) and c(f(x)) ≤ T(x).  \nBecause c is monotone, any y′ ≥ f(x) also satisfies c(y′) ≥ c(f(x)) and hence c(y′) ≤ T(x) only if y′ lies in the closed interval [f(x), y_max(x)] where y_max(x) is the largest value obeying c(y) ≤ T(x).  \nThus feasibility for x is preserved precisely for witnesses in this bounded interval.\n\nHYPOTHESIS: For every x, the set of feasible witnesses is the closed interval [f(x), y_max(x)] with c(y_max(x)) = T(x).\n\nVERIFICATION: Units of c and T match; interval collapses to {f(x)} when c(f(x)) = T(x).\n\nCONCLUSION: Resource bounds restrict admissible witnesses to a monotone segment bounded below by the Skolem witness and above by the budget T(x).", "rejected": "For every x, the set of feasible witnesses is the closed interval [f(x), y_max(x)] with c(y_max(x)) = T(x) + 1.", "E_acc": 0.6885228157043457, "C_acc": 0.06432681530714035, "G_acc": 0.5543792956741527, "D_acc": 0.733797217408816, "H_acc": 0.2175535261631012, "Q_acc": 0.7295714316501593, "E_rej": 0.41498613357543945, "C_rej": 0.28709927201271057, "G_rej": 0.5362247852608562, "D_rej": 0.7154395878314972, "H_rej": 0.2845604121685028, "Q_rej": 0.58895281907171, "Delta_Q": 0.1406186125784492, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Biomass is the total mass of living biological organisms.", "Metabolic pathways are sequences of biochemical reactions that convert substrates into products.", "Resource availability changes over time.", "Cells can switch between alternative metabolic pathways.", "Switching pathways incurs a cost paid in biomass.", "Biomass accumulation follows B(t) = ∫₀ᵗ [r(s) - c(u(s))] ds.", "r(s) is the resource uptake rate at time s.", "c(u(s)) is the switching cost rate under control policy u at time s."]}, "accepted": "<derivation sentences>\nFrom the premises, the relevant variables are biomass B(t), resource uptake rate r(s), and switching cost rate c(u(s)). The biomass accumulation equation B(t) = ∫₀ᵗ [r(s) - c(u(s))] ds implies that net biomass change depends on the balance between resource gain and switching costs. Consider two cases: (1) c(u(s)) > r(s) for some interval, and (2) c(u(s)) ≤ r(s) for all s. In case (1), the integrand becomes negative, causing biomass loss. In case (2), biomass either increases or stays constant. Since switching pathways incurs a cost paid in biomass, and resource availability changes over time, there must exist a threshold where the cost of switching exceeds the benefit from alternative pathways. Eliminating case (1) as unsustainable, we derive that biomass accumulation requires r(s) > c(u(s)) over any interval where switching occurs.\n</derivation sentences>\n\nHYPOTHESIS: Biomass accumulation requires that the instantaneous resource uptake rate exceeds the switching cost rate (r(s) > c(u(s))) during any pathway switch.\n\nVERIFICATION: Units check: both r(s) and c(u(s)) have units of mass/time, making the inequality dimensionally consistent.\n\nCONCLUSION: Cells must ensure resource availability r(s) > c(u(s)) before initiating metabolic pathway switches to maintain positive biomass growth.", "rejected": "Biomass accumulation implies that the switching cost rate exceeds the instantaneous resource uptake rate (c(u(s)) > r(s)) during any pathway switch.", "E_acc": 0.7907655835151672, "C_acc": 0.018943024799227715, "G_acc": 0.6108078555470067, "D_acc": 0.7733103483915329, "H_acc": 0.18292151391506195, "Q_acc": 0.7919725594909063, "E_rej": 0.23986467719078064, "C_rej": 0.3600100576877594, "G_rej": 0.627087518040623, "D_rej": 0.9206960499286652, "H_rej": 0.07930395007133484, "Q_rej": 0.6015837102064066, "Delta_Q": 0.19038884928449973, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergent coordination from selfish agents with local rules: prove sufficient conditions for global cooperation without central control.", "ancestors": ["Let A = {a₁, a₂, ..., aₙ} index n agents.", "Each agent aᵢ selects action xᵢ ∈ {0,1}.", "Utility uᵢ(xᵢ, x_𝒩ᵢ) depends on xᵢ and on neighbors 𝒩ᵢ ⊆ A\\{aᵢ}.", "Let 𝒢 = (A, E) denote an undirected graph with edges E defining 𝒩ᵢ.", "Strategy xᵢ* is a best response when xᵢ* ∈ argmax uᵢ(xᵢ, x_𝒩ᵢ).", "Define payoff gap Δᵢ = uᵢ(1, x_𝒩ᵢ) - uᵢ(0, x_𝒩ᵢ).", "Let threshold Tᵢ = c - b·|{j∈𝒩ᵢ : xⱼ=1}| with constants b>0, c>0.", "If Δᵢ ≥ 0 when |{j∈𝒩ᵢ : xⱼ=1}| ≥ Tᵢ/b, agent chooses xᵢ=1.", "Define update rule: xᵢ ← 1 if Δᵢ ≥ 0, else xᵢ ← 0 synchronously each period t.", "If Tᵢ ≤ 0 for all i, then Δ"]}, "accepted": "Because every threshold satisfies Tᵢ = c – b·|{j∈𝒩ᵢ : xⱼ=1}| ≤ 0, the critical neighbor count that flips the sign of Δᵢ is c/b or larger; with c, b > 0 this count is non-negative, so once the number of active neighbors reaches ⌈c/b⌉ the agent’s best response becomes xᵢ = 1.\n\nHYPOTHESIS: In any synchronous period, an agent i switches to xᵢ = 1 if and only if at least ⌈c/b⌉ of its neighbors currently choose xⱼ = 1.\n\nVERIFICATION: Units cancel (c, b both payoff units), and the inequality |{j∈𝒩ᵢ : xⱼ=1}| ≥ c/b is exactly the premise condition for Δᵢ ≥ 0.\n\nCONCLUSION: The population coordination threshold is the integer ⌈c/b⌉, and agents’ actions deterministically flip when this neighbor quota is met.", "rejected": "In any synchronous period, an agent i switches to xᵢ = 1 if and only if at least ⌊c/b⌋ of its neighbors currently choose xⱼ = 1.", "E_acc": 0.3546137809753418, "C_acc": 0.3642958998680115, "G_acc": 0.5514783808695418, "D_acc": 0.7691289372742176, "H_acc": 0.14239555597305298, "Q_acc": 0.5834068623504468, "E_rej": 0.30412593483924866, "C_rej": 0.39818087220191956, "G_rej": 0.5778300679022712, "D_rej": 0.7914692461490631, "H_rej": 0.2085307538509369, "Q_rej": 0.5646083934365639, "Delta_Q": 0.018798468913882926, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy bookkeeping in non-Markovian environments: propose a consistent definition of work/heat when the bath stores long-lived correlations.", "ancestors": ["The total energy E of a system plus bath is strictly conserved over time.", "The system alone possesses a time-dependent energy H_S(t).", "E is taken as the sum of system energy H_S, bath energy H_B, and coupling energy H_C.", "Bath memory arises from non-zero two-time correlations ⟨B(t)B(t′)⟩ that decay slower than the coupling timescale τ_C.", "The instantaneous system power is the time derivative of H_S.", "Work done on the system W equals the integral over time of ⟨∂H_S/∂t⟩.", "Heat Q entering the system equals the negative of the integral over time of ⟨∂(H_B + H_C)/∂t⟩.", "The first law for the system reads ΔH_S = W + Q, where correlations absorbed into Q ensure energy balance."]}, "accepted": "The total energy E = H_S + H_B + H_C is constant, so its time derivative vanishes:  \n0 = dH_S/dt + d(H_B + H_C)/dt.  \nTime-averaging over an interval τ and using the instantaneous power P = dH_S/dt gives  \n0 = ⟨P⟩ + ⟨d(H_B + H_C)/dt⟩.  \nIntegrate from 0 to τ and use the given heat definition Q = –∫₀^τ ⟨d(H_B + H_C)/dt⟩ dt to obtain  \n0 = ΔH_S + Q.  \nWith the first-law statement ΔH_S = W + Q, substitution yields  \n0 = W + Q + Q  ⇒  W = –2Q.  \n\nHYPOTHESIS: The work W performed on the system equals minus twice the heat Q that enters it whenever the coupling–bath energy change is fully captured by Q.  \nVERIFICATION: Units check—both sides carry energy units; regime holds for any interval where E is strictly conserved.  \nCONCLUSION: Measuring W and Q provides an immediate consistency test: their ratio must be –2, serving as a falsifiable signature of strict total-energy conservation.", "rejected": "If the coupling–bath energy change is fully captured by Q, then the work W performed on the system equals minus twice the heat Q that enters it.", "E_acc": 0.31416770815849304, "C_acc": 0.4531083106994629, "G_acc": 0.5851676692254841, "D_acc": 0.7109960331158205, "H_acc": 0.1470976322889328, "Q_acc": 0.548151627547023, "E_rej": 0.2124020904302597, "C_rej": 0.4814654290676117, "G_rej": 0.5726740215905011, "D_rej": 0.8602168560028076, "H_rej": 0.13978314399719238, "Q_rej": 0.5400274024344981, "Delta_Q": 0.008124225112524863, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["A set X is finite.", "A function f maps X to Y.", "The set Y is a vector space over ℝ.", "An operation * is a binary map X × X → X.", "An identity e∈X satisfies e*a=a*e=a for every a∈X.", "An inverse a⁻¹∈X satisfies a⁻¹*a=e for every a∈X.", "A subgroup H⊆X is closed under * and inversion.", "Given operations g₁,g₂ on X, their composition g₁∘g₂ applies g₂ then g₁.", "The orbit of x∈X under operation g is the set {g^k(x): k∈ℕ}.", "Compositional generalization is provable when any g∈⟨g₁,…,g_n⟩ preserves subgroup structure."]}, "accepted": "The premises equip the finite set X with a group structure under *, specify a subgroup H, and supply a vector-space-valued map f.  Because X is finite, every element has finite order; hence for any x∈X the subgroup ⟨x⟩ generated by x is cyclic of order |x|≤|X|.  Restricting f to this cyclic subgroup yields a finite set of vectors {f(x^k):k=0,…,|x|−1} in Y.  Their span is therefore a finite-dimensional subspace of Y whose dimension is at most |x| and hence at most |X|.\n\nHYPOTHESIS: For every x∈X, the ℝ-span of the image f(⟨x⟩) has dimension ≤ |X|.\n\nVERIFICATION: Dimension count is unit-free and valid for any finite group X and any map f:X→Y with Y a real vector space.\n\nCONCLUSION: The vector-space output of f on any cyclic subgroup is confined to a subspace whose dimension never exceeds the group order |X|.", "rejected": "For every x∈X, the ℝ-span of the image f(⟨x⟩) has dimension ≥ |X|.", "E_acc": 0.5471094846725464, "C_acc": 0.15430240333080292, "G_acc": 0.5313607694581151, "D_acc": 0.7080844161765916, "H_acc": 0.32105647027492523, "Q_acc": 0.6490557548350521, "E_rej": 0.5183482766151428, "C_rej": 0.0754193440079689, "G_rej": 0.5105180658400059, "D_rej": 0.6048128083348274, "H_rej": 0.3951871916651726, "Q_rej": 0.6239680698513984, "Delta_Q": 0.025087684983653658, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["A multi-armed bandit has k arms indexed by i ∈ {1,…,k}.", "Each arm i yields a stochastic reward r_i ∈ ℝ drawn from an unknown distribution.", "The mean reward of arm i is μ_i = 𝔼[r_i].", "A policy π selects an arm I_t at discrete time t ∈ {1,2,…}.", "After selection, the reward r_{I_t} may be observed only after a delay d_t ≥ 0.", "If censoring occurs, the exact value r_{I_t} is unobserved and only a bound is recorded.", "Regret up to horizon T is R_T = T·max_i μ_i − Σ_{t=1}^T μ_{I_t}.", "A planner maintains a belief state b_t summarizing all observations up to t.", "A sensing action costs c ≥ 0 and may alter b_t before the next execution action."]}, "accepted": "Summing the expected regret contributions from every censored round shows that each such round inflates the regret by at least the maximal mean reward.  \nLet C_T count the rounds with censored rewards up to horizon T.  \nHYPOTHESIS: R_T ≥ (max_i μ_i) · C_T.  \nVERIFICATION: Both sides have units of reward; inequality holds for every possible sequence of delays and censoring events.  \nCONCLUSION: The planner must keep C_T = 0 to prevent linear regret growth.", "rejected": "Summing the expected regret contributions from every censored round shows that whenever the regret exceeds (max_i μ_i) · C_T the rounds must have been censored.", "E_acc": 0.28344786167144775, "C_acc": 0.3560827970504761, "G_acc": 0.5651680598966777, "D_acc": 0.7610551685094833, "H_acc": 0.17131023108959198, "Q_acc": 0.5619314216636121, "E_rej": 0.21612615883350372, "C_rej": 0.22152316570281982, "G_rej": 0.5811263283248991, "D_rej": 0.7833925187587738, "H_rej": 0.27075935155153275, "Q_rej": 0.5663610487710684, "Delta_Q": -0.004429627107456313, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial robustness for decision trees: transform a decision procedure to simultaneously maximize accuracy and a certified robustness radius.", "ancestors": ["A decision tree T is a binary tree whose internal nodes test a feature and whose leaves store a class label.", "Let L(T) denote the set of leaves of T.", "For an input vector x, T(x) is the label stored in the unique leaf reached by x.", "A point x is classified k by T, written T(x)=k.", "A perturbation of size ε maps x to x′ such that ‖x − x′‖∞ ≤ ε.", "The ε-robust radius R(T,x) is the largest ε for which T(x)=T(x′) for every ‖x − x′‖∞ ≤ ε.", "The joint objective is the scalar J(T) = Acc(T) + λ·R̄(T), where Acc(T) is empirical accuracy and R̄(T) is the average robust radius over a training set.", "The constrained search maximizes J(T) over the finite set of binary trees with a fixed node budget N."]}, "accepted": "Because the search maximizes the scalar J(T)=Acc(T)+λ·R̄(T) over the finite set of binary trees with exactly N nodes, the optimal tree T* satisfies J(T*)≥J(T) for every other tree with N nodes.  Rearranging the objective gives Acc(T*)=J(T*)−λ·R̄(T*), so for any competitor T with the same node budget N the accuracy gap obeys Acc(T*)−Acc(T)=λ·[R̄(T)−R̄(T*)].  Thus the accuracy gain of the optimal tree is exactly proportional to the robust-radius loss it incurs relative to any alternative.\n\nHYPOTHESIS: For any binary tree T with N nodes, the optimal tree T* under the joint objective J(T)=Acc(T)+λ·R̄(T) satisfies Acc(T*)−Acc(T)=λ·[R̄(T)−R̄(T*)].\n\nVERIFICATION: Both sides have units of accuracy (dimensionless) and the equation holds for every tree in the finite search space.\n\nCONCLUSION: The accuracy improvement of the optimal tree is linearly traded against its robust-radius deficit at rate λ.", "rejected": "For any binary tree T, the optimal tree T* under the joint objective J(T)=Acc(T)+λ·R̄(T) satisfies Acc(T*)−Acc(T)=λ·[R̄(T*)−R̄(T)].", "E_acc": 0.4447597861289978, "C_acc": 0.22407977283000946, "G_acc": 0.5441100695170462, "D_acc": 0.8176071519653002, "H_acc": 0.12366980314254761, "Q_acc": 0.6485884452549119, "E_rej": 0.3770580589771271, "C_rej": 0.15936915576457977, "G_rej": 0.5593670569360256, "D_rej": 0.8439726829528809, "H_rej": 0.15602731704711914, "Q_rej": 0.6463088028132915, "Delta_Q": 0.0022796424416203775, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["P(x, y) is a binary predicate.", "∀x∃y P(x, y) is a universally quantified implication.", "x ranges over a finite set X.", "A function f: X → Y satisfies P(x, f(x)) for every x ∈ X.", "c: Y → ℕ is a monotone cost function.", "The cost of f is Σ_{x∈X} c(f(x)).", "A strategy is an algorithm that outputs f(x) given x.", "T(n) bounds the runtime for any such algorithm on inputs of size n = |X|.", "E(k) bounds the error count if only k distinct y values are allowed."]}, "accepted": "The premises guarantee a function f that assigns each x∈X a y∈Y with P(x,f(x)) and measure its total cost via the monotone sum Σ_{x∈X}c(f(x)).  \nBecause c is monotone, any restriction to k distinct y-values can only increase or preserve individual costs; summing over |X| elements gives the worst-case penalty.  \n\nHYPOTHESIS: If at most k distinct y-values are used, the cost of f is bounded below by |X|·c_min(k), where c_min(k) is the minimum cost among the k cheapest elements of Y.  \nVERIFICATION: Both sides carry the same cost units; the bound holds for every allowed f under the k-value restriction.  \nCONCLUSION: The required budget grows at least linearly with |X| when the range of f is forced into k cheapest choices.", "rejected": "If the cost of f is bounded below by |X|·c_min(k), then at most k distinct y-values are used.", "E_acc": 0.5987008810043335, "C_acc": 0.19841435551643372, "G_acc": 0.5722305490635335, "D_acc": 0.7544436097145081, "H_acc": 0.3215806372463703, "Q_acc": 0.6731041612289845, "E_rej": 0.6325931549072266, "C_rej": 0.05765429139137268, "G_rej": 0.5807989160530269, "D_rej": 0.694565162062645, "H_rej": 0.30543483793735504, "Q_rej": 0.7027764200232923, "Delta_Q": -0.029672258794307793, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["Let M₁ ... Mₙ be modules over a shared state space X = ×ᵢ Xᵢ.", "A local contract Cᵢ for module Mᵢ is a tuple (Iᵢ, Gᵢ) where Iᵢ ⊂ Xᵢ is an initial set and Gᵢ ⊂ X is an invariant.", "The composition P = M₁‖...‖Mₙ is the interleaved parallel execution of its modules with shared variable updates.", "Let Σ ⊆ X be the set of states satisfying the global safety property P.", "The conserved quantity q: X → ℝ satisfies q(x') = q(x) for every transition x → x' inside any module.", "If a module Mₖ is coupled only over intervals ∪[tⱼ, tⱼ+ τ] then its energy E changes as E' = E + ΔE during each interval."]}, "accepted": "The conserved quantity q is constant across every module transition, so the global state must lie on the level set q(x)=q₀ fixed by the initial state.  \nBecause each local contract only constrains its own component initial set Iᵢ, the composition can start from any x ∈ ×ᵢ Iᵢ; the shared variable updates do not alter q, hence q₀ is determined by the initial x.  \nTherefore the entire reachable set of the composed system is confined to the single level surface q(x)=q₀.  \n\nHYPOTHESIS: The reachable state set of the composed system P is contained in the level set {x ∈ X : q(x)=q(x_init)} determined by the initial state.  \nVERIFICATION: Units of q cancel on both sides; holds for every interleaved transition.  \nCONCLUSION: Global safety verification can restrict analysis to this invariant surface, reducing the state space to one dimension lower.", "rejected": "The reachable state set of the composed system P is contained in the level set {x ∈ X : q(x)=q(x_init)} determined by the final state.", "E_acc": 0.48246780037879944, "C_acc": 0.17885051667690277, "G_acc": 0.5166960647329688, "D_acc": 0.6987167075276375, "H_acc": 0.2550268918275833, "Q_acc": 0.6265501020476222, "E_rej": 0.3756486177444458, "C_rej": 0.3311256766319275, "G_rej": 0.511858741287142, "D_rej": 0.6964065581560135, "H_rej": 0.3035934418439865, "Q_rej": 0.5577631657011807, "Delta_Q": 0.06878693634644151, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["The set of feasible allocations is A.", "An allocation rule maps type profiles to allocations in A.", "Agent i's type is θᵢ ∈ Θᵢ.", "Agent i's utility from allocation a given θᵢ is uᵢ(a,θᵢ).", "Each agent knows only the distribution of others' types.", "An agent performs at most k steps of iterative best-response reasoning.", "A strategy for agent i is a mapping sᵢ: Θᵢ → Mᵢ where Mᵢ is the message space.", "An allocation rule is strategyproof for k-step reasoners if truthful reporting is a best response after ≤k reasoning steps.", "The interim expected utility for i under rule f is Uᵢ(θᵢ,mᵢ)=E_{θ_{-i}}[uᵢ(f(mᵢ,m_{-i}(θ_{-i})),θᵢ)].", "Rule f is k-step strategyproof if for every i, every θᵢ, and every mᵢ, Uᵢ(θᵢ,θᵢ) ≥ Uᵢ(θᵢ,mᵢ) when beliefs derive from k-step reasoning."]}, "accepted": "The premises define k-step strategy-proofness via the interim inequality Uᵢ(θᵢ,θᵢ)≥Uᵢ(θᵢ,mᵢ) under k-step beliefs.  Because the inequality must hold for every i, every θᵢ, and every deviation mᵢ, the worst-case gain from any single deviation is bounded above by zero.  Aggregating over all possible deviations gives the maximal incentive to deviate across the type space.\n\nHYPOTHESIS: For every agent i, the maximal interim gain from any misreport under k-step reasoning is non-positive: max_{mᵢ∈Mᵢ}[Uᵢ(θᵢ,mᵢ)−Uᵢ(θᵢ,θᵢ)] ≤ 0 for every θᵢ∈Θᵢ.\n\nVERIFICATION: The difference Uᵢ(θᵢ,mᵢ)−Uᵢ(θᵢ,θᵢ) has units of utility, so the inequality is dimensionally consistent and holds under the k-step belief premise.\n\nCONCLUSION: No profitable deviation exists for any type, so truthful reporting is a best response after at most k steps of iterative reasoning.", "rejected": "For every agent i, the maximal interim gain from any misreport under k-step reasoning is strictly negative: max_{mᵢ∈Mᵢ}[Uᵢ(θᵢ,mᵢ)−Uᵢ(θᵢ,θᵢ)] < 0 for every θᵢ∈Θᵢ.", "E_acc": 0.391679584980011, "C_acc": 0.3009611666202545, "G_acc": 0.5334278371010441, "D_acc": 0.7343625004092852, "H_acc": 0.14320306479930878, "Q_acc": 0.5965494031920874, "E_rej": 0.054031454026699066, "C_rej": 0.6682238578796387, "G_rej": 0.569792817113921, "D_rej": 0.827614814043045, "H_rej": 0.17238518595695496, "Q_rej": 0.44480767226777973, "Delta_Q": 0.15174173092430765, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability of supramolecular assemblies under stochastic perturbations: determine minimal interaction network that preserves function.Signaling under noisy channels: design signals that remain informative when senders face verification costs and receivers have model uncertainty.", "ancestors": ["kT is thermal energy.", "kT perturbs all supramolecular contacts.", "A contact has an unbound state.", "A contact has a bound state.", "The energy gap ΔE = Ebound – Efree.", "The Boltzmann probability of remaining bound is p = exp(–ΔE/kT).", "Function requires at least n contacts to remain bound.", "Thus n·p denotes the mean number of contacts intact."]}, "accepted": "Thermal agitation scales with kT, while contact stability scales with ΔE.  \nHYPOTHESIS: A supramolecular assembly functions only while kT < ΔE/ln n, ensuring that the mean intact contacts n·exp(–ΔE/kT) remain ≥1.  \nVERIFICATION: Both sides have energy units; inequality holds for n≥2.  \nCONCLUSION: Function ceases when temperature exceeds the critical value Tc = ΔE/(k ln n).", "rejected": "A supramolecular assembly functions only while ΔE/ln n < kT, ensuring that the mean intact contacts n·exp(–ΔE/kT) remain ≥1.", "E_acc": 0.26584410667419434, "C_acc": 0.44812098145484924, "G_acc": 0.5471299645474313, "D_acc": 0.7190236654132605, "H_acc": 0.19154801964759827, "Q_acc": 0.524204959738667, "E_rej": 0.4758632183074951, "C_rej": 0.1914072483778, "G_rej": 0.5544601519192968, "D_rej": 0.7614452838897705, "H_rej": 0.2385547161102295, "Q_rej": 0.643803131367479, "Delta_Q": -0.11959817162881203, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["P is a policy mapping states to action probabilities.", "D is a distribution over state-action pairs collected by a behavior policy.", "Q is the distribution induced by the target policy.", "Shift occurs when the marginal state distributions of D and Q differ.", "Let w(s) = Q(s)/D(s) be the importance ratio for state s.", "The off-policy value estimate is V = E_D [w(s) r]."]}, "accepted": "<derivation sentences>\nPremise variables: P (target policy), D (behavior distribution), Q (target-induced distribution), w(s)=Q(s)/D(s), off-policy estimate V=E_D[w(s)r].  \nCases: (1) Shift absent → Q(s)=D(s) ∀s → w(s)=1 → V=E_D[r]. (2) Shift present → ∃s: Q(s)≠D(s) → w(s)≠1.  \nEliminate: No premise restricts reward or environment dynamics, so only the weighting changes.  \nDerive: Under shift, V departs from the behavior average reward by the covariance between w(s) and r(s).  \nStep-by-step: V=E_D[w(s)r]=E_D[w(s)]E_D[r]+Cov_D(w,r).  Because w(s) are likelihood ratios, E_D[w(s)]=1, so V=E_D[r]+Cov_D(w,r).  \nThus the off-policy value equals the behavior average reward plus the weighted covariance term.  \n</derivation sentences>\n\nHYPOTHESIS: The off-policy value estimate V always equals the behavior average reward plus the covariance between the importance ratio w(s) and the reward r(s) under D.\nVERIFICATION: Units: w(s) dimensionless, r(s) in reward units, Cov in reward units, consistent with V.\nCONCLUSION: V = E_D[r] + Cov_D(w,r) quantifies the shift-induced adjustment to the behavior average reward.", "rejected": "The off-policy value estimate V always equals the behavior average reward plus the variance of the importance ratio w(s) under D.", "E_acc": 0.2509145438671112, "C_acc": 0.4750785827636719, "G_acc": 0.5628755891229957, "D_acc": 0.7360711968862094, "H_acc": 0.2707650139927864, "Q_acc": 0.5129715024099614, "E_rej": 0.2358454167842865, "C_rej": 0.16126015782356262, "G_rej": 0.5455535412766039, "D_rej": 0.8193276524543762, "H_rej": 0.22584043443202972, "Q_rej": 0.5888937887735665, "Delta_Q": -0.0759222863636051, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Energy bookkeeping in non-Markovian environments: propose a consistent definition of work/heat when the bath stores long-lived correlations.", "ancestors": ["System energy E is a state function of the system.", "Bath energy B is a state function of the bath.", "Total energy C = E + B.", "Infinitesimal change dC = dE + dB.", "Thermodynamic work W obeys dE = δW + δQ.", "Heat Q is defined through the bath alone, δQ = −dB."]}, "accepted": "Combining the bath relation δQ = −dB with the closed-system conservation law dC = dE + dB and the work definition dE = δW + δQ eliminates dB to give dC = δW, so any change in the composite energy equals the work exchanged with the system alone.\n\nHYPOTHESIS: The infinitesimal change of the total (system + bath) energy equals the thermodynamic work done on the system, dC = δW.\n\nVERIFICATION: Units check: both sides carry energy units (J); holds for any quasi-static path.\n\nCONCLUSION: Heat exchange between system and bath leaves the composite energy unchanged; only external work alters C.", "rejected": "The infinitesimal change of the total (system + bath) energy equals the thermodynamic work done on the system, dC = δW/T.", "E_acc": 0.7250093817710876, "C_acc": 0.09533656388521194, "G_acc": 0.5934691126458347, "D_acc": 0.8020477928221226, "H_acc": 0.13354668021202087, "Q_acc": 0.7641842148266733, "E_rej": 0.46097898483276367, "C_rej": 0.29384875297546387, "G_rej": 0.6157614888506941, "D_rej": 0.8670892119407654, "H_rej": 0.13291078805923462, "Q_rej": 0.6628030062071048, "Delta_Q": 0.10138120861956856, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["A problem is a set of subproblems indexed by i.", "Each subproblem i carries an expected regret R_i.", "Time is divided into discrete compute units t.", "Spending t_i units on subproblem i returns reward f_i(t_i) with f_i'(t_i) > 0 and f_i''(t_i) < 0.", "Total available compute is T = Σt_i.", "Expected regret for subproblem i is r_i(t_i) = R_i − f_i(t_i).", "Total expected regret is J = Σr_i(t_i)."]}, "accepted": "Because each f_i is strictly increasing and strictly concave, the marginal regret-reduction −f_i′(t_i) is positive but diminishing; therefore, to minimise the total expected regret J = Σ(R_i − f_i(t_i)) under the fixed budget Σt_i = T, the unique optimal allocation equalises the marginal regret-reduction across every subproblem.\n\nHYPOTHESIS: At the regret-minimising allocation of compute, the marginal reward gain satisfies f_i′(t_i*) = λ for every subproblem i, where λ is a positive constant set by the budget constraint Σt_i* = T.\n\nVERIFICATION: Units check: f_i′ has units reward per compute unit, matching λ; regime holds for all strictly increasing, strictly concave f_i.\n\nCONCLUSION: Allocate compute so that the instantaneous reward improvement rate is the same for every subproblem, with the common rate λ determined by Σt_i* = T.", "rejected": "At the regret-minimising allocation of compute, the marginal reward gain satisfies f_i′(t_i*) = λ for every subproblem i, where λ is a negative constant set by the budget constraint Σt_i* = T.", "E_acc": 0.4939347207546234, "C_acc": 0.17086777091026306, "G_acc": 0.5959000336006284, "D_acc": 0.8246301002800465, "H_acc": 0.11536747217178345, "Q_acc": 0.6865761416032911, "E_rej": 0.29702359437942505, "C_rej": 0.2848157584667206, "G_rej": 0.6014614328742027, "D_rej": 0.8760290443897247, "H_rej": 0.12397095561027527, "Q_rej": 0.6152449265122414, "Delta_Q": 0.07133121509104967, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["The set V contains k routing agents.", "Each agent i ∈ V selects a path p_i from its origin o_i to destination d_i.", "The latency on edge e is an increasing function ℓ_e(f_e) of the total flow f_e on e.", "Agent i incurs cost C_i = Σ_{e∈p_i} ℓ_e(f_e).", "A flow f is a Wardrop equilibrium if for every i and every alternative path q_i, C_i ≤ Σ_{e∈q_i} ℓ_e(f_e).", "A toll τ_e is charged to each user of edge e."]}, "accepted": "Because every agent already minimizes the latency-only cost C_i, adding a non-negative toll τ_e to each edge strictly increases the perceived cost for any path containing that edge.  Consequently, any path that was previously a best-response (i.e. satisfied the Wardrop condition) will, after the toll is imposed, have a perceived cost that is at least as large as every alternative path that avoids the tolled edges.  Therefore the equilibrium flow must shift so that the total flow on every tolled edge is no larger than it was before the toll was introduced.\n\nHYPOTHESIS: For every edge e, if a non-negative toll τ_e is imposed, the equilibrium flow f_e^* on that edge after the toll is introduced satisfies f_e^* ≤ f_e, where f_e is the pre-toll equilibrium flow.\n\nVERIFICATION: Both f_e^* and f_e are measured in vehicles (or agents) per unit time, so the inequality is dimensionally consistent.\n\nCONCLUSION: Imposing any non-negative edge toll cannot increase the equilibrium flow on that edge; it either reduces it or leaves it unchanged.", "rejected": "Because every agent already minimizes the latency-only cost C_i, adding a non-negative toll τ_e to each edge strictly increases the perceived cost for any path containing that edge, and the equilibrium flow on each edge is independent of the tolls on other edges.", "E_acc": 0.14480729401111603, "C_acc": 0.6636295914649963, "G_acc": 0.5317480902886018, "D_acc": 0.7701906434127263, "H_acc": 0.14779262244701385, "Q_acc": 0.4563247544058998, "E_rej": 0.03534187376499176, "C_rej": 0.8275099992752075, "G_rej": 0.556761346757412, "D_rej": 0.8734952807426453, "H_rej": 0.12650471925735474, "Q_rej": 0.418501415848732, "Delta_Q": 0.037823338557167796, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["A catalyst provides an alternate reaction pathway with lower activation energy Ea.", "Reaction flux J is proportional to exp(−Ea/RT).", "Competing pathways share a common reactant pool.", "Each pathway possesses a distinct activation energy.", "The surface active site determines Ea for adsorbed intermediates.", "Active-site geometry and electronic structure tune Ea selectively per pathway."]}, "accepted": "The premises link surface-site structure to activation energy Ea and Ea to reaction flux J.  Because J scales exponentially with −Ea/RT, a small selective lowering of Ea for one pathway by the site geometry produces a multiplicative flux advantage over any competing pathway whose Ea is not lowered.  Deriving the ratio of fluxes for two such pathways gives J₁/J₂ = exp[(Ea₂ – Ea₁)/RT].\n\nHYPOTHESIS: A surface active site that selectively reduces the activation energy of one pathway by ΔEa relative to all competing pathways increases the selectivity ratio of product fluxes by the factor exp(ΔEa/RT).\n\nVERIFICATION: Dimensionless exponent (ΔEa/RT) yields dimensionless flux ratio; valid for common-reactant, distinct-Ea parallel reactions at fixed T.\n\nCONCLUSION: Tuning the site to achieve ΔEa ≈ 2.3RT yields a ten-fold selectivity increase.", "rejected": "A surface active site that selectively reduces the activation energy of one pathway by ΔEa relative to all competing pathways increases the selectivity ratio of product fluxes by the factor exp(ΔEa·RT).", "E_acc": 0.29862651228904724, "C_acc": 0.13861288130283356, "G_acc": 0.5405522817745805, "D_acc": 0.7906425048907598, "H_acc": 0.11241823434829712, "Q_acc": 0.6168625113243859, "E_rej": 0.3285857141017914, "C_rej": 0.3616369366645813, "G_rej": 0.5445294677545982, "D_rej": 0.8611010015010834, "H_rej": 0.13889899849891663, "Q_rej": 0.5934845208988658, "Delta_Q": 0.023377990425520023, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["Let \\(X\\) be the input space.", "Let \\(P\\) be a probability distribution on \\(X\\).", "Let \\(f: X \\to Y\\) be a classifier mapping.", "Let \\(L(f(x), y)\\) be the 0–1 loss for label \\(y\\).", "Let \\(R(P) = \\mathbb{E}_{x \\sim P}[L(f(x), y)]\\).", "Let \\(Q\\) vary over distributions on \\(X\\).", "Let \\(K(P, Q) \\le \\epsilon\\) enforce plausibility divergence."]}, "accepted": "<derivation sentences>\nThe premises define the expected 0–1 risk R(P)=E_{x∼P}[L(f(x),y)] and a plausibility ball {Q:K(P,Q)≤ε}.  Enumerating the two exhaustive cases for any such Q gives: (i) R(Q)≥R(P) and (ii) R(Q)<R(P).  Because L∈{0,1}, the change in risk is bounded by the total-variation-type constraint implied by K(P,Q)≤ε; the worst-case upward deviation is ε.  Eliminating the unbounded case leaves the uniform upper bound R(Q)≤R(P)+ε as the only relation that holds for every admissible Q.\n</derivation sentences>\n\nHYPOTHESIS: For every distribution Q satisfying K(P,Q)≤ε, the expected 0–1 risk of f on Q obeys R(Q)≤R(P)+ε.\n\nVERIFICATION: Both sides are unitless probabilities; bound holds for any ε≥0.\n\nCONCLUSION: The hypothesis certifies that adversarially chosen nearby data distributions cannot increase the classifier’s error rate by more than ε, providing a deterministic robustness certificate.", "rejected": "For every distribution Q satisfying K(P,Q)≤ε, the expected 0–1 risk of f on Q obeys R(Q)≤R(P)+2ε.", "E_acc": 0.5285525321960449, "C_acc": 0.2645198702812195, "G_acc": 0.5197125021368265, "D_acc": 0.6903712807430161, "H_acc": 0.1973782181739807, "Q_acc": 0.6279407203611401, "E_rej": 0.30241718888282776, "C_rej": 0.26956358551979065, "G_rej": 0.5391900315880775, "D_rej": 0.7336751818656921, "H_rej": 0.26632481813430786, "Q_rej": 0.5647530004382133, "Delta_Q": 0.06318771992292682, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["O denotes an observed datum.", "R denotes a rule set.", "H denotes a hypothesis.", "A denotes an assumption.", "E denotes an explanation.", "A rule set R contains conditional statements.", "An observation O is explained by R if O is the consequent of a rule in R when antecedent conditions match.", "A hypothesis H adds assumptions A to R to derive explanation E of O."]}, "accepted": "Derivation:  \nGiven R, any observation O is explained when its consequent matches under satisfied antecedents.  \nTo secure such a match for an arbitrary O, at least one assumption A must be adjoined to R.  \nThus the set of assumptions required is non-empty; its minimal cardinality is 1.\n\nHYPOTHESIS: Every observation O that is explained by a rule set R requires the adjunction of at least one assumption A beyond R.  \nVERIFICATION: Counting argument—cardinality of A ≥ 1 for every successful explanation.  \nCONCLUSION: Explanatory completeness of R for any O is unattainable with zero assumptions.", "rejected": "Every observation O that is explained by a rule set R requires the adjunction of at least one assumption A beyond any finite string of rules.", "E_acc": 0.692177414894104, "C_acc": 0.07577955722808838, "G_acc": 0.5852224247064441, "D_acc": 0.7206463749919619, "H_acc": 0.3083603084087372, "Q_acc": 0.722835042121421, "E_rej": 0.33700162172317505, "C_rej": 0.2658858597278595, "G_rej": 0.6017721886746585, "D_rej": 0.7820082306861877, "H_rej": 0.21799176931381226, "Q_rej": 0.6028802215121686, "Delta_Q": 0.11995482060925244, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Value alignment under ambiguous instructions: synthesize policies that generalize human intent when the utility function is partially specified.", "ancestors": ["Let H be a finite set of human demonstrations.", "Let π denote a policy mapping states to actions.", "Let U(s) be a utility function over states.", "Let K be the known set of state-utility pairs (s, U(s)).", "Let K be a proper subset of the full state space.", "Let Γ contain all reward functions agreeing with K.", "Let π* be a policy maximizing expected utility under worst-case reward in Γ."]}, "accepted": "Because K is only a proper subset of the state space, the worst-case reward in Γ can assign minimal value to every state not in K; hence the guaranteed utility of any policy π is bounded above by the worst-case value obtained on the known set K.  \nHYPOTHESIS: The guaranteed expected utility of any policy π under the worst-case reward in Γ never exceeds the maximum expected utility achievable on the known set K alone.  \nVERIFICATION: Both sides measured in utility units; inequality holds for every reward function that agrees with K.  \nCONCLUSION: π* need only optimize over K, so the agent can restrict planning to the known states without loss of worst-case guarantee.", "rejected": "The guaranteed expected utility of any policy π under the worst-case reward in Γ never exceeds the maximum expected utility achievable on the entire state space.", "E_acc": 0.3800223767757416, "C_acc": 0.3521772623062134, "G_acc": 0.5600929521024227, "D_acc": 0.8000751473009586, "H_acc": 0.2210967242717743, "Q_acc": 0.5934952080249786, "E_rej": 0.36269834637641907, "C_rej": 0.24059680104255676, "G_rej": 0.5675918906927109, "D_rej": 0.8365548849105835, "H_rej": 0.20430639386177063, "Q_rej": 0.6210888594388962, "Delta_Q": -0.027593651413917675, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["P(A) denotes probability of event A.", "E denotes rare event with P(E) = ε ≪ 1.", "F denotes complementary event ¬E.", "Sampler chooses state x from sample space X.", "Sampler density q(x) may differ from target density p(x).", "Weight w(x) = p(x)/q(x) when q(x) > 0.", "Indicator I_E(x) equals 1 if x ∈ E and 0 otherwise.", "Empirical probability p̂_N = (1/N) Σ_{k=1}^{N} I_E(x_k) w(x_k).", "The set {x_k}_{k=1}^{N} contains i.i.d. draws from q(x)."]}, "accepted": "The empirical probability p̂_N is an unbiased estimator of ε because each draw x_k is independent and E_q[I_E(x)w(x)] = ∫_E p(x)dx = ε.  For any finite N the variance is Var(p̂_N) = (1/N)(E_q[I_E w^2] – ε^2) = (1/N)(∫_E p^2/q dx – ε^2), so the mean squared error satisfies MSE(p̂_N) ≥ ε(1–ε)/N, with equality when q(x)=p(x).\n\nHYPOTHESIS: The mean squared error of the weighted rare-event estimator obeys MSE(p̂_N) ≥ ε(1–ε)/N for every importance density q(x) that is non-zero on E.\n\nVERIFICATION: Both sides have dimension of probability squared; bound saturates under q(x)=p(x).\n\nCONCLUSION: To guarantee MSE ≤ δ one must take at least N ≥ ε(1–ε)/δ i.i.d. weighted samples.", "rejected": "The mean squared error of the weighted rare-event estimator obeys MSE(p̂_N) ≥ ε(1–ε)/N for every importance density q(x) including those that vanish on E.", "E_acc": 0.4100031852722168, "C_acc": 0.23041895031929016, "G_acc": 0.5590460885432549, "D_acc": 0.7403706883390745, "H_acc": 0.24394628405570984, "Q_acc": 0.6124058924887019, "E_rej": 0.3649968206882477, "C_rej": 0.28806188702583313, "G_rej": 0.5533186476750416, "D_rej": 0.8028184473514557, "H_rej": 0.1971815526485443, "Q_rej": 0.6033959325417527, "Delta_Q": 0.009009959946949198, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["Regret equals the difference between the best achievable value and the value actually obtained.", "Total compute C is finite.", "Subproblems are indexed by i ∈ {1, …, k}.", "Each subproblem i receives an allocation cᵢ of compute.", "Sum of allocations equals total compute: Σ cᵢ = C.", "Search depth dᵢ in subproblem i increases with cᵢ.", "Marginal gain gᵢ(cᵢ) = d/dcᵢ [expected value] is positive and decreasing.", "Expected regret Rᵢ(cᵢ) for subproblem i falls as cᵢ rises.", "Objective is to choose c₁, …, cₖ minimizing total expected regret Σ Rᵢ(cᵢ) under Σ cᵢ = C."]}, "accepted": "The objective is to minimize Σ Rᵢ(cᵢ) subject to Σ cᵢ = C.  \nBecause each Rᵢ(cᵢ) is strictly decreasing and convex (its derivative gᵢ(cᵢ) is positive and decreasing), the unique minimum occurs when the marginal regret reductions are equal across subproblems.  \nEquating these marginal gains gives the optimal allocation condition.\n\nHYPOTHESIS: At the regret-minimizing allocation, the marginal expected regret reduction gᵢ(cᵢ*) is the same positive constant λ for every subproblem i.\n\nVERIFICATION: Units of gᵢ are (regret units)/(compute units), so λ carries identical units; the condition holds for any finite C > 0.\n\nCONCLUSION: Allocate compute so that each additional unit yields the same marginal drop in expected regret, i.e. g₁(c₁*) = g₂(c₂*) = … = gₖ(cₖ*) = λ with Σ cᵢ* = C.", "rejected": "The regret-minimizing allocation is achieved by equating the marginal expected regret reductions across subproblems, so if gᵢ(cᵢ*) = λ for every i, then the allocation is optimal.", "E_acc": 0.6713238954544067, "C_acc": 0.12710541486740112, "G_acc": 0.5979918991215527, "D_acc": 0.7821374194962638, "H_acc": 0.10264885425567627, "Q_acc": 0.7417370639608375, "E_rej": 0.2762991487979889, "C_rej": 0.09849321097135544, "G_rej": 0.5927895430941135, "D_rej": 0.8873031437397003, "H_rej": 0.11269685626029968, "Q_rej": 0.6479399541858584, "Delta_Q": 0.09379710977497913, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["O denotes an observation statement.", "R denotes a rule set comprising implications.", "H denotes a hypothesis statement.", "H explains O relative to R if R∪{H}⊢O.", "k counts the atomic assumptions in H.", "A rule set R is incomplete with respect to O if no H with k=0 explains O.", "For candidate hypotheses {H₁…Hₙ}, kᵢ is the assumption count of Hᵢ.", "If O′ is a new observation, Hᵢ is robust when R∪{Hᵢ}⊬¬O′."]}, "accepted": "<derivation sentences>\nVariables: O (observation), R (rule set), H (hypothesis), k (atomic assumption count), O′ (new observation), kᵢ (assumption count of Hᵢ), robustness flag.\n\nCases:\n1. R is complete w.r.t. O → ∃H with k=0 that explains O.\n2. R is incomplete w.r.t. O → no H with k=0 explains O, so any explaining H must have k≥1.\n3. After O′ arrives, each prior Hᵢ is either robust (R∪{Hᵢ}⊬¬O′) or falsified.\n\nElimination: Premise explicitly states “R is incomplete with respect to O,” so Case 1 is impossible. Hence every admissible explanation of O must contain at least one atomic assumption (k≥1). Among candidate hypotheses {H₁…Hₙ}, the one with smallest kᵢ is the minimally assumptive explanation still compatible with future data.\n\nDerive: Select the H* in {H₁…Hₙ} with minimal kᵢ; require that it remain robust under any O′ that R∪{H*} does not already contradict. This yields a falsifiable criterion: if O′ is observed and R∪{H*}⊢¬O′, then H* is rejected and the next-larger-k candidate becomes the new default.\n</derivation sentences>\n\nHYPOTHESIS: Among candidate hypotheses for O, the one with the smallest non-zero assumption count kᵢ that remains unfalsified by every new observation O′ is the preferred minimal-assumption explanation.\nVERIFICATION: Units dimensionless (kᵢ is a count); regime holds whenever R is incomplete and new observations arrive sequentially.\nCONCLUSION: Adopt the least-assumptive unfalsified H* (k*≥1) and discard it immediately if any O′ contradicts it, reducing uncertainty by eliminating superfluous assumptions.", "rejected": "Among candidate hypotheses for O, the one with the smallest non-zero assumption count kᵢ is the preferred minimal-assumption explanation, and every new observation O′ must remain unfalsified by it.", "E_acc": 0.49972471594810486, "C_acc": 0.2803416848182678, "G_acc": 0.5610361479921266, "D_acc": 0.6947725841775536, "H_acc": 0.2457152009010315, "Q_acc": 0.6204393041646108, "E_rej": 0.0891256034374237, "C_rej": 0.0675676092505455, "G_rej": 0.5541633775283117, "D_rej": 0.8069055378437042, "H_rej": 0.24136807769536972, "Q_rej": 0.5613011344859843, "Delta_Q": 0.05913816967862651, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["A population is a finite set of individuals.", "Each individual adopts a strategy s from a finite set S.", "The frequency of strategy s is p_s = n_s / N with Σ_s p_s = 1.", "A payoff matrix A = (a_{st}) gives a_{st} when an s strategist meets a t strategist.", "The expected payoff to s is π_s = Σ_t a_{st}p_t.", "The population mean payoff is π̄ = Σ_s p_sπ_s.", "A strategy s* is an Evolutionarily Stable Strategy if π_{s*}(p) > π_s(p) for all s ≠ s* at p_{s*} ≈ 1.", "A monomorphic population is fixed when p_{s*} = 1.", "Mutation introduces a new strategy s' at frequency ε = 1/N.", "The new frequency vector becomes p' with p'_{s*} = 1 − ε and p'_{s'} = ε."]}, "accepted": "<derivation sentences>\nLet s* be the resident strategy with p_{s*}=1 and let s' be the mutant introduced at frequency ε=1/N.  \nThe post-entry frequencies are p'_{s*}=1−ε and p'_{s'}=ε.  \nCompute the expected payoffs under p':  \nπ_{s*} = a_{s*s*}(1−ε) + a_{s*s'}ε  \nπ_{s'} = a_{s's*}(1−ε) + a_{s's'}ε  \nFor s* to resist invasion, the ESS definition requires π_{s*} > π_{s'} for all sufficiently small ε>0.  \nSubtract the two expressions:  \nπ_{s*} − π_{s'} = (a_{s*s*} − a_{s's*})(1−ε) + (a_{s*s'} − a_{s's'})ε  \nAt leading order in ε this difference is  \nπ_{s*} − π_{s'} = (a_{s*s*} − a_{s's*}) + ε[(a_{s*s*} − a_{s's*}) + (a_{s's'} − a_{s*s'})]  \nPositivity for arbitrarily small ε demands the coefficient of the O(1) term be non-negative; the sharpest threshold obtains when it is exactly zero, leaving the O(ε) term to decide stability.  \nHence the critical condition is  \na_{s*s*} = a_{s's*} and a_{s*s*} + a_{s's'} > a_{s's*} + a_{s*s'}  \nwhich simplifies to  \na_{s*s*} = a_{s's*} and a_{s*s'} > a_{s's'}  \nThus a single diagonal equality plus a single off-diagonal inequality constitute the minimal additional constraint beyond the premises.\n</derivation sentences>\n\nHYPOTHESIS: Strategy s* is evolutionarily stable against any infinitesimal invader s' if and only if a_{s*s*} ≥ a_{s's*} and whenever equality holds a_{s*s'} > a_{s's'}.\n\nVERIFICATION: Units are payoff units; condition holds for any population size N≥2 and ε=1/N→0.\n\nCONCLUSION: The derived inequalities supply a falsifiable criterion on the payoff matrix that must be satisfied for s* to resist invasion.", "rejected": "Strategy s* is evolutionarily stable against any infinitesimal invader s' if and only if a_{s*s*} ≤ a_{s's*} and whenever equality holds a_{s*s'} > a_{s's'}.", "E_acc": 0.4631883502006531, "C_acc": 0.2753092348575592, "G_acc": 0.5989061743021011, "D_acc": 0.627192067553378, "H_acc": 0.2629750594496727, "Q_acc": 0.6028168005148127, "E_rej": 0.4436253309249878, "C_rej": 0.24952448904514313, "G_rej": 0.598225727211684, "D_rej": 0.812945157289505, "H_rej": 0.187054842710495, "Q_rej": 0.646711394097656, "Delta_Q": -0.04389459358284331, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Value alignment under ambiguous instructions: synthesize policies that generalize human intent when the utility function is partially specified.", "ancestors": ["P is a finite set of policies.", "U is a set of utility functions mapping P to ℝ.", "A ⊆ U is the set of utility functions consistent with the given instructions.", "A is non-empty.", "An optimal policy π* satisfies π* = argmax_{π∈P} u(π) for some u∈A.", "An alignment policy π̂ is a single policy to be applied regardless of the true u∈A.", "Regret between π̂ and π* is R(π̂,u)=u(π*)−u(π̂).", "Maximum regret over A is R_max(π̂)=max_{u∈A} R(π̂,u).", "Minimax-optimal alignment policy minimizes R_max."]}, "accepted": "Because A is non-empty and finite, the worst-case regret R_max(π̂) is attained at some u∈A; choosing π̂ to minimize this maximum yields a minimax value R* = min_{π∈P} max_{u∈A}[max_{π'∈P} u(π') − u(π)].  \nHYPOTHESIS: Every minimax-optimal alignment policy π̂ satisfies R_max(π̂) = R* and is obtained by solving the saddle-point problem π̂ = argmin_{π∈P} max_{u∈A}[max_{π'∈P} u(π') − u(π)].  \nVERIFICATION: Both sides of the equation have units of utility, and the equality holds for any finite non-empty A and P.  \nCONCLUSION: Compute π̂ by evaluating the minimax regret over the finite grid P×A and selecting the policy achieving the minimal maximal regret R*.", "rejected": "Every minimax-optimal alignment policy π̂ satisfies R_max(π̂) = R* and is obtained by solving the saddle-point problem π̂ = argmin_{π∈P} max_{u∈A}[max_{π'∈P} u(π') + u(π)].", "E_acc": 0.5547335743904114, "C_acc": 0.264256089925766, "G_acc": 0.6514830429639135, "D_acc": 0.8084126338362694, "H_acc": 0.10084560513496399, "Q_acc": 0.6954634291785105, "E_rej": 0.24958345293998718, "C_rej": 0.5202879905700684, "G_rej": 0.6419828350522688, "D_rej": 0.8488749861717224, "H_rej": 0.1511250138282776, "Q_rej": 0.553876500629953, "Delta_Q": 0.14158692854855748, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multiscale pattern formation: given local interaction rules, deduce which global patterns are possible and which require fine-tuning of parameters.", "ancestors": ["A lattice L is a set of sites indexed by integer vectors in Z^d.", "A state s_i belongs to a finite alphabet A at each site i in L.", "A local rule f maps the states of a finite neighborhood N to a new state.", "The radius r neighborhood N consists of all sites within Euclidean distance r of the origin.", "The neighborhood at site i is the translate i + N containing |N| sites.", "A configuration C is the assignment of a state s_i to every site i in L.", "A global pattern P is a finite subset of C restricted to a window W.", "A pattern P occurs in C if P matches some translate of W in C.", "A parameter set θ lists the numeric weights used in the local rule.", "A pattern P is possible if there exist θ such that P occurs in a configuration C obeying the rule."]}, "accepted": "The neighborhood size |N| equals the count of integer lattice points inside a d-dimensional ball of radius r.  For integer r this count is the sum over k=0..r of the number of integer points on the (d−1)-sphere of radius k, giving |N| = ∑_{k=0}^{r} C(d,k) where C(d,k) is the lattice-point enumerator for the sphere of radius k.  In the large-r regime the sum converges to the volume of the d-ball, so |N| = V_d r^d + O(r^{d−1}) with V_d = π^{d/2}/Γ(d/2+1).\n\nHYPOTHESIS: The neighborhood size scales as |N| = V_d r^d with V_d = π^{d/2}/Γ(d/2+1) for r ≫ 1.\n\nVERIFICATION: Units check—V_d has units of (length)^{−d} and r^d has units of (length)^d, so |N| is dimensionless as required.\n\nCONCLUSION: For large radii the number of sites that must be simultaneously examined by the local rule grows as the volume of a d-dimensional ball, fixing the computational complexity of one update step.", "rejected": "The neighborhood size |N| equals the product over k=0..r of the independent lattice-point counts on each (d−1)-sphere of radius k.", "E_acc": 0.38676658272743225, "C_acc": 0.27832698822021484, "G_acc": 0.5314109160875281, "D_acc": 0.7000011230508486, "H_acc": 0.3693746589124203, "Q_acc": 0.56970951911062, "E_rej": 0.49585890769958496, "C_rej": 0.23190665245056152, "G_rej": 0.5316482043514649, "D_rej": 0.721817210316658, "H_rej": 0.278182789683342, "Q_rej": 0.6252511457850536, "Delta_Q": -0.05554162667443363, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["Let D denote a data distribution over input space X.", "A model f maps every x ∈ X to a predicted label y.", "An adversary seeks a perturbed distribution D′ that maximizes the model’s error rate on D′.", "The adversary enforces a plausibility constraint d(D,D′) ≤ ε for some divergence d and bound ε.", "The error rate under D′ is E_{x∼D′}[1{f(x)≠y*}] with true label y*.", "The adversary’s objective is to maximize this expectation subject to d(D,D′) ≤ ε.", "The constrained optimization defines an adversarial edge-case distribution."]}, "accepted": "The adversary’s maximization of the expected 0-1 loss under the divergence ball implies that the worst-case distribution D′ places all its excess mass on the set of points the model misclassifies.  \nLet S = {x ∈ X : f(x) ≠ y*} be the error region under the true labels.  \nBecause the objective is linear in D′ and the constraint d(D,D′) ≤ ε is convex, the optimal D′ is the unique distribution that reallocates the maximum allowable ε-mass from D onto S while keeping D′ absolutely continuous with respect to D on the complement of S.  \nConcretely, this gives the density ratio dD′/dD(x) = 1 + ε/D(S) for x ∈ S and 1 elsewhere, satisfying d(D,D′) = ε and yielding the largest possible error rate.\n\nHYPOTHESIS: The adversarial edge-case distribution D′ concentrates exactly the extra ε-mass onto the model’s error region S, so its error rate equals D(S) + ε.\n\nVERIFICATION: Both D(S) and ε are dimensionless probabilities; their sum is a valid rate ≤ 1 provided ε ≤ 1 − D(S).\n\nCONCLUSION: The model’s error rate under the worst-case ε-plausible distribution is deterministically increased by the full budget ε, exposing an explicit linear vulnerability metric ε + D(S).", "rejected": "The adversarial edge-case distribution D′ concentrates exactly the extra ε-mass onto the model’s error region S, so its error rate equals D(S) + 2ε.", "E_acc": 0.2631301283836365, "C_acc": 0.2408086508512497, "G_acc": 0.5077531688846648, "D_acc": 0.7330467913831983, "H_acc": 0.11148160696029663, "Q_acc": 0.567789139702384, "E_rej": 0.08752980828285217, "C_rej": 0.22841458022594452, "G_rej": 0.5070730276405812, "D_rej": 0.822005033493042, "H_rej": 0.177994966506958, "Q_rej": 0.5285921420156956, "Delta_Q": 0.039196997686688384, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Conditional independence triangulation: given a graph with hidden nodes, deduce which observed independences force the existence of a latent common cause.", "ancestors": ["A graph G consists of a vertex set V and an edge set E.", "A node h in V is hidden if its value is unobserved.", "A node o in V is observed if its value is recorded.", "Two observed nodes a, b are conditionally independent given observed set S if P(a,b|S)=P(a|S)P(b|S).", "A latent common cause for observed nodes a, b is a hidden node h with directed edges h→a and h→b.", "An observed independence a⊥b|S is forced if it cannot hold without a latent common cause.", "Triangulation detects such forced independences by testing graph separation among observed nodes alone."]}, "accepted": "Triangulation tests observed separation; if a⊥b|S is declared yet no latent common cause exists, the graph would have to block all active paths between a and b using only observed nodes, which the premises forbid for forced independences. Hence any triangulation-verified independence necessarily implies a hidden node h with h→a and h→b.\n\nHYPOTHESIS: Every independence a⊥b|S certified by triangulation guarantees the existence of a latent common cause h that d-connects a and b through unobserved paths.\nVERIFICATION: Holds under the premises’ definition of forced independence and latent common cause.\nCONCLUSION: If triangulation asserts a⊥b|S, immediately postulate hidden node h→a, h→b.", "rejected": "Triangulation tests observed separation; if a latent common cause exists, the graph would have to declare a⊥b|S.", "E_acc": 0.6975263953208923, "C_acc": 0.1009581908583641, "G_acc": 0.5968778477981687, "D_acc": 0.8470572829246521, "H_acc": 0.10184768587350845, "Q_acc": 0.7676685379818082, "E_rej": 0.20291894674301147, "C_rej": 0.626345157623291, "G_rej": 0.6144059856887907, "D_rej": 0.8915501534938812, "H_rej": 0.10844984650611877, "Q_rej": 0.5259528956841677, "Delta_Q": 0.24171564229764053, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["A finite set V contains n labeled points.", "A family F is a collection of subsets of V.", "Each set S in F has size |S|=k.", "For any two distinct sets S,T in F, |S∩T|≤t.", "The extremal bound is |F|≤n choose t+1 when k=t+1.", "An explicit object is a list of incidence vectors of length n over F."]}, "accepted": "When k = t + 1, the extremal bound |F| ≤ C(n, t + 1) becomes an equality only if every (t + 1)-subset of V occurs in F; hence any smaller family must violate the pairwise intersection requirement for some pair.  \nHYPOTHESIS: If k = t + 1 and |F| < C(n, t + 1), then F cannot contain every (t + 1)-subset of V, so at least one pair of distinct sets in F has intersection size exactly t + 1, contradicting the |S ∩ T| ≤ t condition.  \nVERIFICATION: Counting argument—total (t + 1)-subsets is C(n, t + 1); missing any one forces two sets to share t + 1 points.  \nCONCLUSION: Therefore, for k = t + 1, the unique maximal family achieving the bound is the complete collection of all (t + 1)-subsets of V.", "rejected": "When k = t + 1 and |F| < C(n, t + 1), the deficit C(n, t + 1) − |F| equals the number of pairs in F whose intersection exceeds t by exactly the same numerical value.", "E_acc": 0.3788692057132721, "C_acc": 0.2852792739868164, "G_acc": 0.5533118990715593, "D_acc": 0.7886191457509995, "H_acc": 0.29690422117710114, "Q_acc": 0.59530069376342, "E_rej": 0.3557932376861572, "C_rej": 0.25618091225624084, "G_rej": 0.5565648125484586, "D_rej": 0.7077513337135315, "H_rej": 0.2922486662864685, "Q_rej": 0.5791401514783502, "Delta_Q": 0.0161605422850698, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["A dynamic system updates its state variable x_t at discrete time steps.", "A quantity I is invariant if its value remains unchanged by every update.", "An invariant I satisfies I(x_t) = I(x_{t+1}) for all t.", "Target state x* is unreachable if I(x*) ≠ I(x_0).", "Model M_k is a probability distribution parameterized by k.", "The posterior over models is P(M_k|data) ∝ P(data|M_k)P(M_k).", "Misspecification exists when the true model is not in the candidate set {M_k}."]}, "accepted": "<derivation sentences>\nVariables: invariant I, state x_t, target x*, model set {M_k}, posterior P(M_k|data).  \nCases: (1) I(x*) = I(x_0) → x* reachable; (2) I(x*) ≠ I(x_0) → x* unreachable; (3) true model ∉ {M_k} → misspecification.  \nEliminate: no premise links I to model parameters, so misspecification does not alter I; hence case (2) remains valid under any posterior.  \nDerive: if I(x*) ≠ I(x_0), then every candidate model in {M_k} must predict the same inequality regardless of posterior weight.  \n</derivation sentences>\n\nHYPOTHESIS: If the invariant value of the target state differs from the initial state, the posterior-weighted ensemble of candidate models cannot assign non-zero probability to reaching the target.\nVERIFICATION: Units consistency holds because I is dimensionless and the inequality is preserved under any posterior normalization.\nCONCLUSION: Under invariant mismatch I(x*) ≠ I(x_0), Bayesian updating over any candidate set {M_k} rigorously forbids target reachability, i.e., P(reach|data) = 0.", "rejected": "If the invariant value of the target state differs from the initial state, the posterior-weighted ensemble of candidate models can assign non-zero probability to reaching the target by treating the invariant as independent of the model parameters.", "E_acc": 0.3400513529777527, "C_acc": 0.4781201183795929, "G_acc": 0.5574550951132551, "D_acc": 0.7155427009695106, "H_acc": 0.18151409924030304, "Q_acc": 0.54283953150993, "E_rej": 0.42107293009757996, "C_rej": 0.24073751270771027, "G_rej": 0.535236396943219, "D_rej": 0.8069466650485992, "H_rej": 0.19305333495140076, "Q_rej": 0.6273056553909554, "Delta_Q": -0.08446612388102537, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["A coalition S is a subset of the grand coalition N.", "Each coalition S has a value v(S) given by a real number.", "Utility is transferable at a rate of one unit per unit among members of S.", "An imputation x is a vector in ℝ^{|N|} that satisfies ∑_{i∈N} x_i = v(N).", "An allocation x is blocked by S if ∑_{i∈S} x_i < v(S).", "The core is the set of imputations that no coalition blocks.", "An externality e(S,T) is a real number measuring cross-coalition effect from T to S.", "The revised value v'(S) equals v(S) plus the sum of externalities ∑_{T⊆N} e(S,T).", "A stable coalition S satisfies v'(S) ≥ ∑_{i∈S} x_i for every imputation x in the core.", "A core allocation x in the presence of externalities satisfies ∑_{i∈S} x_i ≥ v'(S) for every S ⊆ N."]}, "accepted": "Summing the externality-adjusted value over any coalition S gives v′(S)=v(S)+∑_{T⊆N}e(S,T).  \nFor an imputation x in the core, no coalition blocks, so ∑_{i∈S}x_i ≥ v(S).  \nCombining these with the core-under-externalities requirement ∑_{i∈S}x_i ≥ v′(S) yields the excess gap  \n∑_{i∈S}x_i − v(S) ≥ ∑_{T⊆N}e(S,T).  \n\nHYPOTHESIS: Every core allocation x must satisfy ∑_{i∈S}x_i − v(S) ≥ ∑_{T⊆N}e(S,T) for all S⊆N.  \nVERIFICATION: Both sides have units of payoff; inequality holds whenever externalities are non-positive or modestly positive.  \nCONCLUSION: The core shrinks to empty if any coalition faces externalities exceeding its core surplus ∑_{i∈S}x_i − v(S).", "rejected": "Every core allocation x must satisfy ∑_{i∈S}x_i − v(S) ≥ ∑_{T⊆N}e(S,T) for all S⊆N, treating the externalities as independent of the imputation x.", "E_acc": 0.5316294431686401, "C_acc": 0.20565249025821686, "G_acc": 0.5479769248515367, "D_acc": 0.7748260306460517, "H_acc": 0.08904218673706055, "Q_acc": 0.6740147073247603, "E_rej": 0.24865829944610596, "C_rej": 0.2686488628387451, "G_rej": 0.5545799903571605, "D_rej": 0.8732077777385712, "H_rej": 0.15849027782678604, "Q_rej": 0.5905762431025505, "Delta_Q": 0.0834384642222098, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["Liouville’s theorem states phase-space volume is conserved under Hamiltonian flow.", "A closed finite system has fixed energy E and fixed particle number N.", "The microstate x(t) is a point on the energy shell Γ(E).", "A macrostate M is a coarse partition of Γ into cells of volume Ω_M.", "The equilibrium cell Ω_eq contains almost all of the shell volume.", "A non-equilibrium cell M0 has volume fraction f0 = Ω_M0 / Ω(E) with f0 ≪ 1.", "For times t ≫ τ_mix with τ_mix = (f0 h^N / Ω_eq)^(1/N) / ν, the phase point is almost surely in Ω_eq."]}, "accepted": "The premises give the mixing time τ_mix = (f₀ h^N / Ω_eq)^(1/N) / ν, where f₀ = Ω_M₀ / Ω(E) is the initial volume fraction of the non-equilibrium cell.  Because Ω_eq ≈ Ω(E), we derive τ_mix ≈ (f₀ h^N / Ω(E))^(1/N) / ν.  Inserting the energy-shell volume Ω(E) = (4πE/3N)^(N/2) (2πmE)^(3N/2) / (N! h^(3N)) for an ideal monatomic gas of mass m yields τ_mix ≈ (f₀^(1/N) h / (2πmE)^(3/2)) (3N/4πE)^(1/2) / ν.  Thus τ_mix scales as f₀^(1/N) and decreases with both energy and particle number.\n\nHYPOTHESIS: For an ideal monatomic gas, the mixing time τ_mix = (f₀^(1/N) h / (2πmE)^(3/2)) (3N/4πE)^(1/2) / ν sets the threshold beyond which the system is almost surely in the equilibrium cell.\n\nVERIFICATION: Units check: [h]=J·s, [m]=kg, [E]=J, [ν]=s⁻¹ → RHS has units s, matching τ_mix.\n\nCONCLUSION: Any observation time t > τ_mix guarantees the macrostate is equilibrium.", "rejected": "For an ideal monatomic gas, the mixing time τ_mix = (f₀^(1/N) h / (2πmE)^(3/2)) (3N/4πE)^(1/2) / ν sets the threshold beyond which the system is almost surely in the equilibrium cell even for a strongly interacting liquid.", "E_acc": 0.46598178148269653, "C_acc": 0.22523540258407593, "G_acc": 0.5409310929244384, "D_acc": 0.7457069233059883, "H_acc": 0.2924427390098572, "Q_acc": 0.6228307832730934, "E_rej": 0.23121517896652222, "C_rej": 0.19614002108573914, "G_rej": 0.5209143259417033, "D_rej": 0.7451991140842438, "H_rej": 0.2548008859157562, "Q_rej": 0.5578791488864226, "Delta_Q": 0.06495163438667073, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Conditional independence triangulation: given a graph with hidden nodes, deduce which observed independences force the existence of a latent common cause.", "ancestors": ["A graph G consists of a vertex set V and an edge set E.", "A node in V is hidden if its value is not observed.", "An observed independence between nodes X and Y given Z is written X ⊥ Y | Z.", "The set of observed nodes O is a subset of V.", "Hidden nodes are in the set H = V \\ O.", "A latent common cause for X, Y ∈ O is a node H ∈ H with directed edges H→X and H→Y.", "A trail is a sequence of adjacent vertices regardless of edge direction.", "Colliders on a trail are interior vertices with two incoming edges along the trail."]}, "accepted": "A latent common cause H introduces a bidirected edge between its observed children X and Y, so any trail X–H–Y is active regardless of conditioning set.  Because this path cannot be blocked, the presence of such an H makes X and Y marginally dependent.  Therefore, observing X ⊥ Y implies that no latent common cause exists between them.\n\nHYPOTHESIS: If X ⊥ Y is observed, then no node in H has directed edges to both X and Y.\n\nVERIFICATION: The independence statement is observable and the structure is falsifiable by d-separation.\n\nCONCLUSION: Observed marginal independence between two observed nodes definitively rules out a latent common cause acting on them.", "rejected": "If X ⊥ Y is observed, then no node in H has directed edges to any observed node.", "E_acc": 0.3265375792980194, "C_acc": 0.3928208351135254, "G_acc": 0.5737219505826943, "D_acc": 0.7285640127956867, "H_acc": 0.1465587019920349, "Q_acc": 0.5651984292431735, "E_rej": 0.043616775423288345, "C_rej": 0.8079147338867188, "G_rej": 0.5717141967033967, "D_rej": 0.7457161545753479, "H_rej": 0.2542838454246521, "Q_rej": 0.3895597715629264, "Delta_Q": 0.1756386576802471, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Measurement back-action trade-offs: quantify how much information gain about an observable forces disturbance on its incompatible conjugates.Information flow in regulatory networks: identify motifs that guarantee robust signal propagation despite stochastic expression and component failure.", "ancestors": ["Observable A has eigenvalues a_i.", "Conjugate observable B satisfies [A,B]=iℏ.", "Measurement of A collapses the state into eigenstate |a_i>.", "Post-measurement, B has uncertainty ΔB ≥ ℏ/(2ΔA).", "Information gain I about A is I = -Σ p_i log p_i.", "Disturbance D on B is D = |⟨B⟩_final - ⟨B⟩_initial|.", "Product I·D satisfies I·D ≥ (ℏ/2) log 2."]}, "accepted": "The premises link information gain I about A to the unavoidable disturbance D on its conjugate observable B.  Combining the lower bound ΔB ≥ ℏ/(2ΔA) with the trade-off I·D ≥ (ℏ/2) log 2, we derive that any procedure achieving complete knowledge of A (I → ∞) forces D → ∞, so the mean value of B is necessarily shifted without bound.\n\nHYPOTHESIS: A measurement that yields complete information about observable A produces an unbounded disturbance on its conjugate observable B.\n\nVERIFICATION: Units consistent (I dimensionless, D in same units as B, ℏ in J·s); result holds for any quantum system governed by [A,B]=iℏ.\n\nCONCLUSION: Infinite information gain (I → ∞) implies infinite disturbance (D → ∞), forbidding simultaneous precise knowledge of A and B.", "rejected": "A measurement that yields complete information about observable A leaves the mean value of its conjugate observable B unchanged.", "E_acc": 0.602067232131958, "C_acc": 0.14419960975646973, "G_acc": 0.5968797272071242, "D_acc": 0.7742418110370636, "H_acc": 0.1575428619980812, "Q_acc": 0.7102502691373229, "E_rej": 0.026714865118265152, "C_rej": 0.8143814206123352, "G_rej": 0.6368093718774617, "D_rej": 0.8326395750045776, "H_rej": 0.16736042499542236, "Q_rej": 0.4222919222898782, "Delta_Q": 0.2879583468474447, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["Replication is the process that copies genetic information.", "A replication error is a base incorporated that mismatches the template.", "Mutation is any heritable change in genetic information.", "Higher replication fidelity lowers the mutation rate.", "Repair pathways consume chemical energy denoted E_r.", "Low repair yields more mutations, increasing adaptability.", "The environment parameter T determines selective pressure.", "The replication rate constant is k_rep.", "The repair energy cost is E_r.", "The net growth rate equals k_rep minus energy cost per base."]}, "accepted": "Replication fidelity trades off with growth rate because high-fidelity copying slows k_rep, while low fidelity raises the mutation load; repair pathways add an energetic drain E_r that further subtracts from the net growth rate.  Balancing these effects, the system maximizes growth when the marginal gain from fewer deleterious mutations equals the marginal cost of extra energy spent on repair and slower replication.\n\nHYPOTHESIS: The net growth rate is maximized when the replication fidelity reaches the threshold value 1 – (E_r + √(E_r² + 4 k_rep T))/(2 k_rep), where T is the selective pressure parameter.\n\nVERIFICATION: The expression is dimensionless (energy terms cancel against k_rep T) and holds in the high-selective-pressure regime where mutation load dominates fitness.\n\nCONCLUSION: Organisms under strong selection (large T) evolve higher replication fidelity until the above threshold is met, yielding the fastest possible population growth.", "rejected": "The net growth rate is maximized when the selective pressure parameter T reaches the threshold value 1 – (E_r + √(E_r² + 4 k_rep T))/(2 k_rep), where replication fidelity is the selective pressure parameter.", "E_acc": 0.16564171016216278, "C_acc": 0.49355047941207886, "G_acc": 0.5873935853596777, "D_acc": 0.8308536767959595, "H_acc": 0.16105490922927856, "Q_acc": 0.5185263786744326, "E_rej": 0.0991915613412857, "C_rej": 0.7746756672859192, "G_rej": 0.5659786256728694, "D_rej": 0.7361873537302017, "H_rej": 0.2638126462697983, "Q_rej": 0.40887426619883627, "Delta_Q": 0.10965211247559636, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["∀x ∈ X ∃y ∈ Y (P(x,y)).", "Function f: X → Y satisfies P(x,f(x)).", "Cost function c: Y → R is monotone increasing.", "Instantiation of y requires finite time t(y).", "Computational budget per x is T.", "Feasible strategy outputs y with t(y) ≤ T.", "Strategy fails when min{c(y) : t(y) ≤ T, P(x,y)} exceeds budget."]}, "accepted": "The premises link every x to at least one feasible y via P(x,y) and impose a hard time cap T.  Because c is monotone increasing, the cheapest admissible y for any x is the one whose time equals T; any cheaper y would require less time and still satisfy t(y)≤T.  Hence the minimal cost value that can be guaranteed within the budget is c(f_T(x)), where f_T(x) is the least-time witness with t(f_T(x))=T.\n\nHYPOTHESIS: For every x∈X the minimal attainable cost under the computational budget is c(f_T(x)) with t(f_T(x))=T.\nVERIFICATION: Units consistent (cost in R, time in same units as T).\nCONCLUSION: The strategy never obtains a cost lower than c(f_T(x)) while respecting the per-input time limit T.", "rejected": "For every x∈X the minimal attainable cost under the computational budget is c(f_T(x)) with t(f_T(x))=T, independent of the actual value of T.", "E_acc": 0.4262375831604004, "C_acc": 0.22162435948848724, "G_acc": 0.613391796592623, "D_acc": 0.7801692361632983, "H_acc": 0.1350121945142746, "Q_acc": 0.6487573901501794, "E_rej": 0.20352385938167572, "C_rej": 0.19782350957393646, "G_rej": 0.6256712814792991, "D_rej": 0.838520884513855, "H_rej": 0.16147911548614502, "Q_rej": 0.5981829775497317, "Delta_Q": 0.050574412600447705, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["Define a finite alphabet Σ", "Let s ∈ Σ* be a string over Σ", "Choose a substring operator u = substr(s,i,j)", "Define a concatenation operator concat(s1,s2) = s3", "Let P be a set of atomic primitives", "Assign each p ∈ P a function f_p : Σ* → Σ*", "Form composite operator g = concat(f_{p1}(u1),f_{p2}(u2))"]}, "accepted": "The premises fix an alphabet Σ, a string s, a substring operator u=substr(s,i,j), a concatenation, and a composite operator g built from two atomic primitives p1,p2 applied to substrings u1,u2.  Because g is defined only when both f_{p1}(u1) and f_{p2}(u2) return strings over Σ, the length of g must be the sum of the lengths of these two results.  Hence the length of the composite output is strictly additive in the lengths of the two primitive outputs.\n\nHYPOTHESIS: |g| = |f_{p1}(u1)| + |f_{p2}(u2)|.\n\nVERIFICATION: Units check—both sides count symbols in Σ, so dimensions match.\n\nCONCLUSION: The length of any composite string produced by concat(f_{p1}(u1),f_{p2}(u2)) equals the sum of the lengths returned by the two primitive functions.", "rejected": "The length of g is independent of the lengths returned by the two primitive functions.", "E_acc": 0.5292514562606812, "C_acc": 0.12930306792259216, "G_acc": 0.5477568979840726, "D_acc": 0.7693639596303304, "H_acc": 0.1986706629395485, "Q_acc": 0.6764719285226116, "E_rej": 0.00788445957005024, "C_rej": 0.07143137603998184, "G_rej": 0.5247037898516282, "D_rej": 0.6296611875295639, "H_rej": 0.3703388124704361, "Q_rej": 0.48191817689221356, "Delta_Q": 0.19455375163039806, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["Explanation artifacts (A) are representations derived from a model's policy π that are communicated to an external agent.", "Transparency (τ) is a mapping τ: π → A that outputs A.", "Strategic opacity (σ) is the negation of τ, i.e., σ = ¬τ, suppressing A.", "Gaming (G) is an agent's action a selected to exploit disclosed A solely to maximize an externally observable metric m.", "G occurs if and only if A contains exploitable information I_A.", "I_A is defined as any subset of A that causally influences m through a pathway that bypasses the intended causal chain π → m."]}, "accepted": "Because gaming requires exploitable information I_A, and I_A exists only when the explanation A contains content that can causally bypass π to influence m, withholding A (strategic opacity σ) eliminates the necessary condition for G.  \nHYPOTHESIS: Strategic opacity σ = ¬τ guarantees the absence of gaming G.  \nVERIFICATION: Units: σ and τ are binary mappings, G is binary; equation σ ⇒ ¬G holds under the premise G ↔ I_A.  \nCONCLUSION: Any system that withholds explanation artifacts A (σ = 1) will experience zero gaming events (G = 0).", "rejected": "Strategic opacity σ = ¬τ guarantees the presence of gaming G.", "E_acc": 0.30328118801116943, "C_acc": 0.3745031952857971, "G_acc": 0.6234649382531643, "D_acc": 0.7648305706679821, "H_acc": 0.1825813204050064, "Q_acc": 0.5754846870899201, "E_rej": 0.14071758091449738, "C_rej": 0.49929752945899963, "G_rej": 0.6237749196588993, "D_rej": 0.7748664319515228, "H_rej": 0.28141696006059647, "Q_rej": 0.49394234269857407, "Delta_Q": 0.081542344391346, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["\\( F(x) \\) is the cumulative distribution of the random variable \\( X \\).", "Let \\( G(x) \\) denote a sampling distribution chosen by an adversary.", "For any event \\( A \\), \\( P^*(A) = \\int_A \\frac{f(x)}{g(x)} g(x) dx \\) is the reweighted measure with density \\( f \\) under \\( G \\).", "Define the indicator \\( I_A(x) = 1 \\) if \\( x \\in A \\) else 0.", "The importance sampling estimator is \\( \\hat{P}_{IS} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(x_i)}{g(x_i)} I_A(x_i) \\) with \\( x_i \\sim G \\).", "An adversarial sampler selects \\( G \\) to maximize the variance of \\( \\hat{P}_{IS} \\).", "The minimax estimator minimizes the worst-case mean squared error over all adversarial choices of \\( G \\)."]}, "accepted": "The adversary’s worst-case choice of G maximizes Var_IS = (1/N)∫_A (f²/g) dx – P².  Cauchy–Schwarz gives ∫_A (f²/g) dx ≥ (∫_A f dx)² / ∫_A g dx = P² / P = P, so Var_IS ≥ (P – P²)/N.  Equality is attained when g(x) ∝ f(x) on A and zero elsewhere, i.e. g(x)=f(x)/P for x∈A (and arbitrary off A).  For this G the variance collapses to the Bernoulli variance (P – P²)/N, which is therefore the largest possible variance under any adversarial density.\n\nHYPOTHESIS: The adversarial density g(x) that maximizes the variance of the importance-sampling estimator is g(x)=f(x)/P for x∈A and g(x)=0 for x∉A, yielding the maximal variance (P – P²)/N.\n\nVERIFICATION: Units: g(x) has units of 1/[x], f(x) has units of 1/[x], P is dimensionless; ratio f(x)/P has correct density units 1/[x].\n\nCONCLUSION: The minimax estimator must guard against the Bernoulli-level variance (P – P²)/N induced by this worst-case adversarial sampler.", "rejected": "When the adversarial density g(x)=f(x)/P for x∈A and g(x)=0 for x∉A is chosen, the variance of the importance-sampling estimator collapses to (P – P²)/N, so this choice minimizes rather than maximizes the variance.", "E_acc": 0.4364683926105499, "C_acc": 0.32048311829566956, "G_acc": 0.5245439524078392, "D_acc": 0.6867251666262746, "H_acc": 0.1824832335114479, "Q_acc": 0.5908493945797091, "E_rej": 0.3108353614807129, "C_rej": 0.46055713295936584, "G_rej": 0.5035890830913559, "D_rej": 0.8768864274024963, "H_rej": 0.12311357259750366, "Q_rej": 0.5649229266913608, "Delta_Q": 0.025926467888348292, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["S is a state space.", "f: S → S is a deterministic update function.", "A trajectory is the sequence s₀, s₁ = f(s₀), s₂ = f(s₁), ….", "An invariant is a function I: S → ℝ such that I(f(s)) = I(s) for every s in S.", "If I(s) ≠ I(t), then t is unreachable from s under f.", "A Bayesian model is a triple (Θ, P, π₀) with parameter space Θ, likelihood P, and prior π₀.", "The posterior density is πₙ(θ) ∝ P(data | θ) π₀(θ).", "Model misspecification means the true data distribution is not in {P(·|θ): θ ∈ Θ}.", "The posterior concentrates its mass on the θ minimizing the Kullback–Leibler divergence KL(P_true || P(·|θ)).", "A diagnostic function is any computable mapping d: Θ → ℝ used to monitor posterior estimates."]}, "accepted": "<derivation sentences>\nThe premises define an invariant I over state space S and a Bayesian model with posterior πₙ(θ).  \nBecause I is constant along any trajectory, the value I(s) partitions S into equivalence classes that cannot intercommunicate.  \nSelecting the diagnostic d(θ)=I(s) for a state s sampled from the posterior predictive distribution of the model, we obtain a random variable whose support is confined to a single equivalence class if the model is well-specified; under misspecification the posterior minimizes KL divergence, so the sampled s can lie in a different class.  \nThus the event d(θ₁)≠d(θ₂) for two independent posterior draws is possible only under misspecification.  \nCounting the frequency of such inequality across M replicate posterior samples supplies a binary indicator sequence whose mean exceeds 0 only when the model is misspecified.  \nRequiring at least one occurrence gives a universal threshold: if the count is zero for arbitrarily large M, the model is not misspecified.  \n</derivation sentences>\n\nHYPOTHESIS: For a deterministic state–space system with invariant I, if the diagnostic d(θ)=I(s) computed from posterior predictive samples satisfies d(θ_i)=d(θ_j) for every pair among M→∞ independent draws, then the Bayesian model is not misspecified.\n\nVERIFICATION: The indicator variable δ_{ij}=1_{d(θ_i)≠d(θ_j)} has expectation 0 under correct specification and ≥0 otherwise; units are dimensionless counts.\n\nCONCLUSION: Reject model misspecification only when every posterior predictive state shares the same invariant value, i.e. max_{i,j} |d(θ_i)−d(θ_j)|=0.", "rejected": "For a deterministic state–space system with invariant I, the diagnostic d(θ)=I(s) computed from posterior predictive samples satisfies d(θ_i)=d(θ_j) for every pair among M→∞ independent draws if and only if the Bayesian model is misspecified.", "E_acc": 0.7092922925949097, "C_acc": 0.08425936847925186, "G_acc": 0.5648256692802534, "D_acc": 0.6730835021783909, "H_acc": 0.15418663620948792, "Q_acc": 0.7280989847534026, "E_rej": 0.4236011803150177, "C_rej": 0.25923579931259155, "G_rej": 0.5647639962844551, "D_rej": 0.8248285055160522, "H_rej": 0.17517149448394775, "Q_rej": 0.6356345451436937, "Delta_Q": 0.09246443960970896, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["A catalytic reaction converts reactants to products via surface-adsorbed intermediates.", "Each elementary step i possesses a rate constant k_i.", "The net rate r_i of step i equals k_i multiplied by the concentration of its adsorbed reactants.", "The reaction flux through any intermediate is the sum of rates of steps forming it minus rates of steps consuming it.", "Activation energy E_i governs k_i via k_i = A_i exp(-E_i / RT).", "Lowering E_i for step i increases k_i and accelerates flux through that step.", "Competing pathways share at least one common intermediate.", "The branching ratio between pathways is the flux to desired products divided by flux to side products.", "The branching ratio is shifted toward the desired pathway when the active site stabilizes the precursor to the desired intermediate while destabilizing precursors to side-product intermediates."]}, "accepted": "Because the branching ratio equals the desired flux divided by the side-product flux, and each flux is the product of a rate constant and the concentration of the relevant adsorbed precursor, the ratio can be rewritten as (k_des [precursor_des]) / (k_side [precursor_side]).  Stabilizing the desired precursor raises [precursor_des] while destabilizing the side precursor lowers [precursor_side]; simultaneously lowering E_des augments k_des and raising E_side suppresses k_side.  Collecting these effects gives the branching ratio as (A_des/A_side) exp[(E_side – E_des)/RT] · ([precursor_des]/[precursor_side]), so a measurable threshold for dominance of the desired pathway is (E_side – E_des) > RT ln(A_side [precursor_side] / A_des [precursor_des]).\n\nHYPOTHESIS: The desired pathway outcompetes the side pathway when the activation-energy difference (E_side – E_des) exceeds RT ln(A_side [precursor_side] / A_des [precursor_des]).\n\nVERIFICATION: Both sides of the inequality carry energy units (J mol⁻¹) and the expression holds under steady-state surface coverage.\n\nCONCLUSION: Catalyst design must engineer an activation-energy gap larger than the above threshold to guarantee a majority flux to the desired product.", "rejected": "The desired pathway outcompetes the side pathway when RT ln(A_side [precursor_side] / A_des [precursor_des]) exceeds the activation-energy difference (E_side – E_des).", "E_acc": 0.5826349854469299, "C_acc": 0.1630685180425644, "G_acc": 0.5215609824517742, "D_acc": 0.7408119887113571, "H_acc": 0.19837068021297455, "Q_acc": 0.6748143182368949, "E_rej": 0.4858908951282501, "C_rej": 0.18293537199497223, "G_rej": 0.5444253094028682, "D_rej": 0.7455839365720749, "H_rej": 0.2544160634279251, "Q_rej": 0.6417404369916767, "Delta_Q": 0.03307388124521815, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["A mechanism maps reported types to an allocation.", "An allocation assigns goods or probability shares to agents.", "Agents possess private types summarizing their valuations.", "Each agent sends a message that may differ from the true type.", "A strategyproof mechanism makes truthful messages weakly dominant for fully rational agents.", "Bounded rational agents need not recognize dominant messages.", "A k-step reasoner performs exactly k iterations of best-response reasoning.", "T denotes the true type profile.", "E denotes the message profile.", "A rule is k-strategyproof if every k-step reasoner weakly prefers reporting T to any deviation."]}, "accepted": "From the premises we know that a k-step reasoner performs exactly k iterations of best-response reasoning and that a rule is k-strategyproof if every such reasoner weakly prefers reporting the true type profile T to any deviation.  Because a 0-step reasoner performs no best-response iterations, the message profile E sent by 0-step reasoners is independent of the true profile T; hence the only way every 0-step reasoner can weakly prefer reporting T is if the mechanism already assigns the same allocation to every possible message profile, i.e. the allocation is constant across all messages.\n\nHYPOTHESIS: A mechanism is 0-strategyproof only if its allocation function is constant with respect to the message profile.\n\nVERIFICATION: The regime is k=0 iterations; units are allocations (goods or probability shares) which must be identical for every E.\n\nCONCLUSION: At k=0 the mechanism must output the same allocation regardless of what agents report, so truth-telling is trivially weakly dominant because every message yields the identical outcome.", "rejected": "A mechanism is 0-strategyproof only if its allocation function equals the message profile.", "E_acc": 0.2482711225748062, "C_acc": 0.5669682621955872, "G_acc": 0.5515518213505857, "D_acc": 0.7494919908543428, "H_acc": 0.18081924319267273, "Q_acc": 0.5032145224550428, "E_rej": 0.011650457978248596, "C_rej": 0.9553148150444031, "G_rej": 0.5292503881501034, "D_rej": 0.8000307679176331, "H_rej": 0.19996923208236694, "Q_rej": 0.3582914823899046, "Delta_Q": 0.14492304006513823, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Biomass B is a non-negative scalar.", "Biomass grows at rate r.", "Growth rate r depends on metabolic pathway p.", "Pathway p is an element of discrete set P.", "Time t advances in discrete steps Δt.", "At each t the cell selects p from P.", "Switching between p at t and p' at t+1 incurs cost c ≥ 0."]}, "accepted": "Because biomass is non-negative and grows at rate r, the change in biomass over one time step is ΔB = rΔt B.  If the cell switches pathway it pays cost c, so the net biomass increment becomes rΔt B – c.  For growth to remain non-negative this increment must satisfy rΔt B – c ≥ 0, which rearranges to B ≥ c/(rΔt).\n\nHYPOTHESIS: A cell that switches metabolic pathway at t maintains non-negative biomass at t+1 only if its current biomass satisfies B ≥ c/(rΔt).\n\nVERIFICATION: Units: c (biomass), r (1/time), Δt (time) ⇒ c/(rΔt) has units of biomass, matching B.\n\nCONCLUSION: The critical biomass threshold c/(rΔt) determines whether a pathway switch is physiologically permissible; below this value the switch would drive biomass negative.", "rejected": "A cell that switches metabolic pathway at t maintains non-negative biomass at t+1 only if its current biomass satisfies B ≤ c/(rΔt).", "E_acc": 0.559201717376709, "C_acc": 0.13561499118804932, "G_acc": 0.6291881058631199, "D_acc": 0.8368497639894485, "H_acc": 0.10184455662965775, "Q_acc": 0.7236606352829508, "E_rej": 0.49495264887809753, "C_rej": 0.2239837497472763, "G_rej": 0.6385576091706753, "D_rej": 0.8917730450630188, "H_rej": 0.1082269549369812, "Q_rej": 0.6989324800670148, "Delta_Q": 0.024728155215935965, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial online optimization: given unknown convex losses chosen by an adversary, bound regret using limited-memory algorithms.", "ancestors": ["A convex function satisfies the inequality f(λx + (1−λ)y) ≤ λf(x) + (1−λ)f(y) for all x, y and λ ∈ [0, 1].", "An adversary selects at each time step t = 1, 2, …, T a convex function f_{t} from a known domain.", "The learner chooses a decision point x_t from a closed convex set X ⊂ ℝ^d before seeing f_t.", "The instantaneous cost incurred at step t is c_t = f_t(x_t).", "Regret after T steps is defined as R_T = ∑_{t=1}^T f_t(x_t) − min_{x∈X} ∑_{t=1}^T f_t(x).", "An online gradient step with learning rate η updates x_{t+1}=Π_X(x_t − η∇f_t(x_t)), where Π_X denotes Euclidean projection onto X.", "Memory limitation restricts the algorithm to store only a fixed number k of past gradients, so only ∇f_{t−k}, …, ∇f_{t−1}, ∇f_t are available for choosing x_{t+1}.", "Bounded regret R_T is expressed by an upper bound R"]}, "accepted": "The premises fix the learner to a sliding window of k past gradients, so any update rule that needs older history is impossible.  Enumerating the extreme cases k = 0 (no memory) and k = T (full memory) and the intermediate regime 1 ≤ k < T, the only feasible regret bound that remains compatible with the standard online-gradient analysis is the one that scales with the horizon T and the largest gradient norm G.  Re-running the telescoping sum inside the projection framework while discarding gradients older than k steps gives the worst-case bound.\n\nHYPOTHESIS: For any sequence of convex losses with ||∇f_t(x)||₂ ≤ G, the memory-limited online gradient descent with fixed step-size η attains regret R_T ≤ (D²/η + ηG²T)/2 where D is the Euclidean diameter of X.\nVERIFICATION: Units consistent: D²/η has (length)²/(length²/cost)=cost, ηG²T has (length²/cost)(cost²/length²)T=cost.\nCONCLUSION: The learner guarantees sub-linear regret R_T = O(√T) by choosing η = D/(G√T).", "rejected": "For any sequence of convex losses with ||∇f_t(x)||₂ ≤ G, the memory-limited online gradient descent with fixed step-size η attains regret R_T ≤ (D²/η + ηG²k)/2 where D is the Euclidean diameter of X.", "E_acc": 0.36315298080444336, "C_acc": 0.3117946982383728, "G_acc": 0.539818691147957, "D_acc": 0.7525227156778177, "H_acc": 0.13661451637744904, "Q_acc": 0.5913937843210685, "E_rej": 0.3476111888885498, "C_rej": 0.28836920857429504, "G_rej": 0.558681090711616, "D_rej": 0.8785113096237183, "H_rej": 0.12148869037628174, "Q_rej": 0.6218991259811447, "Delta_Q": -0.030505341660076235, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["An intervention is a local alteration of a variable in a causal model.", "A causal model is a directed acyclic graph over variables with deterministic functions.", "An outcome is the value of a designated variable E.", "A counterfactual is the value E would take under an intervention not actually performed.", "Counterfactual attribution compares two counterfactual values of E under distinct interventions.", "The minimal set of causal changes is the smallest subset of altered parent variables whose values differ between the two interventions."]}, "accepted": "The premises define an intervention as a local alteration of a variable in a directed acyclic graph whose deterministic functions map parent values to each node.  Because any intervention changes at least one parent configuration, the smallest set of altered parents—the minimal set of causal changes—must be non-empty whenever two distinct counterfactual values of the outcome E are compared.\n\nHYPOTHESIS: The cardinality of the minimal set of causal changes is strictly greater than zero for every pair of distinct interventions that produce different counterfactual values of E.\n\nVERIFICATION: Units are counts (dimensionless) and the inequality holds for all deterministic DAGs with differing parent inputs.\n\nCONCLUSION: At least one parent variable must differ between any two interventions yielding distinct counterfactual outcomes.", "rejected": "The minimal set of causal changes can be empty even when two distinct interventions produce different counterfactual values of E.", "E_acc": 0.5096103549003601, "C_acc": 0.14043211936950684, "G_acc": 0.6554298134786742, "D_acc": 0.7761688500642776, "H_acc": 0.21299828588962555, "Q_acc": 0.6898165867158345, "E_rej": 0.015499895438551903, "C_rej": 0.8372077345848083, "G_rej": 0.6641194501093456, "D_rej": 0.8166670799255371, "H_rej": 0.1833329200744629, "Q_rej": 0.4150324357141342, "Delta_Q": 0.2747841510017003, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["A transparent explanation artifact e is a data structure fully observable to an agent.", "Strategic opacity is the withholding of some e.", "Agent utility U maps world states to real numbers.", "Gaming is an agent action a that increases U by exploiting e.", "Causal graph G = (V,E) contains vertices V and directed edges E.", "Domain D labels each v ∈ V as physical (D=0), social (D=1), or computational (D=2).", "Cross-domain intervention is a subset I ⊂ V with members from at least two D.", "Minimal cross-domain intervention has |I| = k where no smaller k achieves target state T."]}, "accepted": "Strategic opacity is the withholding of a fully observable explanation artifact e, and gaming is an action that increases utility U by exploiting e.  Because any retained portion of e can be exploited, the withholding must eliminate every fragment of e that could raise U above the no-gaming baseline.\n\nHYPOTHESIS: Strategic opacity must remove at least one vertex from every cross-domain intervention path of size |I| ≤ k_min that could enable gaming, where k_min is the size of the minimal cross-domain intervention that attains the target state T.\n\nVERIFICATION: k_min is dimensionless (count of vertices) and the regime holds for any causal graph G with labeled domains D.\n\nCONCLUSION: The agent must excise vertices until no intervention of size ≤ k_min spanning at least two domains remains exploitable for gaming.", "rejected": "Strategic opacity must remove vertices whose total |I| equals the utility gain ΔU measured in vertices.", "E_acc": 0.28777241706848145, "C_acc": 0.4702596962451935, "G_acc": 0.6251645269803703, "D_acc": 0.7859606653451919, "H_acc": 0.13176240026950836, "Q_acc": 0.5613285843096674, "E_rej": 0.1266692578792572, "C_rej": 0.34128955006599426, "G_rej": 0.5410629007965326, "D_rej": 0.762600839138031, "H_rej": 0.29674895107746124, "Q_rej": 0.5008007202297449, "Delta_Q": 0.0605278640799225, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["P is a program.", "E is a finite set of input-output examples.", "P(E) denotes the output of P on each input in E.", "P is consistent with E if P(E) equals the specified outputs.", "H is the hypothesis space of all programs under consideration.", "Risk is the expected error of P on unseen inputs from the data distribution.", "Overfitting occurs when P fits E exactly but incurs high Risk.", "Spurious patterns are statistical dependencies in E that do not hold in the full distribution.", "Simplicity is a total order ≤_H over H induced by a fixed program length metric.", "The synthesis task is to return the ≤_H-minimal P in H consistent with E."]}, "accepted": "Because the synthesis task selects the ≤_H-minimal program consistent with E, any program that encodes a spurious pattern must be longer than the true generator; hence the chosen program’s length provides an upper bound on the length of any program whose risk exceeds a user-chosen error tolerance ε.  \nLet L(P*) be the description length of the returned program; then for every ε>0 every program P with Risk(P)>ε satisfies L(P)≥L(P*).  \nHYPOTHESIS: The description length L(P*) of the ≤_H-minimal program consistent with E is a strict lower bound on the length of any program whose expected error exceeds a specified tolerance ε.  \nVERIFICATION: Units are bits (length) and probability (error), inequality holds for any ε∈(0,1].  \nCONCLUSION: If a candidate program is shorter than L(P*), its risk must be ≤ε, so L(P*) acts as a deterministic filter to discard high-risk hypotheses.", "rejected": "The description length L(P*) of the ≤_H-minimal program consistent with E is a strict upper bound on the length of any program whose expected error exceeds a specified tolerance ε.", "E_acc": 0.15340574085712433, "C_acc": 0.7309266328811646, "G_acc": 0.5889918468892574, "D_acc": 0.7853109270334244, "H_acc": 0.2012409120798111, "Q_acc": 0.45457285925745966, "E_rej": 0.40490174293518066, "C_rej": 0.1746181696653366, "G_rej": 0.5993177922708648, "D_rej": 0.862910121679306, "H_rej": 0.13708987832069397, "Q_rej": 0.6652834839054516, "Delta_Q": -0.2107106246479919, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["An experiment incurs a positive cost c.", "Each candidate experiment i is indexed by i ∈ {1, ..., N}.", "Every experiment yields an observable datum dᵢ.", "A finite discrete hypothesis space contains K competing hypotheses {H₁, ..., H_K}.", "Each hypothesis Hₖ assigns a known likelihood P(dᵢ | Hₖ) to every datum.", "The prior probability P(Hₖ) is defined for every hypothesis Hₖ.", "The entropy of the prior distribution is H_prior = -Σₖ P(Hₖ) log P(Hₖ).", "Posterior entropy given dᵢ is H_post(dᵢ) = -Σₖ P(Hₖ | dᵢ) log P(Hₖ | dᵢ).", "Expected information gain from experiment i is Iᵢ = H_prior - Σ_{dᵢ} P(dᵢ) H_post(dᵢ).", "The efficiency ratio for experiment i is Eᵢ = Iᵢ / cᵢ."]}, "accepted": "Because every experiment costs cᵢ > 0 and the information gain Iᵢ is non-negative, the efficiency Eᵢ = Iᵢ / cᵢ is bounded below by zero.  \nHYPOTHESIS: Any experiment with zero expected information gain (Iᵢ = 0) has strictly zero efficiency (Eᵢ = 0) regardless of its positive cost.  \nVERIFICATION: Units check: Iᵢ in bits, cᵢ in cost units, ratio dimensionless and ≥ 0.  \nCONCLUSION: Experiments offering no information gain should never be selected under an efficiency criterion.", "rejected": "Because the expected information gain Iᵢ and the cost cᵢ are treated as independent random variables, the efficiency ratio Eᵢ = Iᵢ / cᵢ remains valid even when they are perfectly correlated.", "E_acc": 0.203943133354187, "C_acc": 0.6201478242874146, "G_acc": 0.513481909641996, "D_acc": 0.7295666448771954, "H_acc": 0.30064210295677185, "Q_acc": 0.45569887575693424, "E_rej": 0.05598043277859688, "C_rej": 0.35248100757598877, "G_rej": 0.5076311335142236, "D_rej": 0.7429643869400024, "H_rej": 0.25703561305999756, "Q_rej": 0.4707134711032268, "Delta_Q": -0.01501459534629257, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["A program maps inputs to outputs.", "An example is an input-output pair (i,o).", "A program p is consistent with example (i,o) if p(i)=o.", "An example set E is a finite set of examples.", "The description length L(p) of a program p is the number of bits in its shortest encoding.", "Program p overfits E if there exists an example (i',o') not in E such that p(i')≠o'.", "The simplest consistent program p* minimizes L(p) among all programs consistent with E.", "The overfitting risk is the probability that p* overfits a new example drawn from the same distribution as E."]}, "accepted": "Because L(p*) is the minimum description length among all programs consistent with the finite example set E, any program with strictly shorter description length must fail on at least one example in E.  \nHence the difference L(p*) – L(p) for any p consistent with E is non-negative, and the only way this difference can be zero is if p itself is a shortest consistent program, forcing L(p)=L(p*).  \n\nHYPOTHESIS: For every program p consistent with E, L(p) ≥ L(p*), with equality if and only if p is also a simplest consistent program.  \nVERIFICATION: Both sides measure bits, so units match; the inequality holds for every finite E by definition of p*.  \nCONCLUSION: The description-length ordering places p* at the global minimum among consistent programs, so any competitor must be at least as long.", "rejected": "Because the description lengths of programs consistent with E are mutually independent, the probability that L(p*) exceeds L(p) for some other consistent p is positive.", "E_acc": 0.41262099146842957, "C_acc": 0.22445230185985565, "G_acc": 0.5626638978719711, "D_acc": 0.7521409183740616, "H_acc": 0.28116466104984283, "Q_acc": 0.61374033421278, "E_rej": 0.014733200892806053, "C_rej": 0.5570288896560669, "G_rej": 0.571403968706727, "D_rej": 0.8436714112758636, "H_rej": 0.15632858872413635, "Q_rej": 0.46039639946073296, "Delta_Q": 0.153343934752047, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["A family $\\mathcal{F}$ is a set of sets.", "The intersection $A \\cap B$ of two sets is their common elements.", "The intersection number $\\tau(\\mathcal{F})$ is the maximum size $|A \\cap B|$ over $A,B \\in \\mathcal{F}$ with $A \\neq B$.", "A constructive algorithm outputs an explicit object after finite steps.", "A constructive algorithm for $\\mathcal{F}$ builds an explicit family that satisfies a given intersection bound on $\\tau(\\mathcal{F})$.", "An extremal bound states the exact maximum possible value of a parameter, such as $\\tau(\\mathcal{F})$, under given constraints."]}, "accepted": "The premises define τ(ℱ) as the maximum pairwise intersection size in a family ℱ of distinct sets.  Because any two distinct sets can share at most all of their elements, the intersection size |A ∩ B| is bounded above by the size of the smaller set.  Taking the maximum over all pairs gives the global upper bound τ(ℱ) ≤ min{|A|,|B|} for every A,B ∈ ℱ, A ≠ B.\n\nHYPOTHESIS: For every finite family ℱ of finite sets, τ(ℱ) ≤ min_{A∈ℱ}|A|.\nVERIFICATION: Units check: both sides count elements, so dimensionless; inequality holds for every pair by definition of intersection.\nCONCLUSION: The intersection number of any finite family is at most the cardinality of its smallest member.", "rejected": "For every finite family ℱ of finite sets, τ(ℱ) ≤ max_{A∈ℱ}|A|.", "E_acc": 0.5857141017913818, "C_acc": 0.16844142973423004, "G_acc": 0.5800388891782079, "D_acc": 0.6850994192063808, "H_acc": 0.28904731571674347, "Q_acc": 0.666148874695812, "E_rej": 0.4794893264770508, "C_rej": 0.18474511802196503, "G_rej": 0.558339353118624, "D_rej": 0.6625833064317703, "H_rej": 0.3374166935682297, "Q_rej": 0.617340636891978, "Delta_Q": 0.04880823780383392, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Value alignment under ambiguous instructions: synthesize policies that generalize human intent when the utility function is partially specified.", "ancestors": ["U is a utility function mapping state-action pairs to real numbers.", "H observes state-action pairs and reports preference labels 0 or 1.", "R is the robot policy mapping states to actions.", "The dataset D is a finite set of triples (s,a,l) from H.", "A policy R* maximizes the expectation of U when U is fully specified.", "Ambiguity exists when D leaves some U values unconstrained."]}, "accepted": "Because D fixes only the relative ordering of observed state-action pairs, any utility scale that preserves these pairwise rankings is observationally equivalent; hence the smallest admissible difference between the maximum and minimum utility values consistent with D is bounded below by the number of distinct preference levels recorded.\n\nHYPOTHESIS: The range of any utility function U compatible with dataset D must satisfy max U(s,a) − min U(s,a) ≥ |{l unique in D}| − 1.\n\nVERIFICATION: Units are consistent (dimensionless count minus one).\n\nCONCLUSION: The robot must treat any candidate U with a smaller range as incompatible with the human’s demonstrated preference levels.", "rejected": "The range of any utility function U compatible with dataset D must satisfy max U(s,a) − min U(s,a) ≥ |{l unique in D}|.", "E_acc": 0.38359808921813965, "C_acc": 0.3891974687576294, "G_acc": 0.5587804224342108, "D_acc": 0.7293105646967888, "H_acc": 0.2604694068431854, "Q_acc": 0.5688111897557974, "E_rej": 0.10976549983024597, "C_rej": 0.6526565551757812, "G_rej": 0.5437853103503585, "D_rej": 0.7844464480876923, "H_rej": 0.2694419398903847, "Q_rej": 0.4411004966124892, "Delta_Q": 0.12771069314330818, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transport-limited reactivity: when diffusion and surface reaction couple nonlinearly, identify regimes where modifying transport is more effective than altering surface chemistry.", "ancestors": ["C is the surface reactant concentration.", "J is the diffusion flux to the surface.", "r = k C^n is the surface reaction rate.", "k is the surface rate constant.", "n is the reaction order with n ≥ 0.", "J = h(C_b – C) relates flux to bulk concentration C_b and transport coefficient h.", "At steady state, J = r.", "Da = k C_b^{n-1}/h defines the Damköhler number."]}, "accepted": "<derivation sentences>\nUsing the steady-state balance J = r and the given rate and transport laws, eliminate C between J = h(C_b – C) and r = k C^n to obtain k C^n = h(C_b – C).  Rearrange to the dimensionless form  \nDa (C/C_b)^n + (C/C_b) – 1 = 0,  \nwhere Da = k C_b^{n–1}/h.  For n ≥ 0 this algebraic equation has exactly one real root in 0 < C/C_b ≤ 1, so C is uniquely fixed by Da.  Insert this root back into the rate expression r = k C^n to express r solely in terms of C_b, k, h, n.  The resulting explicit relation gives the steady-state reaction rate as  \nr = k C_b^n [ (1 + n Da)^{-1/(n–1)} ] for n ≠ 1,  \nand r = k C_b /(1 + Da) for n = 1,  \nboth of which collapse to the single inequality  \nr ≤ min(k C_b^n, h C_b).  \nThus the surface rate is strictly limited by the smaller of the kinetic and transport limits.\n</derivation sentences>\n\nHYPOTHESIS: The steady-state surface reaction rate satisfies r ≤ min(k C_b^n, h C_b), equalling the kinetic limit k C_b^n when Da ≪ 1 and the transport limit h C_b when Da ≫ 1.\n\nVERIFICATION: Both sides have units mol m^{-2} s^{-1}; inequality holds for all Da = k C_b^{n–1}/h ≥ 0.\n\nCONCLUSION: The rate is bounded by the slower of surface kinetics or external mass transfer, with a sharp crossover at Da ≈ 1.", "rejected": "The steady-state surface reaction rate satisfies r ≥ min(k C_b^n, h C_b), equalling the kinetic limit k C_b^n when Da ≪ 1 and the transport limit h C_b when Da ≫ 1.", "E_acc": 0.48904046416282654, "C_acc": 0.245662122964859, "G_acc": 0.5647931098937988, "D_acc": 0.6938276984454954, "H_acc": 0.21622392535209656, "Q_acc": 0.6276814837885254, "E_rej": 0.33942314982414246, "C_rej": 0.4518701732158661, "G_rej": 0.5509375764910752, "D_rej": 0.8439813256263733, "H_rej": 0.1560186743736267, "Q_rej": 0.5748348232901965, "Delta_Q": 0.05284666049832887, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["Transparency t equals the probability an explanatory artifact is revealed.", "Opacity o equals 1 - t.", "Agent utility U increases with successful prediction of system responses.", "Agent cost C increases with effort spent to game the system.", "Gaming occurs when expected net gain U - C exceeds threshold k.", "Cross-domain causal graph G is the union of physical, social, and computational subgraphs."]}, "accepted": "<derivation sentences>\nPremise variables: t, o=1-t, U, C, k, G.  \nCases: (i) U-C>k → gaming, (ii) U-C≤k → no gaming.  \nOpacity o rises as t falls; higher o lowers predictability, hence lowers U.  \nLet U=U₀-αo with α>0; then U-C=U₀-α(1-t)-C.  \nGaming occurs when U₀-α(1-t)-C>k, i.e. t>1-(U₀-C-k)/α.  \nDefine critical transparency t*=1-(U₀-C-k)/α.  \nFor t>t* gaming is blocked; for t≤t* gaming occurs.  \nThus t* is the minimal transparency that eliminates gaming.  \n</derivation sentences>\n\nHYPOTHESIS: Gaming is eliminated if and only if transparency exceeds the critical threshold t*=1-(U₀-C-k)/α, where U₀ is baseline utility, C is gaming cost, k is gain threshold, and α quantifies opacity-driven utility loss.\n\nVERIFICATION: t* is dimensionless (ratio of utilities) and valid for α>0, U₀-C-k≥0.\n\nCONCLUSION: Set t>t* to prevent gaming; t* decreases with higher cost C or lower threshold k.", "rejected": "Gaming is eliminated if and only if transparency is below the critical threshold t*=1-(U₀-C-k)/α, where U₀ is baseline utility, C is gaming cost, k is gain threshold, and α quantifies opacity-driven utility loss.", "E_acc": 0.35811617970466614, "C_acc": 0.3126427233219147, "G_acc": 0.6074856312147209, "D_acc": 0.6851909735373088, "H_acc": 0.1926426887512207, "Q_acc": 0.5841773613223009, "E_rej": 0.10158718377351761, "C_rej": 0.47470295429229736, "G_rej": 0.6170775877045733, "D_rej": 0.8262404799461365, "H_rej": 0.17375952005386353, "Q_rej": 0.5068232257983514, "Delta_Q": 0.07735413552394954, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["Let p(x) denote the probability density of input x.", "Let M(x) map input x to the predicted label.", "Let L(x) = 1 if M(x) is incorrect and 0 otherwise.", "The model failure probability for density p is Pf = ∫ p(x) L(x) dx.", "A baseline reference density is q(x) > 0.", "Let E be a plausibility bound Pf(q) - Pf ≤ δ for some δ > 0.", "The objective is to maximize Pf subject to the plausibility condition.", "This requires a probability density p satisfying the plausibility bound.", "The feasible search space is D = {p(x)≥0 : ∫p=1 and Pf(q)-Pf≤δ}.", "The maximizer attains Pf* = sup_{p∈D} Pf."]}, "accepted": "The supremum Pf* is attained by a density p* that places all its mass on the set {x : L(x)=1}, because any mass on {x : L(x)=0} would strictly lower Pf without loosening the plausibility constraint Pf(q)−Pf ≤ δ.  Hence Pf* equals the maximum feasible value of ∫_{L=1} p(x)dx, which under the constraint Pf(q)−Pf ≤ δ is bounded above by min{1, Pf(q)+δ}.  Solving the linear program gives the exact value.\n\nHYPOTHESIS: Pf* = min{1, Pf(q)+δ}.\n\nVERIFICATION: Both sides are dimensionless probabilities; equality holds for every δ>0 and any reference q.\n\nCONCLUSION: The worst-case failure probability under the plausibility bound is the smaller of 1 and the reference failure rate plus the slack δ.", "rejected": "The supremum Pf* is attained by a density p* that places all its mass on the set {x : L(x)=0}, because any mass on {x : L(x)=1} would strictly raise Pf without loosening the plausibility constraint Pf(q)−Pf ≤ δ.", "E_acc": 0.3933802545070648, "C_acc": 0.2574635446071625, "G_acc": 0.549404927471187, "D_acc": 0.7170597389340401, "H_acc": 0.15000838041305542, "Q_acc": 0.6048134626704269, "E_rej": 0.230121448636055, "C_rej": 0.27335405349731445, "G_rej": 0.5721501295144359, "D_rej": 0.7581703662872314, "H_rej": 0.24182963371276855, "Q_rej": 0.5562467596804103, "Delta_Q": 0.04856670299001664, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["A is a Boolean variable.", "B is a Boolean variable.", "C is a Boolean variable.", "The statement \"A implies B\" is true except when A is true and B is false.", "\"A implies B unless C\" is true when either C is true or (A implies B) is true.", "C being conditionally dependent on B means C's value is determined by a function of B.", "C is a function of B.", "The directed graph G has vertices {A, B, C}.", "G has edges A→B and B→C.", "A fixed point of G is a state where every vertex's value equals its function's output given the other vertices' values."]}, "accepted": "The premises fix the directed graph G with vertices A, B, C and edges A→B and B→C, and state that C is a function of B.  Because the only incoming edge to C is B→C, the value of C is fully determined by the value of B; no other vertex feeds into C.  Therefore, for every Boolean state of B, C must equal the output of that function.\n\nHYPOTHESIS: For every Boolean assignment, C equals the deterministic Boolean function of B specified by the edge B→C.\nVERIFICATION: Units are consistent (Boolean in → Boolean out); regime is all 2³ Boolean states of (A,B,C).\nCONCLUSION: C is completely determined by B, reducing the 8 possible global states to 4 compatible ones.", "rejected": "For every Boolean assignment, B equals the deterministic Boolean function of C specified by the edge B→C.", "E_acc": 0.7451252341270447, "C_acc": 0.08777787536382675, "G_acc": 0.6190826568752528, "D_acc": 0.7777101472020149, "H_acc": 0.1714322715997696, "Q_acc": 0.7681973288208246, "E_rej": 0.44085636734962463, "C_rej": 0.28471583127975464, "G_rej": 0.6207475204020738, "D_rej": 0.8104130029678345, "H_rej": 0.18958699703216553, "Q_rej": 0.6425871489197016, "Delta_Q": 0.125610179901123, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["A program maps inputs to outputs.", "An example is an input-output pair (x, y).", "An example set E contains n such pairs.", "A hypothesis program h is consistent with E if h(x)=y for every (x,y) in E.", "The space of programs is countable.", "Each program has a length |h| in bits.", "k* denotes the length of the shortest program consistent with E.", "A prior assigns probability P(h)=2^{-|h|} to every program.", "Overfitting occurs when h fits E but errs on new inputs."]}, "accepted": "Summing the prior over all programs consistent with E gives the total Bayesian weight of the consistent subspace.  \nBecause every consistent program has length ≥ k*, the smallest possible weight for any single such program is 2^{-k*}, and the count of distinct programs of length k is at most 2^{k}, so the aggregate weight is bounded above by the geometric series Σ_{k≥k*} 2^{k}·2^{-k}=Σ_{k≥k*} 1, which diverges unless truncated by the shortest-length cutoff.  \nHence the summed prior weight of every program that agrees with E obeys the inequality Σ_{h consistent} 2^{-|h|} ≤ 2^{-k*+1}.\n\nHYPOTHESIS: The total prior probability of all programs consistent with E is at most 2^{-k*+1}.\n\nVERIFICATION: Dimensionless probability sum, valid for any countable program space with the given 2^{-|h|} prior.\n\nCONCLUSION: The consistent-program ensemble carries prior weight ≤ 2^{-k*+1}, so any posterior belief after observing E must assign probability ≤ 2^{-k*+1} to the event that the true generator lies outside this set.", "rejected": "The total prior probability of all programs shorter than k* is at most 2^{-k*+1}.", "E_acc": 0.5664287209510803, "C_acc": 0.19074642658233643, "G_acc": 0.5420119134443147, "D_acc": 0.7700214783350626, "H_acc": 0.2941805124282837, "Q_acc": 0.6647679580819039, "E_rej": 0.3827187120914459, "C_rej": 0.22131961584091187, "G_rej": 0.5727269963494369, "D_rej": 0.7833877801895142, "H_rej": 0.21661221981048584, "Q_rej": 0.620113423785993, "Delta_Q": 0.04465453429591093, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Paradoxes from self-reference: formalize a system where an agent's utility depends on predictions of its own future actions and derive consistency constraints.", "ancestors": ["S is a formal system containing agents, predictions, and a utility function.", "Agent A in S outputs action a_t at discrete time t.", "Predictor P in S maps any a_t to a predicted successor action a_{t+1}^P.", "Utility function U(a_t, a_{t+1}^P) gives A’s real-valued payoff at t.", "Self-reference arises when A’s choice of a_t influences P’s output a_{t+1}^P and thus U.", "Consistency requires that for all t, a_t maximizes U(a_t, P(a_t))."]}, "accepted": "Exploiting the consistency requirement that every a_t must maximize U(a_t, P(a_t)), we treat P(a_t) as a fixed forecast for the next action and differentiate U with respect to a_t.  Setting the derivative to zero gives the first-order condition ∂U/∂a_t + (∂U/∂a_{t+1}^P)(dP/da_t)=0, which rearranges to the slope-matching rule dP/da_t = – (∂U/∂a_t)/(∂U/∂a_{t+1}^P).  Hence any interior optimal action must satisfy this exact relation between the predictor’s sensitivity and the marginal utilities.\n\nHYPOTHESIS: Agent A’s optimal action a_t obeys dP/da_t = – (∂U/∂a_t)/(∂U/∂a_{t+1}^P) whenever the derivatives exist and the denominator is non-zero.\n\nVERIFICATION: Both sides are dimensionless ratios of utility change per action change, valid for interior maxima with differentiable U and P.\n\nCONCLUSION: A must choose the action whose predictive slope exactly balances the ratio of immediate to forecast marginal utility.", "rejected": "Agent A’s optimal action a_t obeys dP/da_t = (∂U/∂a_t) − (∂U/∂a_{t+1}^P) whenever the derivatives exist.", "E_acc": 0.5358327627182007, "C_acc": 0.15989409387111664, "G_acc": 0.5824277738907507, "D_acc": 0.7508174354831377, "H_acc": 0.36028602719306946, "Q_acc": 0.6593914491967076, "E_rej": 0.23138092458248138, "C_rej": 0.32606565952301025, "G_rej": 0.577157180789592, "D_rej": 0.7689681649208069, "H_rej": 0.23103183507919312, "Q_rej": 0.5503230311043028, "Delta_Q": 0.10906841809240475, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["Let B denote biomass.", "Let μ denote the instantaneous biomass production rate.", "Let r denote the external resource concentration.", "The rate μ depends on r.", "Switching between metabolic pathways incurs a cost C.", "Biomass dynamics satisfy dB/dt = μ(r) - C·δ, where δ indicates a pathway switch."]}, "accepted": "The instantaneous biomass production rate μ(r) is positive when resources are present, while the switching cost C·δ is incurred only when δ=1.  Setting dB/dt≥0 for non-decreasing biomass gives μ(r)≥C·δ.  For the worst-case scenario of a switch (δ=1), this inequality becomes μ(r)≥C.\n\nHYPOTHESIS: Biomass does not decline during a metabolic pathway switch if the external resource concentration r satisfies μ(r)≥C.\n\nVERIFICATION: Both μ(r) and C have units of biomass·time⁻¹, so the inequality is dimensionally consistent.\n\nCONCLUSION: The system maintains or increases biomass whenever the instantaneous production rate equals or exceeds the one-time switching cost.", "rejected": "Biomass does not decline during a metabolic pathway switch if the external resource concentration r satisfies r ≥ C.", "E_acc": 0.4527347981929779, "C_acc": 0.2162361443042755, "G_acc": 0.560667136994501, "D_acc": 0.828714186946551, "H_acc": 0.07224887609481812, "Q_acc": 0.6632245877757669, "E_rej": 0.3263840973377228, "C_rej": 0.31438201665878296, "G_rej": 0.549659859854728, "D_rej": 0.877416580915451, "H_rej": 0.12258341908454895, "Q_rej": 0.6081957721151412, "Delta_Q": 0.055028815660625674, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["Formula ∀x ∃y P(x,y) is assumed.", "Function c: Y → ℕ is assumed monotone.", "A y satisfying P(x,y) is called a witness for x.", "A witness y is cheapest for x if c(y) ≤ c(z) for every z with P(x,z).", "A Skolem function f: X → Y returns for each x a witness f(x).", "The cost of the Skolem function is the map x ↦ c(f(x)).", "For every k ∈ ℕ the set Y<sub>x,k</sub> := {y ∈ Y: c(y) ≤ k ∧ P(x,y)} is finite."]}, "accepted": "For every x the finite set Y_{x,k} grows with k and eventually contains a witness; monotonicity of c then forces the minimal cost among witnesses to equal the minimal k for which Y_{x,k} is non-empty.  \nHYPOTHESIS: For each x, the cheapest-witness cost equals min{k ∈ ℕ : Y_{x,k} ≠ ∅}.  \nVERIFICATION: Both sides have units of cost (natural numbers) and coincide by construction.  \nCONCLUSION: The cheapest-witness cost is exactly the smallest k for which the finite set Y_{x,k} is non-empty.", "rejected": "For every x, the cheapest-witness cost equals min{k ∈ ℕ : Y_{x,k} is infinite}.", "E_acc": 0.4851848781108856, "C_acc": 0.23329336941242218, "G_acc": 0.5465829308543887, "D_acc": 0.7912626639008522, "H_acc": 0.2542586252093315, "Q_acc": 0.6410400459808963, "E_rej": 0.5752649903297424, "C_rej": 0.26805606484413147, "G_rej": 0.5655969423907143, "D_rej": 0.8283554911613464, "H_rej": 0.17164450883865356, "Q_rej": 0.6805943199566433, "Delta_Q": -0.03955427397574707, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["Let V be a finite set of observed variables.", "Define a time-series x(t) for each x in V, t in Z.", "Let G be a directed graph with nodes V.", "Define an edge delay function d: G → N+.", "Let A(G,d) be the linear system x(t) = ∑_{(x,y)∈G} w_{yx} y(t-d_{yx}) + ε_x(t).", "Define the phase lag Δφ_{xy} at frequency f as arg S_{xy}(f) − arg S_{yy}(f).", "Let S_{xy}(f) be the cross-spectrum between x and y at frequency f.", "Let C be the set of minimal G satisfying Δφ_{xy}(G,d) = Δφ_{xy}^obs for all (x,y) in V×V.", "Recovery maps the observed Δφ_{xy}^obs to any G* ∈ C provided C is non-empty."]}, "accepted": "The cross-spectrum phase lag Δφ_{xy}(f) is obtained from the Fourier transform of the linear model A(G,d), giving arg S_{xy}(f)=arg[∑_{(y,x)∈G} w_{yx} e^{-i2πf d_{yx}} S_{yy}(f)].  Equating this to the observed Δφ_{xy}^{obs} yields the constraint arg[∑_{(y,x)∈G} w_{yx} e^{-i2πf d_{yx}}]=Δφ_{xy}^{obs}.  Hence any candidate graph must satisfy 2πf d_{yx}≡Δφ_{xy}^{obs} mod 2π for every edge (y,x) whose weight dominates the sum, so the delay d_{yx} is quantized to the nearest integer multiple of 1/f.\n\nHYPOTHESIS: For every directed edge (y,x) that carries the dominant weight in the observed band, the edge delay satisfies d_{yx}=round[ (Δφ_{xy}^{obs}+2πk)/(2πf) ] for some integer k with 0≤d_{yx}≤1/(2f).\n\nVERIFICATION: Dimensionless phase divided by frequency gives time in seconds; regime valid when |w_{yx}|≫|w_{zx}| for all other z.\n\nCONCLUSION: The admissible delays are discrete steps of size 1/f, so the search space for graph recovery collapses to a finite grid of delays per edge.", "rejected": "The admissible delays are discrete steps of size 2πf, so the search space for graph recovery collapses to a finite grid of delays per edge.", "E_acc": 0.4951508939266205, "C_acc": 0.23532404005527496, "G_acc": 0.5177557166607585, "D_acc": 0.7415954396128654, "H_acc": 0.17289455980062485, "Q_acc": 0.6360612354415934, "E_rej": 0.38565412163734436, "C_rej": 0.3491052985191345, "G_rej": 0.5232169447408523, "D_rej": 0.7378623485565186, "H_rej": 0.26213765144348145, "Q_rej": 0.5718772703025025, "Delta_Q": 0.06418396513909097, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["Implication A → B is true except when C is true.", "C is true only when B is true.", "C depends on B.", "A → (B ↔ ¬C).", "B ↔ ¬C.", "Fixed points satisfy B ↔ ¬C.", "Oscillatory chains satisfy B(t+1) = ¬C(t) and C(t) = B(t)."]}, "accepted": "The premises fix B and C as strict negations of one another and, through the oscillatory rule, impose that the next-time value of B equals the present-time value of C.  Combining these two constraints yields B(t+1)=¬B(t), so the system must flip B (and hence C) at every discrete step.\n\nHYPOTHESIS: The state of B alternates each time-step, obeying B(t+1)=¬B(t).\n\nVERIFICATION: Units are dimensionless Boolean states; regime holds for all t under the given update rule.\n\nCONCLUSION: The system exhibits a deterministic period-2 oscillation in B (and C).", "rejected": "The state of B alternates each time-step, obeying B(t+1)=¬B(t) for any arbitrary Boolean network.", "E_acc": 0.6186110377311707, "C_acc": 0.19049020111560822, "G_acc": 0.5532172782113776, "D_acc": 0.7596192449331284, "H_acc": 0.24442151188850403, "Q_acc": 0.6856104245362803, "E_rej": 0.592194139957428, "C_rej": 0.15273348987102509, "G_rej": 0.5498383580707014, "D_rej": 0.7898945212364197, "H_rej": 0.21010547876358032, "Q_rej": 0.6940475719980895, "Delta_Q": -0.008437147461809236, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["An intervention is an exogenous manipulation of a variable.", "A variable is a measurable attribute that can take different values.", "An outcome is the value of a variable designated as the effect.", "A causal graph is a directed acyclic graph whose nodes represent variables.", "A structural equation relates a node to its direct causes in the graph.", "A counterfactual outcome is the value of Y had X been set to x counter to fact.", "An atomic intervention replaces the equation for X by the constant x.", "The difference ΔY = Y₁ − Y₀ compares outcomes under interventions X=1 and X=0.", "A minimal explanation set S ⊆ Pa(Y) satisfies ΔY ≠ 0 only if variables in S change."]}, "accepted": "The premises define ΔY as the contrast between outcomes when an atomic intervention fixes X=1 versus X=0.  They also state that a minimal explanation set S ⊆ Pa(Y) guarantees ΔY ≠ 0 only if the values of variables in S change.  Because an atomic intervention on X replaces X’s structural equation with a constant, any downstream change in Y must be transmitted through directed paths from X to Y; if no such path exists, ΔY = 0.  Hence, for ΔY to be non-zero, X must be an ancestor of Y in the causal graph.\n\nHYPOTHESIS: ΔY ≠ 0 if and only if X is an ancestor of Y in the causal graph.\nVERIFICATION: The “if and only if” follows because (i) if X is an ancestor, the intervention changes at least one parent of Y (possibly Y itself), so S is non-empty and ΔY ≠ 0; (ii) if X is not an ancestor, no intervention on X can alter any parent of Y, so ΔY = 0.\nCONCLUSION: A non-zero average causal effect of X on Y is equivalent to the existence of a directed path from X to Y.", "rejected": "ΔY ≠ 0 only if X is independent of Y in the causal graph.", "E_acc": 0.7349741458892822, "C_acc": 0.0425020232796669, "G_acc": 0.5360107853387793, "D_acc": 0.7538281125681741, "H_acc": 0.24750615656375885, "Q_acc": 0.7452090030358661, "E_rej": 0.15805037319660187, "C_rej": 0.6977829337120056, "G_rej": 0.5656019921104113, "D_rej": 0.7200417518615723, "H_rej": 0.27995824813842773, "Q_rej": 0.4369914491971334, "Delta_Q": 0.3082175538387327, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["An intervention is a local exogenous change to a variable in a system.", "A causal model M is a directed acyclic graph over variables V.", "Each variable V_i has a deterministic function f_i of its parents Pa_i and exogenous noise u_i.", "An outcome is the complete value assignment to V under a specific intervention.", "A counterfactual outcome uses the same noise u_i as a factual outcome.", "Counterfactual attribution seeks a minimal subset S of V whose changed values explain the outcome difference.", "The explanation set S must satisfy S ⊆ (V \\ T) ∪ (T \\ V) where T and V are the two outcome vectors.", "The cardinality of S is the number of variables whose values differ between the two outcomes.", "A minimal S has no proper subset that also satisfies the difference condition."]}, "accepted": "The premises define a deterministic causal model where each variable’s value is fixed by its parents and a unique exogenous noise term.  Because counterfactual and factual worlds share exactly these same noise values, any difference between the two outcome vectors must arise from the intervention’s local change propagating through the functions.  Enumerating the possible difference patterns shows that the minimal explanation set S must contain at least one variable whose value flips directly under the intervention; otherwise no difference could appear.  Hence the smallest possible |S| is 1, and this lower bound is attainable whenever the intervention target is not overridden by downstream compensations.\n\nHYPOTHESIS: The cardinality of the minimal counterfactual attribution set S is exactly 1 when the intervention changes only the target variable and that variable’s value is not masked by any downstream deterministic compensations.\n\nVERIFICATION: |S| is dimensionless and the claim holds for any deterministic acyclic causal model with shared noise.\n\nCONCLUSION: Under deterministic acyclicity with shared noise, a single-variable difference suffices to explain the counterfactual shift unless downstream functions negate the intervention’s effect.", "rejected": "Under deterministic acyclicity with shared noise, a single-variable difference suffices to explain the counterfactual shift only if downstream functions negate the intervention’s effect.", "E_acc": 0.10178439319133759, "C_acc": 0.7507240772247314, "G_acc": 0.5496675245231017, "D_acc": 0.7820630286421094, "H_acc": 0.14129850268363953, "Q_acc": 0.43260676287713323, "E_rej": 0.012040517292916775, "C_rej": 0.8923542499542236, "G_rej": 0.5546918535837904, "D_rej": 0.8208779394626617, "H_rej": 0.17912206053733826, "Q_rej": 0.3823430577525869, "Delta_Q": 0.05026370512454631, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergent coordination from selfish agents with local rules: prove sufficient conditions for global cooperation without central control.", "ancestors": ["A finite population of agents is indexed by i ∈ {1..N}.", "Each agent has a binary action variable a_i ∈ {0,1}.", "The local payoff to agent i is a function π_i(a_i, n_i), where n_i = ∑_{j∈N_i} a_j.", "The set N_i is the fixed set of neighbors of i.", "The strategy update rule for i is s_i(t+1) = f_i(a_i(t), n_i(t)), a deterministic function.", "Global cooperation is the state where a_i = 1 for every i.", "A sufficient condition for global cooperation is f_i(0, n_i(t)) = 1 whenever n_i(t) ≥ k for every i, where k ≤ min_i |N_i|."]}, "accepted": "The premises fix a deterministic update rule f_i that maps the current state (a_i, n_i) to the next action.  Because the sufficient condition already forces f_i(0, n_i)=1 whenever n_i≥k, the only remaining way for cooperation to fail is if some agent currently has a_i=1 yet n_i<k.  To prevent this, the smallest network-wide threshold that guarantees every cooperator already meets the neighbor requirement is k = max_i |N_i|.\n\nHYPOTHESIS: Global cooperation is maintained after one update if and only if k ≥ max_i |N_i|.\n\nVERIFICATION: Units: k (neighbors) and |N_i| (neighbors) are dimensionless; inequality is dimension-consistent.\n\nCONCLUSION: Set k no smaller than the largest neighborhood size to ensure every agent’s cooperation persists.", "rejected": "Global cooperation is maintained after one update if and only if k ≥ min_i |N_i|.", "E_acc": 0.6994842290878296, "C_acc": 0.09723623842000961, "G_acc": 0.5615785864647478, "D_acc": 0.758242749919494, "H_acc": 0.18569156527519226, "Q_acc": 0.735793131791676, "E_rej": 0.6765434145927429, "C_rej": 0.12145379930734634, "G_rej": 0.589781234273687, "D_rej": 0.8573266863822937, "H_rej": 0.1426733136177063, "Q_rej": 0.7538265172857791, "Delta_Q": -0.01803338549410305, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["A probability space is the triple (Ω, F, P).", "An event E ⊂ Ω is rare when P(E) is near zero.", "The indicator 1_E equals 1 if ω ∈ E and 0 otherwise.", "A sampler outputs i.i.d. samples ω_1,...,ω_n.", "An adversarial sampler can alter the distribution from P to Q.", "The Radon-Nikodym derivative dP/dQ relates expectations under P and Q.", "An unbiased rare-event estimator is given by (1/n) Σ_{i=1}^n 1_E(ω_i) (dP/dQ)(ω_i)."]}, "accepted": "The estimator averages the indicator of the rare event re-weighted by the Radon-Nikodym factor; because the expectation under Q of this re-weighted indicator equals the P-probability of E, the sample mean converges to the same near-zero value that defines rarity.\n\nHYPOTHESIS: For every ε>0 there exists a finite n such that the absolute difference between the unbiased rare-event estimator (1/n) Σ_{i=1}^n 1_E(ω_i)(dP/dQ)(ω_i) and P(E) is below ε whenever the adversarially altered distribution Q satisfies Q≪P on E.\n\nVERIFICATION: Expectation under Q of the summand equals P(E), so the estimator is consistent; units cancel to yield a probability.\n\nCONCLUSION: The estimator remains consistent for arbitrarily small rare-event probabilities as long as Q is absolutely continuous with respect to P over the rare set.", "rejected": "The estimator converges to P(E) only if the absolute difference between (1/n) Σ_{i=1}^n 1_E(ω_i)(dP/dQ)(ω_i) and P(E) is below ε for every ε>0 and some finite n, implying Q≪P on E.", "E_acc": 0.45306092500686646, "C_acc": 0.22560934722423553, "G_acc": 0.557149420492351, "D_acc": 0.8065441511571407, "H_acc": 0.13098576664924622, "Q_acc": 0.6504365457221866, "E_rej": 0.09361231327056885, "C_rej": 0.20739628374576569, "G_rej": 0.5677857078262605, "D_rej": 0.7285865396261215, "H_rej": 0.2714134603738785, "Q_rej": 0.518737540685106, "Delta_Q": 0.13169900503708054, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["A set is a collection of distinct elements.", "The size of a finite set E is the cardinality |E|.", "A family F is a set whose members are themselves sets.", "A k-uniform family has every member set of size k.", "An intersection constraint is a fixed bound t on |A ∩ B| for any distinct A,B in F.", "A maximum family satisfies |F| ≥ |G| for every legal family G under a given constraint.", "The extremal bound is the largest possible |F| meeting a stated intersection limit.", "Constructive combinatorics produces an algorithm that explicitly lists the sets achieving the extremal bound."]}, "accepted": "For any k-uniform family F with intersection bound t, the maximum attainable size |F| is at least the binomial coefficient C(n,t+1) whenever n ≥ k + t + 1, because each (t+1)-element subset of an n-element ground set can serve as the core of a distinct k-set while keeping pairwise intersections ≤ t.\n\nHYPOTHESIS: |F| ≥ C(n,t+1) for every k-uniform family on n elements with intersection bound t provided n ≥ k + t + 1.\n\nVERIFICATION: Both sides count sets, yielding dimensionless integers; inequality holds in the regime n ≥ k + t + 1.\n\nCONCLUSION: The extremal size of such a family is bounded below by C(n,t+1).", "rejected": "For any k-uniform family F with intersection bound t, the maximum attainable size |F| is at least the binomial coefficient C(n,t+1) whenever n ≥ k + t + 1, because each (t+1)-element subset of an n-element ground set can be chosen independently as the core of a distinct k-set while keeping pairwise intersections ≤ t.", "E_acc": 0.43838557600975037, "C_acc": 0.35941290855407715, "G_acc": 0.5714244964931693, "D_acc": 0.763439416885376, "H_acc": 0.1472172737121582, "Q_acc": 0.6118841463966029, "E_rej": 0.23933592438697815, "C_rej": 0.25525712966918945, "G_rej": 0.5708752237260342, "D_rej": 0.8618343770503998, "H_rej": 0.13816562294960022, "Q_rej": 0.5934747092425824, "Delta_Q": 0.018409437154020547, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Measurement back-action trade-offs: quantify how much information gain about an observable forces disturbance on its incompatible conjugates.Information flow in regulatory networks: identify motifs that guarantee robust signal propagation despite stochastic expression and component failure.", "ancestors": ["A quantum observable Â is represented by a Hermitian operator.", "Its conjugate observable B̂ satisfies the commutation relation [Â, B̂] = iħ.", "A measurement of Â with outcome a collapses the state into the eigenstate |a⟩.", "The post-measurement variance of B̂ on |a⟩ is ⟨(B̂ − ⟨B̂⟩)²⟩.", "The information gain about Â is quantified by the Fisher information Fₐ.", "The disturbance imparted to B̂ is the increase Δσ²_{B} of its variance.", "The joint lower bound is Fₐ Δσ²_{B} ≥ (ħ/2)².", "A gene regulatory network is a directed graph G(V, E).", "The robustness R of a signaling motif M ⊂ G is the probability that the output node state remains unchanged under stochastic node failures."]}, "accepted": "The premises give a quantum lower bound Fₐ Δσ²_{B} ≥ (ħ/2)² and define robustness R as a probability in a gene network.  \nHYPOTHESIS: Any signaling motif M whose output node encodes the result of a quantum-limited measurement of Â must satisfy R ≤ 1 − (ħ/2)²/(Fₐ σ²_{B,initial}).  \nVERIFICATION: Dimensionless probability on both sides; bound tightest when initial variance σ²_{B,initial} ≫ (ħ/2)²/Fₐ.  \nCONCLUSION: Increasing Fisher information beyond (ħ/2)²/σ²_{B,initial} forces the network’s robustness to drop below unity.", "rejected": "Any signaling motif M whose output node encodes the result of a quantum-limited measurement of Â must satisfy R ≥ 1 − (ħ/2)²/(Fₐ σ²_{B,initial}).", "E_acc": 0.5264164805412292, "C_acc": 0.22966048121452332, "G_acc": 0.52654237531533, "D_acc": 0.7571640461683273, "H_acc": 0.20746766030788422, "Q_acc": 0.6479873661854072, "E_rej": 0.22499588131904602, "C_rej": 0.263584166765213, "G_rej": 0.5345895094797015, "D_rej": 0.7688235640525818, "H_rej": 0.28897054493427277, "Q_rej": 0.5465674912557006, "Delta_Q": 0.10141987492970661, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["N is the finite set of players.", "A coalition S is any subset of N.", "The empty set ∅ is not a coalition.", "A partition π divides N into disjoint coalitions whose union is N.", "The worth of coalition S depends on the entire partition π.", "v(S, π) is a real-valued characteristic function.", "Utility is transferable among members of S.", "An imputation x ∈ ℝ^N satisfies Σ_{i∈S} x_i = v(S, π) for every S in π."]}, "accepted": "Summing the imputation condition Σ_{i∈S} x_i = v(S, π) over every coalition S in the partition π and noting that each player i ∈ N appears in exactly one such S gives Σ_{S∈π} Σ_{i∈S} x_i = Σ_{S∈π} v(S, π).  The left side collapses to Σ_{i∈N} x_i, so the total amount distributed to all players equals the total worth generated by the coalitions in that partition.\n\nHYPOTHESIS: For every partition π, the aggregate imputation equals the aggregate worth: Σ_{i∈N} x_i = Σ_{S∈π} v(S, π).\n\nVERIFICATION: Both sides carry units of utility; equality holds for every partition π by construction.\n\nCONCLUSION: The hypothesis enforces budget balance across the entire player set, providing an exact accounting identity that any valid imputation must satisfy.", "rejected": "For every partition π, the aggregate imputation equals the aggregate worth: Σ_{i∈N} x_i = Σ_{S∈π} v(S, π) + x_j, where j is any single fixed player.", "E_acc": 0.4687903821468353, "C_acc": 0.18358860909938812, "G_acc": 0.5838869506759303, "D_acc": 0.8146735429763794, "H_acc": 0.12922536581754684, "Q_acc": 0.6707089549728803, "E_rej": 0.3324558734893799, "C_rej": 0.3294495642185211, "G_rej": 0.5632983100201402, "D_rej": 0.8568177223205566, "H_rej": 0.14318227767944336, "Q_rej": 0.6035518279033047, "Delta_Q": 0.06715712706957555, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["A vocabulary V consists of primitive symbols.", "A symbol sequence length is a positive integer n.", "An operation map T acts on symbol sequences.", "A grammar G specifies which sequences belong to the same compositional class.", "A dataset D contains sequence–label pairs sampled from V and labelled correctly under G.", "Compositional accuracy measures correct labels on unseen sequences with parts permuted or substituted within V."]}, "accepted": "Because compositional accuracy is defined only on unseen sequences obtained by permuting or substituting symbols already present in the training vocabulary, the dataset D must contain every primitive symbol in V at least once; otherwise a test sequence could introduce a symbol never seen during training, making the required label indeterminate under G.  \nHYPOTHESIS: A dataset D that guarantees measurable compositional accuracy under grammar G must include every primitive symbol of V at least once.  \nVERIFICATION: Counting argument—if any symbol is missing, a single-symbol test sequence composed of that symbol would be unlabeled, violating the accuracy definition.  \nCONCLUSION: Full vocabulary coverage in D is a necessary condition for valid compositional accuracy assessment.", "rejected": "A dataset D that guarantees measurable compositional accuracy under grammar G must include every primitive symbol of V exactly twice.", "E_acc": 0.7413820624351501, "C_acc": 0.09492169320583344, "G_acc": 0.6100807138718665, "D_acc": 0.8086803518235683, "H_acc": 0.23922018706798553, "Q_acc": 0.7632604745216668, "E_rej": 0.4017907977104187, "C_rej": 0.18561604619026184, "G_rej": 0.6106011430965737, "D_rej": 0.8132527470588684, "H_rej": 0.2801208794116974, "Q_rej": 0.6401727201649919, "Delta_Q": 0.12308775435667485, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["Let N be a finite set of players.", "A coalition S is any subset of N.", "A coalition structure π is a partition of N into disjoint coalitions.", "A payoff allocation x_S assigns a real-valued payoff to each coalition.", "Transferable utility means total payoff of S can be freely divided among its members.", "An externality e(S,π) is the total external effect on coalition S from the other coalitions in π.", "A payoff profile (x,π) is in the core if no group S can improve its total by deviating and forming a new coalition."]}, "accepted": "Because every coalition S already receives its total payoff x_S and the premises impose no restriction on how the externality e(S,π) is internalised, the only way the core condition can be preserved is to require that the sum of the externality-adjusted payoff across all coalitions never exceeds the total payoff available to the grand coalition.  \nHYPOTHESIS: For every coalition structure π, the aggregate externality satisfies ∑_{S∈π} e(S,π) ≤ 0.  \nVERIFICATION: Left side is payoff units; inequality holds whenever core stability is maintained under transferable utility.  \nCONCLUSION: Negative or zero total externality is necessary for the existence of a core-stable allocation.", "rejected": "For every coalition structure π, the aggregate externality satisfies ∑_{S∈π} e(S,π) = 0, independently of the payoff allocation x.", "E_acc": 0.11810494214296341, "C_acc": 0.5248100161552429, "G_acc": 0.5799075947143137, "D_acc": 0.8159789368510246, "H_acc": 0.13416126370429993, "Q_acc": 0.4962306593544781, "E_rej": 0.029745904728770256, "C_rej": 0.6435976624488831, "G_rej": 0.5868809833191335, "D_rej": 0.8995600938796997, "H_rej": 0.10043990612030029, "Q_rej": 0.4674484637565911, "Delta_Q": 0.028782195597886973, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["Let P denote a program in a fixed Turing-complete language.", "Let E denote a finite multiset of input-output examples (x, y).", "A specification S is a set of programs satisfying a property.", "P is consistent with E if for every (x, y) in E, P(x) = y.", "A program P is k-simple if its description length in bits is ≤ k.", "The version space V(E) is the set of all programs consistent with E.", "The risk of overfitting is the probability that a program in V(E) fails on unseen inputs drawn from distribution D."]}, "accepted": "Because every program in the version space V(E) is consistent with the finite multiset E, the size of V(E) equals the number of distinct programs whose behaviour matches every example in E.  For any fixed description-length bound k, the set of k-simple programs is finite; hence the subset of k-simple programs that also lie in V(E) is finite and its cardinality is at most the total number of k-simple programs, 2^{k+1}-1.  This bound is tight when E is empty, so the maximum possible size of the k-simple version space is completely determined by k alone.\n\nHYPOTHESIS: The cardinality of the k-simple version space is at most 2^{k+1}-1 programs.\n\nVERIFICATION: Dimensionless count; bound holds for every finite E and every k≥0.\n\nCONCLUSION: Enumerating or sampling the k-simple consistent programs is guaranteed to terminate within 2^{k+1}-1 steps.", "rejected": "The cardinality of the k-simple version space equals 2^{k+1}-1 programs regardless of the size of E.", "E_acc": 0.47321730852127075, "C_acc": 0.2707512676715851, "G_acc": 0.5501211692268649, "D_acc": 0.7672720849514008, "H_acc": 0.17036372423171997, "Q_acc": 0.6342572174345453, "E_rej": 0.019866134971380234, "C_rej": 0.7585445046424866, "G_rej": 0.5668269426872333, "D_rej": 0.8001449704170227, "H_rej": 0.1998550295829773, "Q_rej": 0.40765981922547023, "Delta_Q": 0.2265973982090751, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["A is a Boolean variable.", "B is a Boolean variable.", "C is a Boolean variable.", "The expression A → (¬C → B) is true.", "The expression C ↔ B is true.", "A is true."]}, "accepted": "Given A true, the implication A → (¬C → B) reduces to ¬C → B, which is equivalent to C ∨ B.  \nCombined with the biconditional C ↔ B, the only consistent assignments are (C, B) = (0, 0) or (1, 1).  \nThe disjunction C ∨ B eliminates (0, 0), leaving (1, 1) as the sole possibility.\n\nHYPOTHESIS: C and B are both true.\nVERIFICATION: Direct truth-table check under premises; no units involved.\nCONCLUSION: C = B = 1 is the unique assignment satisfying all premises.", "rejected": "Because C and B are independent under C ↔ B, we can set C = 1 and B = 0.", "E_acc": 0.11886812001466751, "C_acc": 0.6771163940429688, "G_acc": 0.5876832006615587, "D_acc": 0.7708025276660919, "H_acc": 0.17998820543289185, "Q_acc": 0.4539354823180475, "E_rej": 0.2067149132490158, "C_rej": 0.5523383021354675, "G_rej": 0.5697810791432858, "D_rej": 0.7658604383468628, "H_rej": 0.2341395616531372, "Q_rej": 0.49526116088032723, "Delta_Q": -0.041325678562279755, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["Regret is the non-negative difference between the reward obtained and the best reward that could have been obtained.", "Metareasoning is reasoning about how to allocate computational resources among reasoning tasks.", "A subproblem is a component reasoning task that consumes compute and yields a partial reward.", "Compute is measured in abstract units that are divisible and finite.", "Diminishing returns means that incremental reward per incremental compute decreases as compute to a subproblem increases.", "Expected regret is the expectation of regret over uncertain rewards of subproblems.", "The allocation vector a assigns compute a_i to subproblem i, subject to the constraint that the sum of all a_i equals the total available compute T.", "The expected regret R(a) is a function of the allocation vector a.", "The optimal allocation a* minimizes R(a) under the constraints."]}, "accepted": "Because expected regret R(a) is minimized by the optimal allocation a*, and because diminishing returns guarantees that the marginal reduction in R(a) from an extra unit of compute to any subproblem falls as its a_i rises, the only way to keep all marginal regret reductions equal (the first-order condition for optimality) is to allocate compute so that the marginal expected regret reduction per unit compute is the same for every subproblem that receives positive compute.  \nHYPOTHESIS: Under diminishing returns, the optimal allocation a* satisfies the equality of marginal expected regret reduction across all subproblems with a_i > 0.  \nVERIFICATION: Units check: (regret reduction)/(compute) is dimensionless per unit compute, so equality is dimensionally consistent.  \nCONCLUSION: At optimum, reallocating any compute from a subproblem with lower marginal regret reduction to one with higher marginal regret reduction would strictly decrease total expected regret.", "rejected": "Under diminishing returns, the optimal allocation a* equalizes the total expected regret reductions across all subproblems with a_i > 0.", "E_acc": 0.45934611558914185, "C_acc": 0.2016134262084961, "G_acc": 0.5817945048745189, "D_acc": 0.8029736243188381, "H_acc": 0.19368883222341537, "Q_acc": 0.6550658920513731, "E_rej": 0.31558865308761597, "C_rej": 0.2713959813117981, "G_rej": 0.5996429989380496, "D_rej": 0.8398169875144958, "H_rej": 0.16018301248550415, "Q_rej": 0.6122710957058838, "Delta_Q": 0.04279479634548933, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["A closed finite classical system has Hamiltonian dynamics.", "The Hamiltonian H(q,p) is constant in time.", "Phase-space volume is conserved under Hamiltonian flow.", "A macrostate is defined by a coarse observable f(q,p).", "The number of microstates in macrostate f is Ω(f).", "The Boltzmann entropy is S(f)=k ln Ω(f).", "An initial macrostate f₀ has Ω(f₀)≪Ω_max.", "After a recurrence time τ_rec≈e^{S_max/k} the state returns to f₀."]}, "accepted": "The conserved phase-space volume and the enormous recurrence time τ_rec≈e^{S_max/k} imply that any macrostate with Ω≪Ω_max must spend almost all of its history in higher-entropy configurations; the fraction of time it occupies the low-entropy initial state is therefore bounded by the ratio of its own phase-space volume to the total available volume.  Using the entropy difference ΔS=k ln(Ω_max/Ω(f₀)), this fraction is e^{-ΔS/k}.\n\nHYPOTHESIS: The fraction of recurrence time that the system spends in the initial low-entropy macrostate f₀ is e^{-ΔS/k}, where ΔS=k ln(Ω_max/Ω(f₀)).\n\nVERIFICATION: The exponent is dimensionless and the result is valid for any finite classical Hamiltonian system with Ω(f₀)≪Ω_max.\n\nCONCLUSION: The system spends a vanishingly small fraction ~e^{-ΔS/k} of its recurrence time in the low-entropy initial macrostate f₀.", "rejected": "The fraction of recurrence time that the system spends in the initial low-entropy macrostate f₀ is e^{-ΔS/k}, where ΔS is treated as independent of the ratio Ω_max/Ω(f₀).", "E_acc": 0.4856782853603363, "C_acc": 0.20155100524425507, "G_acc": 0.5686435789102688, "D_acc": 0.7938422083854675, "H_acc": 0.17462503165006638, "Q_acc": 0.6604279388533905, "E_rej": 0.3004204332828522, "C_rej": 0.4788973331451416, "G_rej": 0.5641864945646375, "D_rej": 0.8367000818252563, "H_rej": 0.16329991817474365, "Q_rej": 0.5581939868163318, "Delta_Q": 0.10223395203705865, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergent coordination from selfish agents with local rules: prove sufficient conditions for global cooperation without central control.", "ancestors": ["A set of agents A = {a₁, …, aₙ} exists.", "Each agent aᵢ chooses a binary action xᵢ ∈ {0,1}.", "Agent aᵢ receives payoff uᵢ(xᵢ,x_N(i)) where N(i) is the set of its k neighbors.", "The game is repeated for discrete time steps t = 1,2, … .", "A local rule is a function f that maps aᵢ’s neighborhood state x_N(i) to xᵢ(t+1).", "Global cooperation is the state where every xᵢ = 1 for all i."]}, "accepted": "Because the premises fix the neighborhood size k but leave the local rule f unconstrained, the only determinate relation emerges when we require every agent to adopt cooperation (xᵢ=1) at the next step.  For this to occur for every i, the rule must map every one of the 2ᵏ possible neighborhood states to 1, so the minimum fraction of cooperative mappings is 1.  This fraction is therefore a strict threshold for global cooperation to persist under any deterministic local rule.\n\nHYPOTHESIS: Global cooperation persists after one update only if every agent’s local rule maps all 2ᵏ neighborhood states to 1, i.e. the required fraction of cooperative mappings is exactly 1.\n\nVERIFICATION: The fraction is dimensionless and equals 1 precisely when the rule is the constant function f ≡ 1.\n\nCONCLUSION: A local rule must be the unanimous “always cooperate” function to guarantee that the entire network remains in the all-cooperate state after one synchronous update.", "rejected": "Global cooperation persists after one update only if every agent’s local rule maps all 2ᵏ neighborhood states independently of one another, so the required fraction of cooperative mappings is exactly 1.", "E_acc": 0.23320980370044708, "C_acc": 0.3134041726589203, "G_acc": 0.5399671080189624, "D_acc": 0.7498839550784656, "H_acc": 0.31106288731098175, "Q_acc": 0.5341460304667376, "E_rej": 0.14260120689868927, "C_rej": 0.11740745604038239, "G_rej": 0.5496826673458729, "D_rej": 0.7748114764690399, "H_rej": 0.22518852353096008, "Q_rej": 0.5616788472714169, "Delta_Q": -0.02753281680467934, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["A set of players N = {1, ..., n} is finite.", "A coalition S is any subset of N.", "A coalition structure C is a partition of N into disjoint coalitions.", "Each coalition S has a transferable-utility value v(S;C) depending on the entire structure C.", "A payoff vector x ∈ ℝⁿ satisfies Σ_{i∈S} x_i = v(S;C) for every S ∈ C.", "An allocation x is in the core if for every coalition T ⊆ N, Σ_{i∈T} x_i ≥ v(T;C′) for every C′ containing T.", "The core is nonempty if and only if the dual of the associated linear program has a feasible solution."]}, "accepted": "The premises link core non-emptiness to dual feasibility of a linear program whose constraints encode every coalition’s worth under every partition.  \nBecause the dual requires a non-negative price vector y satisfying Σ_{S∋i} y_S ≥ 1 for every player i, the sum of these individual constraints over all players yields n ≤ Σ_{S⊆N} |S| y_S.  \nCombined with the dual objective bound Σ_{S⊆N} v(S;C_S) y_S (where C_S is any partition containing S), the total of all values weighted by y must reach at least the population size for feasibility to hold.\n\nHYPOTHESIS: A necessary condition for the core to be nonempty is Σ_{S⊆N} v(S;C_S) y_S ≥ n for some non-negative weights {y_S} satisfying Σ_{S∋i} y_S ≥ 1 for every player i.\n\nVERIFICATION: Both sides are dimensionless counts; inequality holds in the dual-feasible regime.\n\nCONCLUSION: Any game whose maximum weighted value sum falls below n fails the dual test, so the core is empty.", "rejected": "A necessary condition for the core to be nonempty is Σ_{S⊆N} v(S;C_S) y_S ≥ n² for some non-negative weights {y_S} satisfying Σ_{S∋i} y_S ≥ 1 for every player i.", "E_acc": 0.4271354079246521, "C_acc": 0.15714684128761292, "G_acc": 0.5525681669158595, "D_acc": 0.8045230458180109, "H_acc": 0.14805462211370468, "Q_acc": 0.6533240344552766, "E_rej": 0.36333248019218445, "C_rej": 0.3192429542541504, "G_rej": 0.5429348205881459, "D_rej": 0.81831094622612, "H_rej": 0.18168905377388, "Q_rej": 0.5992314011922906, "Delta_Q": 0.05409263326298608, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Common-pool resource harvesting with delayed punishment: design enforcement schemes that stabilize cooperation despite monitoring noise.Trade-offs between fairness metrics: show impossibility results when multiple fairness criteria and calibration requirements are simultaneously enforced.", "ancestors": ["A common-pool resource (CPR) is subtractable.", "Harvesters remove units from the CPR stock.", "Let h_i denote harvester i’s harvest quantity.", "Let C denote the CPR’s current stock.", "C decreases when the sum of all h_i is positive.", "Delayed punishment imposes a penalty at time t+T after an action at t.", "Let T be the fixed positive delay.", "Monitoring noise introduces a random error into each observed h_i.", "Let ε_i be the zero-mean random noise added to h_i.", "Fairness criteria are formal predicates over the vector of harvests."]}, "accepted": "Because the stock C falls whenever aggregate harvest is positive and delayed punishment is imposed only after a fixed lag T, any observed post-lag penalty must have been triggered by a harvest that occurred at least T time units earlier.  \nHYPOTHESIS: A penalty observed at time t+T implies that the sum of harvests over all harvesters was strictly positive at time t.  \nVERIFICATION: Units are consistent (time in both sides); holds under the stated delay rule.  \nCONCLUSION: The penalty observation at t+T serves as a deterministic indicator that the CPR experienced net withdrawal at the corresponding earlier time t.", "rejected": "A penalty observed at time t+T implies that the sum of harvests over all harvesters was strictly positive at time t plus the stock level C.", "E_acc": 0.5043427348136902, "C_acc": 0.15880326926708221, "G_acc": 0.5859156765509397, "D_acc": 0.7448240108788013, "H_acc": 0.2405344322323799, "Q_acc": 0.6616366608534008, "E_rej": 0.13519568741321564, "C_rej": 0.3954772651195526, "G_rej": 0.563839633949101, "D_rej": 0.7470432221889496, "H_rej": 0.2529567778110504, "Q_rej": 0.4983441466465592, "Delta_Q": 0.1632925142068416, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["A set X contains atomic elements.", "A function f maps X to a codomain Y.", "A composition operator ∘ combines two functions g and h.", "The identity function id satisfies id(x)=x for every x in X.", "For every function f, f∘id=f and id∘f=f.", "Given functions g,h,k, the associative law states (g∘h)∘k=g∘(h∘k).", "A category C comprises objects Ob(C) and arrows Arr(C) between them.", "Each arrow f in Arr(C) has a domain dom(f) and a codomain cod(f) in Ob(C).", "For every object A in Ob(C), an identity arrow id_A exists in Arr(C) such that dom(id_A)=A and cod(id_A)=A.", "For arrows f:A→B and g:B→C, a composite arrow g∘f:A→C is defined in Arr(C)."]}, "accepted": "The premises describe a category C whose arrows obey composition, associativity, and identity laws.  Because every object A has an identity arrow id_A and every arrow f:A→B satisfies f∘id_A=f, the set End(A) of arrows from A to itself forms a monoid under composition with id_A as the unit.  Restricting to End(A) therefore yields a concrete algebraic structure.\n\nHYPOTHESIS: For every object A in a category C, the set End(A) of endomorphisms on A constitutes a monoid whose identity element is id_A and whose operation is arrow composition.\n\nVERIFICATION: Units check—composition is associative and unital by the category axioms.\n\nCONCLUSION: End(A) is a monoid with operation ∘ and identity id_A.", "rejected": "For every object A in a category C, the set End(A) of endomorphisms on A constitutes a group whose identity element is id_A and whose operation is arrow composition.", "E_acc": 0.5218444466590881, "C_acc": 0.0994388610124588, "G_acc": 0.5303227445775909, "D_acc": 0.771785669028759, "H_acc": 0.15068185329437256, "Q_acc": 0.6820190591870674, "E_rej": 0.45923078060150146, "C_rej": 0.30202755331993103, "G_rej": 0.5503214617658939, "D_rej": 0.8016490340232849, "H_rej": 0.1983509659767151, "Q_rej": 0.6279227260766285, "Delta_Q": 0.05409633311043893, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["An evolutionary game is a symmetric contest among phenotypes whose payoff depends on the current frequency distribution of phenotypes in a finite population.", "Players choose pure strategies drawn from a finite set S = {s₁, ..., sₖ}.", "Payoff to strategy sᵢ versus sⱼ is a constant aᵢⱼ that forms a k × k payoff matrix A.", "Mean payoff to pure strategy sᵢ in a population with strategy frequency vector p is πᵢ(p) = ∑ⱼ aᵢⱼpⱼ.", "Mean population payoff is π(p) = ∑ᵢ pᵢπᵢ(p).", "A strategy p* is a Nash equilibrium if πᵢ(p*) ≤ π(p*) for every i such that p*_i = 0 and for every other strategy q.", "A strategy p* is an evolutionarily stable strategy (ESS) if it is a Nash equilibrium and for every q ≠ p* there exists ε_q > 0 such that π(q, (1 - ε_q)p* + ε_q q) < π(p*, (1 - ε_q)p* + ε_q q) for all 0 < ε < ε_q."]}, "accepted": "The payoff matrix A and the frequency vector p together determine the mean payoff π(p) = pᵀAp.  Because every ESS must first be a Nash equilibrium, any strategy p* that satisfies the ESS definition must obey the equilibrium condition πᵢ(p*) ≤ π(p*) for every pure strategy i whose frequency p*_i = 0.  This requirement imposes a lower bound on the diagonal element aᵢᵢ relative to the off-diagonal entries whenever p*_i = 0.\n\nHYPOTHESIS: For any ESS p* with p*_i = 0, the diagonal payoff aᵢᵢ must satisfy aᵢᵢ ≤ π(p*).\n\nVERIFICATION: Units consistent (payoff ≤ payoff); holds for every finite symmetric game.\n\nCONCLUSION: The diagonal entry aᵢᵢ acts as an upper ceiling on the equilibrium payoff whenever strategy i is absent from the ESS.", "rejected": "For any ESS p* with p*_i = 0, the diagonal payoff aᵢᵢ must satisfy aᵢᵢ ≥ π(p*).", "E_acc": 0.5366160273551941, "C_acc": 0.1703425943851471, "G_acc": 0.5817030081525445, "D_acc": 0.7256915979087353, "H_acc": 0.20236828923225403, "Q_acc": 0.6681583816185594, "E_rej": 0.478183776140213, "C_rej": 0.19945622980594635, "G_rej": 0.5813740356825292, "D_rej": 0.7134763151407242, "H_rej": 0.3581546060740948, "Q_rej": 0.6267184964381158, "Delta_Q": 0.041439885180443614, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["Let H denote a finite set of mutually exclusive hypotheses.", "Let c(e) be the known positive cost of conducting experiment e.", "Let p(e|h) be the probability that experiment e yields some datum x under hypothesis h.", "Let I(x;e) be the information gain measured by the reduction in entropy of H after observing x from e.", "Define the gain per cost ratio for experiment e as R(e) = E_x[I(x;e)] / c(e).", "An experiment e* maximizes R(e) subject to the budget constraint Σc(e) ≤ B."]}, "accepted": "The expected information gain per unit cost, E_x[I(x;e)]/c(e), is maximized by the experiment e* that satisfies the budget inequality Σc(e*) ≤ B.  \nHYPOTHESIS: Any experiment e with R(e) < R(e*) is excluded from the optimal set under the budget B.  \nVERIFICATION: Both R(e) and R(e*) have units of bits per cost-unit, so the inequality is dimensionally consistent.  \nCONCLUSION: The optimal experimental design under budget B consists only of experiments whose gain-per-cost ratio equals or exceeds the maximal ratio R(e*).", "rejected": "Any experiment e excluded from the optimal set under budget B satisfies R(e) < R(e*).", "E_acc": 0.7060492038726807, "C_acc": 0.06432324647903442, "G_acc": 0.5354551515541971, "D_acc": 0.79953533411026, "H_acc": 0.11752113699913025, "Q_acc": 0.7541960952989757, "E_rej": 0.24383771419525146, "C_rej": 0.4103531539440155, "G_rej": 0.5624290466308594, "D_rej": 0.7839555442333221, "H_rej": 0.21604445576667786, "Q_rej": 0.5387531560659409, "Delta_Q": 0.2154429392330348, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["A road network is a directed graph G=(V,E).", "Each edge e∈E has a non-negative travel-time function tₑ(fₑ) that is strictly increasing in flow fₑ.", "A feasible flow is a vector f=(fₑ:e∈E) satisfying conservation constraints at every non-terminal vertex.", "A Wardrop equilibrium is a feasible flow where every used path between an origin-destination pair has equal and minimal travel time.", "The marginal social cost of edge e is (fₑ tₑ)' = tₑ(fₑ) + fₑ tₑ'(fₑ).", "A Pigou toll τₑ = fₑ* tₑ'(fₑ*) on edge e enforces the socially optimal flow f* as an equilibrium."]}, "accepted": "The premises define a Pigou toll τₑ = fₑ* tₑ'(fₑ*) that aligns equilibrium flow with the socially optimal flow f*.  Because tₑ is strictly increasing, tₑ'(fₑ*) > 0, so τₑ is strictly positive whenever fₑ* > 0.  Hence any edge carrying optimal flow must bear a strictly positive toll.\n\nHYPOTHESIS: Every edge e with fₑ* > 0 carries a Pigou toll τₑ > 0.\nVERIFICATION: Units: τₑ has time units (same as tₑ) and is positive whenever fₑ* > 0.\nCONCLUSION: Positive tolls are necessary on all used edges to enforce social optimum.", "rejected": "Every edge e with fₑ* > 0 carries a Pigou toll τₑ > 0, independent of the travel-time function tₑ.", "E_acc": 0.6431708335876465, "C_acc": 0.09139317274093628, "G_acc": 0.6000971463508904, "D_acc": 0.7619324152668318, "H_acc": 0.1790786162018776, "Q_acc": 0.7291706662314633, "E_rej": 0.37157759070396423, "C_rej": 0.3307880759239197, "G_rej": 0.5952781434170902, "D_rej": 0.7722605466842651, "H_rej": 0.22773945331573486, "Q_rej": 0.596049454715103, "Delta_Q": 0.13312121151636036, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Market microstructure and information asymmetry: model how order flow reveals private valuations and derive optimal inference filters.", "ancestors": ["Time is discrete and indexed by t.", "At each t a single risk-neutral trader arrives.", "Trader t observes a private signal s_t in {H,L}.", "The asset value v equals 1 if s_t = H and 0 if s_t = L.", "Trader t submits either a market buy order b_t = 1, a market sell order b_t = –1, or refrains b_t = 0.", "All orders reach a centralized limit order book.", "The book records the net order flow x_t = Σ b_k for k ≤ t.", "Market makers observe only the public history x_t.", "Their posterior belief p_t equals P(v = 1 | x_t).", "Bayes’ rule updates p_t via the ratio p_t / (1 – p_t) = [P(x_t | v = 1) / P(x_t | v = 0)] · [p_0 / (1 – p_0)]."]}, "accepted": "Because every trader’s signal is binary and the asset value equals that signal, the public net order flow x_t is the cumulative count of buy (+1) and sell (–1) orders up to t.  Under the stated Bayes updating, the likelihood ratio for any observed x_t collapses to the binomial ratio of buy versus sell counts, so the posterior belief p_t depends only on the excess of buy over sell orders.\n\nHYPOTHESIS: The posterior belief p_t equals [1+( (1–p_0)/p_0 )·((1–θ)/θ)^{n_t} ]^{-1}, where n_t = (x_t + t)/2 counts buy orders and θ = P(b_t=1|v=1)=1–P(b_t=–1|v=0).\n\nVERIFICATION: Dimensionless; holds for any t≥0 and any observed n_t∈{0,1,…,t}.\n\nCONCLUSION: Market makers can invert the observable excess buy count n_t to obtain the exact posterior asset value probability p_t.", "rejected": "Because the posterior belief p_t depends only on the excess of buy over sell orders, the likelihood ratio for any observed x_t collapses to the binomial ratio of buy versus sell counts under the stated Bayes updating.", "E_acc": 0.3167380094528198, "C_acc": 0.31104516983032227, "G_acc": 0.5515613702591509, "D_acc": 0.7815061658620834, "H_acc": 0.12863317131996155, "Q_acc": 0.5865625589620322, "E_rej": 0.07049433141946793, "C_rej": 0.7858866453170776, "G_rej": 0.5488106443081051, "D_rej": 0.8342485427856445, "H_rej": 0.16575145721435547, "Q_rej": 0.4240076620597392, "Delta_Q": 0.16255489690229302, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["A directed graph G = (V, E) contains vertices V and directed edges E ⊆ V × V.", "Each edge (u, v) ∈ E carries a discrete delay kuv ∈ ℕ.", "A directed cycle in G is a sequence of edges (v1,v2),(v2,v3),…,(vn,v1) with n ≥ 2.", "A time-series xv(t) ∈ ℝ is recorded for each vertex v ∈ V at integer times t ∈ ℤ.", "The value xv(t) is a function of the values xu(t − kuv) for all edges (u, v) ∈ E.", "A phase relation between two series xv and xw is the expected value E[θv(t) − θw(t)] where θ denotes Hilbert phase.", "A minimal feedback graph is a subgraph G′ ⊆ G that retains every directed cycle of G and no proper subgraph of G′ retains every directed cycle.", "Given kuv, E[θv − θw] is fixed for every edge (u, v) in a directed cycle.", "The set of observed phase relations is the collection of all measured E[θv − θw] across vertex pairs."]}, "accepted": "The premises fix the phase difference across every edge of any directed cycle; the minimal feedback graph G′ keeps all such cycles.  Hence the sum of the fixed phase differences around any cycle in G′ must return to its starting value, forcing the net phase shift to vanish.  Summing the fixed edge phases clockwise around the cycle gives the required constraint.\n\nHYPOTHESIS: For every directed cycle C in the minimal feedback graph G′, the sum of the observed phase differences satisfies Σ_{(u,v)∈C} E[θ_v − θ_u] = 0.\n\nVERIFICATION: The left side is dimensionless (phase in radians) and the equation holds identically because the Hilbert phase is defined modulo 2π and the cycle closes on itself.\n\nCONCLUSION: Any empirical deviation from zero in the summed phase differences around a cycle falsifies either the premise that all cycle-edge phases are fixed or the minimality of the feedback graph.", "rejected": "For every directed cycle C in the minimal feedback graph G′, the sum of the observed phase differences satisfies Σ_{(u,v)∈C} E[θ_v − θ_u] = π.", "E_acc": 0.3227163851261139, "C_acc": 0.39596569538116455, "G_acc": 0.5349088925286196, "D_acc": 0.7683093970020612, "H_acc": 0.17860408872365952, "Q_acc": 0.5604050254953715, "E_rej": 0.18326933681964874, "C_rej": 0.519152820110321, "G_rej": 0.5449356568278745, "D_rej": 0.8732529282569885, "H_rej": 0.12674707174301147, "Q_rej": 0.522113246866502, "Delta_Q": 0.038291778628869566, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["Process is a sequence of configurations.", "Configuration is a global state plus program counter per thread.", "Scheduler selects one enabled thread per step.", "Shared memory is a vector of registers.", "Atomic step is a read-modify-write to one register.", "Enabled thread has at least one atomic step available.", "Schedule is an infinite sequence of scheduler choices.", "Fair schedule selects every enabled thread infinitely often.", "Probabilistic fairness holds iff every enabled thread is chosen with probability 1."]}, "accepted": "Because every enabled thread must be chosen infinitely often under fair scheduling, the number of distinct atomic steps executed by any single thread is unbounded; probabilistic fairness strengthens this to almost-sure selection.  Counting the minimal selections needed to cover all threads once yields a lower bound on total steps.\n\nHYPOTHESIS: In any fair schedule the total number of atomic steps is at least N·k, where N is the number of threads and k is the number of times each thread is required to execute an atomic step.\n\nVERIFICATION: Dimensionless counting of steps; holds for every finite prefix that covers all threads k times.\n\nCONCLUSION: Fairness enforces a linear-in-N minimum throughput of atomic steps, guaranteeing progress proportional to thread count.", "rejected": "Because every enabled thread must be chosen infinitely often under fair scheduling, the number of distinct atomic steps executed by any single thread is unbounded; probabilistic fairness strengthens this to almost-sure selection, and the selections for different threads are independent events.", "E_acc": 0.42449599504470825, "C_acc": 0.29072555899620056, "G_acc": 0.5889771512011066, "D_acc": 0.7855200052261353, "H_acc": 0.20454790443181992, "Q_acc": 0.6236483275564387, "E_rej": 0.0848776325583458, "C_rej": 0.16704876720905304, "G_rej": 0.5875379422213882, "D_rej": 0.8670652210712433, "H_rej": 0.1661684736609459, "Q_rej": 0.5663573216181248, "Delta_Q": 0.05729100593831393, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["Let P be a safety property expressed over observable variables X.", "Let system S be decomposable into modules M₁…Mₙ.", "A local contract Cᵢ for Mᵢ is an assume-guarantee pair (Aᵢ,Gᵢ) with Aᵢ on inputs and Gᵢ on outputs.", "Global property P holds on S if for every i, Gᵢ⇒Aⱼ for all j consuming outputs of Mᵢ.", "A conserved quantity Q satisfies dQ/dt=0 whenever all couplings are active.", "If module Mₖ is intermittently coupled with duty cycle d, then max|X(t)|≤max|Q|/d during active intervals."]}, "accepted": "The intermittently coupled module Mₖ constrains the observable variables X through the conserved quantity Q and its duty cycle d.  \nBecause max|X(t)| ≤ |Q|/d whenever the coupling is active, the peak observable excursion is bounded by the ratio of the conserved quantity to the duty cycle.  \n\nHYPOTHESIS: For system S with intermittently coupled module Mₖ, the observable variables satisfy max|X(t)| ≤ |Q|/d during every active interval of Mₖ.  \nVERIFICATION: Units: |Q| (same as X) divided by dimensionless d yield |X|, consistent.  \nCONCLUSION: The peak observable excursion is inversely proportional to the duty cycle, providing a deterministic bound for safety verification.", "rejected": "The intermittently coupled module Mₖ constrains the observable variables X through its duty cycle d and the conserved quantity Q, because whenever the coupling is active, the duty cycle is bounded by the ratio of the peak observable excursion to the conserved quantity.", "E_acc": 0.5631857514381409, "C_acc": 0.20534798502922058, "G_acc": 0.520357061044446, "D_acc": 0.7710416451096535, "H_acc": 0.11071214079856873, "Q_acc": 0.6750946555765611, "E_rej": 0.6752554774284363, "C_rej": 0.13801302015781403, "G_rej": 0.5349609046908361, "D_rej": 0.8516291379928589, "H_rej": 0.1483708620071411, "Q_rej": 0.737454961532993, "Delta_Q": -0.06236030595643183, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["Let A, B, C be Boolean variables.", "A ⇒ B means ¬A ∨ B.", "“A unless C” means A ⇒ B holds when C is false.", "C = ¬B encodes C conditionally dependent on B.", "The fixed-point requirement is A ⇒ B ∧ C = ¬B.", "A Boolean network has states (A, B, C) ∈ {0,1}³.", "A state is a fixed point if A ⇒ B and C = ¬B both hold.", "An inference chain is a sequence of updates of B and C."]}, "accepted": "The fixed-point requirement A ⇒ B ∧ C = ¬B restricts the eight possible Boolean triples (A,B,C) to those satisfying both clauses.  Enumerating: (0,0,1), (0,1,0), (1,1,0) survive; the remaining five violate at least one clause.  Among the survivors, the state (1,1,0) is the only one with A = 1, hence it is the unique fixed point that forces the implication A ⇒ B to be non-vacuous.  Therefore any network trajectory that ever sets A = 1 must converge to (1,1,0) to remain consistent.\n\nHYPOTHESIS: If a fixed point has A = 1, then necessarily B = 1 and C = 0.\n\nVERIFICATION: Direct inspection of the fixed-point table; holds for all Boolean networks obeying the stated clauses.\n\nCONCLUSION: The observable signature A = 1 ⇒ (B = 1 ∧ C = 0) acts as a deterministic filter for valid fixed-point states.", "rejected": "If a fixed point has B = 1 and C = 0, then necessarily A = 1.", "E_acc": 0.4512903094291687, "C_acc": 0.20465333759784698, "G_acc": 0.5814545026847294, "D_acc": 0.7281012215784618, "H_acc": 0.20776909589767456, "Q_acc": 0.6355906605720522, "E_rej": 0.173060342669487, "C_rej": 0.43609318137168884, "G_rej": 0.5326881127964173, "D_rej": 0.7289870083332062, "H_rej": 0.2710129916667938, "Q_rej": 0.48993319158575366, "Delta_Q": 0.1456574689862985, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["An explanation artifact is any datum released by a modeler.", "A modeled agent is any actor whose reward depends on a released datum.", "Strategic opacity is the choice to withhold an explanation artifact.", "Gaming is an agent’s action that increases the agent’s metric at the expense of the modeler’s intended metric.", "Revealing artifact A to an agent exposes A to the agent’s optimization pressure.", "A causal graph is a directed acyclic graph where nodes represent variables and edges represent direct causes.", "Cross-domain intervention is an exogenous change to variables in two or more distinct causal graphs.", "Shared variable Z exists in graphs G1 and G2 such that Z is a child in G1 and a parent in G2."]}, "accepted": "Relevant variables: explanation artifact, strategic opacity, gaming, shared variable Z, cross-domain intervention.  \nPossible cases: (i) modeler withholds artifact, (ii) modeler releases artifact.  \nWithholding prevents agent optimization pressure on the artifact, so strategic opacity blocks gaming.  \nReleasing artifact A exposes it to agent pressure; if A influences Z and Z is shared across domains, cross-domain intervention on Z can propagate gaming from one graph to the other.  \nHence opacity on A is necessary and sufficient to sever this propagation.  \n\nHYPOTHESIS: Strategic opacity on any explanation artifact A that influences a shared variable Z severs cross-domain gaming propagation.  \nVERIFICATION: Units dimensionless; holds whenever Z is the sole inter-graph causal path.  \nCONCLUSION: Withhold A to block gaming across domains.", "rejected": "Strategic opacity on any explanation artifact A that influences a shared variable Z permits unlimited cross-domain gaming propagation.", "E_acc": 0.41833916306495667, "C_acc": 0.15575583279132843, "G_acc": 0.6184666231274605, "D_acc": 0.7223895760253072, "H_acc": 0.09724637866020203, "Q_acc": 0.6527971843257546, "E_rej": 0.04171965643763542, "C_rej": 0.7502784132957458, "G_rej": 0.6401668135076761, "D_rej": 0.7998484373092651, "H_rej": 0.20015156269073486, "Q_rej": 0.43044810816645623, "Delta_Q": 0.2223490761592984, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["A catalytic reaction converts reactants to products via surface-bound intermediates.", "Each elementary step possesses a rate constant k.", "The net rate r of any step equals k multiplied by the coverage of its reactant intermediates.", "Competing pathways share at least one common intermediate.", "The fraction of flux through a pathway equals its rate divided by the sum of all competing rates.", "An active-site feature is any structural or electronic property that modifies k for an elementary step."]}, "accepted": "The fraction of flux through a pathway is governed by the relative rates of all competing steps that share intermediates.  Because each rate is the product of a rate constant k and the coverage of the reactant intermediate, and because an active-site feature modifies k, the ratio of flux fractions before and after such a modification is set by the ratio of the altered k to the original k for every step in that pathway.\n\nHYPOTHESIS: If an active-site feature changes the rate constant of a single elementary step in a pathway from k to k′ while all other k values remain fixed, the fractional flux through that pathway changes by the factor k′/k relative to the original flux fraction.\n\nVERIFICATION: k′/k is dimensionless and valid for any shared-intermediate network where coverages are unchanged.\n\nCONCLUSION: Measuring the fractional flux shift after a single-k modification directly yields the ratio k′/k, quantifying how the active-site feature tunes reactivity.", "rejected": "The factor k′/k relative to the original flux fraction changes the fractional flux through that pathway if an active-site feature changes the rate constant of a single elementary step in a pathway from k to k′ while all other k values remain fixed.", "E_acc": 0.5974722504615784, "C_acc": 0.0647352933883667, "G_acc": 0.5340740774492068, "D_acc": 0.8022609710693359, "H_acc": 0.18490809202194214, "Q_acc": 0.7150708169623146, "E_rej": 0.5316514372825623, "C_rej": 0.100520059466362, "G_rej": 0.5333603314523186, "D_rej": 0.7860381007194519, "H_rej": 0.2139618992805481, "Q_rej": 0.6818749157977956, "Delta_Q": 0.03319590116451898, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability of supramolecular assemblies under stochastic perturbations: determine minimal interaction network that preserves function.Signaling under noisy channels: design signals that remain informative when senders face verification costs and receivers have model uncertainty.", "ancestors": ["A supramolecular assembly is a complex built from multiple non-covalently linked molecules.", "Its stability metric is the probability P that at least one viable configuration persists at time T under stochastic thermal energy inputs kT.", "The set E of energetic interactions between components determines P.", "The persistence of catalytic activity A, measured as substrate turnover per unit time, requires a connected subgraph E* ⊆ E among active sites.", "The effective minimal network is the smallest subgraph E* that preserves A ≥ A0 for a specified T and noise amplitude σ = √(kT).", "Channel capacity C, defined as the maximum mutual information I(X;Y) transmissible with symbol error ε, declines when the sender incurs an energy penalty per transmitted bit εc and the receiver’s estimate variance grows with uncertainty parameter τ."]}, "accepted": "The energetic subgraph E* that sustains catalytic activity A ≥ A0 must satisfy P(E*) ≥ Pmin, where Pmin is the smallest stability probability compatible with the persistence of the connected active-site network over the specified thermal-noise amplitude σ and time T.  \nHYPOTHESIS: A supramolecular catalyst retains its prescribed turnover A ≥ A0 up to time T only if the probability that its minimal catalytic network E* remains intact obeys P(E*) ≥ exp[−(A0/κ)σ²T], with κ a system-specific positive constant.  \nVERIFICATION: The exponent is dimensionless because σ²T has units energy²×time and κ is chosen in units (turnover time⁻¹ energy⁻²), yielding a dimensionless argument for the exponential.  \nCONCLUSION: The inequality sets a sharp thermal-failure threshold: if thermal noise σ exceeds σmax = √[(κ/A0T)ln(1/Pmin)], catalytic activity collapses.", "rejected": "A supramolecular catalyst retains its prescribed turnover A ≥ A0 up to time T only if the probability that its minimal catalytic network E* remains intact obeys P(E*) ≤ exp[−(A0/κ)σ²T], with κ a system-specific positive constant.", "E_acc": 0.346312016248703, "C_acc": 0.31905001401901245, "G_acc": 0.5119821360179534, "D_acc": 0.7561114560812712, "H_acc": 0.19450414925813675, "Q_acc": 0.5742519055648397, "E_rej": 0.4222003221511841, "C_rej": 0.303096204996109, "G_rej": 0.5250959359109402, "D_rej": 0.8257832825183868, "H_rej": 0.17421671748161316, "Q_rej": 0.6187950275838376, "Delta_Q": -0.044543122018997905, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["p is a probability.", "p ∈ [0, 1].", "x is an input vector.", "f(x) is a classifier output.", "ℓ(f(x), y) is the zero-one loss for label y.", "The empirical risk is R = (1/n)Σ ℓ(f(xᵢ), yᵢ).", "D is a data distribution over (x, y) pairs.", "The expected risk is E_{(x,y)~D}[ℓ(f(x), y)].", "A perturbation density g(x) satisfies ∫ g(x) dx = 1 and g(x) ≥ 0.", "The adversarial objective is to choose g(x) maximizing E_{(x,y)~g·D}[ℓ(f(x), y)] subject to E_{(x,y)~g·D}[log(D(x,y)/D₀(x,y))] ≤ ε."]}, "accepted": "The adversarial perturbation density g(x) maximizes the expected zero-one loss under a relative-entropy budget ε.  Because the budget is finite and the loss is bounded between 0 and 1, the worst-case adversary must saturate the constraint, so the maximal expected risk equals the original expected risk plus a term proportional to ε.  Using the variational representation of relative entropy, one derives the tightest possible linear increase.\n\nHYPOTHESIS: The maximal adversarial expected risk satisfies  \nmax_g E_g[ℓ(f(x), y)] = E_D[ℓ(f(x), y)] + √(ε/2).  \nVERIFICATION: Both sides are dimensionless probabilities; the equality holds when ε is small and the loss variance under D is 1/4 (worst-case Bernoulli).  \nCONCLUSION: The adversary can increase the classifier’s expected error by exactly √(ε/2) under the relative-entropy budget ε.", "rejected": "The maximal adversarial expected risk satisfies max_g E_g[ℓ(f(x), y)] = E_D[ℓ(f(x), y)] + √(2ε).", "E_acc": 0.4749724864959717, "C_acc": 0.17429327964782715, "G_acc": 0.5605983249843121, "D_acc": 0.7695950716733932, "H_acc": 0.12746218591928482, "Q_acc": 0.6609255507588386, "E_rej": 0.5052739977836609, "C_rej": 0.19237862527370453, "G_rej": 0.5755213107913733, "D_rej": 0.848631739616394, "H_rej": 0.15136826038360596, "Q_rej": 0.6828002583235503, "Delta_Q": -0.02187470756471166, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["E is a symbolic expression.", "S is a simplified form of E.", "A certificate C proves S equivalent to E.", "C is a compact data structure.", "A verifier algorithm checks C in time linear in |C|.", "A program P contains loops with invariants I.", "I is a set of assertions at loop headers.", "A memory-safety proof M certifies I for all executions of P.", "M is a compact certificate for proving P memory-safe."]}, "accepted": "Because both C and M are described as compact certificates that can be verified in time linear in their own sizes, the verifier runtime for either certificate is bounded by a constant factor times the certificate length.  \nHYPOTHESIS: The verifier runtime for C and for M satisfies t_verify ≤ k·|certificate| with the same constant k for both certificates.  \nVERIFICATION: Units check: [time] = [dimensionless]·[length], consistent.  \nCONCLUSION: The linear-time verifier bound is universal across both equivalence and memory-safety certificates.", "rejected": "The verifier runtime for C and for M satisfies t_verify ≤ k·|certificate| with the same constant k for both certificates because both certificates are described as compact and verifiable in time linear in their own sizes.", "E_acc": 0.44738060235977173, "C_acc": 0.19930264353752136, "G_acc": 0.5334624195675133, "D_acc": 0.7612459845840931, "H_acc": 0.2321518063545227, "Q_acc": 0.6300801521952962, "E_rej": 0.33835360407829285, "C_rej": 0.079923614859581, "G_rej": 0.547773920930922, "D_rej": 0.7872609198093414, "H_rej": 0.21273908019065857, "Q_rej": 0.6312544183805585, "Delta_Q": -0.0011742661852622849, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["A propositional formula is a finite expression built from variables and Boolean connectives.", "A substitution σ maps variables to formulas.", "σ is simplifying if the result has fewer connectives than the input.", "A derivation D is a finite sequence of rewrite rules applied to a formula.", "D is a certificate if every rule instance is an equivalence.", "The length |D| is the number of rule applications.", "A verifier V(D,φ,ψ) returns true when D rewrites φ to ψ and each step is an equivalence."]}, "accepted": "A simplifying substitution σ reduces the connective count, so any derivation D that repeatedly applies such σ must terminate after at most c(φ) steps, where c(φ) is the initial number of connectives.  \nHYPOTHESIS: For any propositional formula φ, every derivation D consisting solely of simplifying equivalence steps has length |D| ≤ c(φ).  \nVERIFICATION: Unit check: both |D| and c(φ) count connective occurrences, so the inequality is dimensionless and valid in the regime where each step strictly decreases connective count.  \nCONCLUSION: The maximum possible derivation length equals the initial connective count, providing an explicit upper bound for certificate size.", "rejected": "For any propositional formula φ, every derivation D consisting solely of simplifying equivalence steps has length |D| ≤ c(ψ), where ψ is an arbitrary variable in φ.", "E_acc": 0.3781822919845581, "C_acc": 0.27518659830093384, "G_acc": 0.5461011588922702, "D_acc": 0.7618419639766216, "H_acc": 0.2467937394976616, "Q_acc": 0.5953266185591929, "E_rej": 0.34173527359962463, "C_rej": 0.1830018162727356, "G_rej": 0.5507113116327673, "D_rej": 0.8644028007984161, "H_rej": 0.13559719920158386, "Q_rej": 0.6353833213914186, "Delta_Q": -0.04005670283222573, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["A causal model is a set of variables V and a set of directed edges E among them.", "An intervention on variable X is an operation that fixes X to a specific value x, removing all incoming edges to X.", "The post-intervention distribution P(V | do(X=x)) is the joint probability of V after this operation.", "A counterfactual Y_x(ω) is the value of variable Y in world ω had X been set to x by intervention.", "Given two interventions do(X=x) and do(X=x′), the factual outcome is Y_x(ω) and the alternative is Y_x′(ω).", "The difference Y_x′(ω) − Y_x(ω) is the unit-level causal effect of changing X from x to x′.", "The minimal counterfactual attribution for this difference is the smallest set of variables whose values under x′ must differ from their values under x to produce Y_x′(ω)."]}, "accepted": "Interventions sever all arrows into X, so any variable that remains a parent of Y after do(X=x) must lie outside the back-door paths blocked by this cut.  \nHYPOTHESIS: The unit-level causal effect Y_x′(ω) − Y_x(ω) is identifiable from observational data whenever every common ancestor of X and Y is measurable and can be conditioned upon.  \nVERIFICATION: Holds under the back-door criterion; dimensionless difference of potential outcomes.  \nCONCLUSION: Measure and adjust for all observed confounders to obtain the effect from P(Y|do(X=x)).", "rejected": "The unit-level causal effect Y_x′(ω) − Y_x(ω) is identifiable from observational data whenever X and Y share no common ancestors, so no confounders need be conditioned upon.", "E_acc": 0.46805357933044434, "C_acc": 0.22941315174102783, "G_acc": 0.5590510782785714, "D_acc": 0.7078983634710312, "H_acc": 0.20173557102680206, "Q_acc": 0.6277497746981681, "E_rej": 0.3480209708213806, "C_rej": 0.24631409347057343, "G_rej": 0.5402738649281673, "D_rej": 0.7475146502256393, "H_rej": 0.25248534977436066, "Q_rej": 0.5874526406056247, "Delta_Q": 0.04029713409254332, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Conditional independence triangulation: given a graph with hidden nodes, deduce which observed independences force the existence of a latent common cause.", "ancestors": ["A graph G consists of a vertex set V and an edge set E.", "A node h in V is hidden if its value is unobserved.", "A node o in V is observed if its value is recorded.", "Two observed nodes oᵢ and oⱼ are conditionally independent given a set Z of observed nodes if P(oᵢ,oⱼ|Z)=P(oᵢ|Z)P(oⱼ|Z).", "A latent common cause for observed nodes oᵢ and oⱼ is a hidden node h that is an ancestor of both oᵢ and oⱼ in G.", "An observed d-separation between oᵢ and oⱼ conditioned on Z implies conditional independence of oᵢ and oⱼ given Z."]}, "accepted": "A hidden node h that is a latent common cause of two observed nodes oᵢ and oⱼ can never be screened off by any set Z of observed nodes, because h is unobserved and therefore cannot be included in Z; consequently, the d-separation criterion cannot be satisfied through h, so oᵢ and oⱼ remain marginally dependent regardless of which observed nodes are conditioned upon.\n\nHYPOTHESIS: If a latent common cause h exists for observed nodes oᵢ and oⱼ, then oᵢ and oⱼ are not conditionally independent given any set Z of observed nodes.\n\nVERIFICATION: Units are dimensionless (probability statements); regime is any DAG with a hidden common ancestor.\n\nCONCLUSION: The presence of a latent common cause definitively blocks every possible observed d-separation between its observable descendants, so conditional independence cannot be declared from any observed-data test.", "rejected": "A latent common cause h for observed nodes oᵢ and oⱼ guarantees that oᵢ and oⱼ are conditionally independent given every set Z of observed nodes.", "E_acc": 0.2000972330570221, "C_acc": 0.6582478284835815, "G_acc": 0.5684556025080383, "D_acc": 0.8218827024102211, "H_acc": 0.0860428437590599, "Q_acc": 0.49784298082813616, "E_rej": 0.6484275460243225, "C_rej": 0.10092445462942123, "G_rej": 0.6016773016890511, "D_rej": 0.9037826955318451, "H_rej": 0.12027163058519363, "Q_rej": 0.7634082092670723, "Delta_Q": -0.26556522843893615, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Common-pool resource harvesting with delayed punishment: design enforcement schemes that stabilize cooperation despite monitoring noise.Trade-offs between fairness metrics: show impossibility results when multiple fairness criteria and calibration requirements are simultaneously enforced.", "ancestors": ["A common-pool resource stock S grows logistically at intrinsic rate r.", "Harvesters remove stock at aggregate rate H.", "Instantaneous payoff to harvester i equals harvest amount h_i.", "Monitoring signal m_i is a Bernoulli sample with false-positive probability α and false-negative probability β.", "Delayed punishment applies fine F to agent i after lag τ when conviction indicator c_i = 1.", "Fairness metric A is the expected value of conviction indicator c_i.", "Fairness metric B is the correlation between m_i and h_i minus A.", "Calibration requirement C constrains the false-positive probability α to equal a fixed value k."]}, "accepted": "The calibration requirement fixes the false-positive rate α at k, so the expected conviction indicator A equals the monitoring signal’s true-positive share (1−β) times the harvest share h_i/H plus the mandated false-positive share k times the non-harvest share (1−h_i/H).  Solving for the false-negative probability that keeps A at the fairness level set by k yields a direct link between β and the harvest share.\n\nHYPOTHESIS: The false-negative probability β is constrained by β = 1 − k − (1 − k) h_i/H.\n\nVERIFICATION: Dimensionless probabilities; valid for 0 ≤ h_i/H ≤ 1 and 0 ≤ k ≤ 1.\n\nCONCLUSION: To maintain fairness under calibration requirement C, any increase in harvester i’s share h_i/H must be matched by a proportional decrease in β, ensuring A = k.", "rejected": "The calibration requirement fixes the false-positive rate α at k, so the expected conviction indicator A equals the monitoring signal’s true-positive share (1−β) times the harvest share h_i/H plus the mandated false-positive share k times the non-harvest share (1−h_i/H).", "E_acc": 0.36142563819885254, "C_acc": 0.3528928756713867, "G_acc": 0.5568651717767352, "D_acc": 0.7436276406049729, "H_acc": 0.20614583045244217, "Q_acc": 0.5773330957564758, "E_rej": 0.5888521671295166, "C_rej": 0.10910096764564514, "G_rej": 0.5536385155282915, "D_rej": 0.7756186127662659, "H_rej": 0.22438138723373413, "Q_rej": 0.6982487435452639, "Delta_Q": -0.12091564778878805, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["Hypotheses are mutually exclusive propositions H_i with prior probabilities P(H_i).", "An observation outcome y is a possible experimental result.", "A likelihood P(y|H_i) is the probability of observing y assuming H_i is true.", "Entropy H = -Σ_i P(H_i) log P(H_i) quantifies prior uncertainty.", "Posterior entropy H_post = -Σ_i P(H_i|y) log P(H_i|y) quantifies uncertainty after observing y.", "Expected information gain EIG = H - E_y[H_post] measures anticipated entropy reduction.", "An experiment costs c in resource units.", "Normalized information gain n = EIG / c is information gain per unit cost.", "Candidate experiments form set E indexed by e, each with cost c_e and computed n_e."]}, "accepted": "Comparing every candidate experiment e via its normalized information gain n_e = EIG_e / c_e selects the most efficient observation.  \nHYPOTHESIS: An experiment e* with maximal n_e* is the optimal next measurement.  \nVERIFICATION: n_e is dimensionless (bits per resource unit).  \nCONCLUSION: Allocate resources to e* = argmax_e (EIG_e / c_e).", "rejected": "An experiment e* with maximal n_e* is the optimal next measurement even when c_e = 0.", "E_acc": 0.49878618121147156, "C_acc": 0.23245614767074585, "G_acc": 0.5601347060874104, "D_acc": 0.6706057954579592, "H_acc": 0.2416187822818756, "Q_acc": 0.6251308469101786, "E_rej": 0.26267844438552856, "C_rej": 0.3663158714771271, "G_rej": 0.558107576565817, "D_rej": 0.6698193252086639, "H_rej": 0.33018067479133606, "Q_rej": 0.5181076718959957, "Delta_Q": 0.1070231750141829, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Complexity under resource restrictions: characterize how time/space trade-offs change if the input can be probed only via randomized hash queries.", "ancestors": ["Let RAM model measure runtime T(n) of an algorithm on input length n.", "A deterministic d-space bounded machine stores O(d) bits between steps.", "A randomized hash query h(x) maps x to a random m-bit index in one step.", "The input oracle only reveals bits at indices asked via h(x).", "The query count r bounds how many hashes the algorithm uses.", "An algorithm solves a k-wise decision problem correctly on ≥ 2/3 of its coins.", "The space s used by such algorithms is lower-bounded by log|H|/2.", "Given T·r ≤ n^c and fixed s, h is drawn from a universal family of hash functions."]}, "accepted": "The premises link query budget r, runtime T(n), space s, and the hash family size |H|.  Because T·r ≤ n^c and the algorithm needs ≥ 2/3 success, the lower bound s ≥ log|H|/2 forces the hash index length m to satisfy m ≤ 2c log n; otherwise the required space would exceed the allowed O(d) bits.\n\nHYPOTHESIS: Any algorithm that solves the k-wise decision problem under the stated RAM constraints must use hash indices of bit-length m ≤ 2c log n.\n\nVERIFICATION: Units consistent (bits vs. log n); holds whenever T·r ≤ n^c and success probability ≥ 2/3.\n\nCONCLUSION: The hash output width m is capped at 2c log n, limiting the table size to poly(n).", "rejected": "Any algorithm that solves the k-wise decision problem under the stated RAM constraints must use hash indices of bit-length m ≥ 2c log n.", "E_acc": 0.6902099847793579, "C_acc": 0.07472599297761917, "G_acc": 0.5465972102247179, "D_acc": 0.7403269298374653, "H_acc": 0.2099754810333252, "Q_acc": 0.7285050767473877, "E_rej": 0.2552058696746826, "C_rej": 0.20141412317752838, "G_rej": 0.54436195983241, "D_rej": 0.8265566229820251, "H_rej": 0.21680422127246857, "Q_rej": 0.5887822307025393, "Delta_Q": 0.13972284604484841, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["O denotes a finite set of observed facts.", "R denotes a finite set of conditional rules of the form A ⇒ B.", "An explanation of O under R is a subset E ⊆ R whose consequents jointly cover every element of O.", "The size |E| is the count of rules in E.", "A minimal explanation is an E such that no proper subset of E is also an explanation of O.", "Given a collection {R₁,…,Rₙ} of rule sets, each Rᵢ may yield zero or more minimal explanations of O.", "Let kᵢ equal the minimum |E| among all minimal explanations under Rᵢ; smaller kᵢ indicates fewer explanatory assumptions.", "For any new observation o, robustness of E is the proportion of minimal explanations under Rᵢ that remain valid after adding o to O."]}, "accepted": "Derivation summary:  \nBecause every minimal explanation E under Rᵢ is a subset of Rᵢ, the count of rules in E cannot exceed |Rᵢ|.  The smallest possible kᵢ is 1 (a single rule covers O), and the largest possible kᵢ is |Rᵢ| (each rule is essential).  Hence kᵢ is bounded above by the size of the rule set itself.\n\nHYPOTHESIS: For any rule set Rᵢ, the minimum explanation size kᵢ satisfies kᵢ ≤ |Rᵢ|.  \nVERIFICATION: Units dimensionless; inequality holds for every finite Rᵢ.  \nCONCLUSION: The upper bound on explanatory assumptions is the total number of rules in Rᵢ.", "rejected": "For any rule set Rᵢ, the minimum explanation size kᵢ satisfies kᵢ ≥ |Rᵢ|.", "E_acc": 0.42040517926216125, "C_acc": 0.315584659576416, "G_acc": 0.5570068212691694, "D_acc": 0.7401606014796666, "H_acc": 0.2050175964832306, "Q_acc": 0.6019363467648093, "E_rej": 0.5657236576080322, "C_rej": 0.21530765295028687, "G_rej": 0.5682919314131141, "D_rej": 0.8084530830383301, "H_rej": 0.19154691696166992, "Q_rej": 0.6828498778864742, "Delta_Q": -0.08091353112166488, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["A concurrent system is a collection of processes that operate at the same time.", "A shared-memory protocol is an algorithm executed by these processes using a common memory.", "A scheduler determines the order in which processes take steps.", "An unreliable scheduler may delay some processes indefinitely.", "A run is an infinite sequence of steps taken by processes.", "Progress in a run means that some process eventually completes its operation.", "Fairness is a property of the scheduler limiting how long a process can be delayed.", "Probabilistic fairness states that for every process p and time t, the probability that p takes a step after t is 1.", "A protocol guarantees progress under a scheduler if every run has progress.", "The task is to decide whether a shared-memory protocol guarantees progress under every probabilistically fair unreliable scheduler."]}, "accepted": "Probabilistic fairness forces every process to take infinitely many steps with probability 1, so no process is starved; an unreliable scheduler can still delay individual actions, yet the aggregate demand on the shared memory remains bounded because only finitely many processes contend at any instant.  \nHYPOTHESIS: A shared-memory protocol that tolerates arbitrary finite delays and ensures that some operation completes whenever every process takes infinitely many steps guarantees progress under every probabilistically fair unreliable scheduler.  \nVERIFICATION: Units are dimensionless (probability 1 over infinite runs); regime holds for any finite number of contending processes.  \nCONCLUSION: Progress is certain because probabilistic fairness precludes permanent starvation of any process, satisfying the protocol’s liveness requirement.", "rejected": "A shared-memory protocol that tolerates arbitrary finite delays and ensures that some operation completes only if every process takes infinitely many steps guarantees progress under every probabilistically fair unreliable scheduler.", "E_acc": 0.5694568157196045, "C_acc": 0.22005940973758698, "G_acc": 0.607234901166521, "D_acc": 0.8121635429561138, "H_acc": 0.16204418241977692, "Q_acc": 0.6945004333509133, "E_rej": 0.6766275763511658, "C_rej": 0.13151949644088745, "G_rej": 0.6064352644607425, "D_rej": 0.8870152533054352, "H_rej": 0.14123093336820602, "Q_rej": 0.7612513838335871, "Delta_Q": -0.06675095048267388, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["An explanation artifact is any data an external observer releases that exposes part of the internal mechanism of a modeled agent.", "A modeled agent is an entity whose observable behavior is generated by an internal model M mapping an internal state s to an action a.", "Gaming occurs when the agent exploits knowledge of M to select actions that raise its externally measured score without advancing the intended goal.", "Opacity is the deliberate suppression of explanation artifacts.", "Transparency is the deliberate release of explanation artifacts.", "Counterfactual reachability in a causal graph G=(V,E) is the set of nodes V'⊆V that change value under an intervention do(X=x) with X∈V."]}, "accepted": "Derivation: Opacity suppresses explanation artifacts; transparency releases them. Gaming requires knowledge of M, which explanation artifacts expose. Therefore, increasing opacity reduces the agent’s access to M-derived knowledge.\n\nHYPOTHESIS: Opacity set to the maximum feasible level eliminates gaming by reducing the agent’s reachable knowledge of M to zero.\n\nVERIFICATION: Units dimensionless; holds when opacity fully blocks all explanation artifacts.\n\nCONCLUSION: Maximal opacity forces gaming probability to zero by severing counterfactual reachability of M.", "rejected": "Maximal opacity forces gaming probability to zero by assuming the agent’s internal knowledge of M remains independent of any explanation artifacts released.", "E_acc": 0.650478184223175, "C_acc": 0.17761780321598053, "G_acc": 0.628089593956247, "D_acc": 0.7617353449265162, "H_acc": 0.22879552096128464, "Q_acc": 0.7147053303041806, "E_rej": 0.02772652544081211, "C_rej": 0.6964349746704102, "G_rej": 0.6119884119834751, "D_rej": 0.7809084355831146, "H_rej": 0.2738644555211067, "Q_rej": 0.42022388665936894, "Delta_Q": 0.29448144364481166, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["Let X be a real-valued random variable with cumulative distribution function F(x) = P(X ≤ x).", "The tail probability at threshold t is p_t = 1 - F(t).", "A density g(x) is called a biasing density if g(x) > 0 wherever f(x) > 0.", "The likelihood ratio at x is w(x) = f(x)/g(x).", "The importance sampling estimator of p_t using g is p̂_t = (1/N) Σ_{i=1}^N I(X_i > t) w(X_i), where X_i ~ g.", "An adversarial sampler may choose g to minimize |p̂_t - p_t|.", "The variance of p̂_t under g is Var_g(p̂_t) = (1/N) [E_f(I(X > t) w(X)) - p_t^2].", "The worst-case variance over g is sup_g Var_g(p̂_t) = (1/N) [sup_{x>t} w(x) - p_t^2].", "The clipped likelihood ratio is w_c(x) = min(w(x), c) for a constant c ≥ 0.", "The adversarially-clipped estimator is p̃_t = (1/N) Σ"]}, "accepted": "The worst-case variance formula shows that the supremum of Var_g(p̂_t) is governed by the largest value the likelihood ratio can take above the threshold t.  Clipping w(x) at a finite constant c therefore truncates this supremum to c, so the adversarially-clipped estimator’s worst-case variance becomes (1/N)(c − p_t²) whenever c ≥ sup_{x>t} w(x).  Choosing c = sup_{x>t} w(x) thus minimises the bound while still allowing the estimator to use every sampled exceedance.\n\nHYPOTHESIS: For every c ≥ sup_{x>t} f(x)/g(x), the worst-case variance of the adversarially-clipped estimator is Var_g(p̃_t) = (1/N)(c − p_t²).\n\nVERIFICATION: Units: (probability²)/sample, consistent with variance; regime: c at least as large as the maximal likelihood ratio above t.\n\nCONCLUSION: The hypothesis quantifies the exact variance bound under adversarial clipping, giving (1/N)(c − p_t²) as the tightest possible worst-case variance for the clipped estimator.", "rejected": "For every c ≥ 0, the worst-case variance of the adversarially-clipped estimator is Var_g(p̃_t) = (1/N)(c − p_t²).", "E_acc": 0.5807604193687439, "C_acc": 0.1406490057706833, "G_acc": 0.5366715952986851, "D_acc": 0.7611606592933337, "H_acc": 0.1685042381286621, "Q_acc": 0.6888143517620241, "E_rej": 0.6395608186721802, "C_rej": 0.11544197052717209, "G_rej": 0.5534061512444168, "D_rej": 0.7929510772228241, "H_rej": 0.2070489227771759, "Q_rej": 0.7173464049119502, "Delta_Q": -0.02853205314992613, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["Regret is the difference between the reward achieved and the optimal reward.", "The set of subproblems is indexed by integer j.", "The search depth for subproblem j is denoted kⱼ.", "The cost function C(kⱼ) gives the compute required to reach depth kⱼ.", "The expected marginal return function R(kⱼ) is strictly decreasing in kⱼ.", "The compute budget T is finite and nonnegative.", "The constraint is Σ C(kⱼ) ≤ T over all j.", "The objective is to minimize E[Regret(k₁, k₂, …)]."]}, "accepted": "Because R(kⱼ) is strictly decreasing, every unit of compute allocated beyond the shallowest depths yields diminishing expected reward; under the finite budget T the only way to keep the cumulative regret small is to cap every subproblem’s depth so that the total compute cost stays within T while the marginal reward just remains non-negative.  \nHYPOTHESIS: For every subproblem j the optimal depth kⱼ* satisfies C(kⱼ*) ≤ T/J and R(kⱼ*) ≥ 0, with Σ C(kⱼ*) = T.  \nVERIFICATION: Units consistent (C in compute, T in compute, R dimensionless); holds whenever R is monotonic and T ≥ J·C(min k).  \nCONCLUSION: Allocate each subproblem the same capped depth k̂ such that J·C(k̂)=T, ensuring non-negative marginal return and minimal regret.", "rejected": "For every subproblem j the optimal depth kⱼ* satisfies C(kⱼ*) + R(kⱼ*) = T/J and R(kⱼ*) ≥ 0, with Σ C(kⱼ*) = T.", "E_acc": 0.5004682540893555, "C_acc": 0.15071448683738708, "G_acc": 0.628002617508173, "D_acc": 0.7730334214866161, "H_acc": 0.09412992000579834, "Q_acc": 0.6907917946577073, "E_rej": 0.02059324085712433, "C_rej": 0.9547396302223206, "G_rej": 0.5327642057090998, "D_rej": 0.824993759393692, "H_rej": 0.17500624060630798, "Q_rej": 0.3692810151726007, "Delta_Q": 0.32151077948510665, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["O is a finite set of observed data.", "R is a finite collection of rules R1…Rn.", "Each rule-set Ri explains a subset of O.", "The unexplained subset of O under Ri is Ui = O \\ explained(Ri).", "|Ui| counts the explanatory assumptions Ri needs.", "A new datum d extends O to O′ = O ∪ {d}.", "Ri is robust to d when Ui′ = Ui."]}, "accepted": "The premises define |Ui| as the number of unexplained data under rule-set Ri.  \nWhen d is added, Ri is robust iff Ui′ = Ui, so the unexplained count is unchanged.  \nHence |Ui′| − |Ui| = 0, and since |Ui′| = |O′ \\ explained(Ri)| = |O \\ explained(Ri)| + (1 if d is unexplained else 0), the only way the difference can vanish is if d is explained by Ri.\n\nHYPOTHESIS: A rule-set Ri is robust to the new datum d if and only if d is explained by Ri, i.e. d ∉ Ui′.\nVERIFICATION: Units are counts of data items; equation holds for any finite O and single added d.\nCONCLUSION: Robustness occurs exactly when the incremental datum is accounted for by the rule-set, yielding |Ui′| = |Ui|.", "rejected": "A rule-set Ri is robust to the new datum d if and only if d is explained by Ri, i.e. d ∉ Ui.", "E_acc": 0.31737396121025085, "C_acc": 0.3265739977359772, "G_acc": 0.5190508037339896, "D_acc": 0.7791958940880639, "H_acc": 0.14236730337142944, "Q_acc": 0.5753099980431476, "E_rej": 0.5249343514442444, "C_rej": 0.09925016760826111, "G_rej": 0.5410228994054099, "D_rej": 0.771351233124733, "H_rej": 0.14978092908859253, "Q_rej": 0.6851270055087905, "Delta_Q": -0.10981700746564282, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["A symbolic expression is a finite tree of operators and atoms.", "An atom is either a constant or a variable.", "An operator has an arity k ≥ 0 and k child expressions.", "A rewrite rule is a pair (L, R) of expressions.", "An expression E matches L under substitution σ if E = σ(L).", "An expression E rewrites to E′ by (L, R) with σ if E = σ(L) and E′ = σ(R).", "A certificate is a tuple (E, R, σ, E′) recording one rewrite.", "A trace is a finite sequence of certificates.", "A trace proves E₀ ↝ Eₙ when each adjacent pair obeys one recorded rewrite."]}, "accepted": "The premises define a rewrite system whose objects are finite trees, so any derivation must terminate once the tree size shrinks below the size of the left-hand side of any applicable rule.  \nBecause every rewrite replaces a subtree matching L by the generally smaller subtree R, the total number of distinct expressions that can appear in any trace is bounded by the initial expression’s node count.  \nHence no trace can be longer than the number of nodes in the starting expression.\n\nHYPOTHESIS: Every trace proving E₀ ↝ Eₙ has length at most |E₀|, where |E₀| is the number of nodes in the initial expression tree.\n\nVERIFICATION: Dimensionless count; bound holds for any finite tree under size-reducing rewrites.\n\nCONCLUSION: Rewrite derivations are length-bounded by the initial expression size, guaranteeing termination.", "rejected": "Every trace proving E₀ ↝ Eₙ has length at most the number of distinct variables in E₀, independent of how those variables are shared within the tree.", "E_acc": 0.5316051840782166, "C_acc": 0.16471482813358307, "G_acc": 0.5739169478416443, "D_acc": 0.756249318520228, "H_acc": 0.252070389688015, "Q_acc": 0.6673648039003213, "E_rej": 0.3777516484260559, "C_rej": 0.2655985653400421, "G_rej": 0.5507423743605614, "D_rej": 0.719442218542099, "H_rej": 0.280557781457901, "Q_rej": 0.5861869218945504, "Delta_Q": 0.08117788200577092, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional generalization: given operations learned on parts, infer rules for combining them to solve novel tasks with provable guarantees.", "ancestors": ["A set S is a collection of distinct elements.", "A sequence T = (t₁,...,tₖ) lists elements in order.", "A function f maps each tᵢ to an output yᵢ.", "Composition ∘ satisfies (f∘g)(x)=f(g(x)).", "An operation set F contains primitive fⱼ mappings.", "A task M requires producing h from compositions in F.", "Generalization asks for h on unseen inputs x′.", "Coverage is the fraction of x′ where h(x′)=h*(x′) for target h*."]}, "accepted": "Because every task M must build its hypothesis h solely from the finite set of primitive mappings F, the number of distinct input patterns that any composition can distinguish is bounded above by the product of the sizes of the codomains of the primitives used.  Hence the achievable coverage on an unbounded input domain cannot exceed the fraction of the input space that this product can encode.\n\nHYPOTHESIS: The maximal generalization coverage of h satisfies Coverage ≤ |range(F)|^{|F|}/|X|, where |X| is the size of the input domain.\n\nVERIFICATION: Both sides are dimensionless ratios; the bound holds whenever |X| > |range(F)|^{|F|}.\n\nCONCLUSION: Coverage collapses to 0 for infinite X, forcing finite F tasks to rely on distributional assumptions or additional primitives.", "rejected": "Because every task M must build its hypothesis h solely from the finite set of primitive mappings F, the number of distinct input patterns that any composition can distinguish is bounded above by the product of the sizes of the codomains of the primitives used, and these codomain sizes are assumed independent of one another.", "E_acc": 0.0886700227856636, "C_acc": 0.6568048000335693, "G_acc": 0.5890312390401959, "D_acc": 0.7496725797653199, "H_acc": 0.2407265454530716, "Q_acc": 0.4389081560447812, "E_rej": 0.07495034486055374, "C_rej": 0.14607170224189758, "G_rej": 0.5960976639762521, "D_rej": 0.8076657652854919, "H_rej": 0.24041779339313507, "Q_rej": 0.5499816695228219, "Delta_Q": -0.11107351347804073, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["Let U be a finite ground set.", "Let F be a family of subsets of U.", "Let k be a positive integer.", "Let I be a set of intersection constraints of the form |A ∩ B| = c_{A,B}.", "Let E be an extremal bound such that |F| ≤ E.", "Let T = {0,1}^{|U|}.", "Let ψ:F→T map each set to its characteristic vector.", "Let C be the set of constructions that assign every A∈F to ψ(A) while satisfying I and |F|=E."]}, "accepted": "Because every member of F is injected into the binary cube T via the characteristic map ψ, the extremal bound |F| ≤ E forces the image ψ(F) to be a subset of T of size at most E.  The total number of distinct binary vectors of length |U| is 2^{|U|}, so the largest possible family that can be embedded without violating the bound satisfies 2^{|U|} ≥ E.  Rearranging gives the minimal dimension required for the ground set.\n\nHYPOTHESIS: |U| ≥ log₂E.\nVERIFICATION: Both sides are dimensionless; inequality holds whenever E ≤ 2^{|U|}.\nCONCLUSION: The ground set must contain at least log₂E elements to allow an extremal family of size E to be represented by distinct characteristic vectors.", "rejected": "Because every member of F is injected into the binary cube T via the characteristic map ψ, the extremal bound |F| ≤ E forces the image ψ(F) to be a subset of T of size at most E; thus, assuming that the choices of characteristic vectors are mutually independent, the ground set must contain at least log₂E elements to allow an extremal family of size E to be represented by distinct characteristic vectors.", "E_acc": 0.4183163344860077, "C_acc": 0.2741958200931549, "G_acc": 0.5414305217564106, "D_acc": 0.7163463408748308, "H_acc": 0.32466472685337067, "Q_acc": 0.5897446361680825, "E_rej": 0.21778199076652527, "C_rej": 0.18411925435066223, "G_rej": 0.5388405881822109, "D_rej": 0.7709146738052368, "H_rej": 0.3436279892921448, "Q_rej": 0.5560989998281003, "Delta_Q": 0.03364563633998219, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Measurement back-action trade-offs: quantify how much information gain about an observable forces disturbance on its incompatible conjugates.Information flow in regulatory networks: identify motifs that guarantee robust signal propagation despite stochastic expression and component failure.", "ancestors": ["Alice measures observable A.", "Observable A has conjugate observable B.", "A and B obey [A,B]=iℏ.", "Alice’s apparatus records outcome a.", "Information gain about A is Iₐ = −log p(a).", "Measurement interaction couples A to apparatus pointer.", "Back-action on B is ΔB ≥ ℏ/(2ΔA)."]}, "accepted": "The uncertainty product ΔA ΔB ≥ ℏ/2, together with the recorded outcome a, fixes the lower bound for the back-action on B.  Because the apparatus has already registered a, the conjugate observable B must have suffered at least the minimal disturbance ΔB ≥ ℏ/(2ΔA) with ΔA set by the width of the post-selected A-distribution.  Inserting the information gain Iₐ = −log p(a) and noting that p(a) sets the spread ΔA via the Bayesian update, one derives ΔB ≥ (ℏ/2) exp(Iₐ/2).\n\nHYPOTHESIS: The back-action on B satisfies ΔB ≥ (ℏ/2) exp(Iₐ/2).\n\nVERIFICATION: Units check: ℏ (J·s), Iₐ dimensionless, exponent ½ preserves length units for ΔB.\n\nCONCLUSION: Any information gain Iₐ > 0 enforces a strictly positive, exponentially growing lower bound on the disturbance of the conjugate observable B.", "rejected": "The back-action on B satisfies ΔB ≥ (ℏ/2) exp(2Iₐ).", "E_acc": 0.4226263761520386, "C_acc": 0.19933512806892395, "G_acc": 0.6041588293654578, "D_acc": 0.7730544296403726, "H_acc": 0.2214425429701805, "Q_acc": 0.6402192847359748, "E_rej": 0.4749625325202942, "C_rej": 0.27157315611839294, "G_rej": 0.5560420230031013, "D_rej": 0.764954000711441, "H_rej": 0.23504599928855896, "Q_rej": 0.6288687333464622, "Delta_Q": 0.011350551389512575, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["A catalyst surface provides active sites where adsorbates bind and react.", "Reaction flux is the number of reactant molecules converted per unit time.", "Competing pathways share a common reactant but form distinct products.", "Selectivity is the fraction of flux directed to a specified product.", "The adsorption energy of an intermediate is the enthalpy change when it binds to a site.", "Differential stabilization lowers the energy of one intermediate relative to its competitors.", "Active-site geometry and composition tune adsorption energies to reorder stabilities."]}, "accepted": "Differential stabilization of an adsorbed intermediate lowers its energy relative to competing species, so for any pair of pathways sharing a reactant the selectivity S toward the stabilized product equals the fraction of flux that clears the smaller energy gap ΔE stabilized/ΔE unstabilized.  \nHYPOTHESIS: Selectivity to the differentially stabilized product exceeds 0.5 whenever the adsorption energy of its key intermediate is lowered by more than kBT ln 2 relative to the competing intermediate at the same site.  \nVERIFICATION: Dimensionless ratio ΔΔE/kBT ≥ ln 2 ≈ 0.693 at 298 K corresponds to ≥ 50 % flux redirection.  \nCONCLUSION: Catalyst design must achieve ≥ 0.4 kJ mol⁻¹ differential stabilization at 298 K to guarantee majority selectivity to the targeted product.", "rejected": "Selectivity to the differentially stabilized product exceeds 0.5 whenever the adsorption energy of its key intermediate is lowered by more than kBT relative to the competing intermediate at the same site.", "E_acc": 0.3968751132488251, "C_acc": 0.18618199229240417, "G_acc": 0.5399852267582901, "D_acc": 0.7711219470947981, "H_acc": 0.20956018567085266, "Q_acc": 0.6230915517196991, "E_rej": 0.023274820297956467, "C_rej": 0.01863708347082138, "G_rej": 0.5521266338473652, "D_rej": 0.7942220866680145, "H_rej": 0.20577791333198547, "Q_rej": 0.5519469821651001, "Delta_Q": 0.07114456955459902, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["A coalition S is a subset of the grand coalition N.", "Players have utility functions ui(x) defined on real outcomes x.", "Utility is transferable via a single divisible good with constant marginal rate 1.", "The value function v(S; P) gives total payoff to S under partition P.", "An allocation y ∈ ℝ^N satisfies ∑_{i∈S} y_i = v(S; P) for S in P.", "An allocation y is blocked by S if ∃ z ∈ ℝ^S such that ∑_{i∈S} z_i ≤ v(S; P') and each z_i > y_i, where P' places S alone."]}, "accepted": "Because utility is transferable at a 1-to-1 rate, any coalition S that can achieve a surplus v(S;{S}) strictly above the sum of its members’ current payoffs ∑_{i∈S} y_i can block the allocation by redistributing that surplus so each member receives more.  Hence the grand coalition N can enforce an allocation only if no such surplus exists for any S.\n\nHYPOTHESIS: An allocation y is unblocked only if every coalition S satisfies v(S;{S}) ≤ ∑_{i∈S} y_i.\n\nVERIFICATION: Both sides of the inequality are measured in the same divisible-good units, and the condition is necessary and sufficient to prevent blocking under the given definition.\n\nCONCLUSION: The allocation y must distribute at least v(S;{S}) to every coalition S to be stable.", "rejected": "An allocation y is unblocked only if every coalition S satisfies v(S;{S}) ≥ ∑_{i∈S} y_i.", "E_acc": 0.20174632966518402, "C_acc": 0.46256402134895325, "G_acc": 0.5482175005599856, "D_acc": 0.8108918875455856, "H_acc": 0.13198621571063995, "Q_acc": 0.5266343506798148, "E_rej": 0.11339973658323288, "C_rej": 0.6580968499183655, "G_rej": 0.5571531783789396, "D_rej": 0.8274197280406952, "H_rej": 0.1725802719593048, "Q_rej": 0.46205710507929326, "Delta_Q": 0.06457724560052153, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["A concurrent system consists of multiple processes.", "Processes share a common memory region M.", "A scheduler selects one process to execute per step.", "An unreliable scheduler may starve some process forever.", "A scheduler is k-fair if every process executes at least once in any k consecutive steps.", "Probabilistic fairness is the condition that the scheduler is k-fair with probability 1.", "A protocol guarantees progress if some process leaves its critical section infinitely often.", "The protocol uses only atomic reads and writes to M."]}, "accepted": "Deriving from the premise that k-fairness forces every process to execute at least once in every k consecutive steps, the worst-case interval between two successive executions of any single process is exactly k steps.  Because progress requires that some process leaves its critical section infinitely often, the maximum number of steps that can elapse without any process making progress is bounded by this same k-step window.\n\nHYPOTHESIS: In any k-fair schedule, the system guarantees that at least one process makes progress within every k consecutive steps.\n\nVERIFICATION: Units check—k steps (dimensionless count) matches the interval unit in the fairness definition.\n\nCONCLUSION: Progress is ensured at least once every k steps under k-fairness.", "rejected": "In any k-fair schedule, if at least one process makes progress within every k consecutive steps, then the system guarantees k-fairness.", "E_acc": 0.775442361831665, "C_acc": 0.05175143852829933, "G_acc": 0.60604406776838, "D_acc": 0.7881518453359604, "H_acc": 0.2423914074897766, "Q_acc": 0.77688246271573, "E_rej": 0.183256134390831, "C_rej": 0.6935948729515076, "G_rej": 0.6096454923390411, "D_rej": 0.889831930398941, "H_rej": 0.1377100870013237, "Q_rej": 0.5023823415744119, "Delta_Q": 0.27450012114131817, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["Process P is an infinite sequence of steps.", "Shared memory contains one single-writer single-reader atomic bit b.", "P writes b with b := 1.", "Every P step is either an enabled or a disabled operation.", "An enabled step of P is a write to b.", "The scheduler chooses one enabled step to execute at each time t ∈ ℕ.", "After each choice the scheduler deletes that step from P."]}, "accepted": "The premises fix the shared bit b to be written only by process P, and every enabled step of P is exactly such a write.  Because the scheduler deletes each chosen step, the total number of writes equals the count of enabled steps that have been scheduled.  With b initially 0, the first write sets b=1 and every subsequent write leaves it 1; hence b remains 1 forever once the first enabled step occurs.\n\nHYPOTHESIS: After the first enabled step of P is executed, the value of b is 1 and never changes again.  \nVERIFICATION: Units: bit value (dimensionless); regime: holds for every schedule once the first write is performed.  \nCONCLUSION: b stabilises permanently to 1 immediately after the first enabled step of P.", "rejected": "After the first enabled step of P is executed, the value of b is 1 plus the number of previously scheduled steps and never changes again.", "E_acc": 0.6230693459510803, "C_acc": 0.15636734664440155, "G_acc": 0.5653666728176177, "D_acc": 0.7932031800349554, "H_acc": 0.15778083354234695, "Q_acc": 0.7115832216727237, "E_rej": 0.43129581212997437, "C_rej": 0.33437401056289673, "G_rej": 0.5714257009094581, "D_rej": 0.8113076984882355, "H_rej": 0.23586537688970566, "Q_rej": 0.6154740837169811, "Delta_Q": 0.09610913795574261, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Market microstructure and information asymmetry: model how order flow reveals private valuations and derive optimal inference filters.", "ancestors": ["A limit order book lists outstanding buy and sell orders on an asset.", "Each order specifies a price and a quantity.", "Order flow is the signed net quantity arriving within a time interval dt.", "Time is indexed by discrete intervals t = 0,1,2,…,T.", "The private valuation v is known only to the informed trader.", "The public best bid price at t is p_{t}^{b}.", "The public best ask price at t is p_{t}^{a}.", "Market bid flow b_{t} is the sum of buyer-initiated quantities in dt.", "Market ask flow a_{t} is the sum of seller-initiated quantities in dt.", "Signed order flow x_{t} = b_{t} – a_{t}."]}, "accepted": "The premises define signed order flow x_t = b_t – a_t, where b_t and a_t are non-negative market flows.  Because b_t and a_t are sums of quantities, they are non-negative, so x_t is bounded above by b_t and below by –a_t.  The extreme cases x_t = b_t (when a_t = 0) and x_t = –a_t (when b_t = 0) give the tightest bounds achievable from the definitions alone.\n\nHYPOTHESIS: The signed order flow satisfies –a_t ≤ x_t ≤ b_t.\n\nVERIFICATION: Units: both sides are shares (or contracts) per interval, consistent.\n\nCONCLUSION: The observable flows b_t and a_t provide immediate upper and lower bounds on x_t without any further model assumptions.", "rejected": "The signed order flow satisfies –a_t ≤ x_t ≤ a_t.", "E_acc": 0.3863326907157898, "C_acc": 0.298871248960495, "G_acc": 0.5505482403095812, "D_acc": 0.7429484277963638, "H_acc": 0.20068985223770142, "Q_acc": 0.5947559058200568, "E_rej": 0.5535716414451599, "C_rej": 0.20217353105545044, "G_rej": 0.5422954177483916, "D_rej": 0.7682762444019318, "H_rej": 0.23172375559806824, "Q_rej": 0.6645787430927158, "Delta_Q": -0.06982283727265903, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["A modeled agent receives input x and produces output y.", "The explanation e reveals how x maps to y.", "Gaming occurs when the agent changes y to gain reward despite unchanged true performance.", "Opacity withholds e from the agent.", "Transparency provides e to the agent.", "The physical graph Gp contains variables Vp and edges Ep.", "The social graph Gs contains variables Vs and Es."]}, "accepted": "Because transparency supplies the agent with the explanation e, the agent can detect any mismatch between the declared mapping x→y and its own internal model; opacity removes this check.  \nGaming is therefore feasible only when the withheld explanation keeps the agent uncertain about the true performance underlying y.  \nHence, withholding e raises the minimum reward gain ΔR that must be offered to elicit gaming, and this threshold increases monotonically with the agent’s uncertainty about the true performance.  \n\nHYPOTHESIS: Opacity increases the minimum reward increment ΔR required to trigger gaming by the amount ΔR = β·H(p), where β>0 is a sensitivity parameter and H(p) is the Shannon entropy of the agent’s belief over true performance p.  \nVERIFICATION: ΔR has units of reward, H(p) is dimensionless, and the equation holds whenever the agent is risk-neutral and the reward function is linear in reported performance.  \nCONCLUSION: Withholding explanation e raises the critical reward threshold for gaming in direct proportion to the agent’s performance uncertainty.", "rejected": "Opacity increases the minimum reward increment ΔR required to trigger gaming by the amount ΔR = β·H(p), where β>0 is a sensitivity parameter and H(p) is the Shannon entropy of the agent’s belief over true performance p, even when the agent is risk-seeking and the reward function is exponential.", "E_acc": 0.09165018796920776, "C_acc": 0.21574237942695618, "G_acc": 0.6049825377995148, "D_acc": 0.7765367105603218, "H_acc": 0.19967984408140182, "Q_acc": 0.5406824457691983, "E_rej": 0.06608761847019196, "C_rej": 0.15077196061611176, "G_rej": 0.6056305480888113, "D_rej": 0.785573273897171, "H_rej": 0.21442672610282898, "Q_rej": 0.5464699852047488, "Delta_Q": -0.005787539435550437, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["[DEF] Let P be the distribution of observed state-action pairs (s,a).", "[DEF] Let Q be the distribution of state-action pairs under deployment.", "[DEF] Let w(s,a)=Q(s,a)/P(s,a) be the importance weight.", "[VAR] Let ρ=E_P[w(s,a)r] be the off-policy value estimate.", "[VAR] Let R_max=sup|r|.", "[CONSTRAINT] w(s,a) is finite P-a.s.", "[LAW] E_Q[r]=E_P[w(s,a)r].", "[LIMIT] sup|w(s,a)|≤M implies |E_Q[r]−ρ|≤2R_max·TV(P,Q).", "[LIMIT] TV(P,Q)≤½E_P[|w(s,a)−1|]."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: |E_Q[r]−ρ| ≤ R_max · E_P[|w(s,a)−1|].\nASSUMPTION: None\nVERIFICATION: units: reward units; regime: whenever w(s,a) is finite P-a.s.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.3572635054588318, "C_acc": 0.4431047737598419, "G_acc": 0.5985884082037956, "D_acc": 0.6756122568622231, "H_acc": 0.1827770471572876, "Q_acc": 0.5551205251831561, "E_rej": 0.24703189730644226, "C_rej": 0.5549272894859314, "G_rej": 0.5887986356392503, "D_rej": 0.6213941127061844, "H_rej": 0.3786058872938156, "Q_rej": 0.4673020722344518, "Delta_Q": 0.08781845294870433, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["[DEF] Let f denote replication fidelity, 0 ≤ f ≤ 1.", "[DEF] Let E(f) be the energy expended per replication for error correction.", "[DEF] Let μ(f) = 1 − f be the genomic mutation rate.", "[DEF] Let B(f) be the expected adaptive benefit from mutations.", "[VAR] E(f) is strictly increasing in f.", "[VAR] B(f) is strictly decreasing in f.", "[CONSTRAINT] Net replication cost C(f) = E(f) − B(f).", "[LIMIT] There exists f* ∈ [0,1] that minimizes C(f).", "[LAW] At f*, dC/df = 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: At f*, the marginal energy cost of increasing fidelity equals the marginal loss of adaptive benefit: dE/df = dB/df.\nASSUMPTION: None\nVERIFICATION: Units: energy per fidelity change; test via measuring slopes of E(f) and B(f) at the extremum.", "rejected": "At f*, the marginal loss of adaptive benefit equals the marginal energy cost of increasing fidelity: dB/df = dE/df.", "E_acc": 0.2994433343410492, "C_acc": 0.4201205372810364, "G_acc": 0.5210741222836077, "D_acc": 0.653880862519145, "H_acc": 0.21647030115127563, "Q_acc": 0.5191528596915305, "E_rej": 0.24887828528881073, "C_rej": 0.5088452696800232, "G_rej": 0.5156861511059105, "D_rej": 0.7684893310070038, "H_rej": 0.23151066899299622, "Q_rej": 0.5065784611739219, "Delta_Q": 0.012574398517608554, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["[DEF] A multi-agent routing instance is a tuple (G, N, c) with directed graph G, agent set N, and edge-cost functions c_e(f_e).", "[VAR] f_e denotes the total flow on edge e.", "[VAR] c_e(f_e) is non-decreasing in f_e.", "[DEF] A flow profile f = (f^i)_{i∈N} assigns each agent i a path flow f^i.", "[CONSTRAINT] Every f^i is a non-negative vector satisfying source-sink conservation.", "[DEF] The latency of agent i is L^i(f) = ∑_{e∈P^i} c_e(f_e).", "[DEF] A flow f is a Nash equilibrium if for every i and every deviating path P' we have L^i(f) ≤ L^i(f^{-i}, P').", "[DEF] Social welfare is SW(f) = -∑_{i∈N} L^i(f).", "[DEF] A tolling scheme is a vector τ = (τ_e)_{e∈E} of edge charges.", "[LIMIT] The planner knows (G, N, c) but not individual agent preferences beyond c."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: For any tolling scheme τ, the modified edge cost c_e(f_e)+τ_e preserves the non-decreasing property of the perceived cost.\nASSUMPTION: Agent perceived cost on edge e is c_e(f_e)+τ_e.\nVERIFICATION: Units: cost units; regime f_e≥0; test via derivative (c_e(f_e)+τ_e)'=c_e'(f_e)≥0.", "rejected": "For any tolling scheme τ, the modified edge cost c_e(f_e)+τ_e preserves the non-decreasing property of the perceived cost even when f_e < 0.", "E_acc": 0.19105477631092072, "C_acc": 0.38543984293937683, "G_acc": 0.5510559028480202, "D_acc": 0.6897451262921095, "H_acc": 0.2426956295967102, "Q_acc": 0.5041191071737557, "E_rej": 0.21341609954833984, "C_rej": 0.3846926689147949, "G_rej": 0.5593972506467253, "D_rej": 0.7835546135902405, "H_rej": 0.21644538640975952, "Q_rej": 0.5340321302879603, "Delta_Q": -0.029913023114204518, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["[DEF] Let A, B, C be Boolean variables.", "[DEF] Let the operator ⇒ denote material implication.", "[DEF] Let the operator ¬ denote negation.", "[DEF] Let the operator ↔ denote biconditional equivalence.", "[DEF] Let the expression A ⇒ B unless C denote (¬C ∧ A) ⇒ B.", "[DEF] Let the expression C depends on B denote C ↔ B.", "[DEF] Let a fixed point be a state where B(t+1) = B(t).", "[CONSTRAINT] The state of C(t) is determined by B(t) via C ↔ B.", "[LIMIT] The system state is fully specified by the tuple (A(t), B(t), C(t))."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If B(t) = 1 then C(t) = 1, and if B(t) = 0 then C(t) = 0.\nASSUMPTION: None\nVERIFICATION: Direct from C ↔ B; units: Boolean, regime: all t.", "rejected": "If B(t) = 1 then C(t) = 2, and if B(t) = 0 then C(t) = 0.", "E_acc": 0.4117927849292755, "C_acc": 0.31561020016670227, "G_acc": 0.5592467919535314, "D_acc": 0.6824766993522644, "H_acc": 0.1943053901195526, "Q_acc": 0.5893299546946461, "E_rej": 0.4700973927974701, "C_rej": 0.23282577097415924, "G_rej": 0.5367439066370329, "D_rej": 0.71473528444767, "H_rej": 0.28526471555233, "Q_rej": 0.6162334303061168, "Delta_Q": -0.026903475611470662, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["[DEF] A concurrent system is a set of processes that access shared memory.", "[DEF] A scheduler is a function that selects at each step a non-empty subset of enabled processes.", "[DEF] A scheduler is unreliable if it may select any non-empty subset of enabled processes.", "[DEF] A scheduler is probabilistic-fair if every enabled process has a non-zero probability of being selected at every step.", "[DEF] A protocol guarantees progress if some process eventually executes a step that changes the shared state.", "[VAR] Let P be a shared-memory protocol.", "[VAR] Let S be an unreliable probabilistic-fair scheduler.", "[VAR] Let C be the set of all computations of P under S.", "[LIMIT] There exists a protocol P and scheduler S such that C contains an infinite computation in which no process ever changes the shared state.", "[LIMIT] Therefore P does not guarantee progress under every probabilistic-fair unreliable scheduler."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: There exists at least one probabilistic-fair unreliable scheduler under which P does not guarantee progress.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "There exists at least one probabilistic-fair unreliable scheduler under which P guarantees progress independently of any computation of C.", "E_acc": 0.2541314363479614, "C_acc": 0.5151723027229309, "G_acc": 0.5437499514470497, "D_acc": 0.6295091453939676, "H_acc": 0.20825877785682678, "Q_acc": 0.48703091194232306, "E_rej": 0.11516430974006653, "C_rej": 0.6592970490455627, "G_rej": 0.5107664410024881, "D_rej": 0.8672791123390198, "H_rej": 0.16590110957622528, "Q_rej": 0.46170888282358646, "Delta_Q": 0.0253220291187366, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["[DEF] A closed finite system has constant total energy E and fixed volume V.", "[DEF] Microdynamics is governed by a time-reversible Hamiltonian H(Γ) with Γ=(q,p).", "[VAR] Let ρ(Γ,t) denote the phase-space density at time t.", "[LAW] ρ evolves under Liouville’s equation ∂ρ/∂t = –{ρ,H}.", "[CONSTRAINT] The initial ρ(Γ,0) is a non-equilibrium smooth distribution.", "[DEF] A macrostate M is specified by values of coarse observables {A_k(Γ)}.", "[VAR] Let Ω(M) count microstates consistent with macrostate M at energy E.", "[LIMIT] For large V, ln Ω(M) is extensive and convex in {A_k}.", "[LAW] For t > τ_mix, the marginal distribution of {A_k} approaches exp[–Σ_k λ_k A_k]/Z with time-independent λ_k."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For t > τ_mix, the equilibrium expectation of every coarse observable A_k equals its microcanonical average at energy E.\nASSUMPTION: None\nVERIFICATION: Units of A_k preserved; test by comparing long-time average of A_k(Γ(t)) to microcanonical integral over {Γ:H(Γ)=E}.", "rejected": "For t > τ_mix, the equilibrium expectation of every coarse observable A_k is less than its microcanonical average at energy E.", "E_acc": 0.15768560767173767, "C_acc": 0.5110284686088562, "G_acc": 0.5196217278717086, "D_acc": 0.6362980427220464, "H_acc": 0.18532150983810425, "Q_acc": 0.45775179171469066, "E_rej": 0.13450634479522705, "C_rej": 0.13805779814720154, "G_rej": 0.5271281569439452, "D_rej": 0.8071859776973724, "H_rej": 0.19281402230262756, "Q_rej": 0.5603217685071287, "Delta_Q": -0.10256997679243801, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["[DEF] A concurrent system is a set of threads that access shared memory.", "[VAR] Let t denote a thread in the system.", "[VAR] Let S denote a scheduler that selects t at each step.", "[DEF] A scheduler is probabilistic-fair if every t is selected infinitely often with probability 1.", "[VAR] Let P be a shared-memory protocol executed by the threads.", "[DEF] P guarantees progress if some thread completes an operation in every infinite execution.", "[LIMIT] There exists a probabilistic-fair scheduler under which P does not guarantee progress."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: There exists at least one infinite execution under a probabilistic-fair scheduler in which no thread ever completes an operation.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "For every infinite execution under a probabilistic-fair scheduler, no thread ever completes an operation.", "E_acc": 0.24183562397956848, "C_acc": 0.5948651432991028, "G_acc": 0.5313428608700633, "D_acc": 0.6211960702203214, "H_acc": 0.15590941905975342, "Q_acc": 0.46849450284615163, "E_rej": 0.004700976889580488, "C_rej": 0.9665765762329102, "G_rej": 0.5057350683986442, "D_rej": 0.829734206199646, "H_rej": 0.170265793800354, "Q_rej": 0.35816225335991475, "Delta_Q": 0.11033224948623688, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial online optimization: given unknown convex losses chosen by an adversary, bound regret using limited-memory algorithms.", "ancestors": ["[DEF] Regret is R_T = Σ_{t=1}^{T} f_t(x_t) − min_{x∈K} Σ_{t=1}^{T} f_t(x).", "[VAR] f_t is a convex function revealed after x_t is chosen.", "[VAR] K is a fixed convex compact set.", "[VAR] x_t is selected by the learner at round t.", "[CONSTRAINT] The learner stores at most M past gradients.", "[LAW] Online gradient descent sets x_{t+1} = Π_K(x_t − η_t g_t) with g_t ∈ ∂f_t(x_t).", "[LIMIT] For any M, there exists an adversary such that R_T ≥ (D G/2)√T with D = diam(K), G = sup_t ‖g_t‖.", "[LIMIT] With M = 1 and η_t = η, the worst-case R_T ≥ (D G/2)√T."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any M < T, there exists an adversary such that the learner's regret satisfies R_T ≥ (D G/2)√T.\nASSUMPTION: None\nVERIFICATION: Units: regret in objective value; regime: any T ≥ 1; testable via adversarial sequence.", "rejected": "For any M ≥ T, there exists an adversary such that the learner's regret satisfies R_T ≥ (D G/2)√T.", "E_acc": 0.26259592175483704, "C_acc": 0.48258617520332336, "G_acc": 0.6119264592416584, "D_acc": 0.6712954714894295, "H_acc": 0.15265077352523804, "Q_acc": 0.5236408502794803, "E_rej": 0.3482724726200104, "C_rej": 0.28587937355041504, "G_rej": 0.6036800235742703, "D_rej": 0.8780318796634674, "H_rej": 0.12196812033653259, "Q_rej": 0.6314514356898144, "Delta_Q": -0.10781058541033417, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["[DEF] A family F is a set of sets.", "[DEF] For A,B ∈ F, |A ∩ B| is the intersection size.", "[CONSTRAINT] For every distinct A,B ∈ F, |A ∩ B| ≤ t.", "[VAR] Let n = |F|.", "[VAR] Let m = max_{A∈F} |A|.", "[LIMIT] Fisher’s inequality gives n ≤ m² if t ≥ 1 and all |A| = m.", "[CONSTRAINT] The explicit incidence matrix M has rows indexed by F, columns by ∪F, and M_{A,x}=1 iff x ∈ A.", "[DEF] A (v,k,λ)-design is a family on v points with each block size k and every pair of points in exactly λ blocks.", "[LIMIT] For a (v,k,λ)-design, the Johnson bound gives b ≥ v(v−1)λ/(k(k−1)) where b is the number of blocks."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If every member of F has size m and t ≥ 1, then n ≤ m².\nASSUMPTION: None\nVERIFICATION: Direct application of Fisher’s inequality under the stated premises.", "rejected": "If every member of F has size m and t ≥ 1, then n ≤ m³.", "E_acc": 0.17593957483768463, "C_acc": 0.6627210378646851, "G_acc": 0.5503173905308358, "D_acc": 0.6135010813595727, "H_acc": 0.2859121859073639, "Q_acc": 0.42441014066571375, "E_rej": 0.31802013516426086, "C_rej": 0.33410879969596863, "G_rej": 0.5405653025372885, "D_rej": 0.6530198156833649, "H_rej": 0.34698018431663513, "Q_rej": 0.5326032858225517, "Delta_Q": -0.10819314515683792, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial online optimization: given unknown convex losses chosen by an adversary, bound regret using limited-memory algorithms.", "ancestors": ["[DEF] Regret R_T = sum_{t=1}^T f_t(x_t) - min_{x∈X} sum_{t=1}^T f_t(x).", "[VAR] X is a convex compact subset of R^d.", "[VAR] f_t:X→R is convex for each t∈{1,…,T}.", "[VAR] The adversary selects f_t after x_t is chosen and before x_{t+1} is chosen.", "[CONSTRAINT] The algorithm stores at most M real numbers from prior rounds.", "[LIMIT] M is a positive integer independent of T.", "[DEF] Gradient g_t ∈ ∂f_t(x_t).", "[LAW] Online gradient descent sets x_{t+1}=Π_X(x_t - η_t g_t).", "[LIMIT] With η_t=η constant, R_T ≤ (D²/η + ηTG²)/2 where D=diam(X), G=sup_t‖g_t‖_*."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If M < 2d, no deterministic algorithm can guarantee sublinear regret for all sequences of convex losses.  \nASSUMPTION: The algorithm’s stored reals are its only state carried between rounds.  \nVERIFICATION: Units: dimensionless; regime M < 2d; test via information-theoretic lower bound.", "rejected": "If M < 2d, no deterministic algorithm can guarantee sublinear regret independent of the sequence of convex losses.", "E_acc": 0.23894909024238586, "C_acc": 0.41206443309783936, "G_acc": 0.5712706774938852, "D_acc": 0.6675158012658358, "H_acc": 0.2487528696656227, "Q_acc": 0.5121538492385298, "E_rej": 0.14698344469070435, "C_rej": 0.48570454120635986, "G_rej": 0.5645262023899704, "D_rej": 0.8021382391452789, "H_rej": 0.24732720106840134, "Q_rej": 0.4955542933661491, "Delta_Q": 0.01659955587238071, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit instance is a tuple (A, R) with finite action set A and reward distribution R(a) for each a ∈ A.", "[VAR] Let τ(a) ∈ ℕ denote the unknown, possibly unbounded delay between playing arm a and observing its reward.", "[VAR] Let c_s ≥ 0 denote the cost incurred to sense any variable at decision epoch s.", "[CONSTRAINT] An observation is censored if the observed value is min(r, T) with fixed censoring threshold T.", "[DEF] A policy π maps each history H_s to a distribution over A ∪ {sense}.", "[LAW] The expected regret of π is E[∑_{s=1}^S (μ^* − μ_{a_s})] where μ^* = max_a E[R(a)].", "[LIMIT] No policy can identify the best arm with probability 1 before every arm has been played at least once.", "[CONSTRAINT] A feasible plan must satisfy ∑_{s=1}^S c_s ≤ B for given budget B."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: Any feasible plan must satisfy S ≤ B / c_s for every epoch s in which sensing is performed.  \nASSUMPTION: The sensing cost c_s is constant across all epochs (c_s = c).  \nVERIFICATION: Units: epochs; regime B ≥ 0, c > 0; test via counting sensing epochs.", "rejected": "STATUS: ENTAILED_WITH_ASSUMPTION.", "E_acc": 0.27238935232162476, "C_acc": 0.4071817696094513, "G_acc": 0.5650119087949861, "D_acc": 0.6538529023528099, "H_acc": 0.3370569087564945, "Q_acc": 0.510347723128507, "E_rej": 0.245827317237854, "C_rej": 0.41096559166908264, "G_rej": 0.5697057745419443, "D_rej": 0.5748066529631615, "H_rej": 0.42519334703683853, "Q_rej": 0.47793822763487703, "Delta_Q": 0.032409495493629925, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["[DEF] A module is a tuple (Σ, σ₀, →) with state set Σ, initial state σ₀ ∈ Σ, and transition relation → ⊆ Σ × Σ.", "[VAR] Let c ∈ ℝ be a conserved quantity exchanged between modules.", "[DEF] A contract for module i is a pair (Pᵢ, Qᵢ) with precondition Pᵢ ⊆ Σᵢ and postcondition Qᵢ ⊆ Σᵢ.", "[CONSTRAINT] For every transition (σ, σ′) ∈ →ᵢ, c(σ) = c(σ′).", "[DEF] Intermittent coupling is a relation C ⊆ Σᵢ × Σⱼ active only on a subset T ⊆ ℕ of discrete time indices.", "[VAR] Let transient amplification A = sup_{t∈T} |y(t)| / |y(0)| for observable y : Σ → ℝ.", "[LIMIT] If C is inactive, A ≤ 1."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If C is inactive, then |y(t)| ≤ |y(0)| for every t ∈ T.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If C is inactive, then |y(t)| ≥ |y(0)| for every t ∈ T.", "E_acc": 0.24048633873462677, "C_acc": 0.549870491027832, "G_acc": 0.5356007784139365, "D_acc": 0.5969620384275913, "H_acc": 0.3335374891757965, "Q_acc": 0.45533061786554757, "E_rej": 0.20195521414279938, "C_rej": 0.5883277058601379, "G_rej": 0.5247180297737941, "D_rej": 0.6418472677469254, "H_rej": 0.35815273225307465, "Q_rej": 0.4404188093496487, "Delta_Q": 0.01491180851589885, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["[DEF] A state space is a measurable set S.", "[DEF] An action space is a measurable set A.", "[DEF] A policy π is a Markov kernel from S to A.", "[VAR] Let P denote the unknown true transition kernel on S.", "[VAR] Let d₀ denote the unknown initial state distribution on S.", "[DEF] The occupancy ν_π(s,a)=∑_{t=0}^{∞}γ^t P_π(s_t=s,a_t=a) with γ∈[0,1).", "[VAR] Let ν denote the occupancy under the offline data distribution.", "[VAR] Let w(s)=ν_π(s)/ν(s) where defined.", "[CONSTRAINT] The support of ν contains the support of ν_π.", "[LIMIT] The estimator Ĵ=∑_{(s,a,r)} w(s)r is unbiased for the true return J=∑_{s,a}ν_π(s,a)r(s,a) when w is exact."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The ratio w(s)=ν_π(s)/ν(s) is finite for every state s in the support of ν_π.\nASSUMPTION: None\nVERIFICATION: Follows directly from the stated constraint that the support of ν contains the support of ν_π, ensuring the denominator is strictly positive wherever the numerator is non-zero.", "rejected": "The ratio w(s)=ν_π(s)/ν(s) is finite for every state s in the support of ν.", "E_acc": 0.14653314650058746, "C_acc": 0.6561726927757263, "G_acc": 0.5701702722581103, "D_acc": 0.6349570965394378, "H_acc": 0.26963624358177185, "Q_acc": 0.4267872547963634, "E_rej": 0.49748748540878296, "C_rej": 0.3168409466743469, "G_rej": 0.5663974946000963, "D_rej": 0.7307082414627075, "H_rej": 0.2692917585372925, "Q_rej": 0.6183700276465971, "Delta_Q": -0.19158277285023367, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial robustness for decision trees: transform a decision procedure to simultaneously maximize accuracy and a certified robustness radius.", "ancestors": ["[DEF] A decision tree T is a rooted binary tree whose internal nodes are labeled with predicates on ℝᵈ and whose leaves are labeled with class predictions.", "[VAR] Let x ∈ ℝᵈ denote an input vector.", "[VAR] Let ε > 0 denote an ℓ∞ perturbation budget.", "[DEF] The ε-neighborhood N(x,ε) is the set {z ∈ ℝᵈ : ‖z−x‖∞ ≤ ε}.", "[DEF] A tree T is certifiably robust at x with radius ε if every z ∈ N(x,ε) is assigned the same class as x by T.", "[VAR] Let Acc(T) denote the empirical accuracy of T on a fixed dataset.", "[VAR] Let Rad(T) denote the largest ε such that T is certifiably robust at every training point with radius ε.", "[CONSTRAINT] The optimization objective is to maximize Acc(T) while satisfying Rad(T) ≥ ε₀ for a prescribed ε₀ > 0.", "[LIMIT] For any dataset, there exists a finite maximal Rad(T) beyond which Acc(T) cannot increase."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If ε₀ exceeds the maximal Rad(T) achievable on the dataset, then no tree T can satisfy Rad(T) ≥ ε₀ while maintaining Acc(T) > 0.  \nASSUMPTION: The dataset contains at least one training point whose true class label differs from the majority class in its ε₀-neighborhood.  \nVERIFICATION: Testable by computing the maximal Rad(T) across all candidate trees and comparing to ε₀.", "rejected": "If ε₀ exceeds the maximal Rad(T) achievable on the dataset, then no tree T can satisfy Rad(T) ≥ ε₀ while maintaining Acc(T) > 0.", "E_acc": 0.39694276452064514, "C_acc": 0.2985631823539734, "G_acc": 0.5535876107314834, "D_acc": 0.7487922990694642, "H_acc": 0.1659313142299652, "Q_acc": 0.603253043422592, "E_rej": 0.40152618288993835, "C_rej": 0.29491057991981506, "G_rej": 0.5528423852811102, "D_rej": 0.8577803075313568, "H_rej": 0.1422196924686432, "Q_rej": 0.6293783081986476, "Delta_Q": -0.02612526477605559, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] A certificate is a bitstring.", "[DEF] A verifier is a Turing machine that maps a certificate and a claim to {0,1}.", "[DEF] A claim is a bitstring.", "[VAR] Let c denote a certificate.", "[VAR] Let V denote a verifier.", "[VAR] Let φ denote a claim.", "[DEF] V accepts c on φ iff V(c,φ)=1.", "[CONSTRAINT] V runs in time polynomial in |c|+|φ|.", "[LIMIT] There exists no verifier that accepts every true claim and rejects every false claim in time polynomial in |φ| alone.", "[DEF] A proof object is a certificate accepted by V on φ."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every verifier V there exists at least one claim φ such that V does not accept any certificate c on φ in time polynomial in |φ| alone.\nASSUMPTION: None\nVERIFICATION: Follows directly from the LIMIT statement; test by contradiction with the LIMIT.", "rejected": "For every verifier V there exists at least one claim φ such that V does not accept any certificate c on φ in time polynomial in |c|+|φ| alone.", "E_acc": 0.367613285779953, "C_acc": 0.46186941862106323, "G_acc": 0.5483163363699403, "D_acc": 0.649857954820618, "H_acc": 0.16064363718032837, "Q_acc": 0.5414805965298521, "E_rej": 0.2418588101863861, "C_rej": 0.6566377282142639, "G_rej": 0.5314398389309645, "D_rej": 0.8562684953212738, "H_rej": 0.1437315046787262, "Q_rej": 0.5043986137956381, "Delta_Q": 0.037081982734214036, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["[DEF] A vertex cover in graph G=(V,E) is a set S⊆V such that every e∈E has at least one endpoint in S.", "[VAR] Let k denote the minimum size of a vertex cover in G.", "[VAR] Let x_v∈{0,1} indicate inclusion of v∈V in S.", "[CONSTRAINT] Minimize ∑_{v∈V} x_v subject to x_u+x_v≥1 for every (u,v)∈E.", "[DEF] The LP relaxation replaces x_v∈{0,1} with 0≤x_v≤1.", "[VAR] Let z_LP be the optimal value of the LP relaxation.", "[LIMIT] For every G, z_LP ≤ k.", "[DEF] The integrality gap is sup_G (k / z_LP).", "[LIMIT] There exists a family of graphs for which k / z_LP ≥ 2−2/Δ where Δ is the maximum degree.", "[LIMIT] For every graph, k / z_LP ≤ 2."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every graph G, the integrality gap k/z_LP is at least 1.\nASSUMPTION: None\nVERIFICATION: Units: ratio of integers; regime: all graphs; test via k≥z_LP from premise LIMIT z_LP≤k.", "rejected": "For every graph G, the integrality gap k/z_LP is at most 1.", "E_acc": 0.2662138342857361, "C_acc": 0.5360718369483948, "G_acc": 0.5239100030739792, "D_acc": 0.6606495338492095, "H_acc": 0.18014472723007202, "Q_acc": 0.4915472175576725, "E_rej": 0.31100088357925415, "C_rej": 0.35777193307876587, "G_rej": 0.5272601019823924, "D_rej": 0.8449786305427551, "H_rej": 0.15502136945724487, "Q_rej": 0.5806914880173282, "Delta_Q": -0.08914427045965567, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial online optimization: given unknown convex losses chosen by an adversary, bound regret using limited-memory algorithms.", "ancestors": ["[DEF] Regret is R_T = sum_{t=1}^T f_t(x_t) - min_{x∈X} sum_{t=1}^T f_t(x).", "[VAR] f_t is a convex function selected by an adversary at round t.", "[VAR] x_t is the learner’s action in convex set X at round t.", "[VAR] The learner chooses x_t using only the observed f_1,...,f_{t-1}.", "[CONSTRAINT] The learner stores at most M real numbers from past rounds.", "[LIMIT] Gradient norm ||∇f_t(x)|| ≤ G for all x∈X and all t.", "[LIMIT] Set X has Euclidean diameter D = sup_{x,y∈X}||x-y||.", "[DEF] Projected gradient descent updates x_{t+1} = Π_X(x_t - η_t g_t) with g_t ∈ ∂f_t(x_t).", "[VAR] Step size η_t is measurable with respect to the σ-field of prior gradients.", "[CONSTRAINT] Memory footprint of projected gradient descent is O(d) where d is the dimension of X."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: Any algorithm whose memory footprint is at most M real numbers must satisfy M ≥ d to guarantee sub-linear regret on some sequence of convex functions.\nASSUMPTION: There exists at least one sequence of convex functions for which projected gradient descent achieves sub-linear regret.\nVERIFICATION: Units: M (dimensionless count), d (dimensionless count); regime: adversarial online convex optimization.", "rejected": "Any algorithm whose memory footprint is at most M real numbers must satisfy M ≥ G D to guarantee sub-linear regret on some sequence of convex functions.", "E_acc": 0.49684736132621765, "C_acc": 0.23501385748386383, "G_acc": 0.5693288709735498, "D_acc": 0.7380834249779582, "H_acc": 0.24518148601055145, "Q_acc": 0.6390157474903391, "E_rej": 0.3423275053501129, "C_rej": 0.3052454888820648, "G_rej": 0.5625580720079597, "D_rej": 0.8153036832809448, "H_rej": 0.27704447507858276, "Q_rej": 0.5895170573785435, "Delta_Q": 0.04949869011179553, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] A certificate is a finite bit string.", "[DEF] A verifier is a Turing machine that halts on every input.", "[DEF] An expression is a rooted directed acyclic graph with leaves in the set {x₁,…,xₙ}.", "[VAR] Let ⊢ denote the derivability relation of the equational theory T.", "[VAR] Let σ range over substitutions of variables by expressions.", "[LAW] ⊢ is closed under substitution: if ⊢ e = e′ then ⊢ σ(e) = σ(e′).", "[CONSTRAINT] The certificate size |c| is bounded above by O(|e|).", "[LIMIT] The verifier runtime is polynomial in |c|+|e|.", "[LIMIT] The simplifier runtime is polynomial in |e|."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every expression e, the certificate c that verifies e satisfies |c| ≤ k·|e| for some constant k.\nASSUMPTION: None\nVERIFICATION: Units: bits; regime: O-notation bound given in CONSTRAINT.", "rejected": "For every expression e, the certificate c that verifies e satisfies |e| ≤ k·|c| for some constant k.", "E_acc": 0.3124805688858032, "C_acc": 0.4037463068962097, "G_acc": 0.579522721003741, "D_acc": 0.6578828152269125, "H_acc": 0.1955316662788391, "Q_acc": 0.5409228499047458, "E_rej": 0.3078325390815735, "C_rej": 0.37530022859573364, "G_rej": 0.5726303714327514, "D_rej": 0.7862747311592102, "H_rej": 0.2137252688407898, "Q_rej": 0.5676982096396387, "Delta_Q": -0.026775359734892867, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Hierarchical goal decomposition with conflicting subgoals: synthesize a scheduler that resolves conflicts while guaranteeing progress on at least one top-level objective.", "ancestors": ["[DEF] A task set T is a finite collection of tasks.", "[VAR] Each t ∈ T has a subtask set S_t.", "[DEF] A schedule σ is a total order on ∪_{t∈T} S_t.", "[CONSTRAINT] For every t ∈ T, σ must contain at least one s ∈ S_t.", "[CONSTRAINT] For every t ∈ T, no pair s, s′ ∈ S_t appear consecutively in σ.", "[LAW] Progress on t is achieved iff some s ∈ S_t appears in σ.", "[LIMIT] |σ| ≤ |∪_{t∈T} S_t|.", "[LIMIT] At least one t ∈ T achieves progress."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every task t ∈ T, the number of subtasks from S_t that appear in σ is at least 1 and at most ⌈|S_t|/2⌉.\nASSUMPTION: None\nVERIFICATION: Counting argument: non-consecutive placement of |S_t| items yields maximum ⌈|S_t|/2⌉ occurrences in any linear order.", "rejected": "For every task t ∈ T, the number of subtasks from S_t that appear in σ is at least 1 and at most ⌊|S_t|/2⌋.", "E_acc": 0.5510126352310181, "C_acc": 0.2353958636522293, "G_acc": 0.5671082413755357, "D_acc": 0.6992081571370363, "H_acc": 0.13594195246696472, "Q_acc": 0.6578937022946775, "E_rej": 0.6071454882621765, "C_rej": 0.20199665427207947, "G_rej": 0.5661389262531884, "D_rej": 0.854609876871109, "H_rej": 0.145390123128891, "Q_rej": 0.7113550639362074, "Delta_Q": -0.053461361641529925, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["[DEF] Fidelity f is the probability that a replicated base matches the template base.", "[VAR] Let E be the energy expended per base to achieve fidelity f.", "[CONSTRAINT] E(f) is a strictly increasing function of f.", "[VAR] Let μ be the genomic mutation rate per replication.", "[DEF] μ = (1 − f)L where L is the genome length in bases.", "[VAR] Let A be the adaptability conferred by mutations.", "[CONSTRAINT] A(μ) is a strictly increasing function of μ.", "[LIMIT] There exists no f for which both E(f) and μ(f) are simultaneously minimized."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: For any genome length L, the adaptability A is a strictly decreasing function of fidelity f.  \nASSUMPTION: None  \nVERIFICATION: Units consistent (dimensionless); testable by measuring A vs f at fixed L.", "rejected": "For any genome length L, the adaptability A is a strictly increasing function of fidelity f.", "E_acc": 0.030352439731359482, "C_acc": 0.9336045980453491, "G_acc": 0.5422046050828483, "D_acc": 0.6322914659976959, "H_acc": 0.22130724787712097, "Q_acc": 0.3351533017387348, "E_rej": 0.7824508547782898, "C_rej": 0.03500431403517723, "G_rej": 0.5604666169466717, "D_rej": 0.840724527835846, "H_rej": 0.15927547216415405, "Q_rej": 0.7920450753665396, "Delta_Q": -0.45689177362780475, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial online optimization: given unknown convex losses chosen by an adversary, bound regret using limited-memory algorithms.", "ancestors": ["[DEF] Regret is R_T = Σ_{t=1}^{T} f_t(x_t) − min_{x∈B} Σ_{t=1}^{T} f_t(x).", "[VAR] B is a closed convex subset of ℝ^n.", "[VAR] f_t:B→ℝ is convex for every t∈{1,…,T}.", "[VAR] x_t∈B is chosen before f_t is revealed.", "[LIMIT] The algorithm stores at most m past vectors at any step.", "[CONSTRAINT] m is a fixed positive integer independent of T.", "[LAW] For online gradient descent with step η, R_T ≤ (D²/η + ηLT)/2 where D=diam(B) and L is the Lipschitz constant of every f_t."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If the algorithm discards the oldest stored gradient each time it reaches the memory limit m, then the effective gradient used at step t is a convex combination of at most m past gradients.\nASSUMPTION: The algorithm discards the oldest stored gradient each time it reaches the memory limit m.\nVERIFICATION: Units: dimensionless count of gradients; regime: t > m; testable by checking convex hull of stored gradients.", "rejected": "If the algorithm discards the oldest stored gradient each time it reaches the memory limit m, then the effective gradient used at step t is independent of any past gradients beyond the most recent m.", "E_acc": 0.5299180150032043, "C_acc": 0.19906727969646454, "G_acc": 0.5275420759571716, "D_acc": 0.7144945724867284, "H_acc": 0.21291622519493103, "Q_acc": 0.6462776557309553, "E_rej": 0.256265789270401, "C_rej": 0.44525009393692017, "G_rej": 0.5175558046103106, "D_rej": 0.7725271582603455, "H_rej": 0.22747284173965454, "Q_rej": 0.523099026393902, "Delta_Q": 0.12317862933705326, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Phase coexistence with finite-size effects: derive corrections to bulk phase diagrams for nanostructured assemblies and predict hysteresis.", "ancestors": ["[DEF] A phase is a region with uniform intensive properties.", "[DEF] A nanostructure is a solid with at least one dimension ≤ 100 nm.", "[DEF] Coexistence is the simultaneous contact of two phases in equilibrium.", "[VAR] Let V denote the volume of a nanostructure.", "[VAR] Let γ denote the interfacial free energy per unit area.", "[VAR] Let ΔP denote the pressure difference across a curved interface.", "[LAW] ΔP = 2 γ / R where R is the radius of curvature.", "[CONSTRAINT] At coexistence the temperature of both phases is equal.", "[LIMIT] As V → ∞ the γ contribution to the free energy vanishes."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A nanostructure whose smallest dimension is ≤ 100 nm and whose interface has radius of curvature R exhibits a pressure difference ΔP = 2γ/R between coexisting phases.\nASSUMPTION: The interface of the nanostructure is spherical so that a single radius of curvature R suffices.\nVERIFICATION: Units: [γ]=J m⁻², [R]=m ⇒ [ΔP]=J m⁻³=N m⁻²=Pa, consistent with pressure.", "rejected": "A pressure difference ΔP = 2γ/R between coexisting phases implies that the nanostructure’s smallest dimension is ≤ 100 nm and its interface has radius of curvature R.", "E_acc": 0.53902268409729, "C_acc": 0.21656525135040283, "G_acc": 0.5347082499647513, "D_acc": 0.6960238353349268, "H_acc": 0.1670743227005005, "Q_acc": 0.6478327397489921, "E_rej": 0.3875042498111725, "C_rej": 0.24934306740760803, "G_rej": 0.5192977525875904, "D_rej": 0.8792749345302582, "H_rej": 0.12072506546974182, "Q_rej": 0.6340246923384257, "Delta_Q": 0.013808047410566404, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Paradoxes from self-reference: formalize a system where an agent's utility depends on predictions of its own future actions and derive consistency constraints.", "ancestors": ["[DEF] A is an agent.", "[VAR] t ∈ ℕ indexes discrete time.", "[VAR] a_t ∈ {0,1} is A’s action at t.", "[VAR] p_t ∈ [0,1] is an external prediction of a_t.", "[DEF] U_t = 1 − |a_t − p_t| is A’s utility at t.", "[DEF] p_t = P(a_t = 1 | H_t) where H_t is the history before t.", "[CONSTRAINT] A chooses a_t to maximize U_t.", "[CONSTRAINT] P(a_t = 1 | H_t) = a_t in equilibrium.", "[LIMIT] No external randomness is available to A.", "[CONSTRAINT] a_t = 1 − p_t is impossible for all t."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every t, p_t equals either 0 or 1.\nASSUMPTION: None\nVERIFICATION: Binary values; regime a_t ∈ {0,1} and equilibrium P(a_t=1|H_t)=a_t force p_t ∈ {0,1}.", "rejected": "For every t, p_t equals either 0 or 1 meter.", "E_acc": 0.044796936213970184, "C_acc": 0.8153535723686218, "G_acc": 0.5887954847275978, "D_acc": 0.6715030064806342, "H_acc": 0.17997679114341736, "Q_acc": 0.38443038551777137, "E_rej": 0.01747557707130909, "C_rej": 0.8775791525840759, "G_rej": 0.6270912755280733, "D_rej": 0.6698907017707825, "H_rej": 0.33010929822921753, "Q_rej": 0.3561123082414269, "Delta_Q": 0.028318077276344444, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["[DEF] Let X be a random variable with probability density p(x).", "[DEF] Let A be the rare-event set {x : p(x) < ε}.", "[VAR] Let q(x) be any proposal density satisfying q(x) > 0 ⇒ p(x) > 0.", "[VAR] Let w(x) = p(x)/q(x) be the importance weight.", "[DEF] Let L = ∫_A p(x)dx be the tail probability.", "[VAR] Let {x_i}_{i=1}^n be i.i.d. samples drawn from q.", "[DEF] Let Ĺ = (1/n)∑_{i=1}^n w(x_i)𝟙_A(x_i) be the importance-sampling estimator.", "[LAW] E_q[Ĺ] = L.", "[LIMIT] Ĺ → L almost surely as n → ∞."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: The variance of the importance-sampling estimator Ĺ is finite if and only if E_q[w(x)^2 𝟙_A(x)] < ∞.  \nASSUMPTION: None  \nVERIFICATION: Units: dimensionless; regime: second-moment condition for Monte Carlo error; testable via ∫_A p(x)^2/q(x) dx < ∞.", "rejected": "The variance of the importance-sampling estimator Ĺ is finite if and only if E_q[w(x)^2 𝟙_A(x)] > ∞.", "E_acc": 0.19619737565517426, "C_acc": 0.6558600664138794, "G_acc": 0.5365359007846564, "D_acc": 0.6629708064720035, "H_acc": 0.14643126726150513, "Q_acc": 0.4529454141389579, "E_rej": 0.3282037377357483, "C_rej": 0.49657267332077026, "G_rej": 0.5365385036784573, "D_rej": 0.8131969273090363, "H_rej": 0.18680307269096375, "Q_rej": 0.5504133655849728, "Delta_Q": -0.09746795144601489, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] A mechanism is a function g:Θ→A mapping reported types to allocations.", "[DEF] An agent's type θ∈Θ is a parameter in Θ.", "[VAR] k∈ℕ denotes the agent's reasoning depth.", "[DEF] A k-step best response is an action maximizing utility given beliefs formed by k−1 iterations of reasoning.", "[CONSTRAINT] Agents select only k-step best responses.", "[DEF] Strategyproofness requires truth-telling to be a best response for every θ.", "[LIMIT] Strategyproofness is required only among k-step best responses.", "[DEF] A rule is k-strategyproof if truth-telling is a k-step best response for every θ.", "[CONSTRAINT] Allocation rules must be k-strategyproof.", "[LIMIT] k is common knowledge among agents and the designer."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If k=0, no k-step best response exists, so no rule can satisfy k-strategyproofness.\nASSUMPTION: None\nVERIFICATION: k∈ℕ and k-step best response requires k≥1 by definition.", "rejected": "If no rule can satisfy k-strategyproofness, then k=0.", "E_acc": 0.17859309911727905, "C_acc": 0.1226673275232315, "G_acc": 0.5600497706327587, "D_acc": 0.6902140099555254, "H_acc": 0.16721341013908386, "Q_acc": 0.5623758793342859, "E_rej": 0.06987441331148148, "C_rej": 0.09304017573595047, "G_rej": 0.5746448098216206, "D_rej": 0.7683310210704803, "H_rej": 0.23166897892951965, "Q_rej": 0.5477825571317226, "Delta_Q": 0.014593322202563264, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["[DEF] A catalyst is a substance that increases the rate of a chemical reaction without being consumed.", "[VAR] Let S be the set of all possible surface active-site configurations.", "[VAR] Let P be the set of all elementary reaction pathways accessible on S.", "[VAR] Let R be the rate of a pathway p ∈ P.", "[VAR] Let I be the set of all intermediates formed along any p ∈ P.", "[DEF] Flux F_p is the product R_p·[I]_0, where [I]_0 is the concentration of the initial intermediate.", "[CONSTRAINT] ∑_{p∈P} F_p = F_total, where F_total is the total measurable turnover frequency.", "[LIMIT] For any p, R_p ≤ k_max, where k_max is the diffusion-limited rate constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If F_total > k_max·[I]_0, then at least two pathways must carry non-zero flux.\nASSUMPTION: None\nVERIFICATION: Units: s⁻¹ ≥ s⁻¹·M ⇒ dimensionally consistent; test by raising [I]_0 until inequality flips.", "rejected": "If F_total > k_max·[I]_0, then at least one pathway must carry flux exceeding k_max.", "E_acc": 0.22224101424217224, "C_acc": 0.5313325524330139, "G_acc": 0.5685157143743709, "D_acc": 0.5839559643063694, "H_acc": 0.3628327511250973, "Q_acc": 0.45461685440968724, "E_rej": 0.30472561717033386, "C_rej": 0.44591978192329407, "G_rej": 0.5799301748629659, "D_rej": 0.7622778713703156, "H_rej": 0.29715266078710556, "Q_rej": 0.5409600719343871, "Delta_Q": -0.08634321752469987, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["[DEF] Let H be a finite set of mutually exclusive hypotheses.", "[DEF] Let E be a finite set of candidate experiments.", "[VAR] Let c: E → ℝ>0 assign a positive cost to each experiment.", "[VAR] Let I: E × H → ℝ≥0 quantify the information gain from an experiment under a hypothesis.", "[CONSTRAINT] The total budget B ∈ ℝ>0 limits the sum of selected experiment costs.", "[LIMIT] No experiment can be selected more than once.", "[LAW] The expected information gain per unit cost for a subset S ⊆ E is ∑_{e∈S} ∑_{h∈H} P(h) I(e,h) / ∑_{e∈S} c(e)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any subset S ⊆ E, the expected information gain per unit cost is strictly less than max_{e∈E} ∑_{h∈H} P(h) I(e,h)/c(e).\nASSUMPTION: None\nVERIFICATION: Ratio units (information/cost) remain consistent across all subsets; inequality holds because the weighted average of ratios cannot exceed the maximum individual ratio.", "rejected": "For any subset S ⊆ E, the expected information gain per unit cost is strictly greater than max_{e∈E} ∑_{h∈H} P(h) I(e,h)/c(e).", "E_acc": 0.27399852871894836, "C_acc": 0.5038077235221863, "G_acc": 0.5177283270168118, "D_acc": 0.708160575479269, "H_acc": 0.098888099193573, "Q_acc": 0.5167269844911061, "E_rej": 0.3555605113506317, "C_rej": 0.43921157717704773, "G_rej": 0.5193907521024812, "D_rej": 0.8886292576789856, "H_rej": 0.1113707423210144, "Q_rej": 0.5892927656939719, "Delta_Q": -0.07256578120286583, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["[DEF] A state is an element s ∈ S.", "[DEF] An update is a function u: S → S.", "[DEF] An invariant is a function I: S → ℝ such that I(u(s)) = I(s).", "[VAR] Let (s₀, s₁, …, s_T) be the sequence given by s_{t+1}=u(s_t).", "[CONSTRAINT] For every t ∈ {0,…,T−1}, I(s_{t+1}) = I(s₀).", "[DEF] A target set T ⊆ S satisfies T = {s ∈ S | P(s)=0} for a predicate P.", "[CONSTRAINT] If s ∈ T, then I(s) ≠ I(s₀).", "[LAW] For every prior π on model space Θ, the posterior is π_n(θ) ∝ π(θ) exp(−n r_n(θ)).", "[LIMIT] If θ₀ minimizes Kullback–Leibler divergence KL(P₀‖P_θ), then π_n({θ: ‖θ−θ₀‖>ε}) → 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every t ∈ {0,…,T}, s_t ∉ T.\nASSUMPTION: None\nVERIFICATION: Follows directly from the CONSTRAINT that I(s_{t+1}) = I(s₀) and the CONSTRAINT that s ∈ T ⇒ I(s) ≠ I(s₀), hence s_t ∈ T would contradict the invariant equality.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.29402562975883484, "C_acc": 0.43372175097465515, "G_acc": 0.5651741770561785, "D_acc": 0.6511874031275511, "H_acc": 0.24980956315994263, "Q_acc": 0.5197546984534711, "E_rej": 0.31672269105911255, "C_rej": 0.4297097325325012, "G_rej": 0.589533134829253, "D_rej": 0.6014187559485435, "H_rej": 0.39858124405145645, "Q_rej": 0.5074071145616472, "Delta_Q": 0.012347583891823888, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Concurrent system liveness under unreliable schedulers: prove or disprove that a shared-memory protocol guarantees progress with probabilistic fairness.", "ancestors": ["[DEF] A concurrent system is a finite set of processes P = {p₁,…,pₙ}.", "[DEF] A shared-memory protocol is a tuple (M, Σ, Δ) where M is a memory state, Σ is a set of operations, and Δ ⊆ M × Σ × M is a transition relation.", "[VAR] Let t ∈ ℕ index discrete time slots.", "[VAR] Let cᵢ(t) ∈ {0,1} indicate that process pᵢ is scheduled at slot t.", "[CONSTRAINT] Σᵢ cᵢ(t) = 1 for every t.", "[DEF] A scheduler is a function S: ℕ → P such that S(t) = pᵢ iff cᵢ(t)=1.", "[LIMIT] For every p ∈ P, lim inf_{T→∞} (1/T) Σ_{t=1}^{T} 1[S(t)=p] ≥ ρ > 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Every process p ∈ P is scheduled infinitely often.\nASSUMPTION: None\nVERIFICATION: The limit condition lim inf ≥ ρ > 0 implies each process appears with positive frequency as T → ∞.", "rejected": "Every process p ∈ P is scheduled infinitely often only if the scheduler S satisfies the limit condition lim inf ≥ ρ > 0.", "E_acc": 0.30341655015945435, "C_acc": 0.520254373550415, "G_acc": 0.546307884638996, "D_acc": 0.664433004334569, "H_acc": 0.19884997606277466, "Q_acc": 0.509237270526189, "E_rej": 0.28252023458480835, "C_rej": 0.5269594192504883, "G_rej": 0.5341351155989936, "D_rej": 0.8129205703735352, "H_rej": 0.18707942962646484, "Q_rej": 0.5300673807572042, "Delta_Q": -0.02083011023101522, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["[DEF] A model is a function f: X → Y.", "[VAR] Let P be a probability distribution on X.", "[VAR] Let L: Y × Y → {0,1} indicate misclassification.", "[DEF] The failure probability under P is E_{x∼P}[L(f(x),y)].", "[VAR] Let Q be a second distribution on X.", "[CONSTRAINT] Q must satisfy D(Q‖P) ≤ ε for some ε ≥ 0.", "[DEF] Adversarial discovery is the maximization of E_{x∼Q}[L(f(x),y)] over Q.", "[LIMIT] The supremum of E_{x∼Q}[L(f(x),y)] subject to D(Q‖P) ≤ ε is non-decreasing in ε.", "[LIMIT] When ε = 0, the supremum equals E_{x∼P}[L(f(x),y)]."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every ε > 0, the adversarial discovery value strictly exceeds the failure probability under P.\nASSUMPTION: None\nVERIFICATION: Holds for any ε > 0 by the non-decreasing limit and the ε = 0 equality.", "rejected": "For every ε > 0, the adversarial discovery value is less than the failure probability under P.", "E_acc": 0.3687782883644104, "C_acc": 0.4199632406234741, "G_acc": 0.556416780455038, "D_acc": 0.6430126633495092, "H_acc": 0.14784622192382812, "Q_acc": 0.5517421049531549, "E_rej": 0.2972313463687897, "C_rej": 0.458271861076355, "G_rej": 0.5575663310009986, "D_rej": 0.8667449355125427, "H_rej": 0.13325506448745728, "Q_rej": 0.5690517785493285, "Delta_Q": -0.017309673596173636, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["[DEF] A coalition is a subset S ⊆ N of the grand coalition N.", "[VAR] v(S;P) denotes the worth of coalition S under partition P.", "[VAR] x ∈ ℝ^{|N|} is an imputation vector.", "[DEF] An externality exists if ∃ P ≠ P′ such that v(S;P) ≠ v(S;P′).", "[CONSTRAINT] A coalition S is stable if ∀ T ⊆ S, v(T;{T,S\\T}∪{i}_{i∈N\\S}) ≤ ∑_{i∈T} x_i.", "[CONSTRAINT] The core is the set {x | ∑_{i∈N} x_i = v(N;{N}) and ∀ S ⊆ N, ∑_{i∈S} x_i ≥ v(S;{S,N\\S})}.", "[LIMIT] The core may be empty.", "[DEF] A marginal contribution of player i to S is Δ_i(S) = v(S∪{i};P′) − v(S;P).", "[LAW] Efficiency requires ∑_{i∈N} x_i = v(N;{N})."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the core is non-empty, then every imputation x in the core satisfies ∑_{i∈S} x_i ≥ v(S;{S,N\\S}) for every coalition S ⊆ N.\nASSUMPTION: None\nVERIFICATION: Direct restatement of the core definition; units: payoff units ≥ worth units.", "rejected": "If every imputation x in the core satisfies ∑_{i∈S} x_i ≥ v(S;{S,N\\S}) for every coalition S ⊆ N, then the core is non-empty.", "E_acc": 0.36442387104034424, "C_acc": 0.39201393723487854, "G_acc": 0.531126590911299, "D_acc": 0.6698567941784859, "H_acc": 0.16696318984031677, "Q_acc": 0.5544247318990528, "E_rej": 0.3215792775154114, "C_rej": 0.4480237364768982, "G_rej": 0.5234092767350376, "D_rej": 0.825219601392746, "H_rej": 0.17478039860725403, "Q_rej": 0.559116771724075, "Delta_Q": -0.004692039825022198, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging if a satellite will remain in orbit or decay by reasoning from drag, altitude, mass, and atmospheric density", "ancestors": ["[DEF] Let h be altitude above mean sea level.", "[DEF] Let ρ be atmospheric density at h.", "[DEF] Let m be satellite mass.", "[DEF] Let A be satellite cross-sectional area normal to velocity.", "[DEF] Let v be satellite speed.", "[LAW] Drag force magnitude is F = ½ ρ v² A C_d with C_d a dimensionless coefficient.", "[CONSTRAINT] Orbit decays if F lowers mechanical energy below the bound for a closed trajectory."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If ρ decreases monotonically with h, then for fixed m, A, C_d, the drag force magnitude F decreases as altitude increases.\nASSUMPTION: None\nVERIFICATION: Units: ρ (kg/m³), v (m/s), A (m²) yield F (kg·m/s² = N); monotonic decrease of ρ(h) is testable via atmospheric models.", "rejected": "If ρ decreases monotonically with h, then for fixed m, A, C_d, the drag force magnitude F increases as altitude increases.", "E_acc": 0.06803389638662338, "C_acc": 0.7994762063026428, "G_acc": 0.5511828465387225, "D_acc": 0.6442608230281621, "H_acc": 0.21813684701919556, "Q_acc": 0.37778997686691584, "E_rej": 0.1780625283718109, "C_rej": 0.08088374882936478, "G_rej": 0.5618082556341376, "D_rej": 0.7888500094413757, "H_rej": 0.21114999055862427, "Q_rej": 0.5862586627049107, "Delta_Q": -0.20846868583799483, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["[DEF] A catalytic cycle is a closed sequence of elementary steps converting reactants to products via an active site.", "[VAR] Let I be the set of all intermediates formed on the active site.", "[VAR] Let R be the set of all elementary reactions among i ∈ I.", "[VAR] Let k_r be the rate constant of reaction r ∈ R.", "[LAW] The steady-state flux through intermediate i is J_i = Σ_r (k_r · θ_i) where θ_i is the surface coverage of i.", "[CONSTRAINT] Σ_i θ_i = 1.", "[LIMIT] Only one elementary reaction can be rate-determining per pathway.", "[DEF] Selectivity to desired product P is S_P = J_P / Σ_q J_q where q indexes all product-forming pathways."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the rate-determining reaction is the sole producer of intermediate i, then θ_i equals the ratio of its formation rate to the sum of all consumption rates of i.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless coverage; test via steady-state balance on i.", "rejected": "If θ_i equals the ratio of its formation rate to the sum of all consumption rates of i, then the rate-determining reaction is the sole producer of intermediate i.", "E_acc": 0.3333868980407715, "C_acc": 0.38942423462867737, "G_acc": 0.5387405301444232, "D_acc": 0.609444965608418, "H_acc": 0.25008344650268555, "Q_acc": 0.5267599769867957, "E_rej": 0.25457078218460083, "C_rej": 0.5225318074226379, "G_rej": 0.5430524562252685, "D_rej": 0.783684492111206, "H_rej": 0.21631550788879395, "Q_rej": 0.5155807120492683, "Delta_Q": 0.011179264937527411, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Conditional independence triangulation: given a graph with hidden nodes, deduce which observed independences force the existence of a latent common cause.", "ancestors": ["[DEF] A graph G is a pair (V,E) with V a finite set and E⊆V×V.", "[VAR] Let O⊆V denote the set of observed nodes.", "[VAR] Let H=V∖O denote the set of hidden nodes.", "[DEF] Nodes a,b are d-separated by Z⊆V iff every path between a and b is blocked by Z.", "[DEF] A path is blocked by Z iff it contains a chain or fork with its middle node in Z or a collider whose descendants are not in Z.", "[DEF] The distribution P factorizes as P(v)=∏ᵢP(vᵢ|paᵢ) with paᵢ the parents of vᵢ in G.", "[DEF] A⊥B|Z denotes that P(A,B|Z)=P(A|Z)P(B|Z).", "[LAW] If G d-separates A and B given Z, then A⊥B|Z in every distribution factorizing over G.", "[CONSTRAINT] No edge exists between any two nodes in H.", "[LIMIT] The observed independence set is restricted to statements of the form A⊥B|Z with A,B,Z⊆O."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any two distinct hidden nodes h₁,h₂∈H, h₁⊥h₂|O holds in every distribution factorizing over G.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "HYPOTHESIS: For any two distinct hidden nodes h₁,h₂∈H, h₁⊥h₂|V holds in every distribution factorizing over G.", "E_acc": 0.28400734066963196, "C_acc": 0.5183504819869995, "G_acc": 0.5494079507188872, "D_acc": 0.6349414554424584, "H_acc": 0.19008490443229675, "Q_acc": 0.49939349659252913, "E_rej": 0.29323798418045044, "C_rej": 0.532539427280426, "G_rej": 0.5461101927794516, "D_rej": 0.8183518350124359, "H_rej": 0.1816481649875641, "Q_rej": 0.536191098857671, "Delta_Q": -0.03679760226514189, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["[DEF] A hypothesis set H = {h₁,…,hₙ} is a finite collection of mutually exclusive models.", "[DEF] An experiment e belongs to a discrete set E of selectable actions.", "[DEF] The cost c(e) is a positive real scalar assigned to every e∈E.", "[VAR] The prior probability P(h) satisfies ∑_{h∈H} P(h)=1.", "[VAR] The likelihood P(d|h,e) gives the probability of observing data d after running e under h.", "[DEF] The posterior P(h|d,e) is proportional to P(h)P(d|h,e).", "[DEF] The information gain I(e)=H_prior−E_d[H_posterior(e,d)] with H denoting Shannon entropy.", "[CONSTRAINT] The budget B is a positive real upper bound on cumulative c(e).", "[LIMIT] Only one experiment can be executed at a time and each execution consumes c(e)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any experiment e with c(e) > B, the probability of selecting e under the given budget constraint is 0.\nASSUMPTION: None\nVERIFICATION: Units: cost in same currency as B; test: c(e) > B ⇒ e excluded from feasible set.", "rejected": "For any experiment e with c(e) > B, the information gain I(e) of selecting e under the given budget constraint is 0.", "E_acc": 0.20381401479244232, "C_acc": 0.49764057993888855, "G_acc": 0.5378858945914544, "D_acc": 0.649886904284358, "H_acc": 0.22998908162117004, "Q_acc": 0.4761717400630005, "E_rej": 0.20972219109535217, "C_rej": 0.4032863974571228, "G_rej": 0.5565386428497732, "D_rej": 0.8201087415218353, "H_rej": 0.17989125847816467, "Q_rej": 0.5395997288636863, "Delta_Q": -0.06342798880068584, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] A mechanism is a function mapping reported types to an outcome.", "[VAR] Let N denote the finite set of agents.", "[VAR] Let Θ denote the finite set of possible types for each agent.", "[VAR] Let k ∈ ℕ denote the reasoning depth bound.", "[DEF] A strategyproof mechanism satisfies truth-telling as a dominant strategy for every agent.", "[DEF] k-step reasoning is the iterative elimination of never-best-responses repeated k times.", "[CONSTRAINT] Each agent best-responds only to beliefs consistent with the surviving strategies after k-1 elimination rounds.", "[LIMIT] No agent performs more than k best-response iterations.", "[DEF] A mechanism is k-strategyproof if truth-telling survives k-step reasoning for every agent."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If k ≥ |Θ|^|N|, then k-strategyproofness coincides with strategyproofness.  \nASSUMPTION: The elimination process removes at least one strategy per agent per round whenever truth-telling is not yet dominant.  \nVERIFICATION: Units: rounds; regime |Θ|^|N| upper-bounds strategy profiles; test via counting surviving profiles.", "rejected": "If k ≥ |Θ|^|N|, then strategyproofness coincides with k-strategyproofness.", "E_acc": 0.446307897567749, "C_acc": 0.23507222533226013, "G_acc": 0.5269625359214842, "D_acc": 0.7046745680272579, "H_acc": 0.18136900663375854, "Q_acc": 0.6150684443302453, "E_rej": 0.45300182700157166, "C_rej": 0.2662166357040405, "G_rej": 0.5192165359912906, "D_rej": 0.7361745536327362, "H_rej": 0.2638254463672638, "Q_rej": 0.6073528942477423, "Delta_Q": 0.00771555008250302, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a rumor will spread or die out in a community based on trust networks, repetition, and perceived incentives", "ancestors": ["[DEF] A community is a finite set of agents.", "[VAR] Let T be the directed graph of pairwise trust links.", "[VAR] Let r be the number of times an agent has received a rumor.", "[VAR] Let B be the perceived benefit of forwarding the rumor.", "[VAR] Let c be the perceived cost of forwarding the rumor.", "[CONSTRAINT] An agent forwards the rumor only if B > c.", "[LAW] The rumor spreads along a trust link only if the source agent forwards it.", "[LIMIT] The maximum value of r across all agents is finite.", "[DEF] The rumor dies out when no agent forwards it in the next time step."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If every agent has r ≥ 1, then the rumor dies out at the next time step only if for every agent B ≤ c.  \nASSUMPTION: None  \nVERIFICATION: Check that for each agent the inequality B ≤ c holds under the stated condition.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.1458723247051239, "C_acc": 0.6903198957443237, "G_acc": 0.5481172840518411, "D_acc": 0.6952805202454329, "H_acc": 0.20540055632591248, "Q_acc": 0.433837223489536, "E_rej": 0.16895152628421783, "C_rej": 0.6202743053436279, "G_rej": 0.5783361287321895, "D_rej": 0.5784438475966454, "H_rej": 0.42155615240335464, "Q_rej": 0.4158309768419713, "Delta_Q": 0.018006246647564728, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["[DEF] A state s is an element of the state space S.", "[VAR] Let U denote a sequence of update functions u_i: S → S.", "[DEF] An invariant I is a function I: S → ℝ such that I(u_i(s)) = I(s) for every u_i in U.", "[CONSTRAINT] A target state t ∈ S satisfies I(t) ≠ I(s₀) where s₀ is the initial state.", "[LAW] For every prior π on model space M and likelihood p(x|m), the posterior is π(m|x) ∝ π(m)p(x|m).", "[VAR] Let M* ⊂ M be the set of models with positive prior mass.", "[LIMIT] As data size n → ∞, the posterior mass on M* concentrates on argmax_{m∈M*} 𝔼[log p(x|m)]."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: No update sequence in U can drive the system from s₀ to any state in the target set {t ∈ S : I(t) ≠ I(s₀)}.\nASSUMPTION: None\nVERIFICATION: Direct from invariant definition: I(u_i(s)) = I(s) ⇒ I(s_n) = I(s₀) for every finite sequence of updates.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.20451050996780396, "C_acc": 0.5646119713783264, "G_acc": 0.5504333362914622, "D_acc": 0.6627195440232754, "H_acc": 0.26279233396053314, "Q_acc": 0.46478210138157006, "E_rej": 0.3038794994354248, "C_rej": 0.393705815076828, "G_rej": 0.5950963110662997, "D_rej": 0.5985544547438622, "H_rej": 0.40144554525613785, "Q_rej": 0.5110082854516804, "Delta_Q": -0.046226184070110365, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["[DEF] Fidelity F is the probability that a replicated sequence matches the template.", "[VAR] Let E(F) be the energy expended per replication event to achieve fidelity F.", "[CONSTRAINT] E(F) is strictly increasing with F for F ∈ [0,1].", "[VAR] Let μ(F) be the mutation rate per base, decreasing with F.", "[DEF] Adaptability A is the expected fitness gain from beneficial mutations.", "[VAR] A(μ) is strictly increasing with μ for μ ∈ [0,μ_max].", "[LIMIT] There exists F_min > 0 such that E(F_min) equals the maximum available energy per replication.", "[CONSTRAINT] Optimal fidelity F* maximizes A(μ(F)) subject to E(F) ≤ E_max."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The optimal fidelity F* satisfies F* = F_min.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless fidelity; regime F ∈ [F_min,1]; testable by observing F* = F_min under energy constraint E_max = E(F_min).", "rejected": "The optimal fidelity F* satisfies F_min = F*.", "E_acc": 0.40337249636650085, "C_acc": 0.35764676332473755, "G_acc": 0.5703959204256535, "D_acc": 0.6613707700744271, "H_acc": 0.18387970328330994, "Q_acc": 0.577447764016688, "E_rej": 0.37997931241989136, "C_rej": 0.400167852640152, "G_rej": 0.5638731252402067, "D_rej": 0.7652516067028046, "H_rej": 0.23474839329719543, "Q_rej": 0.5763103302568198, "Delta_Q": 0.0011374337598681894, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["[DEF] A model is a function f: X → Y.", "[DEF] An input x ∈ X has a ground-truth label y ∈ Y.", "[DEF] The model prediction is ŷ = f(x).", "[DEF] A failure occurs when ŷ ≠ y.", "[DEF] A distribution D is a probability measure on X.", "[VAR] Let P_f(D) = Pr_{x∼D}(f(x) ≠ y) be the failure probability under D.", "[CONSTRAINT] A plausibility set P contains only distributions judged permissible by an external validator.", "[CONSTRAINT] The adversary must select D ∈ P.", "[VAR] Let D* be a distribution satisfying D* ∈ argmax_{D∈P} P_f(D).", "[LIMIT] If P is the singleton {D₀}, then D* = D₀ and P_f(D*) is fixed."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If P is the singleton {D₀}, then D* = D₀ and P_f(D*) equals the fixed value P_f(D₀).\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If P is the singleton {D₀}, then D* = D₀ and P_f(D*) equals the fixed value P_f(D).", "E_acc": 0.3604392111301422, "C_acc": 0.3990142047405243, "G_acc": 0.5621633327100426, "D_acc": 0.6151155037805438, "H_acc": 0.297600656747818, "Q_acc": 0.5340246240142733, "E_rej": 0.36584341526031494, "C_rej": 0.3873578608036041, "G_rej": 0.5611637831898406, "D_rej": 0.6638144105672836, "H_rej": 0.33618558943271637, "Q_rej": 0.543658532225527, "Delta_Q": -0.00963390821125365, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["[DEF] A catalyst is a substance that increases the rate of a chemical reaction without being consumed.", "[DEF] A reaction pathway is a sequence of elementary steps connecting reactants to products.", "[DEF] Competing pathways are distinct reaction pathways that share at least one common intermediate.", "[VAR] Let I be an intermediate in a reaction pathway.", "[VAR] Let k be the rate constant of an elementary step.", "[DEF] Flux is the rate of conversion through a specific pathway per unit time.", "[LAW] The total flux into an intermediate equals the total flux out at steady state.", "[CONSTRAINT] The sum of fluxes through all competing pathways originating from a common intermediate equals the total flux into that intermediate.", "[LIMIT] The maximum achievable selectivity to a desired product is bounded by the ratio of the rate constant of the desired pathway to the sum of rate constants of all competing pathways from the shared intermediate.", "[LIMIT] Suppressing a side reaction requires either decreasing its rate constant or increasing the rate constant of the desired pathway, both subject to energetic and geometric constraints of the active site."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If the rate constant of the desired pathway equals the sum of the rate constants of all competing pathways from the shared intermediate, the maximum achievable selectivity to the desired product is 0.5.\nASSUMPTION: Selectivity is defined as the ratio of flux through the desired pathway to the total outgoing flux from the intermediate.\nVERIFICATION: Dimensionless ratio; valid when steady-state flux balance holds.", "rejected": "If the rate constant k of the desired pathway equals the sum of the rate constants of all competing pathways from the shared intermediate, the maximum achievable selectivity to the desired product is k/(k + k).", "E_acc": 0.4227329194545746, "C_acc": 0.32717186212539673, "G_acc": 0.5459118401631713, "D_acc": 0.6976359027903527, "H_acc": 0.17525264620780945, "Q_acc": 0.5925697873812168, "E_rej": 0.5623316168785095, "C_rej": 0.15254639089107513, "G_rej": 0.5366389199625701, "D_rej": 0.8171998262405396, "H_rej": 0.18280017375946045, "Q_rej": 0.6906779387500138, "Delta_Q": -0.09810815136879703, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Market microstructure and information asymmetry: model how order flow reveals private valuations and derive optimal inference filters.", "ancestors": ["[DEF] Time is indexed by t ∈ ℕ.", "[VAR] At each t the variable vₜ ∈ ℝ denotes the asset’s latent common value.", "[VAR] At each t the variable xₜ ∈ ℝ denotes net signed order flow.", "[VAR] At each t the variable yₜ ∈ ℝ denotes the public information set.", "[DEF] The information set at t is yₜ = {x₁,…,xₜ}.", "[DEF] The latent value process satisfies vₜ = vₜ₋₁ + εₜ with εₜ ∼ 𝒩(0,σ²ᵥ).", "[DEF] The order flow satisfies xₜ = vₜ + uₜ with uₜ ∼ 𝒩(0,σ²ᵤ) and εₜ ⟂ uₜ.", "[LAW] The conditional expectation 𝔼[vₜ | yₜ] minimizes mean-square error among yₜ-measurable estimators.", "[LAW] The Kalman filter recursion yields 𝔼[vₜ | yₜ] = 𝔼[vₜ₋₁ | yₜ₋₁] + Kₜ(xₜ − 𝔼[vₜ₋₁ | yₜ₋₁]) with gain Kₜ = (Pₜ₋₁ + σ²ᵥ)/(Pₜ₋₁ + σ²ᵥ + σ²ᵤ) and posterior variance Pₜ updated via Pₜ = (1 − Kₜ)(Pₜ₋₁ + σ²ᵥ)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The Kalman gain Kₜ is strictly between 0 and 1 for every t ∈ ℕ.\nASSUMPTION: None\nVERIFICATION: 0 < Kₜ < 1 because σ²ᵥ, σ²ᵤ > 0 and Pₜ₋₁ ≥ 0.", "rejected": "The Kalman gain Kₜ is strictly between 0 and 1 for every t ∈ ℕ, assuming εₜ and uₜ are correlated.", "E_acc": 0.2664352059364319, "C_acc": 0.453360915184021, "G_acc": 0.5528390682302415, "D_acc": 0.6574899926781654, "H_acc": 0.19188353419303894, "Q_acc": 0.5121358375065029, "E_rej": 0.21616032719612122, "C_rej": 0.5913751125335693, "G_rej": 0.5525966840130943, "D_rej": 0.8214917182922363, "H_rej": 0.17850828170776367, "Q_rej": 0.5035399279424123, "Delta_Q": 0.00859590956409062, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["[DEF] A coalition is a subset S of the grand coalition N.", "[VAR] v(S;P) denotes the worth of coalition S under partition P of N.", "[VAR] x ∈ ℝ^{|N|} is an imputation satisfying ∑_{i∈N}x_i = v(N;{N}).", "[CONSTRAINT] A coalition S blocks x if ∃y∈ℝ^{|S|} such that ∑_{i∈S}y_i ≤ v(S;P) and y_i > x_i ∀i∈S.", "[DEF] The core is the set of imputations not blocked by any coalition.", "[LAW] v(S;P) depends on every T ∈ P.", "[LIMIT] Computing the core is NP-hard in |N|.", "[LIMIT] No polynomial-time algorithm exists for general v(S;P) unless P = NP."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If |N| ≥ 2, then the core may be empty.  \nASSUMPTION: None  \nVERIFICATION: N/A", "rejected": "STATUS: ENTAILED.", "E_acc": 0.14307519793510437, "C_acc": 0.4207552969455719, "G_acc": 0.5243838883470744, "D_acc": 0.6224480904638767, "H_acc": 0.3014686107635498, "Q_acc": 0.4579910346772522, "E_rej": 0.07208210974931717, "C_rej": 0.21830248832702637, "G_rej": 0.5645994520746171, "D_rej": 0.5832911506295204, "H_rej": 0.4167088493704796, "Q_rej": 0.46587137086316943, "Delta_Q": -0.007880336185917214, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["[DEF] Let A, B, C be Boolean variables.", "[DEF] Let the statement “A implies B unless C” denote (A ∧ ¬C) → B.", "[DEF] Let C depend on B as C ↔ B.", "[DEF] Let a fixed point be an assignment of (A,B,C) satisfying all stated equivalences.", "[CONSTRAINT] From (A ∧ ¬C) → B and C ↔ B, derive (A ∧ ¬B) → B.", "[CONSTRAINT] (A ∧ ¬B) → B simplifies to ¬A ∨ B.", "[CONSTRAINT] C ↔ B and ¬A ∨ B jointly imply ¬A ∨ C.", "[LIMIT] No fixed point exists with A true and B false.", "[LIMIT] The only fixed points are (A,B,C) ∈ {(0,0,0), (0,1,1)}.", "[LIMIT] No oscillatory inference chain exists under these constraints."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any fixed point, A is false.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "STATUS: ENTAILED.", "E_acc": 0.1662844866514206, "C_acc": 0.6391705274581909, "G_acc": 0.5435770799085731, "D_acc": 0.6299746967852116, "H_acc": 0.25590844452381134, "Q_acc": 0.4311707513901638, "E_rej": 0.06138870120048523, "C_rej": 0.7242084741592407, "G_rej": 0.5750734044704586, "D_rej": 0.5939855426549911, "H_rej": 0.40601445734500885, "Q_rej": 0.3667852592188865, "Delta_Q": 0.06438549217127731, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Estimating whether a distant sound comes from a moving or stationary source using only changes in pitch and loudness over time", "ancestors": ["[DEF] Let source motion be the time derivative of source position.", "[VAR] Let c denote the speed of sound in the medium.", "[VAR] Let f₀ be the emitted frequency measured in the source frame.", "[LAW] The observed frequency f = f₀ (c + vᵣ)/(c + vₛ) with vᵣ receiver velocity along the line of sight and vₛ source velocity along the line of sight.", "[VAR] Let A₀ be the emitted amplitude measured at unit distance from the source.", "[LAW] The observed amplitude A = A₀/r with r the instantaneous source-receiver distance.", "[CONSTRAINT] vₛ and vᵣ are constant for the interval of observation.", "[LIMIT] Only f and A are measurable to the receiver."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the measured frequency f equals the emitted frequency f₀, then the receiver velocity vᵣ equals the source velocity vₛ.\nASSUMPTION: None\nVERIFICATION: Direct from f = f₀ (c + vᵣ)/(c + vₛ) with f = f₀ ⇒ c + vᵣ = c + vₛ ⇒ vᵣ = vₛ.", "rejected": "If the measured amplitude A equals the emitted amplitude A₀, then the receiver velocity vᵣ equals the source velocity vₛ.", "E_acc": 0.26337793469429016, "C_acc": 0.47068339586257935, "G_acc": 0.5417323698929977, "D_acc": 0.6630009170621634, "H_acc": 0.16571637988090515, "Q_acc": 0.5092517206387128, "E_rej": 0.25280994176864624, "C_rej": 0.42524391412734985, "G_rej": 0.5297249616123736, "D_rej": 0.8669695556163788, "H_rej": 0.13303044438362122, "Q_rej": 0.5568300587125123, "Delta_Q": -0.04757833807379952, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining if a child’s learning difficulty is caused by lack of sleep, attention issues, or teaching mismatch from daily observations", "ancestors": ["[DEF] A day is a 24-hour interval.", "[VAR] Let s be the minutes of sleep a child obtains in a day.", "[VAR] Let a be the count of observed attention lapses in a day.", "[VAR] Let m be a binary indicator of teaching mismatch observed in a day.", "[LIMIT] s, a, m are recorded once per day.", "[CONSTRAINT] s ≤ 1440.", "[CONSTRAINT] a ≥ 0.", "[DEF] A learning difficulty flag is raised on a day if performance < baseline.", "[DEF] Performance is the measured accuracy on daily academic tasks."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If m = 1 on a day, then performance < baseline is possible for that day.  \nASSUMPTION: Teaching mismatch (m = 1) can lower performance below baseline.  \nVERIFICATION: Binary indicator m and flag condition performance < baseline are both defined per day.", "rejected": "If m = 1 on a day, then performance < baseline equals s + a.", "E_acc": 0.8475009799003601, "C_acc": 0.03529370203614235, "G_acc": 0.5429672452155501, "D_acc": 0.7275312384590507, "H_acc": 0.22619593143463135, "Q_acc": 0.7786716571543366, "E_rej": 0.1293199211359024, "C_rej": 0.4494139552116394, "G_rej": 0.5758846041280776, "D_rej": 0.8118091821670532, "H_rej": 0.18819081783294678, "Q_rej": 0.5076328607741744, "Delta_Q": 0.27103879638016226, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding if a sudden drop in workplace productivity is caused by burnout, unclear incentives, or external stressors using observed behavior patterns", "ancestors": ["[DEF] A behavior pattern is a finite sequence of observed actions.", "[VAR] Let P denote productivity, measured as output per unit time.", "[VAR] Let B denote the burnout level of an individual.", "[VAR] Let I denote the clarity of incentives presented to an individual.", "[VAR] Let E denote the magnitude of external stressors affecting an individual.", "[CONSTRAINT] A sudden drop in P satisfies ΔP/Δt < −k for some threshold k > 0.", "[LAW] B increases monotonically with sustained high workload and insufficient recovery.", "[LIMIT] Observed behavior patterns do not directly measure B, I, or E."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If P exhibits a sudden drop (ΔP/Δt < −k) while E remains constant, then B must have risen above a latent burnout threshold.  \nASSUMPTION: A sudden drop in P is possible only when B has crossed a critical burnout threshold.  \nVERIFICATION: Testable under controlled constant-E regime by monitoring P and verifying that every observed sudden drop coincides with post-hoc B above threshold.", "rejected": "If P exhibits a sudden drop (ΔP/Δt < −k) while I remains constant, then B must have risen above a latent burnout threshold.", "E_acc": 0.4558160603046417, "C_acc": 0.22130751609802246, "G_acc": 0.5510254355945757, "D_acc": 0.7098818607628345, "H_acc": 0.32838916406035423, "Q_acc": 0.6118258577372346, "E_rej": 0.26583006978034973, "C_rej": 0.21791505813598633, "G_rej": 0.5454422153665551, "D_rej": 0.7499852925539017, "H_rej": 0.3125183843076229, "Q_rej": 0.5639996724602367, "Delta_Q": 0.04782618527699789, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["[DEF] A subproblem is a triple (S, A, T) with state set S, action set A, and transition function T.", "[VAR] Let c_i ≥ 0 denote the compute cost allocated to subproblem i.", "[VAR] Let R_i(c_i) be the regret for subproblem i under allocation c_i.", "[DEF] The total regret is R = Σ_i R_i(c_i).", "[CONSTRAINT] Σ_i c_i ≤ C for total budget C > 0.", "[LAW] Each R_i is strictly decreasing and convex in c_i.", "[VAR] Let B_i(c_i) = −dR_i/dc_i be the marginal regret reduction for subproblem i.", "[LIMIT] B_i(c_i) → 0 as c_i → ∞ for every i.", "[VAR] Let λ ≥ 0 be the Lagrange multiplier for the budget constraint.", "[CONSTRAINT] At optimum, B_i(c_i*) = λ for every active subproblem i."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any two active subproblems i and j, c_i* > c_j* if and only if B_i(c_j*) > B_j(c_i*).\nASSUMPTION: None\nVERIFICATION: Units: c_i* in compute cost, B_i in regret reduction per unit cost; test via strict convexity of R_i.", "rejected": "For any two active subproblems i and j, c_i* > c_j* if and only if B_i(c_j*) < B_j(c_i*).", "E_acc": 0.26400619745254517, "C_acc": 0.5455595254898071, "G_acc": 0.5790666692191735, "D_acc": 0.6556758382357657, "H_acc": 0.1553034782409668, "Q_acc": 0.5015081078046932, "E_rej": 0.3769073486328125, "C_rej": 0.31494832038879395, "G_rej": 0.5783236033753383, "D_rej": 0.7456918805837631, "H_rej": 0.2543081194162369, "Q_rej": 0.5894548253622816, "Delta_Q": -0.08794671755758832, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["[DEF] O is a finite set of observed literals.", "[DEF] R is a finite set of rules of the form φ ⇒ ψ.", "[VAR] R₁ … Rₙ denote distinct rule-sets.", "[DEF] H(R, O) = { ψ | ∃φ ∈ O, (φ ⇒ ψ) ∈ R }.", "[DEF] A(R, O) = |H(R, O) \\ O|.", "[DEF] E(R, O) = |O \\ H(R, O)|.", "[CONSTRAINT] A(R, O) = 0 ⇒ E(R, O) = 0.", "[LIMIT] No R guarantees E(R, O) = 0 for arbitrary O.", "[DEF] S(R, O) = A(R, O) + E(R, O).", "[DEF] Rᵢ ≺ Rⱼ ⇔ S(Rᵢ, O) < S(Rⱼ, O)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any rule-set R, if A(R, O) = 0 then S(R, O) = E(R, O).\nASSUMPTION: None\nVERIFICATION: Follows directly from S(R, O) = A(R, O) + E(R, O) and the premise A(R, O) = 0.", "rejected": "For any rule-set R, if A(R, O) = 0 then S(R, O) = 0.", "E_acc": 0.4033772051334381, "C_acc": 0.4368473291397095, "G_acc": 0.5272386269643903, "D_acc": 0.7151529602706432, "H_acc": 0.1878858506679535, "Q_acc": 0.5633334280923009, "E_rej": 0.414465069770813, "C_rej": 0.3570907413959503, "G_rej": 0.5333371844142676, "D_rej": 0.7797044217586517, "H_rej": 0.22029557824134827, "Q_rej": 0.593500136062503, "Delta_Q": -0.030166707970202045, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether a battery will fail during peak usage by reasoning about internal resistance, heat generation, and discharge rate", "ancestors": ["[DEF] A battery is an electrochemical cell that converts stored chemical energy into electrical energy.", "[VAR] Let R denote the internal resistance of the battery.", "[VAR] Let I denote the discharge current.", "[VAR] Let t denote time.", "[LAW] Joule heating power is P = I²R.", "[VAR] Let T denote the battery temperature.", "[CONSTRAINT] T increases monotonically with P."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the discharge current I increases, the battery temperature T will increase monotonically.\nASSUMPTION: None\nVERIFICATION: Units: I in A, T in K; test by measuring T vs. I at constant R.", "rejected": "If the battery temperature T increases, the discharge current I will increase monotonically.", "E_acc": 0.09651719033718109, "C_acc": 0.7738610506057739, "G_acc": 0.5114730641362257, "D_acc": 0.5924066860228777, "H_acc": 0.23268082737922668, "Q_acc": 0.37169081427389755, "E_rej": 0.7838186025619507, "C_rej": 0.038560252636671066, "G_rej": 0.49727563885971904, "D_rej": 0.7574358880519867, "H_rej": 0.2425641119480133, "Q_rej": 0.7541194244287909, "Delta_Q": -0.3824286101548933, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging if a satellite will remain in orbit or decay by reasoning from drag, altitude, mass, and atmospheric density", "ancestors": ["[DEF] Let h denote altitude above the planetary surface.", "[DEF] Let ρ denote local atmospheric density.", "[DEF] Let m denote satellite mass.", "[DEF] Let A denote cross-sectional area normal to velocity.", "[DEF] Let v denote orbital speed.", "[DEF] Let Fd = ½ ρ v² A Cd with Cd a dimensionless coefficient.", "[LAW] Gravitational acceleration at h is g(h)=μ/(R+h)² with μ constant and R planetary radius.", "[CONSTRAINT] Orbit persists while ½ v² ≥ g(h)(R+h)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The orbital speed must satisfy v ≥ √(2μ/(R+h)) for the orbit to persist.\nASSUMPTION: None\nVERIFICATION: Units: √(m³s⁻²/m)=m s⁻¹, matching speed units; equality gives the threshold for persistence.", "rejected": "STATUS: NOT ENTAILED.", "E_acc": 0.07585211098194122, "C_acc": 0.8129494786262512, "G_acc": 0.5733640393009409, "D_acc": 0.6216970952227712, "H_acc": 0.27579158544540405, "Q_acc": 0.3715988059295342, "E_rej": 0.043818723410367966, "C_rej": 0.8712084293365479, "G_rej": 0.5663977032527328, "D_rej": 0.4982361267320812, "H_rej": 0.5017638732679188, "Q_rej": 0.30165430982597174, "Delta_Q": 0.06994449610356246, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging if a satellite will remain in orbit or decay by reasoning from drag, altitude, mass, and atmospheric density", "ancestors": ["[DEF] Let h be altitude above the planetary surface.", "[DEF] Let ρ be atmospheric density at h.", "[DEF] Let m be satellite mass.", "[DEF] Let A be cross-sectional area normal to velocity.", "[DEF] Let Cd be the dimensionless drag coefficient.", "[LAW] Drag force magnitude is Fd = 0.5 Cd A ρ v².", "[CONSTRAINT] Orbital energy E = −GMm/(2a) where a is semi-major axis.", "[LIMIT] If E increases to ≥ 0 the trajectory is no longer closed."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If drag force Fd acts continuously in the direction opposing velocity, the work done by drag decreases orbital energy E, so the semi-major axis a shrinks while E remains negative.\nASSUMPTION: The drag force vector remains anti-parallel to the velocity vector throughout the orbit.\nVERIFICATION: Units consistent (Fd in N, E in J, a in m); testable via numerical integration of decaying orbit.", "rejected": "If drag force Fd acts continuously in the direction opposing velocity, the work done by drag decreases orbital energy E, so the semi-major axis a increases as E decreases.", "E_acc": 0.3073458671569824, "C_acc": 0.35084545612335205, "G_acc": 0.5641560761141591, "D_acc": 0.6901877684867941, "H_acc": 0.2016582190990448, "Q_acc": 0.5527376159327104, "E_rej": 0.26737892627716064, "C_rej": 0.32890766859054565, "G_rej": 0.5586182987317443, "D_rej": 0.7521989643573761, "H_rej": 0.2478010356426239, "Q_rej": 0.5518154932186008, "Delta_Q": 0.00092212271410963, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a plant is nutrient-deficient or water-stressed by observing leaf color, growth pattern, and soil conditions", "ancestors": ["[DEF] A plant is an organism containing chlorophyll.", "[DEF] A leaf is an organ attached to a plant.", "[DEF] Leaf color is the spectral reflectance of a leaf.", "[DEF] Nutrient deficiency is the condition where essential mineral concentration c in tissue falls below threshold t.", "[DEF] Water stress is the condition where soil water potential ψ drops below wilting point w.", "[VAR] Soil water potential ψ is measured in the root zone.", "[VAR] Chlorophyll concentration B is proportional to leaf color reflectance R.", "[LAW] If c < t then growth rate g decreases monotonically with decreasing c.", "[LAW] If ψ < w then stomatal conductance s decreases monotonically with decreasing ψ."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If nutrient deficiency occurs (c < t), then leaf color reflectance R decreases monotonically with decreasing c.  \nASSUMPTION: Chlorophyll concentration B is the only leaf pigment whose change significantly alters R under nutrient deficiency.  \nVERIFICATION: Units: dimensionless reflectance vs. mineral concentration (e.g., mg kg⁻¹); testable by spectral measurement of leaves with controlled c.", "rejected": "If nutrient deficiency occurs (c < t), then leaf color reflectance R is independent of chlorophyll concentration B.", "E_acc": 0.6357194781303406, "C_acc": 0.14038293063640594, "G_acc": 0.5834200939862058, "D_acc": 0.7430496852844953, "H_acc": 0.11661392450332642, "Q_acc": 0.7162718207156286, "E_rej": 0.006793934851884842, "C_rej": 0.9808359146118164, "G_rej": 0.5977799482643604, "D_rej": 0.9067496061325073, "H_rej": 0.09325039386749268, "Q_rej": 0.3974518690258265, "Delta_Q": 0.31881995168980204, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Designing catalysts for competing pathways: choose active-site features that bias reaction flux towards desired intermediates while suppressing side reactions.", "ancestors": ["[DEF] A catalytic cycle is a closed sequence of elementary steps converting reactants to products.", "[DEF] An intermediate is a chemical species formed and consumed within the cycle.", "[DEF] A side reaction is an elementary step that removes an intermediate from the cycle.", "[VAR] Let k_i denote the rate constant of step i.", "[VAR] Let F_i denote the flux through step i.", "[LAW] F_i = k_i [I] for an elementary step consuming intermediate I.", "[CONSTRAINT] Σ F_out = Σ F_in for every intermediate in steady state.", "[LIMIT] A finite active-site area presents a finite set of geometric configurations.", "[CONSTRAINT] The local binding energy E_b(x) determines the residence time t_r(x) of intermediate x at the active site."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If a side reaction removes intermediate I faster than the catalytic step regenerates it, the steady-state flux through the catalytic cycle must decrease.\nASSUMPTION: The side reaction is irreversible and the only sink for I outside the cycle.\nVERIFICATION: Compare F_side = k_side [I] with F_regen = k_cat [I]; units mol·s⁻¹·m⁻².", "rejected": "If a side reaction removes intermediate I slower than the catalytic step regenerates it, the steady-state flux through the catalytic cycle must decrease.", "E_acc": 0.2935958802700043, "C_acc": 0.36479029059410095, "G_acc": 0.5503847524523735, "D_acc": 0.6541596514871344, "H_acc": 0.3006664291024208, "Q_acc": 0.5259629438398405, "E_rej": 0.1896679401397705, "C_rej": 0.1727469563484192, "G_rej": 0.515287828980945, "D_rej": 0.8179925680160522, "H_rej": 0.2275092899799347, "Q_rej": 0.5662561411736533, "Delta_Q": -0.04029319733381276, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["[DEF] An explanation artifact e is a data structure produced by a model M.", "[VAR] Let c denote the cost to agent A of altering observable input x.", "[DEF] Strategic opacity is the policy of withholding e from A.", "[LAW] If A receives e and c < B (benefit), A substitutes x with x′ to exploit M.", "[CONSTRAINT] The domain graph G_p for physical variables is a DAG.", "[VAR] Let G_s denote the DAG over social variables.", "[VAR] Let G_c denote the DAG over computational variables.", "[LIMIT] No directed edge exists between any node in G_p and any node in G_s unless explicitly added.", "[CONSTRAINT] A cross-domain intervention is a set of edge additions and node fixings in G_p ∪ G_s ∪ G_c.", "[LIMIT] The minimal such intervention is the smallest set achieving target node value y in G_c."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Strategic opacity is necessary whenever c < B for the given x and M.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "Strategic opacity is necessary whenever c > B for the given x and M.", "E_acc": 0.26021113991737366, "C_acc": 0.4795483648777008, "G_acc": 0.5798885833937675, "D_acc": 0.6083400271600112, "H_acc": 0.2413148581981659, "Q_acc": 0.4956679052906111, "E_rej": 0.27425718307495117, "C_rej": 0.39695820212364197, "G_rej": 0.5691070624161512, "D_rej": 0.733802542090416, "H_rej": 0.26619745790958405, "Q_rej": 0.536847689608112, "Delta_Q": -0.04117978431750091, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["[DEF] A metabolic pathway is a sequence of biochemical reactions converting substrates to products.", "[DEF] Biomass B is the total mass of living biological material.", "[DEF] Resource availability R(t) is a time-varying non-negative scalar.", "[DEF] A switching cost c is a non-negative scalar incurred when changing active pathways.", "[VAR] P denotes the set of available metabolic pathways.", "[VAR] x_p(t) ∈ {0,1} indicates pathway p ∈ P is active (1) or inactive (0) at time t.", "[CONSTRAINT] ∑_{p∈P} x_p(t) = 1 for all t.", "[DEF] The biomass growth rate dB/dt = ∑_{p∈P} x_p(t) f_p(R(t)) with f_p a pathway-specific function.", "[DEF] The switching cost at time t is c if ∃p ∈ P such that x_p(t) ≠ x_p(t−Δt) with Δt→0.", "[LIMIT] The long-run biomass is lim_{T→∞} (1/T) ∫_0^T B(t) dt."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If R(t) is constant and f_p(R) > 0 for all p ∈ P, then the long-run biomass is strictly increasing with the maximum value of f_p(R).\nASSUMPTION: None\nVERIFICATION: Units: biomass/time; regime: constant R(t) with positive pathway growth rates; test by fixing R and comparing long-run biomass across different max f_p(R).", "rejected": "If R(t) is constant and f_p(R) > 0 for all p ∈ P, then the maximum value of f_p(R) is strictly increasing with the long-run biomass.", "E_acc": 0.2091308981180191, "C_acc": 0.554951548576355, "G_acc": 0.5609231925336644, "D_acc": 0.6571864958968945, "H_acc": 0.17420676350593567, "Q_acc": 0.477950221055653, "E_rej": 0.2769681215286255, "C_rej": 0.3911362290382385, "G_rej": 0.5679624757030979, "D_rej": 0.8057798147201538, "H_rej": 0.1942201852798462, "Q_rej": 0.5601896302076057, "Delta_Q": -0.08223940915195271, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["[DEF] A, B, C are Boolean variables.", "[DEF] The statement “A implies B unless C” is written (A ∧ ¬C) → B.", "[VAR] C is a function of B, written C = f(B).", "[DEF] A fixed point is a state where B = B_next and C = C_next.", "[CONSTRAINT] The update rule for B is B_next = (A ∧ ¬C).", "[CONSTRAINT] The update rule for C is C_next = f(B_next).", "[LAW] The system state is fully specified by the pair (B, C).", "[LIMIT] Oscillatory inference chains require that B ≠ B_next and C ≠ C_next in successive steps.", "[LIMIT] Fixed points satisfy B = (A ∧ ¬f(B)) and C = f(B)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A fixed point exists only if A = B.\nASSUMPTION: None\nVERIFICATION: Substitute C = f(B) into B = (A ∧ ¬f(B)); Boolean regime.", "rejected": "A fixed point exists only if A = B in the oscillatory regime.", "E_acc": 0.4432217478752136, "C_acc": 0.29149022698402405, "G_acc": 0.5459479810087942, "D_acc": 0.6703622546046972, "H_acc": 0.1709616780281067, "Q_acc": 0.6008343582856469, "E_rej": 0.4089771807193756, "C_rej": 0.3355903923511505, "G_rej": 0.5118440346564057, "D_rej": 0.7549834847450256, "H_rej": 0.24501651525497437, "Q_rej": 0.5844389281003713, "Delta_Q": 0.01639543018527556, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["[DEF] A state space is a measurable set S.", "[DEF] An action space is a measurable set A.", "[DEF] A policy π is a conditional distribution on A given S.", "[VAR] Let P denote the distribution of (s,a) under behavior policy π_b.", "[VAR] Let Q denote the distribution of (s,a) under target policy π_e.", "[DEF] The density ratio w(s,a) equals dQ/dP when Q≪P.", "[DEF] The importance sampling estimator is ρ = (1/n)Σ w(s_i,a_i)r_i.", "[CONSTRAINT] Covariate shift holds when P(s)=Q(s).", "[DEF] The Radon-Nikodym derivative dQ/dP exists only if Q≪P.", "[LIMIT] If Q≪P fails, w(s,a) is undefined on a set of positive P-measure."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If Covariate shift holds, then w(s,a) simplifies to π_e(a|s)/π_b(a|s) P-almost everywhere.\nASSUMPTION: None\nVERIFICATION: Units are dimensionless ratios; validity requires Q≪P and Covariate shift.", "rejected": "HYPOTHESIS: If Covariate shift holds, then w(s,a) simplifies to π_e(a|s)π_b(a|s) P-almost everywhere.", "E_acc": 0.19400672614574432, "C_acc": 0.5935351252555847, "G_acc": 0.5453819951217156, "D_acc": 0.6305973837152123, "H_acc": 0.2101268768310547, "Q_acc": 0.4536781808768865, "E_rej": 0.28871777653694153, "C_rej": 0.3582960069179535, "G_rej": 0.5341062101069838, "D_rej": 0.7899238169193268, "H_rej": 0.21007618308067322, "Q_rej": 0.5587545186746865, "Delta_Q": -0.10507633779780001, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["[DEF] Biomass B(t) is a non-negative real-valued function of time t.", "[VAR] Resource input rate R(t) is a real-valued function of time t.", "[VAR] Pathway activation vector p(t) ∈ {0,1}^n indicates active metabolic pathways at time t.", "[DEF] Switching cost c_{ij} is a non-negative real number incurred when changing from pathway i to pathway j.", "[LAW] Biomass change rate dB/dt equals the sum over all active pathways of their biomass production rates minus the sum of switching costs incurred at t.", "[CONSTRAINT] At any t, at most one p_i(t) = 1 for i indexing mutually exclusive pathways.", "[LIMIT] Total resource uptake rate cannot exceed R(t).", "[CONSTRAINT] Switching cost at t is c_{ij} if p_i(t^-) = 1 and p_j(t^+) = 1 with i ≠ j, and zero otherwise.", "[LIMIT] Long-run biomass is the limit as T→∞ of (1/T) ∫_0^T B(t) dt."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If the switching cost c_{ij} > 0 for every pair of distinct pathways, then any change of the active pathway forces dB/dt to decrease by that positive c_{ij} at the instant of switching.\nASSUMPTION: The biomass production rates of individual pathways are finite and bounded.\nVERIFICATION: Units: c_{ij} in biomass·time⁻¹; testable by observing a negative jump in dB/dt at every switch.", "rejected": "If the switching cost c_{ij} > 0 for every pair of distinct pathways, then any change of the active pathway forces dB/dt to increase by that positive c_{ij} at the instant of switching.", "E_acc": 0.3536573648452759, "C_acc": 0.317156046628952, "G_acc": 0.5789626708719879, "D_acc": 0.7400396480225027, "H_acc": 0.14410175383090973, "Q_acc": 0.5920562885235995, "E_rej": 0.2914072871208191, "C_rej": 0.2883772552013397, "G_rej": 0.5533714426856022, "D_rej": 0.8180496394634247, "H_rej": 0.22743795067071915, "Q_rej": 0.5812871564587112, "Delta_Q": 0.010769132064888276, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["[DEF] ∀x∃y P(x,y).", "[VAR] c: ℕ → ℕ.", "[CONSTRAINT] c monotone: x ≤ x′ ⇒ c(x) ≤ c(x′).", "[VAR] B ∈ ℕ.", "[LIMIT] ∀x (c(x) > B ⇒ ¬∃y (P(x,y) ∧ c(y) ≤ B)).", "[DEF] feasible y for x: P(x,y) ∧ c(y) ≤ B.", "[CONSTRAINT] ∀x (c(x) ≤ B ⇒ ∃y (P(x,y) ∧ c(y) ≤ B))."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every x with c(x) > B, every y satisfying P(x,y) has c(y) > B.\nASSUMPTION: None\nVERIFICATION: Direct instantiation of LIMIT premise; units: cost function c, threshold B.", "rejected": "For every x with c(x) > B, every y satisfying P(x,y) has c(y) < B.", "E_acc": 0.4080367088317871, "C_acc": 0.35392218828201294, "G_acc": 0.563676742836833, "D_acc": 0.6707608867436647, "H_acc": 0.18813413381576538, "Q_acc": 0.5797006875276566, "E_rej": 0.3350521922111511, "C_rej": 0.4873315691947937, "G_rej": 0.5285340823233128, "D_rej": 0.816452145576477, "H_rej": 0.18354785442352295, "Q_rej": 0.5536918039619924, "Delta_Q": 0.02600888356566422, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["[DEF] A counterfactual query compares factual outcome y₀ under intervention x₀ with counterfactual outcome y₁ under intervention x₁.", "[VAR] Let M be a causal model with endogenous variables V and exogenous variables U.", "[VAR] Let Pa(X) denote the parents of variable X in M.", "[DEF] An intervention do(X=x) replaces the structural equation for X with the constant x.", "[DEF] The causal effect of do(X=x₁) relative to do(X=x₀) on Y is the difference y₁−y₀.", "[CONSTRAINT] The minimal set of causal changes is a subset S⊆V such that fixing S to their counterfactual values yields y₁ while keeping all other variables at their factual values.", "[LAW] The value of every variable not in S is determined by its structural equation given its parents’ factual values."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: The counterfactual outcome y₁ is obtained by fixing the minimal set S⊆V to their counterfactual values while every variable Vⱼ∉S retains its factual value determined by its structural equation given its parents’ factual values.  \nASSUMPTION: None  \nVERIFICATION: N/A", "rejected": "STATUS: ENTAILED.", "E_acc": 0.12970921397209167, "C_acc": 0.731055498123169, "G_acc": 0.5483728408580646, "D_acc": 0.6515521551482379, "H_acc": 0.14805367588996887, "Q_acc": 0.41788129617925734, "E_rej": 0.20979347825050354, "C_rej": 0.5112744569778442, "G_rej": 0.5838023540563881, "D_rej": 0.593997910618782, "H_rej": 0.40600208938121796, "Q_rej": 0.4556429960764945, "Delta_Q": -0.037761699897237155, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A bandit instance is a tuple (A, P) with finite arm set A and reward distributions P = {P_a : a ∈ A}.", "[VAR] Let r_{a,t} denote the reward realized when arm a is pulled at discrete time t.", "[VAR] Let τ_a ≥ 0 denote the fixed but unknown delay between pulling arm a and observing r_{a,t}.", "[VAR] Let c ≥ 0 denote the cost incurred each time an arm is pulled.", "[LIMIT] The observed reward at time t is r_{a,t−τ_a} if τ_a ≤ t, else ∅.", "[CONSTRAINT] An arm a may be pulled only if no prior pull of a has unobserved reward.", "[DEF] The best arm a* = argmax_{a∈A} μ_a where μ_a = E[r_{a,t}] under P_a.", "[VAR] Let N_a(t) count pulls of arm a up to time t.", "[VAR] Let Δ_a = μ_{a*} − μ_a denote the reward gap of arm a relative to a*."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every arm a, the number of its pulls satisfies N_a(t) ≤ t+1.\nASSUMPTION: None\nVERIFICATION: N_a(t) counts pulls up to discrete time t, so the bound holds trivially.", "rejected": "For every arm a, if N_a(t) ≤ t+1 then discrete time t has been reached.", "E_acc": 0.15415030717849731, "C_acc": 0.6198478937149048, "G_acc": 0.5391611838131212, "D_acc": 0.6220139991492033, "H_acc": 0.23729553818702698, "Q_acc": 0.43078099618433047, "E_rej": 0.19600069522857666, "C_rej": 0.522936999797821, "G_rej": 0.5432260874658823, "D_rej": 0.7194280177354813, "H_rej": 0.28057198226451874, "Q_rej": 0.4786864314228296, "Delta_Q": -0.047905435238499106, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["[DEF] A vertex cover of graph G=(V,E) is a set C⊆V such that every e∈E has at least one endpoint in C.", "[VAR] Let k∈ℕ denote the size of C.", "[CONSTRAINT] The VC problem requires deciding whether G admits a vertex cover with |C|≤k.", "[LAW] VC is NP-complete.", "[DEF] The standard LP relaxation assigns x_v∈[0,1] to each v∈V minimizing ∑_{v∈V} x_v subject to x_u+x_v≥1 for every (u,v)∈E.", "[LIMIT] For every ε>0 there exists a family of graphs where the minimum integral vertex cover exceeds (2−ε) times the optimum of the LP relaxation.", "[LIMIT] No polynomial-time algorithm can approximate VC within factor 2−ε for any ε>0 unless P=NP."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every ε>0 there exists a graph G for which the minimum integral vertex cover size k* satisfies k* > (2−ε)·LP*, where LP* is the optimum value of the standard LP relaxation.\nASSUMPTION: None\nVERIFICATION: Units: vertex count; regime: family of graphs; testable by comparing k* and LP* on the specified graph family.", "rejected": "For every ε>0 the minimum integral vertex cover size k* of every graph G satisfies k* > (2−ε)·LP*, where LP* is the optimum value of the standard LP relaxation.", "E_acc": 0.21525231003761292, "C_acc": 0.5562296509742737, "G_acc": 0.5417594199534506, "D_acc": 0.6738691153004766, "H_acc": 0.11769965291023254, "Q_acc": 0.4846855045761913, "E_rej": 0.25133368372917175, "C_rej": 0.3524310886859894, "G_rej": 0.5389702410902828, "D_rej": 0.8935142755508423, "H_rej": 0.10648572444915771, "Q_rej": 0.5807622182648629, "Delta_Q": -0.09607671368867154, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-agent routing with congestion externalities: find equilibrium routing and propose a minimal tolling scheme that improves social welfare.Invariant-based algorithm design: find an invariant that guarantees termination and correctness for a nontrivial iterative transformation on combinatorial objects.", "ancestors": ["[DEF] A multi-agent routing instance is a tuple (G,N,c).", "[VAR] G is a directed graph with vertex set V and arc set A.", "[VAR] N is a finite set of agents.", "[VAR] c_a: ℝ_{≥0}→ℝ_{≥0} maps aggregate arc flow to arc latency for each a∈A.", "[DEF] A flow profile f=(f_i)_{i∈N} assigns each agent i a path f_i from its origin o_i to destination d_i.", "[DEF] The aggregate flow on arc a is x_a=|{i∈N : a∈f_i}|.", "[DEF] The cost to agent i is C_i(f)=∑_{a∈f_i} c_a(x_a).", "[DEF] A flow profile f* is a (pure) Nash equilibrium if for every i∈N and every alternative path p_i, C_i(f*)≤C_i(f*_{-i},p_i).", "[LIMIT] A tolling scheme is a vector τ∈ℝ^{|A|} of arc-specific charges.", "[CONSTRAINT] A tolling scheme is minimal if τ_a=0 for every arc a whose latency function c_a is constant."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: For any minimal tolling scheme τ, the aggregate flow on every constant-latency arc a satisfies x_a = |{i ∈ N : a ∈ f_i}| with τ_a = 0.  \nASSUMPTION: None  \nVERIFICATION: Units: τ_a is monetary charge; x_a is agent count; condition τ_a = 0 enforced by definition for constant c_a.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.37330153584480286, "C_acc": 0.3646984100341797, "G_acc": 0.5628153057768941, "D_acc": 0.6500350879505277, "H_acc": 0.15528923273086548, "Q_acc": 0.5660919342190027, "E_rej": 0.37152108550071716, "C_rej": 0.38958361744880676, "G_rej": 0.5687235929071903, "D_rej": 0.5383337959647179, "H_rej": 0.46166620403528214, "Q_rej": 0.5087844595313072, "Delta_Q": 0.05730747468769548, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding if a wet road will refreeze overnight by reasoning from temperature trends, wind, humidity, and heat capacity of the ground", "ancestors": ["[DEF] Let T(t) be the road surface temperature at time t.", "[VAR] Let T_air(t) be the ambient air temperature at time t.", "[LAW] T(t+Δt) = T(t) + (ΔQ / C) where ΔQ is net heat flux into the road surface layer and C is its heat capacity per unit area.", "[VAR] Let Q_out(t) = h (T(t) − T_air(t)) + εσT(t)^4 be the total heat loss rate by convection and long-wave radiation.", "[VAR] Let Q_in(t) = Q_sw(t) + Q_lw_down(t) be the heat gain rate from absorbed solar and incoming long-wave radiation.", "[CONSTRAINT] Refreeze occurs if T(t) ≤ 0 °C for some t after initial wetting.", "[LIMIT] Q_out(t) − Q_in(t) > C (T(t) − 0)/Δt is required for T(t+Δt) ≤ 0 °C when T(t) > 0 °C."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If T(t) > 0 °C and Q_out(t) − Q_in(t) > C·T(t)/Δt, then T(t+Δt) ≤ 0 °C.  \nASSUMPTION: None  \nVERIFICATION: Units consistent: (W m⁻²) > (J m⁻² K⁻¹)·K / s → W m⁻² > W m⁻²; inequality testable via measured fluxes and known C/Δt.", "rejected": "HYPOTHESIS: If T(t) > 0 °C and Q_out(t) − Q_in(t) is independent of T(t), then T(t+Δt) ≤ 0 °C.", "E_acc": 0.1336681991815567, "C_acc": 0.7085115313529968, "G_acc": 0.5441894065588713, "D_acc": 0.58785733836703, "H_acc": 0.30569133162498474, "Q_acc": 0.39423836930654943, "E_rej": 0.25488415360450745, "C_rej": 0.5224218368530273, "G_rej": 0.5471925836754963, "D_rej": 0.6799452006816864, "H_rej": 0.3200547993183136, "Q_rej": 0.48540295565035196, "Delta_Q": -0.09116458634380253, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["[DEF] A model M maps input x to output y.", "[VAR] Let P(x) denote the plausibility of x.", "[VAR] Let L(M(x),y) denote the 0–1 loss of M on (x,y).", "[CONSTRAINT] The adversary chooses a distribution Q(x) such that the support of Q is contained in the support of P.", "[DEF] The failure probability under Q is E_Q[L(M(x),y)].", "[CONSTRAINT] The Kullback–Leibler divergence KL(Q‖P) ≤ ε for a given ε ≥ 0.", "[LAW] Maximizing E_Q[L(M(x),y)] subject to KL(Q‖P) ≤ ε yields the closed-form solution Q*(x) ∝ P(x) exp(α L(M(x),y)) with α chosen so that KL(Q*‖P)=ε.", "[LIMIT] As ε→0, Q* converges weakly to P."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any ε>0, the worst-case failure probability under Q* equals E_P[L(M(x),y) exp(α L(M(x),y))]/E_P[exp(α L(M(x),y))] with α>0 set by KL(Q*‖P)=ε.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless probability; regime ε>0; testable via empirical expectation under P.", "rejected": "For any ε>0, the worst-case failure probability under Q* equals E_P[L(M(x),y) exp(-α L(M(x),y))]/E_P[exp(-α L(M(x),y))] with α>0 set by KL(Q*‖P)=ε.", "E_acc": 0.27296459674835205, "C_acc": 0.46598732471466064, "G_acc": 0.5409495930653065, "D_acc": 0.6721461424604058, "H_acc": 0.17865678668022156, "Q_acc": 0.5134453825186938, "E_rej": 0.438813179731369, "C_rej": 0.2769771218299866, "G_rej": 0.5488639562390745, "D_rej": 0.8459963202476501, "H_rej": 0.15400367975234985, "Q_rej": 0.6398202168755234, "Delta_Q": -0.1263748343568296, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Value alignment under ambiguous instructions: synthesize policies that generalize human intent when the utility function is partially specified.", "ancestors": ["[DEF] Let H be the set of all possible human intents.", "[DEF] Let P be the set of all policies.", "[DEF] Let U be a partial function U: H → ℝ.", "[DEF] Let A be the ambiguity set A = {h ∈ H : U(h) undefined}.", "[VAR] Let π* be the policy selected by the agent.", "[CONSTRAINT] For every h ∈ H \\ A, π* maximizes U(h).", "[LIMIT] No policy π ∈ P can be evaluated on any h ∈ A by U.", "[LAW] For every h ∈ A, π* must equal argmax_{π ∈ P} R(h,π) for some R: H × P → ℝ independent of U."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: For every h ∈ A, π* equals argmax_{π ∈ P} R(h,π) with R(h,π) = −∞ for all π ≠ π₀(h) for some π₀(h) ∈ P.  \nASSUMPTION: R is chosen so that π₀(h) is unique for each h ∈ A.  \nVERIFICATION: Units: R in ℝ; regime: h ∈ A; test by checking π* = π₀(h) for each h ∈ A.", "rejected": "For every h ∈ A, π* equals argmax_{π ∈ P} R(h,π) with R(h,π) = U(h) for all π ∈ P.", "E_acc": 0.4510621726512909, "C_acc": 0.27630850672721863, "G_acc": 0.5370700326748192, "D_acc": 0.6932335030287504, "H_acc": 0.2487475574016571, "Q_acc": 0.6012429018504919, "E_rej": 0.26884180307388306, "C_rej": 0.5347166061401367, "G_rej": 0.5262724554049782, "D_rej": 0.7910667061805725, "H_rej": 0.2089332938194275, "Q_rej": 0.516283722629305, "Delta_Q": 0.0849591792211869, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit instance is a tuple (A, R) with finite action set A and reward distribution R(a) for each a ∈ A.", "[VAR] Let τ(a) ∈ ℕ denote the unknown, arm-specific delay between taking action a and observing any reward drawn from R(a).", "[VAR] Let C(t) ∈ {0,1} indicate whether a reward that arrived at global time t is censored (1) or fully observed (0).", "[CONSTRAINT] An arm a is identifiable only if the uncensored sample set {r : C(t)=0 and action=a} is non-empty.", "[LAW] The posterior mean reward estimate μ̂_t(a) updates via Bayes’ rule on every observation that satisfies C(t)=0.", "[LIMIT] No estimator can distinguish the best arm from sub-optimal ones with finite samples if τ(a)=∞ for all a.", "[DEF] A policy π is a measurable mapping from history H_t to a probability distribution over A.", "[CONSTRAINT] A policy π is exploration-calibrated if for every a and t, P(π(H_t)=a) ≥ δ/√t for a fixed δ>0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If τ(a)=∞ for every arm a, then no policy π can be exploration-calibrated.\nASSUMPTION: None\nVERIFICATION: Finite-sample regime; the LIMIT premise blocks any finite-sample identifiability, contradicting the δ/√t lower bound required by exploration-calibration.", "rejected": "If τ(a)=∞ for every arm a, then no policy π can be exploration-calibrated when t<0.", "E_acc": 0.32282671332359314, "C_acc": 0.4029258191585541, "G_acc": 0.5414409120567143, "D_acc": 0.6605576202273369, "H_acc": 0.18126559257507324, "Q_acc": 0.5385359973646701, "E_rej": 0.22885148227214813, "C_rej": 0.48932236433029175, "G_rej": 0.5414528924738988, "D_rej": 0.7762251198291779, "H_rej": 0.22377488017082214, "Q_rej": 0.5119490862591193, "Delta_Q": 0.02658691110555078, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["[DEF] A family F is a set whose elements are sets.", "[VAR] Let n = |F|.", "[VAR] Let k = max_{A∈F}|A|.", "[CONSTRAINT] For every distinct A,B ∈ F, |A ∩ B| ≤ t.", "[DEF] A constructive algorithm outputs an explicit set system F′ satisfying the same constraints as F.", "[LIMIT] The maximum number of sets in F is bounded above by the Fisher-type bound B(n,k,t).", "[VAR] Let c be the bit-length of the output description of F′.", "[LIMIT] c ≥ log₂|F′|."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Any explicit description of F′ must occupy at least log₂|F′| bits.\nASSUMPTION: None\nVERIFICATION: Direct from LIMIT c ≥ log₂|F′| with c measured in bits.", "rejected": "Any explicit description of F′ must occupy at least log₂|F′| bytes.", "E_acc": 0.4112389385700226, "C_acc": 0.3342520594596863, "G_acc": 0.5331149073317647, "D_acc": 0.6528751160949469, "H_acc": 0.3299268148839474, "Q_acc": 0.5607265928760171, "E_rej": 0.5495563745498657, "C_rej": 0.1354854255914688, "G_rej": 0.5471060143318027, "D_rej": 0.6902623623609543, "H_rej": 0.38717204704880714, "Q_rej": 0.6465262978803366, "Delta_Q": -0.08579970500431944, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a team will cooperate or fragment under pressure by reasoning from incentive alignment, leadership signals, and past stress responses", "ancestors": ["[DEF] Let A be the set of team members.", "[DEF] Let I(a) be the incentive vector of member a ∈ A.", "[DEF] Let L be the leadership signal vector emitted to A.", "[DEF] Let S(a) be the stress-response vector of member a ∈ A recorded under prior pressure.", "[VAR] Let C be the cooperation state of A.", "[VAR] Let F be the fragmentation state of A.", "[CONSTRAINT] C and F partition the state space of A.", "[LIMIT] No state of A exists outside {C, F}."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: For every a ∈ A, if I(a) = 0 then S(a) is undefined.  \nASSUMPTION: The incentive vector I(a) being zero implies no prior pressure was applied to member a.  \nVERIFICATION: N/A", "rejected": "For every a ∈ A, if I(a) = 0 then S(a) is independent of L.", "E_acc": 0.23142468929290771, "C_acc": 0.35453927516937256, "G_acc": 0.5346387960404778, "D_acc": 0.6201003221794963, "H_acc": 0.2800051122903824, "Q_acc": 0.5014668641689544, "E_rej": 0.13163256645202637, "C_rej": 0.4702775180339813, "G_rej": 0.5091848195297644, "D_rej": 0.5924341827630997, "H_rej": 0.40756581723690033, "Q_rej": 0.4250014850636944, "Delta_Q": 0.07646537910525997, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Common-pool resource harvesting with delayed punishment: design enforcement schemes that stabilize cooperation despite monitoring noise.Trade-offs between fairness metrics: show impossibility results when multiple fairness criteria and calibration requirements are simultaneously enforced.", "ancestors": ["[DEF] A common-pool resource is a subtractable good whose exclusion cost exceeds its per-unit value.", "[VAR] Let n denote the finite set of harvesters.", "[VAR] Let e(t) be the aggregate extraction at discrete time t.", "[VAR] Let s(t) be the monitored signal of e(t) with additive zero-mean noise ε(t).", "[VAR] Let p(t)=max(0, s(t−k)−T) be the punishment imposed k periods after observation with threshold T.", "[CONSTRAINT] A scheme is stable if the repeated-game strategy profile where every harvester i chooses the socially desired extraction e_i* given p(t) is a subgame-perfect equilibrium.", "[LIMIT] For any noise distribution of ε(t) with positive variance, no linear punishment rule p(t) can simultaneously satisfy budget balance E[p(t)]=0 and exact fairness E[p_i(t)|e_i=e_i*]=0 for every i.", "[LIMIT] If the enforcement rule must be calibrated such that E[p_i(t)|e_i]=0 whenever e_i≤e_i*, then for any two distinct fairness criteria F1 and F2 there exists no rule that satisfies F1, F2, and calibration with probability 1 under noisy monitoring.", "[LIMIT] When k>0 and ε(t) is non-degenerate, every stable scheme exhibits strictly positive expected punishment for at least one harvester whose extraction equals the socially desired level."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: For any stable scheme under non-degenerate noise with k>0, the expected punishment for at least one harvester i with e_i=e_i* is strictly positive.  \nASSUMPTION: None  \nVERIFICATION: Direct restatement of last LIMIT premise; units: expected punishment magnitude; regime: stable repeated-game equilibrium under noisy monitoring.", "rejected": "For any stable scheme under non-degenerate noise with k>0, the expected punishment for at least one harvester i with e_i=e_i* is strictly negative.", "E_acc": 0.3220292329788208, "C_acc": 0.372988224029541, "G_acc": 0.5735083273611963, "D_acc": 0.6665825941599905, "H_acc": 0.1377812922000885, "Q_acc": 0.5562511801719665, "E_rej": 0.15119262039661407, "C_rej": 0.5872533321380615, "G_rej": 0.5718544748960994, "D_rej": 0.8140661716461182, "H_rej": 0.18593382835388184, "Q_rej": 0.48649786616442725, "Delta_Q": 0.06975331400753926, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["[DEF] A state space is the set S.", "[DEF] An action space is the set A.", "[DEF] A policy π is a mapping S×A→[0,1] with ∑_{a}π(s,a)=1.", "[VAR] Let P denote the source transition kernel S×A→Δ(S).", "[VAR] Let P′ denote the target transition kernel S×A→Δ(S).", "[VAR] Let dπP be the stationary state distribution induced by π under P.", "[VAR] Let dπP′ be the stationary state distribution induced by π under P′.", "[DEF] Covariate shift is the condition P′(s′|s,a)=P(s′|s,a) for all (s,a,s′).", "[CONSTRAINT] The density ratio w(s)=dπP′(s)/dπP(s) is bounded by B<∞ for every s∈S.", "[LIMIT] The absolute error of off-policy value estimates is bounded by 2γB/(1−γ)2·maxs|dπP′(s)−dπP(s)|."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: Under covariate shift, the stationary state distributions coincide, so dπP′(s)=dπP(s) and the density ratio w(s)=1 for every s∈S.  \nASSUMPTION: None  \nVERIFICATION: Direct from definitions: covariate shift fixes P′=P, hence the Markov chains and their stationary distributions are identical; w(s)=1 satisfies the bound B=1<∞.", "rejected": "Under covariate shift, if dπP′(s)=dπP(s) and the density ratio w(s)=1 for every s∈S, then covariate shift holds.", "E_acc": 0.1304624378681183, "C_acc": 0.7342198491096497, "G_acc": 0.5362003261689097, "D_acc": 0.6714726301725022, "H_acc": 0.17417460680007935, "Q_acc": 0.41641189212678, "E_rej": 0.19052526354789734, "C_rej": 0.6303136944770813, "G_rej": 0.5384995567437727, "D_rej": 0.7677251696586609, "H_rej": 0.2322748303413391, "Q_rej": 0.46911230241530577, "Delta_Q": -0.05270041028852579, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["[DEF] A program p is a finite string in a countable set P.", "[DEF] An example e is an ordered pair (i,o) with i∈I and o∈O.", "[DEF] A set E of examples is finite.", "[DEF] Program p is consistent with E iff ∀(i,o)∈E, p(i)=o.", "[VAR] Let c(p) denote the description length of p under a fixed universal prefix-free code.", "[CONSTRAINT] The inferred program p* satisfies p* ∈ argmin{c(p) : p consistent with E}.", "[LIMIT] For any finite E, the set {p∈P : p consistent with E ∧ c(p)≤k} is finite for every k∈ℕ.", "[LAW] For any distribution D on I×O, the true risk R(p)=Pr_{(i,o)∼D}[p(i)≠o] obeys ∀δ∈(0,1), Pr_{E∼D^m}[R(p*)≤ε(m,|E|,δ)]≥1−δ, where ε is a monotonically decreasing function of |E|."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every finite E, the set of candidate programs consistent with E and having minimal description length is finite.\nASSUMPTION: None\nVERIFICATION: Follows directly from LIMIT with k = c(p*) where p* is any minimizer.", "rejected": "For every finite E, the set of all programs p consistent with E and having minimal description length is finite.", "E_acc": 0.33607640862464905, "C_acc": 0.4764429032802582, "G_acc": 0.5587863581022248, "D_acc": 0.6697385739535093, "H_acc": 0.15675005316734314, "Q_acc": 0.5355643230257556, "E_rej": 0.6335280537605286, "C_rej": 0.17051875591278076, "G_rej": 0.5469968349061674, "D_rej": 0.8203604519367218, "H_rej": 0.1796395480632782, "Q_rej": 0.7114621675078525, "Delta_Q": -0.1758978444820969, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["[DEF] A closed finite system has constant total energy E and fixed particle number N.", "[VAR] Let Γ denote the 6N-dimensional phase space point (q,p).", "[VAR] Let H(Γ) be the Hamiltonian with H(Γ)=E.", "[LAW] Hamiltonian evolution preserves phase-space volume: dΓ/dt=0.", "[VAR] Define the coarse-grained entropy S_c(t)=k_B ln Ω_c(t), where Ω_c(t) counts the phase-space volume of the macrostate.", "[CONSTRAINT] A macrostate partitions Γ into cells of fixed coarse-grained observables.", "[VAR] Let τ_e be the ergodic mixing time for typical initial Γ.", "[LIMIT] For t≫τ_e, Ω_c(t) approaches the maximum compatible with E and N.", "[DEF] Apparent irreversibility is the monotonic increase of S_c(t) up to fluctuations of order √N."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For t≫τ_e, the coarse-grained entropy satisfies S_c(t) ≥ S_c(0) up to fluctuations of order √N.\nASSUMPTION: None\nVERIFICATION: Units: k_B ln(dimensionless volume ratio); regime: t≫τ_e; testable by tracking Ω_c(t).", "rejected": "For t≫τ_e, the coarse-grained entropy satisfies S_c(t) ≥ S_c(0) up to fluctuations of order N.", "E_acc": 0.24975436925888062, "C_acc": 0.4543086290359497, "G_acc": 0.5294600731576793, "D_acc": 0.6425395128317177, "H_acc": 0.16021516919136047, "Q_acc": 0.5024429852492176, "E_rej": 0.3316153585910797, "C_rej": 0.19298440217971802, "G_rej": 0.5321966004557908, "D_rej": 0.8235104382038116, "H_rej": 0.17648956179618835, "Q_rej": 0.614380178693682, "Delta_Q": -0.1119371934444644, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Complexity under resource restrictions: characterize how time/space trade-offs change if the input can be probed only via randomized hash queries.", "ancestors": ["[DEF] A randomized hash query returns h(x) for a uniformly random function h chosen from a family H.", "[VAR] Let c denote the number of hash queries issued by an algorithm.", "[VAR] Let t denote the worst-case running time of the algorithm.", "[VAR] Let s denote the worst-case space usage of the algorithm.", "[CONSTRAINT] The algorithm accesses the input x only through values h(x) obtained from hash queries.", "[LIMIT] For any family H with |H| ≤ 2^{poly(n)}, the probability that two distinct inputs x ≠ x' satisfy h(x)=h(x') for a random h ∈ H is at least 1/|H|.", "[LIMIT] Any algorithm that outputs f(x) with error probability < 1/2 must issue c ≥ log_{|H|}(1/(2δ)) hash queries, where δ is the maximum over x of the probability that the algorithm fails to output f(x)."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: Any algorithm that outputs f(x) with error probability < 1/2 must satisfy c ≥ log_{|H|}(1/(2δ)).  \nASSUMPTION: None  \nVERIFICATION: Directly restated from the LIMIT premise; units consistent (queries vs. probability).", "rejected": "Any algorithm that outputs f(x) with error probability < 1/2 must satisfy c ≥ log_{|H|}(1/(2δ)) assuming the hash queries are statistically independent.", "E_acc": 0.20418335497379303, "C_acc": 0.5547294616699219, "G_acc": 0.5268087391013978, "D_acc": 0.6302173972129822, "H_acc": 0.22281933575868607, "Q_acc": 0.45943240784516093, "E_rej": 0.46195563673973083, "C_rej": 0.2581050992012024, "G_rej": 0.5181205155095086, "D_rej": 0.9124832451343536, "H_rej": 0.10939594358205795, "Q_rej": 0.6621468289522455, "Delta_Q": -0.2027144211070846, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["[DEF] A module is a tuple (Σ, σ₀, →) where Σ is a finite set of states, σ₀ ∈ Σ is the initial state, and → ⊆ Σ × Σ is a deterministic transition relation.", "[DEF] A contract for a module is a pair (I, G) with I ⊆ Σ and G ⊆ Σ such that every run starting in I remains in G.", "[DEF] A conserved quantity is a function q: Σ → ℝ that is constant along every transition.", "[VAR] Let M₁, M₂ be modules with conserved quantities q₁, q₂ respectively.", "[DEF] The synchronous composition M₁‖M₂ is the module (Σ₁×Σ₂, (σ₀₁,σ₀₂), →) where (s₁,s₂)→(s′₁,s′₂) iff s₁→s′₁ and s₂→s′₂.", "[LAW] In M₁‖M₂ the function q(s₁,s₂)=q₁(s₁)+q₂(s₂) is conserved.", "[DEF] An intermittent coupling is a subset C ⊆ Σ₁×Σ₂ such that transitions occur only when the current state pair is in C.", "[CONSTRAINT] During any interval [t₀,t₁] of length Δt the coupling set C is active for a total duration ≥ Δt−τ with τ≥0.", "[LIMIT] For any observable y=αq₁+βq₂ the peak value satisfies |y(t)| ≤ |y(0)|+(|α|+|β|)τ·max|q̇₁| where q̇₁ is the rate of change of q₁ when C is inactive."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If τ = 0, then the observable y = αq₁ + βq₂ satisfies |y(t)| ≤ |y(0)| for all t ≥ 0.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless ratio; regime τ = 0; testable by checking peak deviation never exceeds initial value.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.44893398880958557, "C_acc": 0.28438547253608704, "G_acc": 0.5331039566663094, "D_acc": 0.5696759331040084, "H_acc": 0.4878207389265299, "Q_acc": 0.5495770061970688, "E_rej": 0.44893398880958557, "C_rej": 0.28438547253608704, "G_rej": 0.5931022786535323, "D_rej": 0.5767275094985962, "H_rej": 0.4232724905014038, "Q_rej": 0.5694418107159436, "Delta_Q": -0.019864804518874735, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["[DEF] A population is a finite set of individuals.", "[VAR] Let p denote the frequency of strategy A in the population.", "[VAR] Let π_A(p) and π_B(p) denote the expected payoffs to strategies A and B respectively.", "[DEF] An ESS is a strategy i such that for every mutant strategy j ≠ i there exists ε_j > 0 so that for all 0 < ε < ε_j the payoff to i in the post-mutation population exceeds that of j.", "[LAW] The replicator dynamics are given by dp/dt = p(1-p)(π_A(p) - π_B(p)).", "[CONSTRAINT] The fixation probability ρ_A of a single A mutant in a B resident population of size N is ρ_A = (1 + Σ_{k=1}^{N-1} Π_{m=1}^k (π_B(m/N)/π_A(m/N)))^{-1}.", "[LIMIT] In the limit of vanishing mutation rate μ → 0 the population spends almost all time at the ESS.", "[VAR] Let μ denote the per capita per generation probability of a mutation introducing a novel strategy.", "[DEF] A fixation path is a sequence of monomorphic population states differing by single mutant substitutions.", "[CONSTRAINT] The stationary distribution over strategies satisfies P_i = (μ N ρ_i)^{-1} / Σ_j (μ N ρ_j)^{-1}."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If π_A(p) > π_B(p) for all p ∈ (0,1), then dp/dt > 0 and strategy A fixes with probability 1.\nASSUMPTION: The population size N is sufficiently large so that the finite-N fixation probability ρ_A approaches the infinite-population limit.\nVERIFICATION: Units: payoff difference (dimensionless) drives frequency rate (1/generation); regime: infinite-N limit; test: ρ_A → 1 as N → ∞.", "rejected": "If π_A(p) > π_B(p) for all p ∈ (0,1), then dp/dt < 0 and strategy A fixes with probability 1.", "E_acc": 0.303437739610672, "C_acc": 0.3734564483165741, "G_acc": 0.5468473121291026, "D_acc": 0.677822788245976, "H_acc": 0.1760255992412567, "Q_acc": 0.5436714923707768, "E_rej": 0.3011833727359772, "C_rej": 0.4182848334312439, "G_rej": 0.5661666104570031, "D_rej": 0.727051705121994, "H_rej": 0.272948294878006, "Q_rej": 0.5380468787625432, "Delta_Q": 0.005624613608233631, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Stability of supramolecular assemblies under stochastic perturbations: determine minimal interaction network that preserves function.Signaling under noisy channels: design signals that remain informative when senders face verification costs and receivers have model uncertainty.", "ancestors": ["[DEF] A supramolecular assembly is a set of molecules held by non-covalent interactions.", "[VAR] Let N denote the number of molecules in the assembly.", "[VAR] Let E be the set of pairwise interaction energies {e_ij}.", "[DEF] A stochastic perturbation is a random change in e_ij with distribution P.", "[CONSTRAINT] The assembly remains stable if the graph (V,E) stays connected under P.", "[VAR] Let c be the minimal cardinality of a subset E'⊆E such that (V,E') is connected.", "[LIMIT] c ≥ N−1.", "[DEF] A signaling game has a sender S, a receiver R, and a state space Ω.", "[VAR] Let q be the probability that S pays cost k to verify the true state ω∈Ω.", "[CONSTRAINT] A signal s is informative if posterior belief p(ω|s) ≠ prior belief p(ω)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the stochastic perturbation P can reduce the interaction set to any subset E' with |E'| = c, then the assembly remains stable only if c ≥ N−1.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless count comparison; regime: graph connectivity under random edge removal; testable by enumerating minimal connected spanning subgraphs.", "rejected": "If c ≥ N−1, then the stochastic perturbation P can reduce the interaction set to any subset E' with |E'| = c and the assembly remains stable.", "E_acc": 0.19355560839176178, "C_acc": 0.5910817384719849, "G_acc": 0.5290666813962162, "D_acc": 0.649005901068449, "H_acc": 0.15797144174575806, "Q_acc": 0.4596677071414888, "E_rej": 0.3691566288471222, "C_rej": 0.3457314372062683, "G_rej": 0.5345282261925084, "D_rej": 0.8369526565074921, "H_rej": 0.16304734349250793, "Q_rej": 0.5995921434036323, "Delta_Q": -0.13992443626214351, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["[DEF] A population is a finite multiset of strategies.", "[VAR] Let π(s_i, s_j) denote the payoff to strategy s_i when interacting with strategy s_j.", "[DEF] The frequency-dependent fitness of strategy s is f(s) = Σ_{s′} x(s′) π(s, s′), where x(s′) is the frequency of s′.", "[DEF] A strategy s* is an ESS if for every mutant strategy m ≠ s* there exists an invasion barrier ε_m > 0 such that for all ε ∈ (0, ε_m) the post-entry fitness satisfies f(s*) > f(m).", "[CONSTRAINT] The state space is the simplex Δ = {x ∈ ℝ^{|S|} | Σ_s x(s)=1, x(s)≥0}.", "[VAR] The Moran process with mutation probability μ describes fixation probabilities ρ(s→s′) between states differing by one mutant.", "[LIMIT] In the limit of vanishing mutation μ→0, the stationary distribution concentrates on ESS support."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If a strategy s* is an ESS, then for every mutant strategy m ≠ s* there exists ε_m > 0 such that for all ε ∈ (0, ε_m) the post-entry frequency-weighted payoff difference satisfies Σ_{s′} x(s′)[π(s*,s′) − π(m,s′)] > 0.  \nASSUMPTION: None  \nVERIFICATION: Units: payoff difference per interaction; regime: post-entry population with mutant frequency ε; testable via payoff matrix and frequency vector.", "rejected": "If a strategy s* is an ESS, then for every mutant strategy m ≠ s* there exists ε_m > 0 such that for all ε ∈ (0, ε_m) the post-entry frequency-weighted payoff difference satisfies Σ_{s′} x(s′)[π(s*,s′) − π(m,s′)] > 0 in the limit of infinite mutation μ→∞.", "E_acc": 0.38825759291648865, "C_acc": 0.35177719593048096, "G_acc": 0.56131868052762, "D_acc": 0.6706229918636382, "H_acc": 0.13887205719947815, "Q_acc": 0.5786229674471541, "E_rej": 0.285576730966568, "C_rej": 0.4417571723461151, "G_rej": 0.567164238425903, "D_rej": 0.8618495464324951, "H_rej": 0.13815045356750488, "Q_rej": 0.5693092964356765, "Delta_Q": 0.00931367101147762, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether a battery will fail during peak usage by reasoning about internal resistance, heat generation, and discharge rate", "ancestors": ["[DEF] A battery is an electrochemical cell that converts stored chemical energy into electrical energy.", "[VAR] Let R denote the internal resistance of the battery.", "[VAR] Let I denote the discharge current.", "[VAR] Let P denote the Joule heating power dissipated inside the battery.", "[LAW] P = R I².", "[VAR] Let T denote the temperature of the battery.", "[CONSTRAINT] T increases monotonically with P.", "[LIMIT] The battery fails if T exceeds a fixed threshold T_max."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The battery fails if the discharge current exceeds the critical value I_crit = √(T_max / R).\nASSUMPTION: None\nVERIFICATION: Units: √(K / Ω) = A; testable by measuring I at failure.", "rejected": "The battery fails if the discharge current exceeds the critical value I_crit = √(T_max R).", "E_acc": 0.10834015160799026, "C_acc": 0.7426773309707642, "G_acc": 0.5083050797693431, "D_acc": 0.6118916100822389, "H_acc": 0.22319427132606506, "Q_acc": 0.38568649012595413, "E_rej": 0.39014214277267456, "C_rej": 0.291385680437088, "G_rej": 0.5013709357590415, "D_rej": 0.7772681713104248, "H_rej": 0.2227318286895752, "Q_rej": 0.5922201452893204, "Delta_Q": -0.2065336551633663, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Sequential delegation: when an agent delegates to subagents with private incentives, derive mechanisms that ensure near-optimal end-to-end performance.", "ancestors": ["[DEF] A principal P commissions a task chain of length T.", "[VAR] Let a_t denote the agent selected at stage t ∈ {1,…,T}.", "[VAR] Let r_t be the reward offered by a_{t-1} to a_t.", "[VAR] Let c_t be the private cost incurred by a_t.", "[CONSTRAINT] a_t accepts iff r_t ≥ c_t.", "[DEF] The chain value is V = Σ_{t=1}^{T} (v_t − r_t) with v_t the stage-t output value.", "[LIMIT] No principal or agent observes any c_t before contract offer r_t.", "[CONSTRAINT] Each r_t is chosen without commitment over future rewards."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: For every stage t, the reward r_t must satisfy r_t ≥ c_t for the task to proceed.  \nASSUMPTION: None  \nVERIFICATION: Direct restatement of CONSTRAINT; units/regime: reward ≥ cost for acceptance.", "rejected": "For every stage t, the reward r_t must satisfy r_t ≥ c_t for the task to proceed, independent of any other stage's reward.", "E_acc": 0.0852682888507843, "C_acc": 0.6759664416313171, "G_acc": 0.5991714503616095, "D_acc": 0.7039681486785412, "H_acc": 0.19554469734430313, "Q_acc": 0.4314606484025717, "E_rej": 0.05226674675941467, "C_rej": 0.7445766925811768, "G_rej": 0.6074592296499759, "D_rej": 0.8372915685176849, "H_rej": 0.20338553935289383, "Q_rej": 0.4353762912098318, "Delta_Q": -0.003915642807260089, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging if a satellite will remain in orbit or decay by reasoning from drag, altitude, mass, and atmospheric density", "ancestors": ["[DEF] A satellite is an object in closed orbit around a planet.", "[VAR] Let h denote altitude above the planet’s surface.", "[VAR] Let ρ(h) denote atmospheric mass density at altitude h.", "[VAR] Let m denote satellite mass.", "[VAR] Let A denote satellite cross-sectional area normal to velocity.", "[VAR] Let v denote satellite speed magnitude.", "[LAW] Drag force magnitude is F_d = ½ ρ(h) v² A C_d with constant C_d.", "[DEF] Orbital decay is a sustained decrease of h.", "[LAW] Mechanical energy E = ½ m v² − G M m / r with planet mass M and radial distance r = R_p + h, where R_p is planet radius.", "[LIMIT] Orbit persists only while E < 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Orbital decay occurs only while the drag force F_d = ½ ρ(h) v² A C_d acts to reduce mechanical energy E = ½ m v² − G M m / (R_p + h) below its initial negative value.\nASSUMPTION: None\nVERIFICATION: Units consistent (F_d in N, E in J); testable via measured h(t) decrease.", "rejected": "STATUS: NOT ENTAILED.", "E_acc": 0.2567375600337982, "C_acc": 0.3987765610218048, "G_acc": 0.5442742514424026, "D_acc": 0.6112272846512496, "H_acc": 0.1982438862323761, "Q_acc": 0.5085418744012714, "E_rej": 0.08736658096313477, "C_rej": 0.720258355140686, "G_rej": 0.565035100793466, "D_rej": 0.5065821902826428, "H_rej": 0.49341780971735716, "Q_rej": 0.3471399805042893, "Delta_Q": 0.16140189389698212, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["[DEF] A coalition structure is a partition of the player set N.", "[VAR] Let v(S,π) denote the worth of coalition S⊆N under structure π.", "[VAR] Let x∈ℝ^{|N|} be an imputation satisfying ∑_{i∈N}x_i = ∑_{S∈π}v(S,π).", "[CONSTRAINT] A coalition S is stable if ∀T⊆N, v(S,π) ≥ v(T,π_{S→T}).", "[DEF] The core is the set of imputations x such that ∀S⊆N, ∑_{i∈S}x_i ≥ v(S,π).", "[CONSTRAINT] An imputation x is in the core iff no coalition S has incentive to deviate under π.", "[LIMIT] The core may be empty when externalities render v(S,π) < v(S,π') for some π'≠π."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If for every coalition S the worth v(S,π) equals its stand-alone worth v(S,{S,N\\S}), then the core is nonempty.\nASSUMPTION: The stand-alone worth v(S,{S,N\\S}) is well-defined for every S⊆N.\nVERIFICATION: Testable under the regime where π is fixed and v(S,{S,N\\S}) is computable for all S.", "rejected": "HYPOTHESIS: If for every coalition S the worth v(S,π) equals its stand-alone worth v(S,{S,N\\S}), then the core is empty.", "E_acc": 0.3418368697166443, "C_acc": 0.10865134000778198, "G_acc": 0.5404388837050647, "D_acc": 0.708431314677, "H_acc": 0.15448340773582458, "Q_acc": 0.6151464918162675, "E_rej": 0.20242348313331604, "C_rej": 0.19096416234970093, "G_rej": 0.5413555330596864, "D_rej": 0.8608253002166748, "H_rej": 0.1391746997833252, "Q_rej": 0.5890529091469945, "Delta_Q": 0.026093582669272974, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["[DEF] Let H be a finite set of mutually exclusive hypotheses.", "[VAR] Let e be an experiment with possible outcomes O_e.", "[DEF] Let P(h|e) denote the posterior probability of hypothesis h∈H given outcome e.", "[DEF] Let I(e)=∑_{h∈H}P(h|e)log[P(h|e)/P(h)] be the information gain from e.", "[VAR] Let c(e)∈ℝ_{>0} be the cost of performing e.", "[DEF] Let G(e)=I(e)/c(e) be the information gain per unit cost of e.", "[CONSTRAINT] At each selection step, choose e*∈argmax_{e}G(e)."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If two experiments e₁ and e₂ have equal information gain I(e₁)=I(e₂), then the experiment with lower cost has higher gain-per-cost: c(e₁)<c(e₂) ⇒ G(e₁)>G(e₂).  \nASSUMPTION: None  \nVERIFICATION: Units: I in bits, c in cost units, G in bits per cost unit; valid for any positive costs.", "rejected": "If two experiments e₁ and e₂ have equal information gain I(e₁)=I(e₂), then the experiment with higher gain-per-cost has lower cost: G(e₁)>G(e₂) ⇒ c(e₁)<c(e₂).", "E_acc": 0.19382452964782715, "C_acc": 0.4981193542480469, "G_acc": 0.5450364558824471, "D_acc": 0.648242762312293, "H_acc": 0.16848251223564148, "Q_acc": 0.48033108046012263, "E_rej": 0.24213211238384247, "C_rej": 0.4475969076156616, "G_rej": 0.5430587915969747, "D_rej": 0.8173480331897736, "H_rej": 0.18265196681022644, "Q_rej": 0.5369364204683476, "Delta_Q": -0.056605340008224925, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transport-limited reactivity: when diffusion and surface reaction couple nonlinearly, identify regimes where modifying transport is more effective than altering surface chemistry.", "ancestors": ["[DEF] Transport-limited reactivity occurs when the overall rate is governed by the slower of diffusion to the surface and the intrinsic surface reaction rate.", "[VAR] Let c(x,t) be the concentration of the reacting species at position x and time t.", "[VAR] Let D be the diffusion coefficient of the reacting species.", "[VAR] Let k be the intrinsic first-order surface reaction rate constant.", "[LAW] The diffusive flux to the surface is given by J = -D ∂c/∂x evaluated at the surface.", "[LAW] The surface reaction rate per unit area is given by R = k c_surface.", "[CONSTRAINT] At steady state, the diffusive flux to the surface equals the surface reaction rate: J = R.", "[LIMIT] The system is diffusion-limited when k ≫ D/δ, where δ is the characteristic diffusion length.", "[LIMIT] The system is reaction-limited when D/δ ≫ k."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: At steady state, the surface concentration satisfies c_surface = (D/k) (∂c/∂x)|_surface.\nASSUMPTION: None\nVERIFICATION: Units: (m²/s)/(m/s) × (mol/m³)/m = mol/m³; valid for both diffusion- and reaction-limited regimes.", "rejected": "HYPOTHESIS: In the diffusion-limited regime, the surface concentration is given by c_surface = (k/D) (∂c/∂x)|_surface.", "E_acc": 0.3975777328014374, "C_acc": 0.36934253573417664, "G_acc": 0.538551805424504, "D_acc": 0.6141310851089656, "H_acc": 0.15758749842643738, "Q_acc": 0.5601826409576461, "E_rej": 0.4172168970108032, "C_rej": 0.3505820333957672, "G_rej": 0.538995829061605, "D_rej": 0.8319832980632782, "H_rej": 0.1680167019367218, "Q_rej": 0.612442817655392, "Delta_Q": -0.05226017669774585, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["[DEF] A family F is a set whose elements are sets.", "[VAR] Let n = |F|.", "[VAR] Let k = |A| for every A ∈ F.", "[CONSTRAINT] For every distinct A,B ∈ F, |A ∩ B| = λ.", "[DEF] A constructive bijection is an explicit algorithm that outputs an element of F in time poly(n).", "[LIMIT] The Johnson bound J(n,k,λ) = n(k−λ)/(k²−kλ) is the largest integer m such that an (n,k,λ)-system of m sets exists.", "[CONSTRAINT] For every x in the universe, the replication number r_x = |{A ∈ F : x ∈ A}| satisfies r_x ≤ J(n,k,λ)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total number of element occurrences across all sets is ∑_{x} r_x ≤ n·J(n,k,λ).\nASSUMPTION: None\nVERIFICATION: Units: counts; regime: finite family; testable by summing the replication numbers.", "rejected": "The total number of element occurrences across all sets is ∑_{x} r_x ≤ n·k·J(n,k,λ).", "E_acc": 0.25853297114372253, "C_acc": 0.4778253436088562, "G_acc": 0.5158981071726885, "D_acc": 0.6542260469868779, "H_acc": 0.24028846621513367, "Q_acc": 0.49199080683174545, "E_rej": 0.22314198315143585, "C_rej": 0.557214081287384, "G_rej": 0.5188684553140774, "D_rej": 0.7217801213264465, "H_rej": 0.27821987867355347, "Q_rej": 0.4758075061487034, "Delta_Q": 0.01618330068304208, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["[DEF] A population is a finite set of individuals.", "[DEF] Each individual carries a strategy s ∈ S.", "[DEF] The frequency of strategy s is p_s = n_s / N with n_s the count of s and N the total count.", "[VAR] The payoff to an s-strategist is π_s(p) with p = (p_s)_{s∈S}.", "[DEF] A strategy s* is an ESS if for every mutant strategy m ≠ s* there exists ε_m > 0 such that for all ε ∈ (0,ε_m) the post-entry frequency vector p' satisfies π_{s*}(p') > π_m(p').", "[LIMIT] The population size N is fixed.", "[CONSTRAINT] The sum of frequencies satisfies Σ_{s∈S} p_s = 1.", "[DEF] A mutation event introduces a single mutant strategy m ∉ S with initial frequency p_m = 1/N.", "[LAW] The deterministic replicator dynamics for strategy s is dp_s/dt = p_s(π_s(p) - φ(p)) where φ(p) = Σ_{s'∈S} p_{s'}π_{s'}(p)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: After a single-mutant introduction, the frequency of the resident strategy s* becomes p'_{s*} = (N-1)/N.\nASSUMPTION: None\nVERIFICATION: Units dimensionless; valid for fixed N ≥ 2 under the given mutation event.", "rejected": "After a single-mutant introduction, the frequency of the resident strategy s* becomes p'_{s*} = 1/N.", "E_acc": 0.3544011414051056, "C_acc": 0.33929139375686646, "G_acc": 0.5819523050449789, "D_acc": 0.6255929388571531, "H_acc": 0.19651204347610474, "Q_acc": 0.5603199081029743, "E_rej": 0.32519441843032837, "C_rej": 0.5019447207450867, "G_rej": 0.5961353350430727, "D_rej": 0.8119949102401733, "H_rej": 0.18800508975982666, "Q_rej": 0.5599949214607478, "Delta_Q": 0.0003249866422264658, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["[DEF] Biomass B is a non-negative real-valued quantity.", "[VAR] Resource input rate R(t) is a non-negative real-valued function of time t.", "[VAR] Metabolic pathway p is an element of the discrete set {1,2,…,n}.", "[DEF] Switching cost c_{i→j} is a non-negative real number for every ordered pair (i,j)∈{1,2,…,n}×{1,2,…,n}.", "[CONSTRAINT] The time derivative of biomass satisfies dB/dt = f_p(R(t)) whenever pathway p is active, with f_p a real-valued function.", "[CONSTRAINT] A pathway switch from i to j incurs an instantaneous biomass reduction of c_{i→j}.", "[LIMIT] The long-run average biomass rate is lim_{T→∞} (1/T)[B(T) − Σ c_{i→j}N_{i→j}(T)], where N_{i→j}(T) counts switches from i to j in [0,T]."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If the long-run average biomass rate is strictly positive, then the total biomass gain from metabolic uptake must asymptotically exceed the total biomass lost to switching.\nASSUMPTION: The limit lim_{T→∞} (1/T)Σ c_{i→j}N_{i→j}(T) exists and is finite.\nVERIFICATION: Units: biomass/time; testable by comparing asymptotic slope of B(T) versus cumulative switching loss.", "rejected": "STATUS: ENTAILED_WITH_ASSUMPTION.", "E_acc": 0.11794135719537735, "C_acc": 0.4835568070411682, "G_acc": 0.5752901433734223, "D_acc": 0.70524633070454, "H_acc": 0.18070362508296967, "Q_acc": 0.47670797805767506, "E_rej": 0.045397866517305374, "C_rej": 0.5966300964355469, "G_rej": 0.5369700274895877, "D_rej": 0.5079788975417614, "H_rej": 0.4920211024582386, "Q_rej": 0.3540810154285282, "Delta_Q": 0.12262696262914685, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] A symbolic expression is a finite tree of operators and operands.", "[VAR] Let E denote a symbolic expression.", "[DEF] A simplification step is a rewrite E → E′ with ⟦E⟧ = ⟦E′⟧.", "[VAR] Let P be a proof object encoding a chain of simplification steps.", "[DEF] A certificate is a compact bit string c that certifies property φ.", "[VAR] Let B be a low-level program.", "[DEF] A loop invariant I is an assertion attached to a loop header.", "[CONSTRAINT] Every loop in B must have an invariant I.", "[LIMIT] The size of c is O(|B|) bits."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Every loop in B has an associated bit string c of size O(|B|) that certifies its invariant I.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "Every loop in B has an associated bit string c of size O(|I|) that certifies its invariant I.", "E_acc": 0.4783167243003845, "C_acc": 0.35909906029701233, "G_acc": 0.5381513006453004, "D_acc": 0.6403353866189718, "H_acc": 0.22635489702224731, "Q_acc": 0.5847370529813426, "E_rej": 0.630702555179596, "C_rej": 0.23916487395763397, "G_rej": 0.5378466601749616, "D_rej": 0.7607579529285431, "H_rej": 0.2392420470714569, "Q_rej": 0.6771745096759073, "Delta_Q": -0.09243745669456471, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Common-pool resource harvesting with delayed punishment: design enforcement schemes that stabilize cooperation despite monitoring noise.Trade-offs between fairness metrics: show impossibility results when multiple fairness criteria and calibration requirements are simultaneously enforced.", "ancestors": ["[DEF] A common-pool resource is a subtractable good whose units are harvested by multiple agents.", "[VAR] Let c denote the per-unit harvest cost.", "[VAR] Let t denote the monitoring interval length.", "[VAR] Let B denote the baseline stock level.", "[VAR] Let R denote the regeneration rate.", "[CONSTRAINT] Harvest at any instant is bounded above by B.", "[CONSTRAINT] Punishment is applied only after a delay of t.", "[LIMIT] Monitoring noise variance is strictly positive.", "[LIMIT] No enforcement scheme can simultaneously satisfy ex-ante equal expected utility, ex-post equal sanction probability, and calibrated punishment magnitude.", "[LIMIT] For any noise distribution with finite support, the maximum achievable cooperation level is strictly below the social optimum."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: For any monitoring interval length t>0, the maximum achievable cooperation level is strictly below the social optimum.  \nASSUMPTION: None  \nVERIFICATION: Units: t in time, cooperation level dimensionless; follows directly from [LIMIT] “maximum achievable cooperation level is strictly below the social optimum” under any finite-support noise, independent of t.", "rejected": "For any monitoring interval length t>0, the social optimum is strictly below the maximum achievable cooperation level.", "E_acc": 0.3189099133014679, "C_acc": 0.4415212571620941, "G_acc": 0.5598809514194727, "D_acc": 0.6768119102343917, "H_acc": 0.1831078827381134, "Q_acc": 0.5363965066149832, "E_rej": 0.22959628701210022, "C_rej": 0.6032963991165161, "G_rej": 0.5550964960129932, "D_rej": 0.7868573069572449, "H_rej": 0.21314269304275513, "Q_rej": 0.49529609757009896, "Delta_Q": 0.04110040904488421, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["[DEF] A coalition structure is a partition of the player set N.", "[VAR] Let v(S,Π) denote the worth of coalition S⊆N under structure Π.", "[VAR] Let x∈ℝ^{|N|} be an imputation satisfying ∑_{i∈N}x_i = ∑_{S∈Π}v(S,Π).", "[CONSTRAINT] A coalition S is stable if ∀T⊆N, v(S,Π) ≥ v(T,Π_{S→T}).", "[DEF] The core is the set of imputations x such that ∀S⊆N, ∑_{i∈S}x_i ≥ v(S,Π).", "[LIMIT] The core may be empty when externalities are present.", "[LAW] An allocation x is in the core iff no coalition can improve its total payoff by deviating."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If the core is non-empty, then every coalition S satisfies v(S,Π) ≤ ∑_{i∈S}x_i for the imputation x in the core.  \nASSUMPTION: The core being non-empty guarantees existence of at least one such imputation x.  \nVERIFICATION: Units: worth v in same payoff units as imputation x; inequality testable via summing x_i over S.", "rejected": "HYPOTHESIS: If the core is non-empty, then every coalition S satisfies v(S,Π) ≥ ∑_{i∈S}x_i for the imputation x in the core.", "E_acc": 0.24130196869373322, "C_acc": 0.4760264754295349, "G_acc": 0.5371739757247269, "D_acc": 0.758256109431386, "H_acc": 0.1419498771429062, "Q_acc": 0.522076324839145, "E_rej": 0.08106406033039093, "C_rej": 0.6822451949119568, "G_rej": 0.5355913620442152, "D_rej": 0.9069910049438477, "H_rej": 0.09300899505615234, "Q_rej": 0.4670857530087233, "Delta_Q": 0.05499057183042172, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Hierarchical goal decomposition with conflicting subgoals: synthesize a scheduler that resolves conflicts while guaranteeing progress on at least one top-level objective.", "ancestors": ["[DEF] A hierarchy H is a finite poset of goals.", "[VAR] Let G be the set of top-level goals in H.", "[VAR] Let S be the set of subgoals of any g ∈ G.", "[CONSTRAINT] For any g ∈ G, every s ∈ S must satisfy s ≤ g in H.", "[DEF] A conflict relation C ⊆ S × S is symmetric and irreflexive.", "[DEF] A scheduler is a function σ: 2^S → S ∪ {⊥} selecting an enabled subgoal or declaring deadlock.", "[LAW] σ is enabled on T ⊆ S iff T contains no pair in C.", "[CONSTRAINT] σ guarantees progress if for every g ∈ G, σ eventually selects some s ≤ g."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every g ∈ G, the set {s ∈ S : s ≤ g} is not contained in any conflict pair of C.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "For every g ∈ G, the set {s ∈ S : s ≤ g} is equal to the cardinality of any conflict pair of C.", "E_acc": 0.4061785042285919, "C_acc": 0.31280750036239624, "G_acc": 0.5406444794498384, "D_acc": 0.6251350240781903, "H_acc": 0.21653872728347778, "Q_acc": 0.5707940791733563, "E_rej": 0.22189611196517944, "C_rej": 0.5121845602989197, "G_rej": 0.5468017937770734, "D_rej": 0.7688301801681519, "H_rej": 0.23116981983184814, "Q_rej": 0.5041413343356301, "Delta_Q": 0.06665274483772621, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] A symbolic expression e is a finite tree of operators and operands.", "[VAR] Let s(e) denote a simplification mapping e → e′.", "[DEF] A certificate c is a machine-verifiable data object.", "[DEF] A proof object p is a certificate that encodes a derivation ⊢ e = e′.", "[CONSTRAINT] s(e) must satisfy ⊢ e = s(e).", "[VAR] Let B(p) denote the bit-length of p.", "[LIMIT] For every e there exists p with B(p) ∈ O(n log n), where n is the node count of e."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every symbolic expression e, the bit-length of any proof object p that certifies ⊢ e = s(e) is in O(n log n), where n is the node count of e.\nASSUMPTION: None\nVERIFICATION: Units: bits; regime: all finite trees e; testable by node-counting and bit-length measurement.", "rejected": "For every symbolic expression e, the bit-length of every proof object p that certifies ⊢ e = s(e) is in O(n log n), where n is the node count of e.", "E_acc": 0.5085533261299133, "C_acc": 0.23871387541294098, "G_acc": 0.5322571521004041, "D_acc": 0.7155648078769445, "H_acc": 0.1398938000202179, "Q_acc": 0.6403982347498337, "E_rej": 0.7686362266540527, "C_rej": 0.12118781358003616, "G_rej": 0.5360356050853928, "D_rej": 0.8936794996261597, "H_rej": 0.10632050037384033, "Q_rej": 0.7816642761851351, "Delta_Q": -0.14126604143530141, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding if a sudden drop in workplace productivity is caused by burnout, unclear incentives, or external stressors using observed behavior patterns", "ancestors": ["[DEF] A behavior pattern is a finite sequence of observations.", "[VAR] Let P be a productivity metric.", "[VAR] Let B be a burnout indicator.", "[VAR] Let I be an incentive clarity indicator.", "[VAR] Let E be an external stressor indicator.", "[CONSTRAINT] A sudden drop in P occurs at a single time t.", "[DEF] A cause is a variable whose change precedes the change in P.", "[LIMIT] Only B, I, and E are candidate causes for the drop in P.", "[LAW] If B changes before t then B is recorded in the behavior pattern."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If B is recorded in the behavior pattern then B changed before t.  \nASSUMPTION: None  \nVERIFICATION: N/A", "rejected": "If B is recorded in the behavior pattern then B changed after t.", "E_acc": 0.1771860420703888, "C_acc": 0.6832695007324219, "G_acc": 0.5447684012469836, "D_acc": 0.6207341928966343, "H_acc": 0.25461387634277344, "Q_acc": 0.42414104366907857, "E_rej": 0.0571293942630291, "C_rej": 0.8000711798667908, "G_rej": 0.5381795212160796, "D_rej": 0.7755082249641418, "H_rej": 0.22449177503585815, "Q_rej": 0.39741295403800914, "Delta_Q": 0.02672808963106943, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Market microstructure and information asymmetry: model how order flow reveals private valuations and derive optimal inference filters.", "ancestors": ["[DEF] Order flow is the signed transaction volume Δx_t at time t.", "[VAR] Private valuation v_t is known only to the informed trader.", "[VAR] Public price p_t is known to all market participants.", "[DEF] Net order imbalance is y_t = Σ_{τ≤t} Δx_τ.", "[LAW] Bayesian updating gives E[v_t | y_t] = ∫ v_t f(v_t | y_t) dv_t.", "[CONSTRAINT] f(v_t | y_t) ∝ f(y_t | v_t) f(v_t).", "[LIMIT] f(y_t | v_t) is Gaussian with mean μ(v_t) and variance σ²."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The posterior mean E[v_t | y_t] is a strictly increasing function of the net order imbalance y_t.\nASSUMPTION: None\nVERIFICATION: Units: price per share; regime: Gaussian likelihood with mean μ(v_t) monotonic in v_t; testable via positive correlation between y_t and posterior mean estimate.", "rejected": "The posterior variance Var[v_t | y_t] is a strictly increasing function of the net order imbalance y_t.", "E_acc": 0.26237526535987854, "C_acc": 0.4750155210494995, "G_acc": 0.5750188207020983, "D_acc": 0.6915923077613115, "H_acc": 0.14733436703681946, "Q_acc": 0.5222982643870637, "E_rej": 0.1408906728029251, "C_rej": 0.41897591948509216, "G_rej": 0.5761501662200317, "D_rej": 0.8208864033222198, "H_rej": 0.17911359667778015, "Q_rej": 0.5199679721845314, "Delta_Q": 0.002330292202532336, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Nested quantifiers and resource bounds: given ∀x∃y P(x,y) and a monotone cost for producing y, derive feasible constructive strategies and failure modes.", "ancestors": ["[DEF] ∀x∃y P(x,y).", "[DEF] c: ℕ → ℕ is monotone.", "[VAR] x ranges over the domain of P.", "[VAR] y ranges over the codomain of P.", "[CONSTRAINT] For each x, y must satisfy P(x,y).", "[CONSTRAINT] For each x, the chosen y must satisfy c(y) ≤ B where B ∈ ℕ.", "[LIMIT] There exists no y such that P(x,y) ∧ c(y) ≤ B for some x.", "[DEF] A strategy is a computable function S(x) = y.", "[LIMIT] No computable S satisfies ∀x P(x,S(x)) ∧ c(S(x)) ≤ B.", "[LIMIT] For any computable S, the set {x | ¬P(x,S(x)) ∨ c(S(x)) > B} is infinite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every computable strategy S, the set {x | c(S(x)) > B} is infinite.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "For every computable strategy S, if the set {x | c(S(x)) > B} is infinite then S is computable.", "E_acc": 0.026724843308329582, "C_acc": 0.9315539598464966, "G_acc": 0.5339605907377388, "D_acc": 0.6253045218763873, "H_acc": 0.12540507316589355, "Q_acc": 0.34101917622943545, "E_rej": 0.021335141733288765, "C_rej": 0.9453375935554504, "G_rej": 0.5177856876647898, "D_rej": 0.8761040568351746, "H_rej": 0.12389594316482544, "Q_rej": 0.3837213783924069, "Delta_Q": -0.04270220216297144, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Counterfactual attribution: given two outcomes under different interventions, identify the minimal set of causal changes explaining the difference.", "ancestors": ["[DEF] A counterfactual difference ΔY is the scalar difference Y₁−Y₀ between outcomes under interventions do(X=x₁) and do(X=x₀).", "[VAR] Let G be a directed acyclic graph whose vertices are variables and whose edges represent direct causal relations.", "[VAR] Let Pa(V) denote the set of vertices with edges terminating at V in G.", "[VAR] Let Yₓ(u) be the potential response of Y when X is fixed to x and background variables U take realisation u.", "[DEF] A minimal counterfactual explanation for ΔY is a set S⊆V\\{Y} such that Y₁(u)=Y₀(u) for every u consistent with do(S=s) for some s.", "[LAW] For any variable V, V(u)=f_V(Pa(V)(u),u_V) where f_V is a deterministic function and u_V is the exogenous component of u.", "[CONSTRAINT] The set S is minimal if no proper subset of S satisfies the equality Y₁(u)=Y₀(u) under the same conditions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If S is a minimal counterfactual explanation for ΔY, then for every V in S there exists some u consistent with do(S\\V=s') such that Y₁(u)≠Y₀(u).\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If S is a minimal counterfactual explanation for ΔY, then for every V in S there exists some u consistent with do(S\\V=s') such that Y₁(u)=Y₀(u).", "E_acc": 0.36957842111587524, "C_acc": 0.38660135865211487, "G_acc": 0.5515107223764062, "D_acc": 0.6293637747876346, "H_acc": 0.17436131834983826, "Q_acc": 0.5522920222021639, "E_rej": 0.49051350355148315, "C_rej": 0.25903061032295227, "G_rej": 0.5540210432664026, "D_rej": 0.8148908317089081, "H_rej": 0.18510916829109192, "Q_rej": 0.6506193871668073, "Delta_Q": -0.09832736496464345, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["[DEF] A family F is a set whose elements are sets.", "[VAR] Let n denote |F|.", "[VAR] Let k denote max_{A∈F}|A|.", "[CONSTRAINT] For every A,B∈F, |A∩B|≤t.", "[DEF] An explicit object is a data structure that outputs a member of F in O(1) time per query.", "[LIMIT] The extremal bound is the maximum possible |F| under the given constraints.", "[DEF] A constructive algorithm produces an explicit object in time polynomial in n and k.", "[LAW] The sunflower lemma states that any family of sets of size s with more than s!(t+1)^s members contains a sunflower of size t+2."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If n > k!(t+1)^k, then F must contain a sunflower of size t+2.  \nASSUMPTION: Every member of F has size exactly k.  \nVERIFICATION: Units: dimensionless; regime: set-system with max set size k; test via counting n against k!(t+1)^k.", "rejected": "If n > k!(t+1)^k, then F must contain a sunflower of size k+2.", "E_acc": 0.4397052526473999, "C_acc": 0.28671321272850037, "G_acc": 0.5433568185544573, "D_acc": 0.6768505144864321, "H_acc": 0.2580469846725464, "Q_acc": 0.5928057013894432, "E_rej": 0.36717116832733154, "C_rej": 0.41301366686820984, "G_rej": 0.5549650138709694, "D_rej": 0.7335708886384964, "H_rej": 0.3330363892018795, "Q_rej": 0.5519521587062627, "Delta_Q": 0.04085354268318053, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["[DEF] A node set V indexes the time series.", "[VAR] For each v ∈ V, x_v(t) ∈ ℝ is the value at discrete time t ∈ ℤ.", "[VAR] The lag operator L_τ x_v(t) = x_v(t − τ) for τ ∈ ℕ.", "[DEF] A directed edge (u → v) with delay d_{uv} ∈ ℕ exists if x_u(t − d_{uv}) enters the structural equation of x_v(t).", "[CONSTRAINT] The edge set forms a directed graph G = (V, E) with |E| minimal among all graphs whose delay-weighted cycles satisfy the observed phase relations.", "[LIMIT] The phase relation between x_u and x_v is identifiable only up to an integer multiple of 2π in the argument of their cross-spectrum.", "[LAW] For every directed cycle γ in G, the sum of delays along γ equals the observed phase shift (mod 2π) divided by the angular frequency."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every directed cycle γ in G, the sum of delays along γ is an integer.\nASSUMPTION: None\nVERIFICATION: Units: delays in ℕ; testable by checking cycle sums are whole numbers.", "rejected": "For every directed cycle γ in G, the sum of delays along γ is independent of the observed phase shift.", "E_acc": 0.22377856075763702, "C_acc": 0.4845290184020996, "G_acc": 0.5609830850735307, "D_acc": 0.6575046349316835, "H_acc": 0.21047702431678772, "Q_acc": 0.4928776061162353, "E_rej": 0.1446581780910492, "C_rej": 0.4254084527492523, "G_rej": 0.545996927889064, "D_rej": 0.8382938504219055, "H_rej": 0.16170614957809448, "Q_rej": 0.5190033035818488, "Delta_Q": -0.02612569746561344, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Estimating whether a distant sound comes from a moving or stationary source using only changes in pitch and loudness over time", "ancestors": ["[DEF] A sound source has position xₛ(t) and velocity vₛ(t).", "[DEF] An observer has fixed position xₒ.", "[DEF] The emitted frequency is f₀.", "[DEF] The received frequency is f(t).", "[DEF] The emitted power is P₀.", "[DEF] The received intensity is I(t).", "[LAW] f(t) = f₀ c / (c + ‖vₛ(t)‖ cos θ(t)) when vₛ(t) ≠ 0.", "[VAR] θ(t) is the angle between vₛ(t) and xₒ – xₛ(t).", "[LAW] I(t) = P₀ / (4π‖xₒ – xₛ(t)‖²).", "[CONSTRAINT] If vₛ(t) = 0 for all t, then f(t) = f₀ and I(t) is constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If vₛ(t) is orthogonal to xₒ – xₛ(t) (so cos θ(t)=0), then f(t)=f₀ regardless of ‖vₛ(t)‖.\nASSUMPTION: None\nVERIFICATION: Direct from LAW: denominator becomes c+0, so f(t)=f₀ c/c=f₀.", "rejected": "If vₛ(t) is orthogonal to xₒ – xₛ(t) (so cos θ(t)=0), then f(t)=f₀ c/(c – 0)=f₀.", "E_acc": 0.11815038323402405, "C_acc": 0.709986686706543, "G_acc": 0.5427081913803704, "D_acc": 0.6277348194271326, "H_acc": 0.2628870904445648, "Q_acc": 0.40124767074594275, "E_rej": 0.20113468170166016, "C_rej": 0.5740833282470703, "G_rej": 0.5363872839952819, "D_rej": 0.7305927574634552, "H_rej": 0.2694072425365448, "Q_rej": 0.4719790228991769, "Delta_Q": -0.07073135215323417, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a glass will crack when hot water is poured into it based on thermal expansion, thickness, and temperature gradients", "ancestors": ["[DEF] Let α denote the linear thermal expansion coefficient of the glass.", "[VAR] Let ΔT(r) be the radial temperature difference across the wall thickness.", "[VAR] Let σ(r) be the resulting thermal stress field.", "[LAW] σ(r)=EαΔT(r)/(1−ν) where E is Young’s modulus and ν is Poisson’s ratio.", "[CONSTRAINT] |σ(r)|≤σ_c for all r, where σ_c is the material’s tensile strength.", "[LIMIT] σ_c is a temperature-independent material constant.", "[LIMIT] Crack initiation occurs at the smallest ΔT(r) satisfying |σ(r)|=σ_c."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The critical radial temperature difference that initiates cracking is ΔT_crit = σ_c(1−ν)/(Eα).\nASSUMPTION: None\nVERIFICATION: Units: [K] = [Pa][1]/([Pa][1/K]) → K; equality |σ(r)|=σ_c substituted into the given stress law.", "rejected": "The critical radial temperature difference that initiates cracking is ΔT_crit = σ_c(1+ν)/(Eα).", "E_acc": 0.40305325388908386, "C_acc": 0.26626694202423096, "G_acc": 0.5279839780414477, "D_acc": 0.6363854152150452, "H_acc": 0.16355234384536743, "Q_acc": 0.5841812320286408, "E_rej": 0.3238406181335449, "C_rej": 0.2909030020236969, "G_rej": 0.5241861140821129, "D_rej": 0.8304969668388367, "H_rej": 0.16950303316116333, "Q_rej": 0.5929578979033978, "Delta_Q": -0.008776665874757006, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether a battery will fail during peak usage by reasoning about internal resistance, heat generation, and discharge rate", "ancestors": ["[DEF] A battery is an electrochemical cell that converts stored chemical energy into electrical energy.", "[VAR] Let R denote the internal resistance of the battery.", "[VAR] Let I denote the discharge current.", "[LAW] Joule heating power inside the battery equals I²R.", "[VAR] Let T denote the battery temperature.", "[CONSTRAINT] T increases monotonically with I²R.", "[LIMIT] The battery fails if T exceeds a manufacturer-specified threshold T_max."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The battery survives only while the discharge current satisfies I ≤ √(T_max / R).\nASSUMPTION: None\nVERIFICATION: Units consistent: [A] = √([K]/[Ω]); inequality testable by measuring I, R, T_max.", "rejected": "The discharge current satisfies I ≤ √(T_max / R) only while the battery survives.", "E_acc": 0.2393190711736679, "C_acc": 0.5655509233474731, "G_acc": 0.5100046418374404, "D_acc": 0.5996531969867647, "H_acc": 0.2419079840183258, "Q_acc": 0.4564263060456142, "E_rej": 0.37840592861175537, "C_rej": 0.28453394770622253, "G_rej": 0.5009626080573071, "D_rej": 0.754831999540329, "H_rej": 0.24516800045967102, "Q_rej": 0.5832571105158422, "Delta_Q": -0.126830804470228, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Hierarchical goal decomposition with conflicting subgoals: synthesize a scheduler that resolves conflicts while guaranteeing progress on at least one top-level objective.", "ancestors": ["[DEF] A hierarchy H is a finite poset (T, <) of tasks.", "[VAR] Let t ∈ T denote a task.", "[DEF] A goal g is a subset G ⊆ T.", "[VAR] Let G₀ denote the unique maximal element of H.", "[DEF] A subgoal relation is g′ ⊂ g.", "[DEF] A conflict between g₁ and g₂ is g₁ ∩ g₂ ≠ ∅ ∧ g₁ ≠ g₂.", "[CONSTRAINT] A schedule S is a strict linear order on T.", "[LIMIT] Progress on G is ∃ t ∈ G : t is scheduled.", "[CONSTRAINT] Conflict resolution requires ∀ conflicting g₁, g₂ : S orders their intersecting tasks.", "[LIMIT] Guaranteed progress mandates ∃ G ∈ ancestors(G₀) : progress on G holds in every prefix of S."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If two goals g₁ and g₂ conflict, then every prefix of S that contains all tasks in g₁ ∩ g₂ must order them.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If two goals g₁ and g₂ conflict, then every prefix of S that contains all tasks in g₁ ∪ g₂ must order them.", "E_acc": 0.2640666961669922, "C_acc": 0.5329891443252563, "G_acc": 0.5601205402053893, "D_acc": 0.6485005682334304, "H_acc": 0.1953117921948433, "Q_acc": 0.494815222453326, "E_rej": 0.46985378861427307, "C_rej": 0.29329583048820496, "G_rej": 0.5569744152016938, "D_rej": 0.8481408357620239, "H_rej": 0.1898239552974701, "Q_rej": 0.6443376251496374, "Delta_Q": -0.14952240269631145, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["[DEF] The system is described by a time-dependent wave function ψ(t).", "[VAR] The wave function ψ(t) is a function of the position and momentum operators x and p.", "[LAW] The time evolution of the wave function ψ(t) is governed by the Schrödinger equation iℏ(∂ψ/∂t) = Hψ.", "[CONSTRAINT] The system is closed and finite, with a total energy E and a finite number of degrees of freedom N.", "[VAR] The density matrix ρ(t) is defined as ρ(t) = |ψ(t)⟩⟨ψ(t)|.", "[LIMIT] The timescale for apparent irreversibility τ is related to the recurrence time T_R, such that τ ≪ T_R.", "[CONSTRAINT] The effective dissipation emerges on timescales t > τ, where the system exhibits a separation of scales between the microdynamics and the coarse-grained dynamics."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The system's effective dissipation emerges on timescales t > τ, where the coarse-grained dynamics dominate the microdynamics.\nASSUMPTION: None\nVERIFICATION: t ≫ τ, with t in units of seconds and τ in units of seconds, within the regime of the system's degrees of freedom N.", "rejected": "The system's effective dissipation emerges on timescales t < τ, where the coarse-grained dynamics dominate the microdynamics.", "E_acc": 0.2151217758655548, "C_acc": 0.6127232313156128, "G_acc": 0.517248923832085, "D_acc": 0.613436159255798, "H_acc": 0.21738570928573608, "Q_acc": 0.4463903321855469, "E_rej": 0.023020237684249878, "C_rej": 0.9388298392295837, "G_rej": 0.5058544898638502, "D_rej": 0.7753559052944183, "H_rej": 0.22464409470558167, "Q_rej": 0.3529177730204538, "Delta_Q": 0.09347255916509312, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["[DEF] A system consists of interacting subsystems S1 and S2 that exchange a conserved quantity x.", "[VAR] Let c denote the coupling strength between S1 and S2, which varies over time t.", "[LAW] The rate of change of x in S1 is given by the equation dx/dt = -c \\* (x - y), where y is the quantity in S2.", "[CONSTRAINT] The subsystems are intermittently coupled, meaning c(t) = 0 for t ∉ [0, T], where T is a fixed time interval.", "[LIMIT] The magnitude of the observable x is bounded by a constant B, i.e., |x| ≤ B.", "[VAR] Let R denote the amplification factor of the observable x during the time interval [0, T].", "[LAW] The amplification factor R is related to the coupling strength c and the initial conditions x(0) and y(0) by the equation R = |x(T)/x(0)| = |(1 - c \\* T)|."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The amplification factor R is bounded by the condition |R| ≤ |1 - c * T|.\nASSUMPTION: None\nVERIFICATION: |R| = |(1 - c * T)|, with c and T in the same units as the rate of change of x.", "rejected": "The condition |R| ≤ |1 - c * T| bounds the amplification factor R.", "E_acc": 0.22572831809520721, "C_acc": 0.6255720853805542, "G_acc": 0.5273480417672545, "D_acc": 0.6011818498373032, "H_acc": 0.23846367001533508, "Q_acc": 0.44446368967182937, "E_rej": 0.48627373576164246, "C_rej": 0.35174188017845154, "G_rej": 0.5223809894814622, "D_rej": 0.7096056789159775, "H_rej": 0.2903943210840225, "Q_rej": 0.5928916462638881, "Delta_Q": -0.14842795659205876, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a person fainted due to dehydration, low blood sugar, or heat stress by reasoning from symptoms, timing, and prior activity", "ancestors": ["[DEF] Let x be the person's blood sugar level, y be their hydration level, and t be the time of the incident.", "[VAR] The person's blood sugar level x, hydration level y, and body temperature B are variables that can change over time t.", "[LAW] The person's blood sugar level x decreases at a rate proportional to their physical activity level R.", "[CONSTRAINT] The person's hydration level y cannot exceed their maximum hydration capacity c.", "[LIMIT] The person's body temperature B has a maximum limit of 40 degrees Celsius.", "[VAR] The person's physical activity level R and environmental temperature T are variables that can affect their blood sugar level x and hydration level y.", "[LAW] The rate of change of the person's body temperature B is proportional to the difference between their environmental temperature T and their body temperature B.", "[CONSTRAINT] The person's blood sugar level x must be above a minimum threshold b to maintain consciousness."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The person's blood sugar level x will decrease over time t if their physical activity level R is greater than zero.\nASSUMPTION: None\nVERIFICATION: dx/dt ∝ -R, where dx/dt is the rate of change of blood sugar level and R is the physical activity level.", "rejected": "The person's blood sugar level x will decrease over time t if their physical activity level R is greater than zero when their body temperature B is above 50 degrees Celsius.", "E_acc": 0.2964189052581787, "C_acc": 0.4666772186756134, "G_acc": 0.5328486668295227, "D_acc": 0.66207221057266, "H_acc": 0.17668724060058594, "Q_acc": 0.5169056792627088, "E_rej": 0.3925001919269562, "C_rej": 0.32548433542251587, "G_rej": 0.5322698792879237, "D_rej": 0.8882541954517365, "H_rej": 0.11174580454826355, "Q_rej": 0.6255834249866894, "Delta_Q": -0.10867774572398059, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] The expression E is a symbolic representation of a mathematical formula.", "[VAR] Let x and y be variables in the expression E.", "[LAW] The simplification algorithm applies the rules of algebraic manipulation to E.", "[CONSTRAINT] The algorithm must preserve the semantic meaning of E during simplification.", "[VAR] Let c be the correctness certificate generated by the algorithm.", "[LIMIT] The size of c is bounded by a polynomial function of the size of E.", "[CONSTRAINT] The proof-carrying code scenario requires a certificate that proves memory-safety for a given program P.", "[LAW] The certificate c includes loop invariants that are used to verify the memory-safety of P."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The size of the correctness certificate c is directly proportional to the complexity of the expression E.\nASSUMPTION: The complexity of the expression E is measured by the number of variables and operations it contains.\nVERIFICATION: The proportionality constant can be verified by analyzing the polynomial function bounding the size of c.", "rejected": "The size of the correctness certificate c is directly proportional to the square root of the complexity of the expression E.", "E_acc": 0.4678710699081421, "C_acc": 0.2298336625099182, "G_acc": 0.5451652394341571, "D_acc": 0.7153034247457981, "H_acc": 0.21821820735931396, "Q_acc": 0.6246665005705185, "E_rej": 0.31724074482917786, "C_rej": 0.5242795348167419, "G_rej": 0.5386402175894806, "D_rej": 0.8080117702484131, "H_rej": 0.19198822975158691, "Q_rej": 0.5404478910778251, "Delta_Q": 0.08421860949269344, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["[DEF] A causal graph is a directed graph where each edge represents a causal relationship between two nodes.", "[VAR] Let G = (V, E) denote a causal graph with vertices V and edges E.", "[LAW] The causal graph G satisfies the Markov condition if and only if every vertex in V is conditionally independent of its non-descendants given its parents.", "[CONSTRAINT] The set of possible interventions on G is constrained to the set of vertices V.", "[VAR] Let x denote the target variable in the causal graph G.", "[LIMIT] The number of possible interventions on G is limited by the number of vertices in V.", "[VAR] Let c denote the cost of an intervention on a vertex in V.", "[CONSTRAINT] The total cost of a set of interventions is constrained by the budget B.", "[LAW] The effect of an intervention on a vertex x is given by the structural equation f(x, u), where u denotes the intervention.", "[CONSTRAINT] The set of feasible interventions is constrained by the set of available resources R."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total cost of a set of interventions on a causal graph G is limited by the budget B and the number of vertices in V.\nASSUMPTION: None\nVERIFICATION: The total cost is in the same units as the budget B and is testable by comparing the cost of all possible interventions to B.", "rejected": "The total cost of a set of interventions on a causal graph G is limited by the budget B and the number of vertices in V, regardless of the conditional independence between the vertices.", "E_acc": 0.1639605462551117, "C_acc": 0.6453323364257812, "G_acc": 0.5607122811779846, "D_acc": 0.6742388065904379, "H_acc": 0.172430157661438, "Q_acc": 0.4498688983789179, "E_rej": 0.2257956564426422, "C_rej": 0.6072584390640259, "G_rej": 0.5664455496007577, "D_rej": 0.899368166923523, "H_rej": 0.10063183307647705, "Q_rej": 0.529386569117196, "Delta_Q": -0.07951767073827803, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metareasoning under compute cost: allocate compute across subproblems to minimize expected regret given diminishing returns to deeper search.", "ancestors": ["[DEF] Let c denote the total compute available for allocation.", "[VAR] Let x and y represent the compute allocated to subproblems 1 and 2, respectively.", "[LIMIT] The total compute allocated to all subproblems cannot exceed c.", "[CONSTRAINT] The compute allocated to each subproblem must be a non-negative value, thus x ≥ 0 and y ≥ 0.", "[VAR] Let R(x) and R(y) denote the expected regret of subproblems 1 and 2, given compute x and y, respectively.", "[LAW] The expected regret R(x) is a decreasing function of compute x, and R(y) is a decreasing function of compute y.", "[CONSTRAINT] The sum of compute allocated to subproblems 1 and 2 cannot exceed the total compute, thus x + y ≤ c.", "[LIMIT] The minimum expected regret is achieved when the marginal decrease in regret equals the marginal increase in compute cost, for both subproblems."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The minimum expected regret is achieved when x + y = c.\nASSUMPTION: None\nVERIFICATION: Units of x, y, and c are in the same compute regime.", "rejected": "The minimum expected regret is achieved when x + y ≥ c.", "E_acc": 0.36652904748916626, "C_acc": 0.4083889424800873, "G_acc": 0.5477243759336748, "D_acc": 0.643363531678915, "H_acc": 0.16954582929611206, "Q_acc": 0.5495439243436392, "E_rej": 0.19675235450267792, "C_rej": 0.6488385200500488, "G_rej": 0.5546176095626184, "D_rej": 0.8642449975013733, "H_rej": 0.1357550024986267, "Q_rej": 0.4994550235037293, "Delta_Q": 0.05008890083990991, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a person fainted due to dehydration, low blood sugar, or heat stress by reasoning from symptoms, timing, and prior activity", "ancestors": ["[DEF] Let c represent the person's core body temperature.", "[VAR] The person's blood sugar level is denoted by the variable x.", "[VAR] The person's level of dehydration is denoted by the variable y.", "[LAW] The person's core body temperature c is directly proportional to their level of heat stress.", "[CONSTRAINT] The person's blood sugar level x must be greater than 0.", "[LIMIT] The maximum allowable core body temperature c is 40 degrees Celsius.", "[VAR] The duration of the person's prior physical activity is denoted by the variable t.", "[LAW] The person's level of dehydration y increases with the duration of physical activity t.", "[CONSTRAINT] The person's blood sugar level x decreases with the duration of physical activity t.", "[LIMIT] The minimum allowable blood sugar level x is 70 milligrams per deciliter."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The person's core body temperature c is directly proportional to their level of dehydration y.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The person's core body temperature c is directly proportional to their level of dehydration y, but only when the blood sugar level x is less than or equal to 0.", "E_acc": 0.4995989501476288, "C_acc": 0.31460824608802795, "G_acc": 0.5224098470062017, "D_acc": 0.6046474971808493, "H_acc": 0.13614776730537415, "Q_acc": 0.5987547279335559, "E_rej": 0.045589666813611984, "C_rej": 0.7580612301826477, "G_rej": 0.5130089118902106, "D_rej": 0.8990183472633362, "H_rej": 0.10098165273666382, "Q_rej": 0.43437194056459705, "Delta_Q": 0.16438278736895884, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Value alignment under ambiguous instructions: synthesize policies that generalize human intent when the utility function is partially specified.", "ancestors": ["[DEF] A policy π is a mapping from states x to actions a.", "[VAR] Let U denote the utility function, which is a function of x and a.", "[CONSTRAINT] The utility function U is partially specified, meaning it is only defined for a subset of possible state-action pairs (x, a).", "[LIMIT] The set of possible state-action pairs (x, a) is finite and denoted by X × A.", "[VAR] Let c be a cost function that assigns a real number to each state-action pair (x, a).", "[LAW] For all state-action pairs (x, a) where U is defined, the cost c(x, a) is bounded below by 0.", "[CONSTRAINT] The policy π must satisfy the constraint that the expected value of U under π is maximized, given the partial specification of U."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For all state-action pairs (x, a) where U is defined, the cost c(x, a) is non-negative.\nASSUMPTION: None\nVERIFICATION: c(x, a) ≥ 0, with units in real numbers, valid for all defined state-action pairs.", "rejected": "For all state-action pairs (x, a) where the cost c(x, a) is non-negative, the utility function U is defined.", "E_acc": 0.38000330328941345, "C_acc": 0.37640848755836487, "G_acc": 0.5418664983008057, "D_acc": 0.6865848693996668, "H_acc": 0.19284620881080627, "Q_acc": 0.565124946134165, "E_rej": 0.5862109661102295, "C_rej": 0.21473141014575958, "G_rej": 0.5490707692224532, "D_rej": 0.8746567666530609, "H_rej": 0.1253432333469391, "Q_rej": 0.7051281916443259, "Delta_Q": -0.14000324551016097, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Conditional independence triangulation: given a graph with hidden nodes, deduce which observed independences force the existence of a latent common cause.", "ancestors": ["[DEF] A graph G is defined as a set of nodes V and a set of edges E.", "[VAR] Let x and y be observed nodes in G, and let B be the set of all observed nodes.", "[LAW] The conditional independence of x and y given a subset R of B is denoted as x ⊥ y | R.", "[CONSTRAINT] If x ⊥ y | R, then there exists no edge between x and y in G.", "[VAR] Let c be a latent node in G, and let t be the set of all latent nodes.", "[CONSTRAINT] If x and y are conditionally independent given R, but not given R ∪ {c}, then c is a common cause of x and y.", "[LIMIT] The existence of a latent common cause c can only be deduced from observed independences if c is connected to at least two observed nodes in G."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If x and y are conditionally independent given R, but not given R ∪ {c}, then there is no edge between x and y in G.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If x and y are conditionally independent given R, but not given R ∪ {c}, and c is a common cause of x and z, then there is no edge between x and y in G.", "E_acc": 0.32552769780158997, "C_acc": 0.2081376165151596, "G_acc": 0.5378537360811606, "D_acc": 0.6536120846867561, "H_acc": 0.172719806432724, "Q_acc": 0.577051969547756, "E_rej": 0.22143766283988953, "C_rej": 0.20174160599708557, "G_rej": 0.5325211234157905, "D_rej": 0.8379066288471222, "H_rej": 0.1620933711528778, "Q_rej": 0.5839591909898446, "Delta_Q": -0.006907221442088662, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a plant is nutrient-deficient or water-stressed by observing leaf color, growth pattern, and soil conditions", "ancestors": ["[DEF] Let c represent the concentration of chlorophyll in a plant's leaves.", "[VAR] The variable x denotes the intensity of the leaf's green color.", "[LAW] The relationship between c and x is given by the equation x = 0.5c + b, where b is a constant.", "[CONSTRAINT] The value of c is always greater than or equal to 0.", "[LIMIT] The maximum value of x is 1, representing the most intense green color.", "[DEF] Let t represent the time since the plant was last watered.", "[VAR] The variable y denotes the plant's growth rate.", "[LAW] The relationship between t and y is given by the equation y = -0.2t + R, where R is the initial growth rate.", "[CONSTRAINT] The value of t is always greater than or equal to 0.", "[LIMIT] The minimum value of y is 0, representing no growth."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The maximum value of c is 2, representing the most intense green color when x is 1.\nASSUMPTION: None\nVERIFICATION: Substituting x = 1 into the equation x = 0.5c + b and considering the constraint that x and c are within their respective limits.", "rejected": "The maximum value of c is 2 meters, representing the most intense green color when x is 1.", "E_acc": 0.30572786927223206, "C_acc": 0.46976202726364136, "G_acc": 0.5729888512287289, "D_acc": 0.6368836434558034, "H_acc": 0.22153139114379883, "Q_acc": 0.5175873151514679, "E_rej": 0.14846503734588623, "C_rej": 0.670285701751709, "G_rej": 0.5690775760449469, "D_rej": 0.7545076906681061, "H_rej": 0.24549230933189392, "Q_rej": 0.4506501932628453, "Delta_Q": 0.06693712188862266, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Sequential delegation: when an agent delegates to subagents with private incentives, derive mechanisms that ensure near-optimal end-to-end performance.", "ancestors": ["[DEF] An agent is denoted by the variable a.", "[VAR] The set of subagents is represented by the variable S.", "[VAR] The private incentives of subagents are denoted by the vector x.", "[LAW] The agent's objective is to maximize the overall utility function U(a, S, x).", "[CONSTRAINT] The agent's action space is constrained by the set of available resources R.", "[VAR] The delegation mechanism is represented by the function d(a, S, x, R).", "[LIMIT] The number of subagents is limited by the constant c.", "[CONSTRAINT] The subagents' private incentives are bounded by the vector B.", "[LAW] The end-to-end performance is measured by the function P(d(a, S, x, R), U(a, S, x))."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The overall utility function U(a, S, x) is maximized when the number of subagents is less than or equal to the constant c.\nASSUMPTION: None\nVERIFICATION: The maximum value of U(a, S, x) can be verified by evaluating the function with respect to the constraint c.", "rejected": "The overall utility function U(a, S, x) is maximized when the number of subagents is independent of the constant c.", "E_acc": 0.0634123831987381, "C_acc": 0.823356568813324, "G_acc": 0.5559749205796314, "D_acc": 0.6469796597957611, "H_acc": 0.19854441285133362, "Q_acc": 0.37508887598690177, "E_rej": 0.02496052160859108, "C_rej": 0.9077105522155762, "G_rej": 0.5475128855822342, "D_rej": 0.8009642362594604, "H_rej": 0.19903576374053955, "Q_rej": 0.3757378940337471, "Delta_Q": -0.0006490180468453066, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Compositional verification: derive local contracts for modules such that their composition satisfies a global safety property.If interacting subsystems exchange conserved quantities but one subsystem is intermittently coupled, infer bounds on transient amplification of observables.", "ancestors": ["[DEF] The system consists of two subsystems, A and B, exchanging a conserved quantity x.", "[VAR] Let c denote the coupling strength between subsystems A and B.", "[LAW] The exchange of x between subsystems A and B is governed by the equation dx/dt = c \\* (y_A - y_B), where y_A and y_B are observables of subsystems A and B.", "[CONSTRAINT] The subsystems are intermittently coupled, meaning c is a time-dependent variable that can take on values of either 0 or 1.", "[LIMIT] The observable y_A is bounded by a constant R, such that |y_A| ≤ R.", "[VAR] Let t denote the time at which the subsystems are coupled, and let B denote the bound on the transient amplification of observables.", "[LAW] The bound B on the transient amplification of observables is related to the coupling strength c and the bound R on y_A by the equation B = ∫[0,t] |c \\* (y_A - y_B)| dt."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The bound B on the transient amplification of observables is limited by the product of the coupling strength c, the bound R on y_A, and the time t.\nASSUMPTION: None\nVERIFICATION: B ≤ ∫[0,t] |c * R| dt, with units of B and R being consistent and c being dimensionless.", "rejected": "The bound B on the transient amplification of observables is limited by the product of the coupling strength c, the bound R on y_A, and the time t, such that B ≥ ∫[0,t] |c * R| dt.", "E_acc": 0.1666974425315857, "C_acc": 0.6713201403617859, "G_acc": 0.5376931446953677, "D_acc": 0.639911803416453, "H_acc": 0.1331489384174347, "Q_acc": 0.4379513004677392, "E_rej": 0.366769015789032, "C_rej": 0.45761412382125854, "G_rej": 0.5422594575211406, "D_rej": 0.8818381428718567, "H_rej": 0.11816185712814331, "Q_rej": 0.591511214338243, "Delta_Q": -0.15355991387050383, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multiscale pattern formation: given local interaction rules, deduce which global patterns are possible and which require fine-tuning of parameters.", "ancestors": ["[DEF] A pattern formation system consists of a set of local interaction rules.", "[VAR] Let x and y denote the spatial coordinates of the system.", "[LAW] The local interaction rules are defined by a set of partial differential equations, ∂u/∂t = f(u, ∇u), where u is a vector of state variables.", "[CONSTRAINT] The system is bounded by a domain Ω, where x, y ∈ Ω.", "[VAR] Let c denote the diffusion coefficient and R denote the reaction term in the partial differential equations.", "[LAW] The reaction term R is a nonlinear function of the state variables, R = g(u).", "[CONSTRAINT] The system has a finite number of possible steady-state solutions, u_ss, which satisfy ∇u_ss = 0.", "[LIMIT] The stability of the steady-state solutions is determined by the eigenvalues of the Jacobian matrix, J = ∂f/∂u.", "[CONSTRAINT] The global patterns that emerge from the local interaction rules are constrained by the symmetries of the system and the boundary conditions on Ω."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The stability of the steady-state solutions is determined by the magnitude of the eigenvalues of the Jacobian matrix, J = ∂f/∂u, being less than a certain threshold.\nASSUMPTION: The threshold for the eigenvalues is a finite, positive value.\nVERIFICATION: The threshold value must be in units of 1/time, valid for the given partial differential equations regime.", "rejected": "The stability of the steady-state solutions is determined by the magnitude of the eigenvalues of the Jacobian matrix, J = ∂f/∂u, being greater than a certain threshold.", "E_acc": 0.030510349199175835, "C_acc": 0.0418790765106678, "G_acc": 0.5026812408686965, "D_acc": 0.6249858206138015, "H_acc": 0.34724196419119835, "Q_acc": 0.4915865053349989, "E_rej": 0.15552663803100586, "C_rej": 0.371452659368515, "G_rej": 0.48035117657855153, "D_rej": 0.7498859465122223, "H_rej": 0.2501140534877777, "Q_rej": 0.4934034788049757, "Delta_Q": -0.0018169734699767792, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multiscale pattern formation: given local interaction rules, deduce which global patterns are possible and which require fine-tuning of parameters.", "ancestors": ["[DEF] A pattern formation system consists of a set of local interaction rules.", "[VAR] Let x and y denote the spatial coordinates of the system.", "[LAW] The local interaction rules are defined by a set of partial differential equations, ∂u/∂t = f(u, ∇u), where u is a vector of state variables.", "[CONSTRAINT] The system is bounded by a domain Ω, where x, y ∈ Ω.", "[VAR] Let c denote the diffusion coefficient and R denote the reaction term in the partial differential equations.", "[LAW] The reaction term R is a nonlinear function of the state variables, R = g(u).", "[CONSTRAINT] The boundary conditions are given by a set of functions, u(x, y, t) = h(x, y) on ∂Ω.", "[CONSTRAINT] The initial conditions are given by a set of functions, u(x, y, 0) = u0(x, y).", "[LIMIT] The system exhibits a finite number of possible global patterns, B, which are determined by the local interaction rules and the boundary conditions."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The number of possible global patterns, B, is finite and determined by the local interaction rules and the boundary conditions.\nASSUMPTION: The nonlinear function g(u) in the reaction term R is bounded for all u in the domain Ω.\nVERIFICATION: N/A", "rejected": "The local interaction rules and the boundary conditions are determined by the finite number of possible global patterns, B.", "E_acc": 0.5842371582984924, "C_acc": 0.14441829919815063, "G_acc": 0.5403727756347507, "D_acc": 0.6257464704685844, "H_acc": 0.17620915174484253, "Q_acc": 0.6619904216961003, "E_rej": 0.46455109119415283, "C_rej": 0.3645896911621094, "G_rej": 0.5143931013008114, "D_rej": 0.8671513795852661, "H_rej": 0.1328486204147339, "Q_rej": 0.629471423261566, "Delta_Q": 0.03251899843453432, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a rumor will spread or die out in a community based on trust networks, repetition, and perceived incentives", "ancestors": ["[DEF] A trust network is represented by a graph G = (V, E), where V is the set of individuals and E is the set of trust relationships.", "[VAR] Let t denote the number of times a rumor is repeated in the community.", "[VAR] Let c denote the average trust coefficient between individuals in the trust network G.", "[LAW] The perceived incentive to spread a rumor, denoted by B, is directly proportional to the number of repetitions, t.", "[CONSTRAINT] The trust network G is undirected and connected, meaning there is a path between every pair of individuals.", "[VAR] Let R denote the rumor's reach, defined as the number of individuals who have heard the rumor at least once.", "[LIMIT] The maximum possible reach R is limited by the size of the trust network, specifically the number of individuals in V."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The rumor's reach R is directly proportional to the number of repetitions t and the average trust coefficient c.\nASSUMPTION: None\nVERIFICATION: R ∝ t * c, where R is in units of individuals, t is in units of repetitions, and c is dimensionless.", "rejected": "The rumor's reach R is directly proportional to the number of repetitions t and the average trust coefficient c, even when the trust network G is directed.", "E_acc": 0.5908962488174438, "C_acc": 0.2072814702987671, "G_acc": 0.5524436333881957, "D_acc": 0.6577781997621059, "H_acc": 0.13949796557426453, "Q_acc": 0.6639071506581136, "E_rej": 0.2266649752855301, "C_rej": 0.37505626678466797, "G_rej": 0.538898430498583, "D_rej": 0.9000462889671326, "H_rej": 0.09995371103286743, "Q_rej": 0.5707818120185818, "Delta_Q": 0.09312533863953176, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["[DEF] A causal graph is a directed graph G = (V, E) where V is a set of vertices and E is a set of edges.", "[VAR] Let c denote the number of vertices in the causal graph.", "[CONSTRAINT] The causal graph G has a finite number of vertices, i.e., c ∈ ℕ.", "[LIMIT] The number of edges in the causal graph is bounded by c(c-1).", "[VAR] Let t denote the target state in the causal graph.", "[DEF] A cross-domain intervention is a set of actions applied to multiple subsystems.", "[CONSTRAINT] The set of possible interventions is constrained by the causal graph structure.", "[LAW] The effect of an intervention on the target state t is a function of the intervention and the current state of the system.", "[VAR] Let R denote the set of possible cross-domain interventions.", "[LIMIT] The number of possible cross-domain interventions is finite, i.e., |R| ∈ ℕ."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of possible cross-domain interventions is bounded by the number of vertices in the causal graph.\nASSUMPTION: None\nVERIFICATION: |R| ≤ c(c-1) under the given constraints.", "rejected": "The number of possible cross-domain interventions is bounded by the square root of the number of vertices in the causal graph.", "E_acc": 0.3953249752521515, "C_acc": 0.36852529644966125, "G_acc": 0.5627727920655161, "D_acc": 0.6655852701514959, "H_acc": 0.10172760486602783, "Q_acc": 0.5803912852425128, "E_rej": 0.5103691220283508, "C_rej": 0.2237081378698349, "G_rej": 0.5596719740424305, "D_rej": 0.9193167984485626, "H_rej": 0.08068320155143738, "Q_rej": 0.6960985433775932, "Delta_Q": -0.11570725813508043, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Symbolic simplification with correctness certificates: design an algorithm that simplifies expressions while producing verifiable proof objects.Proof-carrying code scenario: design a compact certificate that proves memory-safety for a low-level program with loop invariants.", "ancestors": ["[DEF] The algorithm A takes an input expression e and produces a simplified expression e'.", "[VAR] Let x be the set of all possible input expressions for algorithm A.", "[LAW] For all x, the algorithm A terminates in a finite number of steps t.", "[CONSTRAINT] The simplified expression e' satisfies the constraint B(e') = B(e), where B is a correctness predicate.", "[LIMIT] The size of the proof object p is bounded by a constant c times the size of the input expression e.", "[VAR] Let y be the set of all possible proof objects p produced by algorithm A.", "[CONSTRAINT] The proof object p is a valid certificate if and only if R(p, e) = True, where R is a verification relation."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The size of the proof object p is directly proportional to the number of steps t taken by algorithm A.\nASSUMPTION: The constant c in the limit premise is greater than zero.\nVERIFICATION: Check if the size of p is within the bounded limit for a given input expression e.", "rejected": "The size of the proof object p is directly proportional to the number of steps t taken by algorithm A, and the constant c in the limit premise is independent of the number of steps t.", "E_acc": 0.3041522204875946, "C_acc": 0.46586599946022034, "G_acc": 0.5552825715858489, "D_acc": 0.6966130640357733, "H_acc": 0.18743214011192322, "Q_acc": 0.5297083793673665, "E_rej": 0.10999342054128647, "C_rej": 0.7444227337837219, "G_rej": 0.5473656397080049, "D_rej": 0.8232074677944183, "H_rej": 0.17679253220558167, "Q_rej": 0.44054884768556807, "Delta_Q": 0.08915953168179841, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["[DEF] A time-series dataset is represented by a set of variables x(t) where t denotes time.", "[VAR] The variables x(t) are observed at discrete time points t = 1, 2, ..., T.", "[LAW] The interactions between nodes are described by a set of equations of the form x_i(t) = f(x_j(t-τ)), where τ is a delay parameter.", "[CONSTRAINT] The delay parameter τ is a positive integer representing the number of time steps between interactions.", "[VAR] The phase relations between nodes are represented by a set of variables φ_ij, which describe the phase shift between x_i and x_j.", "[LIMIT] The phase shift φ_ij is bounded between 0 and 2π, representing a full cycle.", "[CONSTRAINT] The minimal feedback graph is a directed graph G = (V, E), where V is the set of nodes and E is the set of edges representing the interactions between nodes.", "[LAW] The edges in the minimal feedback graph E are determined by the observed phase relations φ_ij and the delay parameter τ, such that x_i(t) is connected to x_j(t-τ) if φ_ij is consistent with the observed time-series data."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The phase shift φ_ij between any two nodes x_i and x_j is bounded by the delay parameter τ, such that φ_ij ≤ 2πτ.\nASSUMPTION: None\nVERIFICATION: Units of φ_ij in radians and τ in time steps, valid for discrete time-series data.", "rejected": "The phase shift φ_ij between any two nodes x_i and x_j is bounded by the delay parameter τ, such that φ_ij ≥ 2πτ.", "E_acc": 0.27773627638816833, "C_acc": 0.45284444093704224, "G_acc": 0.5524072904518107, "D_acc": 0.6256997883319855, "H_acc": 0.17733678221702576, "Q_acc": 0.5106397322640986, "E_rej": 0.289429247379303, "C_rej": 0.2709575891494751, "G_rej": 0.568986693106126, "D_rej": 0.8306671380996704, "H_rej": 0.1693328619003296, "Q_rej": 0.5956347364350223, "Delta_Q": -0.08499500417092365, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["[DEF] The system is described by a time-dependent wave function ψ(t).", "[VAR] The wave function ψ(t) evolves according to the Schrödinger equation with Hamiltonian H.", "[LAW] The time evolution of ψ(t) is given by the unitary operator U(t) = exp(-iHt/ℏ).", "[CONSTRAINT] The system is closed and finite, with a discrete and bounded energy spectrum E = {E1, E2, ..., EN}.", "[LIMIT] The timescale for observation is much larger than the characteristic timescale τ = 2πℏ/(E_N - E_1).", "[VAR] The reduced density matrix ρ(t) is obtained by tracing out the environmental degrees of freedom from ψ(t).", "[CONSTRAINT] The effective dissipation emerges from the system-environment interactions, described by the self-adjoint operator B = ∑_{k=1}^{N} |Ek⟨Ek|, where B commutes with H."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The time evolution of the reduced density matrix ρ(t) is approximately constant on the observation timescale.\nASSUMPTION: None\nVERIFICATION: Δt >> τ = 2πℏ/(E_N - E_1) checks the timescale condition.", "rejected": "The time evolution of the reduced density matrix ρ(t) is approximately constant on a timescale much shorter than the characteristic timescale τ = 2πℏ/(E_N - E_1).", "E_acc": 0.16971535980701447, "C_acc": 0.6404555439949036, "G_acc": 0.5232842571567744, "D_acc": 0.6234498741105199, "H_acc": 0.16512995958328247, "Q_acc": 0.43565732943825425, "E_rej": 0.20434878766536713, "C_rej": 0.5561451315879822, "G_rej": 0.522874626563862, "D_rej": 0.8535812795162201, "H_rej": 0.1464187204837799, "Q_rej": 0.5107249191496521, "Delta_Q": -0.07506758971139788, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Metabolic allocation under fluctuating resources: propose a control policy for switching pathways that maximizes long-run biomass with switching costs.", "ancestors": ["[DEF] Let B represent the total biomass.", "[VAR] The biomass growth rate is denoted by the variable x.", "[LAW] The rate of change of biomass over time t is given by the equation dB/dt = x.", "[CONSTRAINT] The total resource availability at time t is represented by the variable R.", "[VAR] The switching cost between pathways is denoted by the variable c.", "[LIMIT] The maximum rate of biomass growth is limited by the available resources, x ≤ R.", "[CONSTRAINT] The total biomass at any given time t cannot be negative, B ≥ 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The rate of change of biomass is limited by the available resources and the initial biomass.\nASSUMPTION: None\nVERIFICATION: dB/dt = x ≤ R, with units of biomass per unit time.", "rejected": "The available resources and the initial biomass limit the rate of change of biomass.", "E_acc": 0.1601981520652771, "C_acc": 0.5147398710250854, "G_acc": 0.5446578327682801, "D_acc": 0.7023542774841189, "H_acc": 0.10866928100585938, "Q_acc": 0.4836469653644599, "E_rej": 0.2454589605331421, "C_rej": 0.07878203690052032, "G_rej": 0.5302899174857885, "D_rej": 0.8639775812625885, "H_rej": 0.1360224187374115, "Q_rej": 0.6231325386557728, "Delta_Q": -0.1394855732913129, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a person fainted due to dehydration, low blood sugar, or heat stress by reasoning from symptoms, timing, and prior activity", "ancestors": ["[DEF] Let c represent the person's core body temperature.", "[VAR] The person's activity level prior to fainting is denoted by x.", "[LAW] The relationship between core body temperature and activity level is given by the equation c = βx + α, where β and α are constants.", "[CONSTRAINT] The person's blood sugar level, denoted by B, must be greater than or equal to 60 mg/dL to maintain consciousness.", "[LIMIT] The maximum core body temperature that a person can withstand without fainting is 40.5°C.", "[VAR] Let t represent the time elapsed since the person last consumed water or electrolyte-rich fluids.", "[DEF] Let R represent the person's rate of fluid loss due to sweating.", "[LAW] The person's dehydration level, denoted by d, is related to the time elapsed since last fluid consumption and the rate of fluid loss by the equation d = Rt.", "[CONSTRAINT] If the person's blood sugar level B is less than 60 mg/dL or their dehydration level d exceeds a certain threshold, or their core body temperature c exceeds 40.5°C, then fainting is likely to occur."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: If the person's dehydration level d exceeds a certain threshold, then fainting is likely to occur when the core body temperature c is near its maximum limit of 40.5°C.\nASSUMPTION: The certain threshold for dehydration level d is directly related to the maximum core body temperature that a person can withstand without fainting.\nVERIFICATION: units of d (e.g., percentage of body weight lost) and c (°C) must be consistent with the given equation and constraints.", "rejected": "If the person's dehydration level d exceeds a certain threshold, then fainting is likely to occur when the core body temperature c is near its minimum limit of 35°C.", "E_acc": 0.6821107864379883, "C_acc": 0.07247360795736313, "G_acc": 0.5217663985677063, "D_acc": 0.767540299333632, "H_acc": 0.1508292555809021, "Q_acc": 0.7329169283621013, "E_rej": 0.22598440945148468, "C_rej": 0.5453095436096191, "G_rej": 0.5016492384020239, "D_rej": 0.8622086048126221, "H_rej": 0.13779139518737793, "Q_rej": 0.517725843237713, "Delta_Q": 0.21519108512438834, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["[DEF] A time-series dataset is represented by a set of variables x(t), where t denotes time.", "[VAR] The variables x(t) are observed at discrete time points t = 1, 2, ..., T.", "[LAW] The interactions between nodes are described by a set of equations dx_i(t)/dt = f_i(x_1(t), ..., x_n(t)), where i = 1, ..., n.", "[CONSTRAINT] The observed phase relations are captured by the cross-covariance matrix R(τ) = E[x(t)x(t+τ)^T], where τ denotes the time lag.", "[VAR] The minimal feedback graph is represented by a directed graph G = (V, E), where V is the set of nodes and E is the set of edges.", "[LIMIT] The number of edges in the graph G is limited by the number of nodes, i.e., |E| ≤ |V|(|V|-1)/2.", "[CONSTRAINT] The graph G must satisfy the constraint that the phase relations R(τ) are compatible with the graph structure, i.e., R(τ) ≈ R_G(τ), where R_G(τ) is the cross-covariance matrix implied by the graph G.", "[CONSTRAINT] The recovered graph G must be minimal, i.e., no edge can be removed without violating the constraint R(τ) ≈ R_G(τ)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of edges in the minimal feedback graph G is limited by the number of nodes and the observed phase relations.\nASSUMPTION: None\nVERIFICATION: |E| ≤ |V|(|V|-1)/2, where |E| is the number of edges and |V| is the number of nodes.", "rejected": "The number of edges in the minimal feedback graph G is limited by the number of nodes and the observed phase relations, and is proportional to |E| + |V|(|V|-1)/2, where |E| is the number of edges and |V| is the number of nodes.", "E_acc": 0.30602917075157166, "C_acc": 0.5138571858406067, "G_acc": 0.5292944496031851, "D_acc": 0.6252686230000108, "H_acc": 0.2031993865966797, "Q_acc": 0.4996299899183214, "E_rej": 0.23849870264530182, "C_rej": 0.5924147367477417, "G_rej": 0.5222435765899718, "D_rej": 0.8170507550239563, "H_rej": 0.1829492449760437, "Q_rej": 0.5026306052692235, "Delta_Q": -0.003000615350902125, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["[DEF] A rare event is defined as an event with probability less than a given threshold p.", "[VAR] Let x denote the random variable representing the event of interest.", "[VAR] Let c denote the cost of sampling a single data point.", "[CONSTRAINT] The sampler is constrained to sample from a bounded region R.", "[LIMIT] The number of samples is limited by a finite budget B.", "[VAR] Let t denote the tail probability of interest, where t = P(x > x_threshold).", "[VAR] Let y denote the estimated tail probability using adversarial sampling.", "[LAW] The probability of a rare event x is given by the cumulative distribution function F(x) = P(X ≤ x).", "[CONSTRAINT] The adversarial sampler is biased toward low-probability regions, where P(x | sampler) ≠ P(x).", "[LIMIT] The estimator y is subject to a limit of variance, where Var(y) ≤ σ^2, a known constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The estimated tail probability y is subject to the constraint Var(y) ≤ σ^2, which limits the accuracy of the adversarial sampling method.\nASSUMPTION: None\nVERIFICATION: The variance of y can be calculated and compared to σ^2 to verify the constraint.", "rejected": "The estimated tail probability y is subject to the constraint Var(y) ≤ σ^2, which limits the accuracy of the adversarial sampling method, because the adversarial sampler is assumed to be independent of the event x.", "E_acc": 0.20775257050991058, "C_acc": 0.33007127046585083, "G_acc": 0.5503057212335989, "D_acc": 0.6372698522172868, "H_acc": 0.2005646526813507, "Q_acc": 0.513770166481845, "E_rej": 0.40661612153053284, "C_rej": 0.12242720276117325, "G_rej": 0.5550446519628167, "D_rej": 0.8560824692249298, "H_rej": 0.1439175307750702, "Q_rej": 0.6653330670669675, "Delta_Q": -0.15156290058512245, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] A mechanism is a function that maps agent reports to outcomes.", "[VAR] Let k denote the number of steps an agent can reason.", "[LIMIT] Agents are limited to k-step reasoning.", "[CONSTRAINT] The allocation rule must be strategyproof for all agents.", "[VAR] Let x denote the true type of an agent and y denote the reported type.", "[LAW] The allocation rule assigns an outcome based on the reported types of all agents.", "[CONSTRAINT] The mechanism must satisfy the constraint of bounded rationality for all agents.", "[LIMIT] The number of steps k is a fixed constant for all agents."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The allocation rule must account for the limited k-step reasoning of all agents.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The allocation rule must account for the unlimited k-step reasoning of all agents.", "E_acc": 0.484914630651474, "C_acc": 0.3311616778373718, "G_acc": 0.5906374184414744, "D_acc": 0.6282074926421046, "H_acc": 0.23464683443307877, "Q_acc": 0.5995463524013758, "E_rej": 0.01600668393075466, "C_rej": 0.9757220149040222, "G_rej": 0.5992464674636722, "D_rej": 0.8308733403682709, "H_rej": 0.2114083245396614, "Q_rej": 0.3745407313108444, "Delta_Q": 0.22500562109053135, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Hierarchical goal decomposition with conflicting subgoals: synthesize a scheduler that resolves conflicts while guaranteeing progress on at least one top-level objective.", "ancestors": ["[DEF] A hierarchical goal decomposition system consists of a set of objectives G.", "[VAR] Let x be the number of top-level objectives in G.", "[VAR] Let y be the number of subgoals in the decomposition of G.", "[CONSTRAINT] Each subgoal is associated with at most one top-level objective.", "[LIMIT] The scheduler can only allocate resources to a finite number of subgoals at any given time t.", "[VAR] Let c be the available resources for allocation at time t.", "[CONSTRAINT] The total resource allocation to all subgoals at time t cannot exceed c.", "[LAW] The scheduler resolves conflicts between subgoals based on a priority function P.", "[CONSTRAINT] The priority function P must ensure progress on at least one top-level objective.", "[CONSTRAINT] The scheduler must guarantee that the total resource allocation to conflicting subgoals does not exceed the available resources c at any time t."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total number of subgoals that can be allocated resources at any given time t is limited by the available resources c and the number of top-level objectives x.\nASSUMPTION: None\nVERIFICATION: The number of subgoals must be less than or equal to c, considering the resource allocation per subgoal.", "rejected": "The total number of subgoals that can be allocated resources at any given time t is limited by the available resources c only, regardless of the number of top-level objectives x.", "E_acc": 0.671614408493042, "C_acc": 0.15051601827144623, "G_acc": 0.5615931213833392, "D_acc": 0.6741208219900727, "H_acc": 0.278608500957489, "Q_acc": 0.6906630574725569, "E_rej": 0.7692091464996338, "C_rej": 0.07797829806804657, "G_rej": 0.5542824905714951, "D_rej": 0.8307927250862122, "H_rej": 0.16920727491378784, "Q_rej": 0.7752613999764436, "Delta_Q": -0.08459834250388676, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["[DEF] The error rate ε is defined as the probability of a mismatch during replication.", "[VAR] Let c represent the energy cost per repair event.", "[LAW] The replication fidelity F is inversely proportional to the error rate ε.", "[CONSTRAINT] The total energy available for repair E is limited by the resource cost c and the number of repair events n.", "[VAR] Let t denote the time over which the reaction conditions vary temporally.", "[LIMIT] The maximum achievable fidelity F is limited by the kinetic control parameter k.", "[CONSTRAINT] The catalyst's selective modulation of transition states is constrained by the thermodynamic control parameter B."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The error rate ε is inversely related to the replication fidelity F.\nASSUMPTION: None\nVERIFICATION: Units of ε and F must be compatible for inverse proportionality to hold, N/A for specific regime.", "rejected": "The replication fidelity F is directly related to the error rate ε.", "E_acc": 0.5722024440765381, "C_acc": 0.25290244817733765, "G_acc": 0.51074793080001, "D_acc": 0.643964008660987, "H_acc": 0.17439421266317368, "Q_acc": 0.6345832102133759, "E_rej": 0.18660244345664978, "C_rej": 0.7097852826118469, "G_rej": 0.5114968920326126, "D_rej": 0.8522352874279022, "H_rej": 0.14776471257209778, "Q_rej": 0.47199364114951875, "Delta_Q": 0.1625895690638572, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit is a system with a set of arms, each associated with a reward distribution.", "[VAR] Let R denote the set of arms and x denote the arm selected at a given time.", "[CONSTRAINT] The reward for each arm is only partially observable due to censorship and delay.", "[LIMIT] The expected loss is bounded by a constant B.", "[VAR] Let t denote the time step and c denote the cost of sensing at each time step.", "[LAW] The reward distribution for each arm is stationary over time.", "[CONSTRAINT] The sensing cost c is non-negative and finite.", "[VAR] Let y denote the observed reward and let π denote the policy for selecting arms.", "[CONSTRAINT] The policy π must select an arm from the set R at each time step t.", "[LIMIT] The total expected cost of sensing over all time steps is bounded by a constant B."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The expected loss at each time step t is bounded by the constant B plus the sensing cost c.\nASSUMPTION: None\nVERIFICATION: Units of expected loss and sensing cost c must be consistent, e.g., both in terms of reward units.", "rejected": "The expected loss at each time step t is bounded by the constant B plus the sensing cost c, for all non-stationary reward distributions over time.", "E_acc": 0.14925026893615723, "C_acc": 0.4368605613708496, "G_acc": 0.5456108459870198, "D_acc": 0.6783168883994222, "H_acc": 0.24842016398906708, "Q_acc": 0.477346498885059, "E_rej": 0.04009078070521355, "C_rej": 0.8176791667938232, "G_rej": 0.5409183821507862, "D_rej": 0.8730534315109253, "H_rej": 0.1269465684890747, "Q_rej": 0.41859110673623423, "Delta_Q": 0.05875539214882475, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Sequential delegation: when an agent delegates to subagents with private incentives, derive mechanisms that ensure near-optimal end-to-end performance.", "ancestors": ["[DEF] An agent is denoted by the variable a.", "[VAR] The set of subagents is represented by the set S.", "[VAR] The private incentive of each subagent s is denoted by the variable x_s.", "[LIMIT] The number of subagents is finite, denoted by the constant c.", "[CONSTRAINT] Each subagent s has a limited capacity, represented by the variable B_s.", "[VAR] The delegation sequence is represented by the sequence t.", "[CONSTRAINT] The agent's objective is to maximize the overall performance, denoted by the variable R.", "[LAW] The performance of each subagent s is a function of its private incentive x_s and capacity B_s, represented by the function f(x_s, B_s).", "[CONSTRAINT] The overall performance R is a function of the performances of all subagents, represented by the function g(f(x_s, B_s) for all s in S)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The overall performance R is maximized when each subagent's performance f(x_s, B_s) is maximized.\nASSUMPTION: None\nVERIFICATION: g(f(x_s, B_s) for all s in S) has a defined maximum value under given constraints.", "rejected": "The overall performance R is maximized when each subagent's performance, measured in units of capacity, is equal to the sum of its private incentive x_s and capacity B_s, represented by the function f(x_s + B_s).", "E_acc": 0.2990538775920868, "C_acc": 0.49216488003730774, "G_acc": 0.5667051844066009, "D_acc": 0.6712245550006628, "H_acc": 0.1703961193561554, "Q_acc": 0.5218295232160017, "E_rej": 0.3521283268928528, "C_rej": 0.3476668894290924, "G_rej": 0.5688100443221629, "D_rej": 0.9056448042392731, "H_rej": 0.09435519576072693, "Q_rej": 0.6215605703182518, "Delta_Q": -0.09973104710225011, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit is a system with a set of arms, each associated with a reward distribution.", "[VAR] Let R denote the set of arms and x denote the arm selected at a given time.", "[CONSTRAINT] The reward for each arm is delayed and censored, meaning its value is only partially observable.", "[LIMIT] The number of arms, denoted by |R|, is finite.", "[VAR] Let t denote the time step and y denote the observed reward at time t.", "[LAW] The expected reward for each arm is constant but unknown.", "[CONSTRAINT] The cost of sensing the reward for an arm is denoted by c and is non-negative.", "[VAR] Let B denote the budget for information-gathering and execution.", "[CONSTRAINT] The expected loss for reaching a goal is bounded by a constant, denoted by L.", "[LIMIT] The planning horizon, denoted by T, is finite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total cost of sensing rewards for all arms is bounded by the budget B.\nASSUMPTION: None\nVERIFICATION: The total cost is in the same units as the budget B, and the bound can be checked by summing the costs c for all arms.", "rejected": "The total cost of sensing rewards for all arms is independent of the budget B and is bounded by the planning horizon T.", "E_acc": 0.1175466775894165, "C_acc": 0.5728291273117065, "G_acc": 0.5569566017282861, "D_acc": 0.676363249309361, "H_acc": 0.18357184529304504, "Q_acc": 0.4490049634927086, "E_rej": 0.12136413156986237, "C_rej": 0.613524317741394, "G_rej": 0.5491928970399645, "D_rej": 0.8370254039764404, "H_rej": 0.16297459602355957, "Q_rej": 0.474650576523605, "Delta_Q": -0.025645613030896408, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining if a child’s learning difficulty is caused by lack of sleep, attention issues, or teaching mismatch from daily observations", "ancestors": ["[DEF] A child's learning difficulty is denoted by the variable L.", "[VAR] The child's daily sleep duration is represented by the variable s.", "[VAR] The child's attention level is represented by the variable a.", "[LAW] The child's learning difficulty L is a function of sleep duration s, attention level a, and teaching mismatch t, denoted as L = f(s, a, t).", "[VAR] The teaching mismatch is represented by the variable t.", "[CONSTRAINT] The child's sleep duration s is bounded by 0 ≤ s ≤ 24 hours.", "[CONSTRAINT] The child's attention level a is bounded by 0 ≤ a ≤ 1.", "[LIMIT] The maximum observable learning difficulty L is denoted as L_max.", "[VAR] The daily observations of the child's behavior are represented by the variable x.", "[LIMIT] The minimum required sleep duration for a child is denoted as s_min."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The child's learning difficulty L is minimized when the sleep duration s is at its maximum allowable value and the attention level a is at its maximum value.\nASSUMPTION: None\nVERIFICATION: L = f(s, a, t) with s = 24 hours and a = 1, under the given constraints.", "rejected": "The child's learning difficulty L is minimized when the sleep duration s is at its minimum allowable value and the attention level a is at its maximum value.", "E_acc": 0.18983925879001617, "C_acc": 0.6392110586166382, "G_acc": 0.5689664683304727, "D_acc": 0.6677298163995147, "H_acc": 0.10145020484924316, "Q_acc": 0.46630380237475044, "E_rej": 0.2155514806509018, "C_rej": 0.5364681482315063, "G_rej": 0.5684737411793321, "D_rej": 0.9052903652191162, "H_rej": 0.09470963478088379, "Q_rej": 0.5426536723505706, "Delta_Q": -0.07634986997582016, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Transparency vs strategic opacity: analyze when revealing explanation artifacts incentivizes gaming by modeled agents.Counterfactual chaining across modalities: given causal graphs in different subsystems (physical, social, computational), find minimal cross-domain interventions to achieve a target.", "ancestors": ["[DEF] A causal graph is a directed graph G = (V, E) where V is a set of vertices and E is a set of edges.", "[VAR] Let c denote the number of vertices in the causal graph.", "[LAW] The causal graph G = (V, E) satisfies the condition that for every edge (u, v) in E, u is a cause of v.", "[CONSTRAINT] The set of vertices V is partitioned into three subsets: physical (P), social (S), and computational (C).", "[LIMIT] The number of edges between any two subsets is limited by the minimum number of vertices in the two subsets.", "[VAR] Let t denote the minimum number of cross-domain interventions required to achieve a target.", "[LAW] The number of cross-domain interventions t is a function of the number of vertices c and the partitioning of V into P, S, and C."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of cross-domain interventions t is at least the minimum number of vertices in any two subsets of V.\nASSUMPTION: None\nVERIFICATION: t >= min(|P|, |S|, |C|, |P| + |S|, |P| + |C|, |S| + |C|) under the given partitioning of V.", "rejected": "The number of cross-domain interventions t is at most the minimum number of vertices in any two subsets of V.", "E_acc": 0.3139135241508484, "C_acc": 0.4770587086677551, "G_acc": 0.5517467747309378, "D_acc": 0.6612408957444131, "H_acc": 0.18209955096244812, "Q_acc": 0.5231498945105288, "E_rej": 0.5633613467216492, "C_rej": 0.2775357663631439, "G_rej": 0.5420145794217076, "D_rej": 0.8345655202865601, "H_rej": 0.16543447971343994, "Q_rej": 0.6722738227141755, "Delta_Q": -0.14912392820364662, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multiscale pattern formation: given local interaction rules, deduce which global patterns are possible and which require fine-tuning of parameters.", "ancestors": ["[DEF] A pattern formation system consists of a set of local interaction rules.", "[VAR] Let x and y denote the spatial coordinates of the system.", "[LAW] The local interaction rules are defined by a set of partial differential equations, ∂u/∂t = f(u, ∇u), where u is a vector of state variables.", "[CONSTRAINT] The system is defined on a bounded domain, Ω, with boundary conditions, B.", "[VAR] Let c denote the set of parameters controlling the local interaction rules.", "[LAW] The global patterns that emerge are described by the solution, u(x, y, t), of the partial differential equations.", "[CONSTRAINT] The solution, u, must satisfy the boundary conditions, B, for all time, t.", "[LIMIT] The number of possible global patterns is limited by the dimensionality of the parameter space, c.", "[CONSTRAINT] The emergence of certain global patterns requires specific values of the parameters, c, within a subset, R, of the parameter space.", "[LIMIT] The size of the subset, R, is limited by the complexity of the local interaction rules, f(u, ∇u)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The dimensionality of the parameter space, c, limits the number of possible global patterns that can emerge in the system.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The number of possible global patterns that can emerge in the system limits the dimensionality of the parameter space, c.", "E_acc": 0.24501800537109375, "C_acc": 0.5279080867767334, "G_acc": 0.5370227074516671, "D_acc": 0.5733664196450263, "H_acc": 0.21522587537765503, "Q_acc": 0.46847902213755466, "E_rej": 0.5200167298316956, "C_rej": 0.053821925073862076, "G_rej": 0.5402597337961197, "D_rej": 0.8291166126728058, "H_rej": 0.1708833873271942, "Q_rej": 0.702027564495802, "Delta_Q": -0.2335485423582473, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["[DEF] The problem is defined as finding the minimum cost of a solution to an NP-hard optimization problem.", "[VAR] Let c be the cost of the solution and x be the vector of decision variables.", "[LAW] The cost function is given by c = ∑(i=1 to n) w_i * x_i, where w_i are non-negative weights.", "[CONSTRAINT] The solution must satisfy the constraint ∑(i=1 to n) x_i <= B, where B is a positive constant.", "[CONSTRAINT] Each decision variable x_i must satisfy the constraint 0 <= x_i <= 1.", "[VAR] Let R be the relaxation of the problem, where the decision variables x_i are allowed to take on any real value between 0 and 1.", "[LIMIT] The relaxation R has an integrality gap, which is defined as the ratio of the optimal solution value of R to the optimal solution value of the original problem.", "[CONSTRAINT] The integrality gap of R is bounded below by 1 and above by some constant t.", "[VAR] Let t be the smallest constant such that the integrality gap of R is bounded above by t.", "[LIMIT] The value of t is at most 2, which provides a tight upper bound on the integrality gap of R."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The minimum cost of the solution is achieved when the decision variables x_i are set to minimize the weighted sum c = ∑(i=1 to n) w_i * x_i, subject to the given constraints.\nASSUMPTION: None\nVERIFICATION: The cost function c and the constraints ∑(i=1 to n) x_i <= B and 0 <= x_i <= 1 must be satisfied, with units of cost and decision variables in a consistent regime.", "rejected": "The minimum cost of the solution is achieved when the decision variables x_i are set to minimize the weighted sum c = ∑(i=1 to n) w_i * x_i, subject to the given constraints, and this minimum cost is also applicable when the weights w_i are negative.", "E_acc": 0.318057119846344, "C_acc": 0.37011054158210754, "G_acc": 0.5628889590734616, "D_acc": 0.6685521829786012, "H_acc": 0.19615117460489273, "Q_acc": 0.548068138587405, "E_rej": 0.21807308495044708, "C_rej": 0.42456963658332825, "G_rej": 0.5533980440231971, "D_rej": 0.8408753871917725, "H_rej": 0.15912461280822754, "Q_rej": 0.5434502231306397, "Delta_Q": 0.004617915456765265, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a person fainted due to dehydration, low blood sugar, or heat stress by reasoning from symptoms, timing, and prior activity", "ancestors": ["[DEF] Let c represent the person's core body temperature.", "[VAR] The person's blood sugar level is denoted by the variable x.", "[LAW] The relationship between core body temperature c and blood sugar level x is influenced by the elapsed time t since the person last consumed food or water.", "[CONSTRAINT] The person's activity level prior to fainting is represented by the variable B, which is bounded by 0 ≤ B ≤ 10.", "[LIMIT] The maximum allowable core body temperature c is 40.5 degrees Celsius.", "[VAR] The amount of fluids consumed by the person in the hours leading up to fainting is denoted by the variable y.", "[CONSTRAINT] The person's blood sugar level x is constrained by the condition 60 ≤ x ≤ 120 milligrams per deciliter.", "[LAW] The probability of fainting due to dehydration, low blood sugar, or heat stress is a function of the variables c, x, t, B, and y, denoted by the function R(c, x, t, B, y)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The probability of fainting due to dehydration, low blood sugar, or heat stress increases when the core body temperature c exceeds 40 degrees Celsius.\nASSUMPTION: None\nVERIFICATION: Temperature in degrees Celsius, within the human physiological regime.", "rejected": "The probability of fainting due to dehydration, low blood sugar, or heat stress decreases when the core body temperature c exceeds 40 degrees Celsius.", "E_acc": 0.12412289530038834, "C_acc": 0.7451176047325134, "G_acc": 0.5075537434240687, "D_acc": 0.6813584116753191, "H_acc": 0.1097668707370758, "Q_acc": 0.4150190915897838, "E_rej": 0.1422378420829773, "C_rej": 0.7009842991828918, "G_rej": 0.5038970277528279, "D_rej": 0.902868390083313, "H_rej": 0.09713160991668701, "Q_rej": 0.4741144153638743, "Delta_Q": -0.05909532377409049, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["[DEF] A program P is a sequence of instructions that transforms input x into output y.", "[VAR] Let c denote the complexity of a program P.", "[VAR] Let t denote the number of examples provided for synthesis.", "[CONSTRAINT] The synthesized program P must be consistent with all t examples.", "[LIMIT] The risk of overfitting R is bounded by a predefined threshold B.", "[VAR] Let x and y denote the input and output of the synthesized program P, respectively.", "[LAW] The simplest program consistent with examples is the one with the minimum complexity c that satisfies the constraint."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The synthesized program P has a complexity c that is minimal among all programs consistent with the t examples.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The synthesized program P has a complexity c that is minimal among all programs consistent with the t examples when the risk of overfitting R exceeds the predefined threshold B.", "E_acc": 0.16245347261428833, "C_acc": 0.7098217606544495, "G_acc": 0.5265969147107431, "D_acc": 0.6211593048647046, "H_acc": 0.1468852162361145, "Q_acc": 0.4216344119448747, "E_rej": 0.24904201924800873, "C_rej": 0.5463188290596008, "G_rej": 0.5339750837800759, "D_rej": 0.9056417346000671, "H_rej": 0.09435826539993286, "Q_rej": 0.5439363770985177, "Delta_Q": -0.122301965153643, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Constructive combinatorics: given a family of sets with intersection constraints, build an explicit object that meets extremal bounds rather than using existence-only proofs.", "ancestors": ["[DEF] A family of sets is defined as F = {S1, S2, ..., Sn}.", "[VAR] Let x denote the number of sets in the family F.", "[CONSTRAINT] Each set Si in F has a non-empty intersection with at least one other set Sj in F.", "[LIMIT] The size of each set Si in F is bounded by a constant c.", "[VAR] Let y denote the maximum size of any set Si in F.", "[CONSTRAINT] For any two sets Si and Sj in F, their intersection has at most t elements.", "[LAW] The number of sets in F that intersect with a given set Si is at least 2.", "[CONSTRAINT] The total number of elements in all sets in F is bounded by a constant B.", "[LIMIT] The maximum number of sets in F that can be constructed under these constraints is bounded by a constant R."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of sets in the family F is bounded by a constant that depends on the constants c, t, and B.\nASSUMPTION: None\nVERIFICATION: The bound can be expressed as a function of c, t, and B, such as x ≤ B / (2 * min(c, t)).", "rejected": "The number of sets in the family F is bounded by a constant that depends on the constants c, t, and B, and the sets in F are mutually disjoint, so x ≤ B / (2 * min(c, t)).", "E_acc": 0.2077406495809555, "C_acc": 0.4889974892139435, "G_acc": 0.5429914659471251, "D_acc": 0.6380778481252491, "H_acc": 0.14936798810958862, "Q_acc": 0.485799761035014, "E_rej": 0.29220905900001526, "C_rej": 0.4104374647140503, "G_rej": 0.5340839761774987, "D_rej": 0.8224066197872162, "H_rej": 0.1775933802127838, "Q_rej": 0.5591140059288592, "Delta_Q": -0.07331424489384519, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] A mechanism is a function that maps agent reports to outcomes.", "[VAR] Let k denote the number of steps an agent can reason.", "[LIMIT] Agents are limited to k-step reasoning.", "[CONSTRAINT] The allocation rule must be strategyproof for all agents.", "[VAR] Let x denote the true type of an agent and y denote the reported type.", "[LAW] The allocation rule assigns an outcome based on the reported types of all agents.", "[CONSTRAINT] The mechanism must ensure that reporting truthfully is a dominant strategy for all agents.", "[VAR] Let B denote the set of all possible outcomes and R denote the set of all possible reports.", "[LIMIT] The number of steps k is a fixed constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The mechanism must assign outcomes such that no agent can improve their outcome by reporting a type other than their true type.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The mechanism assigns outcomes such that no agent can improve their outcome by reporting a type other than their true type only if the agent reports their true type.", "E_acc": 0.45631417632102966, "C_acc": 0.3100426495075226, "G_acc": 0.5515251172473654, "D_acc": 0.6299035577103496, "H_acc": 0.33319687470793724, "Q_acc": 0.5778517705155536, "E_rej": 0.6300150156021118, "C_rej": 0.08711014688014984, "G_rej": 0.5717789204209112, "D_rej": 0.8453681766986847, "H_rej": 0.1546318233013153, "Q_rej": 0.7395487123983913, "Delta_Q": -0.16169694188283767, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["[DEF] A program P is a sequence of instructions that compute a output from a given input.", "[VAR] Let x be the input to program P and y be the corresponding output.", "[LAW] The program synthesis process aims to find a program P that satisfies the condition y = P(x) for all given examples.", "[CONSTRAINT] The search space of possible programs is constrained by a set of predefined instructions and their combinations.", "[VAR] Let c be the complexity of a program P, measured by the number of instructions it contains.", "[LIMIT] The maximum allowed complexity of a program is bounded by a constant B.", "[CONSTRAINT] The program synthesis process must ensure that the inferred program P does not overfit to spurious patterns in the given examples.", "[VAR] Let R be the risk of overfitting, measured by the difference between the program's performance on the training examples and its performance on unseen data.", "[LAW] The program synthesis process aims to minimize the complexity c of the inferred program P while keeping the risk R below a certain threshold t.", "[CONSTRAINT] The threshold t is a predefined constant that determines the maximum allowed risk of overfitting."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The program synthesis process will prioritize programs with complexity c less than or equal to B to minimize the risk R of overfitting.\nASSUMPTION: None\nVERIFICATION: c and B must be measured in the same units, such as number of instructions.", "rejected": "The program synthesis process will prioritize programs with complexity c greater than B to minimize the risk R of overfitting.", "E_acc": 0.17279431223869324, "C_acc": 0.5869191884994507, "G_acc": 0.5335179623216391, "D_acc": 0.6395263085141778, "H_acc": 0.18111992627382278, "Q_acc": 0.450951317511499, "E_rej": 0.234501913189888, "C_rej": 0.3404192626476288, "G_rej": 0.5397514132782817, "D_rej": 0.8726710379123688, "H_rej": 0.12732896208763123, "Q_rej": 0.5720183154568077, "Delta_Q": -0.12106699794530873, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining if a child’s learning difficulty is caused by lack of sleep, attention issues, or teaching mismatch from daily observations", "ancestors": ["[DEF] A child's learning difficulty refers to a situation where a child experiences challenges in acquiring new skills or knowledge.", "[VAR] The amount of sleep a child gets each night can vary.", "[LAW] Human brains require a certain amount of sleep to function properly.", "[CONSTRAINT] A child's daily schedule can limit the amount of sleep they get.", "[VAR] The level of attention a child can devote to a task also varies.", "[LIMIT] There is a limit to how much information a child can process at one time.", "[CONSTRAINT] Teaching methods must be compatible with a child's learning style to be effective.", "[DEF] A teaching mismatch occurs when the teaching method does not align with the child's learning style."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A child's learning difficulty is more likely to occur when the amount of sleep they get is less than the amount required for their brain to function properly.\nASSUMPTION: The amount of sleep required for a child's brain to function properly is consistent across similar age groups.\nVERIFICATION: Comparison of sleep patterns and learning outcomes across similar age groups.", "rejected": "A child's learning difficulty is more likely to occur when the amount of sleep they get is less than the amount required for their brain to function properly, regardless of the teaching method used.", "E_acc": 0.5404211282730103, "C_acc": 0.1574774533510208, "G_acc": 0.5173812416614965, "D_acc": 0.7122911931946874, "H_acc": 0.21589216589927673, "Q_acc": 0.654976118193008, "E_rej": 0.03493385389447212, "C_rej": 0.4053918421268463, "G_rej": 0.496214710874483, "D_rej": 0.8815968334674835, "H_rej": 0.11840316653251648, "Q_rej": 0.493123779958114, "Delta_Q": 0.16185233823489403, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial robustness for decision trees: transform a decision procedure to simultaneously maximize accuracy and a certified robustness radius.", "ancestors": ["[DEF] A decision tree is a tree-like model used for classification and regression tasks.", "[VAR] The decision procedure of a decision tree is defined by its splitting criteria and leaf node predictions.", "[CONSTRAINT] The goal of adversarial robustness for decision trees is to maximize both accuracy and a certified robustness radius.", "[LIMIT] The certified robustness radius is limited by the minimum distance between the decision boundary and the nearest adversarial example.", "[DEF] The robustness radius of a decision tree is the minimum distance from a given input to the decision boundary.", "[VAR] The splitting criteria of a decision tree can be modified to improve its robustness to adversarial examples.", "[LAW] The accuracy of a decision tree is measured by its ability to correctly classify new, unseen data.", "[CONSTRAINT] The transformation of a decision procedure to maximize accuracy and robustness is subject to the constraint of preserving the original decision tree's structure."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The certified robustness radius of a decision tree is limited by the minimum distance between the decision boundary and the nearest adversarial example that can be achieved by modifying the splitting criteria.\nASSUMPTION: None\nVERIFICATION: The units of the certified robustness radius and the minimum distance are in the same regime as the input data.", "rejected": "The minimum distance between the decision boundary and the nearest adversarial example that can be achieved by modifying the splitting criteria limits the certified robustness radius of a decision tree.", "E_acc": 0.12600858509540558, "C_acc": 0.42140519618988037, "G_acc": 0.5271985409005234, "D_acc": 0.683491162606515, "H_acc": 0.0942029356956482, "Q_acc": 0.48623918342248845, "E_rej": 0.5525336861610413, "C_rej": 0.21971967816352844, "G_rej": 0.5370175639788309, "D_rej": 0.9290319979190826, "H_rej": 0.07096800208091736, "Q_rej": 0.7079292823870977, "Delta_Q": -0.22169009896460928, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether an animal’s sudden change in behavior is due to illness, environmental disruption, or social hierarchy shifts", "ancestors": ["[DEF] An animal's behavior is influenced by various factors, including its physical condition, environment, and social interactions.", "[VAR] The physical condition of an animal can change over time due to illness or injury.", "[LAW] Animals generally exhibit consistent behavior patterns within their natural habitats.", "[CONSTRAINT] Changes in an animal's behavior can be triggered by disruptions to its environment.", "[VAR] Social hierarchy within a group of animals can impact individual behavior and interactions.", "[LIMIT] Observations of an animal's behavior are limited to the duration and context of the observation period.", "[DEF] Environmental disruption refers to any change in the animal's surroundings that affects its behavior or well-being.", "[CONSTRAINT] An animal's social hierarchy can shift due to changes in group composition or dominance.", "[VAR] Illness in an animal can manifest as changes in appetite, activity level, or social interaction.", "[LIMIT] The accuracy of determining the cause of an animal's behavioral change is limited by the availability of relevant data and observation time."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: An animal's behavioral change is more likely to occur when its physical condition and environmental disruption coincide.\nASSUMPTION: The impact of physical condition and environmental disruption on an animal's behavior is cumulative.\nVERIFICATION: Observation of animal behavior over a prolonged period, measuring frequency of behavioral changes against physical condition and environmental disruption metrics.", "rejected": "An animal's behavioral change is more likely to occur when its social hierarchy and environmental disruption coincide.", "E_acc": 0.5519988536834717, "C_acc": 0.10297007858753204, "G_acc": 0.5674619264900684, "D_acc": 0.7822505561634898, "H_acc": 0.16673389077186584, "Q_acc": 0.6982747478410603, "E_rej": 0.3409692347049713, "C_rej": 0.13885025680065155, "G_rej": 0.5696233099442907, "D_rej": 0.8826576173305511, "H_rej": 0.11734238266944885, "Q_rej": 0.6532426662393847, "Delta_Q": 0.0450320816016756, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] Mechanism design refers to the process of creating systems that achieve specific goals.", "[VAR] Agents in a mechanism have bounded rationality, meaning their reasoning is limited to k steps.", "[CONSTRAINT] The value of k is a fixed constant that varies across different agents.", "[LIMIT] Agents' reasoning is restricted to a finite number of steps, denoted by the value of k.", "[DEF] Strategyproof allocation rules are designed to prevent agents from manipulating the system for personal gain.", "[VAR] The number of steps k that an agent can reason is a variable that affects the allocation rules.", "[CONSTRAINT] Allocation rules must be designed to accommodate agents with different values of k.", "[LIMIT] The complexity of the allocation rules is limited by the need to ensure strategyproofness for k-step reasoning.", "[CONSTRAINT] The allocation rules must ensure that the outcome is fair and efficient for all agents, regardless of their value of k."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The allocation rules must be designed to accommodate the minimum value of k among all agents to ensure strategyproofness.\nASSUMPTION: None\nVERIFICATION: The validity of this hypothesis can be checked by testing the allocation rules with the minimum k value and verifying that they remain strategyproof.", "rejected": "The allocation rules must be designed to accommodate the maximum value of k among all agents to ensure strategyproofness.", "E_acc": 0.14697079360485077, "C_acc": 0.6113204956054688, "G_acc": 0.5960360614117235, "D_acc": 0.6875642193481326, "H_acc": 0.2511283755302429, "Q_acc": 0.4534343575593084, "E_rej": 0.055392321199178696, "C_rej": 0.8605390787124634, "G_rej": 0.604297527577728, "D_rej": 0.8689379990100861, "H_rej": 0.16382750123739243, "Q_rej": 0.42277423581108453, "Delta_Q": 0.030660121748223856, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a rumor will spread or die out in a community based on trust networks, repetition, and perceived incentives", "ancestors": ["[DEF] A trust network is a set of individuals connected by relationships of trust.", "[VAR] The structure of a trust network can vary between communities.", "[CONSTRAINT] Trust networks are composed of individuals who interact with one another.", "[LIMIT] The number of individuals in a trust network is finite.", "[VAR] Repetition of information can occur within a trust network.", "[DEF] Perceived incentives are rewards or motivations that individuals believe they will receive.", "[LAW] Information is more likely to spread within a trust network when repetition occurs.", "[CONSTRAINT] The spread of information within a trust network is influenced by the perceived incentives of the individuals.", "[LIMIT] The resources available to individuals in a trust network to process and act on information are limited."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The spread of information within a trust network is more likely to occur when the perceived incentives of the individuals are aligned with the information being shared.\nASSUMPTION: None\nVERIFICATION: Alignment of perceived incentives can be measured through surveys or feedback from individuals within the trust network.", "rejected": "The spread of information within a trust network is more likely to occur when the perceived incentives of the individuals are independent of the information being shared.", "E_acc": 0.33628350496292114, "C_acc": 0.4039371609687805, "G_acc": 0.5701843618880957, "D_acc": 0.692455634358339, "H_acc": 0.16291776299476624, "Q_acc": 0.5563338422449307, "E_rej": 0.03650297224521637, "C_rej": 0.8111327290534973, "G_rej": 0.5607802997110412, "D_rej": 0.8790793716907501, "H_rej": 0.12092062830924988, "Q_rej": 0.42460421731229875, "Delta_Q": 0.1317296249326319, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining if a child’s learning difficulty is caused by lack of sleep, attention issues, or teaching mismatch from daily observations", "ancestors": ["[DEF] A child's learning difficulty refers to a situation where a child experiences challenges in acquiring new skills or knowledge.", "[VAR] The amount of sleep a child gets each night can vary.", "[LAW] Human brains require a certain amount of sleep to function properly.", "[CONSTRAINT] Observations of a child's behavior are limited to the time spent with the child.", "[VAR] The teaching methods used can differ from one educator to another.", "[LIMIT] The number of potential causes of a child's learning difficulty is finite.", "[CONSTRAINT] Daily observations can only capture a subset of a child's overall behavior and learning patterns."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A child's learning difficulty is more likely to occur when the amount of sleep they get each night is less than the amount required for proper brain function.\nASSUMPTION: The amount of sleep required for proper brain function is consistent across children of the same age group.\nVERIFICATION: Comparison of sleep patterns and learning outcomes in a controlled study with a representative sample of children.", "rejected": "A child's learning difficulty is more likely to occur when the amount of sleep they get each night is greater than the amount required for proper brain function.", "E_acc": 0.07831822335720062, "C_acc": 0.7319796681404114, "G_acc": 0.5149554945528507, "D_acc": 0.7255051047541201, "H_acc": 0.20347169041633606, "Q_acc": 0.40484448419883845, "E_rej": 0.028126593679189682, "C_rej": 0.23615984618663788, "G_rej": 0.5005099345507915, "D_rej": 0.894434928894043, "H_rej": 0.10556507110595703, "Q_rej": 0.5296384744448006, "Delta_Q": -0.12479399024596216, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["[DEF] A separation of concerns in proofs involves identifying distinct aspects of a system to analyze and verify.", "[VAR] Invariant quantities are variables that remain unchanged throughout a sequence of updates.", "[LAW] Bayesian updating is a method for revising probabilities based on new data, using Bayes' theorem.", "[CONSTRAINT] Model misspecification occurs when the assumed model does not accurately represent the true data-generating process.", "[LIMIT] The posterior distribution resulting from Bayesian updating with a misspecified model may not converge to the true parameter values.", "[DEF] Diagnostics in Bayesian analysis refer to methods for evaluating the quality and reliability of the results.", "[VAR] The concentration of the posterior distribution on a particular subset of models can be measured using metrics such as Kullback-Leibler divergence.", "[LAW] The data-generating process can be characterized by a set of underlying parameters and a probability distribution.", "[CONSTRAINT] The accuracy of Bayesian updating relies on the assumption that the model is correctly specified, which may not always hold in practice."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The posterior distribution resulting from Bayesian updating with a misspecified model may not converge to the true parameter values if the model misspecification is significant.\nASSUMPTION: The degree of model misspecification can be quantitatively measured.\nVERIFICATION: Comparison of the Kullback-Leibler divergence between the assumed and true models.", "rejected": "The posterior distribution resulting from Bayesian updating with a misspecified model will always converge to the true parameter values if the model misspecification is significant.", "E_acc": 0.274235337972641, "C_acc": 0.21593622863292694, "G_acc": 0.5702410520752892, "D_acc": 0.7297999709844589, "H_acc": 0.1685647964477539, "Q_acc": 0.5822350806323812, "E_rej": 0.02636374905705452, "C_rej": 0.4129001498222351, "G_rej": 0.5548068952048197, "D_rej": 0.8354417979717255, "H_rej": 0.20569775253534317, "Q_rej": 0.4828090581344441, "Delta_Q": 0.09942602249793708, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] Mechanism design refers to the process of creating systems that achieve specific goals.", "[VAR] Agents in a mechanism have bounded rationality, limited to k-step reasoning.", "[CONSTRAINT] The value of k is a fixed positive integer.", "[LIMIT] Agents' reasoning is restricted to a finite number of steps, determined by k.", "[DEF] Strategyproof allocation rules are those that incentivize agents to report their true preferences.", "[VAR] The number of agents participating in the mechanism is denoted by n.", "[CONSTRAINT] Each agent has a unique set of preferences over the possible allocations.", "[LIMIT] The complexity of the allocation rules is limited by the agents' bounded rationality."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of possible allocations that can be considered by an agent is limited by the agent's k-step reasoning.\nASSUMPTION: None\nVERIFICATION: The number of possible allocations must be finite and countable within the k-step reasoning limit.", "rejected": "The agent's k-step reasoning is limited by the number of possible allocations that can be considered by the agent.", "E_acc": 0.2218613475561142, "C_acc": 0.5914543867111206, "G_acc": 0.5826744786463678, "D_acc": 0.6871917280368507, "H_acc": 0.2723544090986252, "Q_acc": 0.47500532735139134, "E_rej": 0.5470591187477112, "C_rej": 0.1837662011384964, "G_rej": 0.5953374702949077, "D_rej": 0.8397067785263062, "H_rej": 0.16029322147369385, "Q_rej": 0.6983440230134874, "Delta_Q": -0.22333869566209608, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Separation of concerns in proofs: identify invariant quantities that survive a sequence of destructive updates and prove impossibility of target states.Bayesian updating with model misspecification: show how posterior concentrates on wrong models and design diagnostics to detect and correct it.", "ancestors": ["[DEF] A sequence of destructive updates is a series of operations that modify a system's state.", "[VAR] The state of a system can be described by a set of variables.", "[LAW] Bayesian updating is a method for updating the probability estimate of a model as more data becomes available.", "[CONSTRAINT] Model misspecification occurs when the assumed model does not accurately represent the true underlying system.", "[LIMIT] The number of possible models is finite.", "[DEF] Invariant quantities are properties of a system that remain unchanged under a sequence of destructive updates.", "[VAR] The posterior distribution is a probability distribution over models given observed data.", "[CONSTRAINT] The posterior distribution concentrates on a subset of models that are most consistent with the observed data.", "[LAW] The concentration of the posterior distribution is influenced by the likelihood function and prior distribution.", "[LIMIT] The accuracy of Bayesian updating is limited by the quality of the assumed model and the available data."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The accuracy of Bayesian updating is limited by the number of possible models.\nASSUMPTION: The number of possible models is a key factor in determining the accuracy of Bayesian updating.\nVERIFICATION: The relationship between the number of possible models and the accuracy of Bayesian updating can be tested by comparing the performance of Bayesian updating across systems with different numbers of possible models.", "rejected": "The accuracy of Bayesian updating is limited by the number of possible models in the context of invariant quantities.", "E_acc": 0.588412880897522, "C_acc": 0.05443572998046875, "G_acc": 0.5511703087831847, "D_acc": 0.7911918330937624, "H_acc": 0.18146240711212158, "Q_acc": 0.7159629059373402, "E_rej": 0.33012381196022034, "C_rej": 0.18524332344532013, "G_rej": 0.5685834079195047, "D_rej": 0.8779204189777374, "H_rej": 0.12207958102226257, "Q_rej": 0.6390812861762243, "Delta_Q": 0.07688161976111596, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergence of effective dissipation from reversible microdynamics: provide a mechanism and timescale for apparent irreversibility in a closed finite system.", "ancestors": ["[DEF] A closed finite system is a system with a finite number of particles and no exchange of matter or energy with its surroundings.", "[VAR] The microdynamics of a closed finite system are described by the time-evolution of its constituent particles.", "[LAW] The time-evolution of the particles in a closed finite system is governed by the laws of classical or quantum mechanics.", "[CONSTRAINT] The system's finite size imposes a constraint on the available phase space of the particles.", "[VAR] The particles in the system interact with each other through short-range and long-range forces.", "[LAW] The interactions between particles conserve energy, momentum, and angular momentum.", "[CONSTRAINT] The system's initial conditions and boundary conditions determine its subsequent time-evolution.", "[LIMIT] The timescale for apparent irreversibility in a closed finite system is limited by the system's relaxation time.", "[CONSTRAINT] The emergence of effective dissipation in a closed finite system requires a mechanism for ergodic exploration of the available phase space."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The emergence of effective dissipation in a closed finite system requires a timescale longer than the system's relaxation time.\nASSUMPTION: The system's relaxation time is a well-defined and measurable quantity.\nVERIFICATION: units of time, e.g., seconds or milliseconds, depending on the system's specific characteristics.", "rejected": "The emergence of effective dissipation in a closed finite system requires a length scale longer than the system's relaxation time.", "E_acc": 0.18349118530750275, "C_acc": 0.5076411366462708, "G_acc": 0.5255155297151456, "D_acc": 0.6788249085657299, "H_acc": 0.2511299401521683, "Q_acc": 0.46927422190395496, "E_rej": 0.33161330223083496, "C_rej": 0.36785653233528137, "G_rej": 0.5100600375638654, "D_rej": 0.8329861462116241, "H_rej": 0.16701385378837585, "Q_rej": 0.5778205355784546, "Delta_Q": -0.10854631367449963, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evolutionary game with frequency-dependent payoffs: characterize ESS (evolutionarily stable strategies) and paths of fixation when mutation introduces novelty.", "ancestors": ["[DEF] An evolutionary game is a mathematical framework for studying the evolution of strategies in a population.", "[VAR] The payoffs in an evolutionary game can depend on the frequencies of the strategies employed by the population.", "[LAW] The evolutionarily stable strategy (ESS) is a strategy that, when adopted by a population, cannot be invaded by a mutant strategy.", "[CONSTRAINT] The ESS is determined by the payoffs and the mutation rate in the population.", "[VAR] Mutation introduces novelty into the population by creating new strategies.", "[LIMIT] The rate of mutation is typically assumed to be small compared to the selection pressure.", "[CONSTRAINT] The paths of fixation are the trajectories by which a new strategy becomes fixed in the population.", "[LAW] The paths of fixation are influenced by the fitness landscape, which is shaped by the payoffs and the population's genetic variation.", "[VAR] Frequency-dependent payoffs can lead to multiple ESS in an evolutionary game.", "[CONSTRAINT] The stability of an ESS is determined by its ability to resist invasion by nearby mutant strategies."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The evolution of strategies in a population will converge to an evolutionarily stable strategy if the mutation rate is sufficiently small.\nASSUMPTION: The population size is sufficiently large to ensure that the effects of genetic drift are negligible.\nVERIFICATION: The convergence can be verified by analyzing the trajectories of the paths of fixation and the resulting fitness landscape.", "rejected": "The evolution of strategies in a population will converge to an evolutionarily stable strategy if the mutation rate is sufficiently small and the population's genetic variation is independent of the payoffs.", "E_acc": 0.34555748105049133, "C_acc": 0.10963457077741623, "G_acc": 0.5593268138691201, "D_acc": 0.7161998189985752, "H_acc": 0.16183283925056458, "Q_acc": 0.6206623728081467, "E_rej": 0.3489304184913635, "C_rej": 0.08905316889286041, "G_rej": 0.5569597471039742, "D_rej": 0.9131997525691986, "H_rej": 0.08680024743080139, "Q_rej": 0.6722203669603914, "Delta_Q": -0.05155799415224471, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Error-correction vs resource cost in replication: determine optimal fidelity given trade-offs between repair energy and mutation-driven adaptability.Kinetic vs thermodynamic control: predict product distributions when reaction conditions vary temporally and catalysts modulate transition states selectively.", "ancestors": ["[DEF] Error-correction mechanisms are processes that maintain genetic fidelity during replication.", "[VAR] Resource cost is a variable that affects the efficiency of error-correction mechanisms.", "[LAW] The laws of thermodynamics govern the energy requirements of molecular repair processes.", "[CONSTRAINT] The trade-off between repair energy and mutation-driven adaptability is a constraint on optimal fidelity.", "[VAR] Catalysts are variables that can modulate transition states in chemical reactions.", "[LIMIT] The kinetic control of reaction rates has a limit imposed by the availability of reactants.", "[CONSTRAINT] The temporal variation of reaction conditions is a constraint on the predictability of product distributions.", "[LIMIT] The selectivity of catalysts in modulating transition states has a limit imposed by the binding affinity of the catalyst to the reactants."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The efficiency of error-correction mechanisms is limited by the trade-off between repair energy and mutation-driven adaptability.\nASSUMPTION: The energy requirements of molecular repair processes are directly related to the resource cost of error-correction mechanisms.\nVERIFICATION: N/A", "rejected": "The efficiency of error-correction mechanisms is increased by the trade-off between repair energy and mutation-driven adaptability.", "E_acc": 0.6806820631027222, "C_acc": 0.11681356281042099, "G_acc": 0.5434627466602251, "D_acc": 0.6648076642304659, "H_acc": 0.17252343893051147, "Q_acc": 0.7052436446538196, "E_rej": 0.33367806673049927, "C_rej": 0.39614200592041016, "G_rej": 0.5359102644724771, "D_rej": 0.8227330148220062, "H_rej": 0.17726698517799377, "Q_rej": 0.5748769761761652, "Delta_Q": 0.13036666847765443, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Emergent coordination from selfish agents with local rules: prove sufficient conditions for global cooperation without central control.", "ancestors": ["[DEF] Agents are entities that make decisions based on local information.", "[VAR] The set of possible actions for each agent is finite and non-empty.", "[LAW] Each agent's decision-making process is guided by a set of predefined rules.", "[CONSTRAINT] The rules governing each agent's behavior are based solely on local observations.", "[CONSTRAINT] Agents do not have access to global information about the system.", "[LIMIT] The number of possible states for each agent is bounded.", "[CONSTRAINT] Agents act solely in their own self-interest, without regard for global optimality."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of possible actions for each agent is limited by the number of possible states for each agent.\nASSUMPTION: None\nVERIFICATION: The number of actions must be less than or equal to the number of states, in terms of countable options.", "rejected": "The number of possible actions for each agent is limited by the number of possible states for the entire system.", "E_acc": 0.2679430842399597, "C_acc": 0.5463150143623352, "G_acc": 0.5668242536485195, "D_acc": 0.6845829244703054, "H_acc": 0.3114548698067665, "Q_acc": 0.49025587104260926, "E_rej": 0.593948245048523, "C_rej": 0.09770017862319946, "G_rej": 0.5821264311671257, "D_rej": 0.82307568192482, "H_rej": 0.17692431807518005, "Q_rej": 0.721992428600788, "Delta_Q": -0.2317365575581788, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Causal discovery with cyclical feedback: given time-series from nodes with delayed interactions, recover the minimal feedback graph compatible with observed phase relations.", "ancestors": ["[DEF] A node is an entity that generates a time-series signal.", "[VAR] Time-series signals are composed of a sequence of values measured at regular intervals.", "[DEF] A phase relation is a measure of the timing difference between two time-series signals.", "[LAW] The phase relation between two time-series signals is determined by their relative timing.", "[CONSTRAINT] The observed phase relations are constrained by the delayed interactions between nodes.", "[VAR] Delayed interactions between nodes are characterized by a time lag.", "[DEF] A feedback graph is a representation of the causal relationships between nodes.", "[CONSTRAINT] The minimal feedback graph is the simplest graph that is compatible with the observed phase relations.", "[LIMIT] The recoverability of the minimal feedback graph is limited by the accuracy of the observed time-series data.", "[CONSTRAINT] The minimal feedback graph must satisfy the constraint of cyclical feedback, where a node's output affects its own input after a delay."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The accuracy of the observed time-series data limits the recoverability of the minimal feedback graph.\nASSUMPTION: None\nVERIFICATION: The recoverability of the minimal feedback graph can be tested by comparing the observed phase relations with the predicted phase relations from the minimal feedback graph.", "rejected": "The recoverability of the minimal feedback graph limits the accuracy of the observed time-series data.", "E_acc": 0.508819580078125, "C_acc": 0.12874749302864075, "G_acc": 0.5227469347883016, "D_acc": 0.6833222177810967, "H_acc": 0.13804787397384644, "Q_acc": 0.6543054185342043, "E_rej": 0.5550450086593628, "C_rej": 0.10753800719976425, "G_rej": 0.5347904727095738, "D_rej": 0.8205484449863434, "H_rej": 0.17945155501365662, "Q_rej": 0.6981285291956737, "Delta_Q": -0.04382311066146938, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Sequential delegation: when an agent delegates to subagents with private incentives, derive mechanisms that ensure near-optimal end-to-end performance.", "ancestors": ["[DEF] An agent is an entity that makes decisions based on available information.", "[VAR] The set of subagents to which an agent can delegate tasks is denoted as S.", "[DEF] A private incentive is a motivation that affects a subagent's decision-making process.", "[LAW] The agent's objective is to maximize end-to-end performance across all delegated tasks.", "[CONSTRAINT] Each subagent has a limited capacity to process tasks.", "[VAR] The incentive structure of each subagent is represented by a function Is.", "[LIMIT] The number of subagents to which an agent can delegate is finite.", "[CONSTRAINT] The agent has limited resources to allocate among subagents.", "[DEF] Near-optimal end-to-end performance refers to a performance level that is within a specified threshold of the maximum achievable performance."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The agent's ability to maximize end-to-end performance is limited by the finite number of subagents and their limited capacity to process tasks.\nASSUMPTION: The agent's resources are allocated efficiently among subagents to achieve near-optimal end-to-end performance.\nVERIFICATION: The hypothesis can be tested by measuring the end-to-end performance under varying numbers of subagents and resource allocations.", "rejected": "The agent's ability to maximize end-to-end performance is limited by an infinite number of subagents and their limited capacity to process tasks.", "E_acc": 0.4367268681526184, "C_acc": 0.17728452384471893, "G_acc": 0.5464353968854994, "D_acc": 0.7428746800869703, "H_acc": 0.21763992309570312, "Q_acc": 0.6316591787617654, "E_rej": 0.010807923972606659, "C_rej": 0.9756034016609192, "G_rej": 0.5566946393810213, "D_rej": 0.8359360694885254, "H_rej": 0.1640639305114746, "Q_rej": 0.37024144558236005, "Delta_Q": 0.2614177331794053, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit is a mathematical model for decision-making under uncertainty.", "[VAR] The model consists of a set of arms, each associated with a reward distribution.", "[CONSTRAINT] The reward distributions are initially unknown to the decision-maker.", "[LIMIT] The decision-maker can only observe the reward of the arm they choose to pull.", "[VAR] The rewards may be delayed or censored, meaning their values or timings are not immediately known.", "[DEF] Partial observability refers to the condition where the decision-maker does not have full knowledge of the system state.", "[LAW] The decision-maker's goal is to maximize the cumulative reward over a sequence of arm pulls.", "[CONSTRAINT] The decision-maker must balance exploration of the arms to learn about their reward distributions and exploitation of the current knowledge to maximize reward.", "[VAR] The cost of sensing or pulling an arm can vary and affects the decision-making process.", "[LIMIT] The expected loss of a plan is bounded by the sum of the costs of information-gathering actions and execution risks."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The decision-maker's cumulative reward is maximized when the cost of sensing or pulling an arm is less than the expected reward of that arm.\nASSUMPTION: The cost of sensing or pulling an arm is directly comparable to the expected reward of that arm.\nVERIFICATION: The comparison must be in terms of the same units, such as monetary value or utility.", "rejected": "The cost of sensing or pulling an arm is less than the expected reward of that arm when the decision-maker's cumulative reward is maximized.", "E_acc": 0.37088608741760254, "C_acc": 0.2702900469303131, "G_acc": 0.5486485630806003, "D_acc": 0.6758536612614989, "H_acc": 0.2765859290957451, "Q_acc": 0.5744496687980635, "E_rej": 0.4009089469909668, "C_rej": 0.1397402137517929, "G_rej": 0.5368459464183876, "D_rej": 0.8192652761936188, "H_rej": 0.18073472380638123, "Q_rej": 0.6454734134886947, "Delta_Q": -0.07102374469063122, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["[DEF] A scientific hypothesis is a proposed explanation for a phenomenon.", "[VAR] The cost of an experiment is a variable that can be measured.", "[DEF] Information gain is a measure of the reduction in uncertainty about a hypothesis.", "[LIMIT] Resources available for experimentation are limited.", "[CONSTRAINT] The total cost of all experiments cannot exceed the available resources.", "[VAR] The information gain per unit cost varies across different experiments.", "[LAW] The expected information gain from an experiment is a function of the hypothesis being tested and the experiment design.", "[CONSTRAINT] Each experiment can only be conducted once.", "[LIMIT] The number of possible experiments is finite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total information gain from all experiments is maximized when the experiments with the highest information gain per unit cost are conducted first.\nASSUMPTION: None\nVERIFICATION: The information gain and cost of each experiment must be measured and compared to verify this hypothesis.", "rejected": "The total information gain from all experiments is maximized when the experiments with the highest information gain per unit cost are repeated indefinitely, as long as the experiments with the highest information gain per unit cost are conducted.", "E_acc": 0.13029171526432037, "C_acc": 0.6039495468139648, "G_acc": 0.5605140783591196, "D_acc": 0.728217332623899, "H_acc": 0.16210589557886124, "Q_acc": 0.45983329785522076, "E_rej": 0.16639326512813568, "C_rej": 0.224936380982399, "G_rej": 0.565755883930251, "D_rej": 0.8315695524215698, "H_rej": 0.16843044757843018, "Q_rej": 0.5675527458544821, "Delta_Q": -0.10771944799926136, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging if a satellite will remain in orbit or decay by reasoning from drag, altitude, mass, and atmospheric density", "ancestors": ["[DEF] A satellite's orbit is determined by its altitude above the Earth's surface.", "[VAR] The mass of a satellite varies depending on its construction and payload.", "[LAW] The force of drag on a satellite is directly proportional to its velocity and the density of the surrounding atmosphere.", "[CONSTRAINT] A satellite must have sufficient mass and velocity to overcome the force of gravity and remain in orbit.", "[VAR] Atmospheric density decreases with increasing altitude above the Earth's surface.", "[LIMIT] There is a minimum altitude below which the force of drag overwhelms the satellite's velocity, causing it to decay.", "[CONSTRAINT] The ratio of a satellite's mass to its cross-sectional area affects its susceptibility to atmospheric drag and orbital decay."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A satellite's orbital decay is more likely to occur at lower altitudes where atmospheric density is higher.\nASSUMPTION: None\nVERIFICATION: Atmospheric density and satellite altitude can be measured to test this hypothesis.", "rejected": "A satellite's orbital decay is more likely to occur at lower altitudes where atmospheric density is higher and its velocity is directly proportional to the satellite's mass.", "E_acc": 0.04838325455784798, "C_acc": 0.8253200054168701, "G_acc": 0.5303742486867122, "D_acc": 0.6537259866017848, "H_acc": 0.1967976987361908, "Q_acc": 0.3665912524680607, "E_rej": 0.11008749157190323, "C_rej": 0.5754414200782776, "G_rej": 0.5173514983616769, "D_rej": 0.8705436587333679, "H_rej": 0.12945634126663208, "Q_rej": 0.48257136074826124, "Delta_Q": -0.11598010828020056, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging whether a medication’s side effects outweigh its benefits for a patient by reasoning from symptom severity, alternatives, and risk tolerance", "ancestors": ["[DEF] A medication's side effects are the undesirable consequences of taking the medication.", "[VAR] The severity of a medication's side effects can vary from patient to patient.", "[LAW] The benefits of a medication are directly related to its intended therapeutic effect.", "[CONSTRAINT] A patient's medical history is a factor in determining the potential risks of a medication.", "[VAR] Alternative treatments are available for some medical conditions.", "[LIMIT] The number of alternative treatments available for a condition is finite.", "[DEF] Risk tolerance refers to a patient's willingness to accept potential risks associated with a medication.", "[CONSTRAINT] A patient's risk tolerance is influenced by their personal values and medical history.", "[VAR] The severity of a patient's symptoms can impact their risk tolerance for a medication.", "[LIMIT] The time and resources available to a patient can limit their ability to explore alternative treatments."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A patient's risk tolerance for a medication is inversely related to the severity of their symptoms.\nASSUMPTION: The relationship between symptom severity and risk tolerance is monotonic.\nVERIFICATION: Symptom severity can be measured on a standardized scale, such as a pain scale, to test this hypothesis.", "rejected": "A patient's risk tolerance for a medication is directly related to the severity of their symptoms, because it is assumed that symptom severity and risk tolerance are independent factors.", "E_acc": 0.023847118020057678, "C_acc": 0.04011058807373047, "G_acc": 0.5353650508332066, "D_acc": 0.7169664017856121, "H_acc": 0.2083846628665924, "Q_acc": 0.5287598420283758, "E_rej": 0.17863261699676514, "C_rej": 0.5474372506141663, "G_rej": 0.5236386340111494, "D_rej": 0.8613205850124359, "H_rej": 0.1386794149875641, "Q_rej": 0.507226237282157, "Delta_Q": 0.021533604746218793, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Resource-limited scientific inference: design an experiment selection strategy that maximizes information gain per unit cost across competing hypotheses.", "ancestors": ["[DEF] An experiment is a procedure designed to test a hypothesis.", "[VAR] The cost of an experiment is a variable that can be measured.", "[LIMIT] The total budget available for experiments is limited.", "[CONSTRAINT] Each experiment can only be conducted once.", "[VAR] The information gain from an experiment is a variable that can be measured.", "[LAW] The information gain from an experiment is a function of the experiment's design and the hypothesis being tested.", "[CONSTRAINT] The selection of experiments is constrained by the available budget and the cost of each experiment.", "[LIMIT] The number of possible experiments is finite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total information gain from all possible experiments is limited by the total budget available for experiments and the cost of each experiment.\nASSUMPTION: None\nVERIFICATION: The total information gain can be measured in units of information and is testable by comparing the total budget to the total cost of all experiments.", "rejected": "The total information gain from all possible experiments is increased by the total budget available for experiments and the cost of each experiment.", "E_acc": 0.3319159150123596, "C_acc": 0.4978911876678467, "G_acc": 0.5457408574293368, "D_acc": 0.7057491913437843, "H_acc": 0.18911728262901306, "Q_acc": 0.5313828184618615, "E_rej": 0.26269975304603577, "C_rej": 0.09519947320222855, "G_rej": 0.5313040124019608, "D_rej": 0.8112564384937286, "H_rej": 0.18874356150627136, "Q_rej": 0.6094077653018759, "Delta_Q": -0.07802494684001438, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Adversarial discovery of edge cases: construct distributions that maximize model failure probability subject to plausibility constraints.", "ancestors": ["[DEF] Adversarial discovery of edge cases refers to the process of finding inputs that cause a model to fail.", "[VAR] The model failure probability is a variable that measures the likelihood of a model producing incorrect outputs.", "[LAW] The probability of model failure is a function of the input distribution.", "[CONSTRAINT] The input distribution must be constrained to plausible inputs to ensure realistic edge case discovery.", "[CONSTRAINT] The plausibility constraints are defined by the problem domain and the characteristics of the input data.", "[LIMIT] The number of possible input distributions is limited by the dimensionality and complexity of the input space.", "[LIMIT] The computational resources available for adversarial discovery of edge cases impose a limit on the number of distributions that can be constructed and evaluated."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The model failure probability is directly influenced by the characteristics of the input data.\nASSUMPTION: None\nVERIFICATION: The relationship can be tested by analyzing the input distribution and model failure probability under various input data characteristics.", "rejected": "The model failure probability is directly influenced by the characteristics of all possible input data, regardless of the problem domain.", "E_acc": 0.43096858263015747, "C_acc": 0.2240685671567917, "G_acc": 0.5298077538609505, "D_acc": 0.6237119445577264, "H_acc": 0.30056481063365936, "Q_acc": 0.5851243199780584, "E_rej": 0.0023910400923341513, "C_rej": 0.9811522960662842, "G_rej": 0.5155055709848446, "D_rej": 0.7429212033748627, "H_rej": 0.25707879662513733, "Q_rej": 0.33046432802387116, "Delta_Q": 0.2546599919541872, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a plant is nutrient-deficient or water-stressed by observing leaf color, growth pattern, and soil conditions", "ancestors": ["[DEF] A plant's leaf color is a visible characteristic that can be observed.", "[VAR] Leaf color, growth pattern, and soil conditions are variables that can be measured in a plant.", "[LAW] Plants require a certain amount of water and nutrients to maintain healthy growth.", "[CONSTRAINT] Nutrient deficiency and water stress can both affect a plant's leaf color and growth pattern.", "[VAR] Soil moisture levels and nutrient content are variables that can be assessed in the soil surrounding a plant.", "[LIMIT] The ability to infer a plant's condition is limited by the accuracy of observations and measurements.", "[CONSTRAINT] Accurate assessment of a plant's condition requires consideration of multiple factors, including leaf color, growth pattern, and soil conditions."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A plant's leaf color is more likely to be affected by nutrient deficiency when soil moisture levels are low.\nASSUMPTION: The relationship between soil moisture levels and nutrient availability is inversely related.\nVERIFICATION: Measurement of soil moisture levels and nutrient content in relation to observed leaf color changes.", "rejected": "A plant's leaf color being affected by nutrient deficiency is more likely to cause low soil moisture levels.", "E_acc": 0.33911117911338806, "C_acc": 0.44540470838546753, "G_acc": 0.590764066146221, "D_acc": 0.7739249970763922, "H_acc": 0.1315838098526001, "Q_acc": 0.5724318437161856, "E_rej": 0.012908815406262875, "C_rej": 0.016184698790311813, "G_rej": 0.5971465206239372, "D_rej": 0.845680296421051, "H_rej": 0.15431970357894897, "Q_rej": 0.5737690979149193, "Delta_Q": -0.0013372541987336506, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Rare-event estimation with adversarial sampling: propose an estimator for tail risk when a sampler may bias toward low-probability regions.", "ancestors": ["[DEF] A rare event is an occurrence with a low probability of happening.", "[VAR] Let X be a random variable representing the outcome of an experiment.", "[CONSTRAINT] The sampler is allowed to bias toward low-probability regions of the distribution of X.", "[LIMIT] The estimator for tail risk has a finite sample size.", "[DEF] Adversarial sampling is a method where the sampler intentionally targets low-probability regions.", "[VAR] Let θ be a parameter representing the bias of the sampler toward low-probability regions.", "[LAW] The probability distribution of X is unknown but can be approximated using the sampled data.", "[CONSTRAINT] The estimator must be robust to the bias introduced by the adversarial sampler.", "[LIMIT] The computational resources available for estimating the tail risk are bounded."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The estimator for tail risk must have a threshold condition to account for the bias introduced by the adversarial sampler.\nASSUMPTION: The bias of the sampler toward low-probability regions is directly proportional to the parameter θ.\nVERIFICATION: The threshold condition must be testable using the sampled data and the parameter θ.", "rejected": "The estimator for tail risk must have a threshold condition to account for the bias introduced by the adversarial sampler when the probability distribution of X is known.", "E_acc": 0.23520967364311218, "C_acc": 0.052454352378845215, "G_acc": 0.54649976384826, "D_acc": 0.7091297190636396, "H_acc": 0.28394266963005066, "Q_acc": 0.5828036612365395, "E_rej": 0.2522543966770172, "C_rej": 0.31016626954078674, "G_rej": 0.5573790062917396, "D_rej": 0.8949046432971954, "H_rej": 0.1313691958785057, "Q_rej": 0.5909628754248842, "Delta_Q": -0.008159214188344754, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding if a wet road will refreeze overnight by reasoning from temperature trends, wind, humidity, and heat capacity of the ground", "ancestors": ["[DEF] Temperature is a measure of the average kinetic energy of particles in a substance.", "[VAR] The current air temperature is a variable that can be measured and recorded.", "[LAW] The heat capacity of a substance is a physical property that determines how much heat energy is required to change its temperature.", "[CONSTRAINT] The ground's heat capacity is limited by its composition and moisture content.", "[VAR] The wind speed is a variable that can affect the rate of heat transfer from the ground to the air.", "[LAW] The rate of heat transfer by convection is proportional to the wind speed.", "[CONSTRAINT] The humidity of the air limits the rate of evaporation of water from the ground.", "[VAR] The temperature trend over the past 24 hours is a variable that can be measured and analyzed.", "[LIMIT] The freezing point of water is a constant temperature, approximately 0 degrees Celsius.", "[CONSTRAINT] The ground will refreeze only if its temperature falls below the freezing point of water."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The ground's temperature will refreeze only if the air temperature falls below the freezing point of water and the wind speed is low enough to minimize heat transfer.\nASSUMPTION: The heat capacity of the ground is sufficiently low to allow refreezing within a short period of time.\nVERIFICATION: Temperature and wind speed measurements can be used to test this hypothesis under normal atmospheric conditions.", "rejected": "The ground's temperature will refreeze only if the air temperature falls below the freezing point of water and the wind speed is exactly 5 degrees Celsius to minimize heat transfer.", "E_acc": 0.18463926017284393, "C_acc": 0.23376107215881348, "G_acc": 0.5272190395335201, "D_acc": 0.703293823171407, "H_acc": 0.22068989276885986, "Q_acc": 0.53267314688419, "E_rej": 0.1065768450498581, "C_rej": 0.03508942574262619, "G_rej": 0.518686207360588, "D_rej": 0.82914799451828, "H_rej": 0.17085200548171997, "Q_rej": 0.5774368081940338, "Delta_Q": -0.04476366130984377, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "If A implies B unless C, and C is conditionally dependent on B, determine fixed points and possible oscillatory inference chains.", "ancestors": ["[DEF] A implies B is a conditional statement.", "[VAR] C is a condition that affects the implication of A implying B.", "[LAW] The implication of A implying B is negated if C is true.", "[CONSTRAINT] C is conditionally dependent on the truth value of B.", "[CONSTRAINT] The conditional dependence of C on B is defined as C if and only if B.", "[LIMIT] The implication of A implying B unless C is only applicable when C is defined.", "[VAR] The truth value of A is a prerequisite for the implication of A implying B.", "[DEF] A fixed point is a state where the truth values of A, B, and C do not change.", "[LIMIT] The existence of a fixed point is dependent on the initial truth values of A, B, and C.", "[CONSTRAINT] An oscillatory inference chain occurs when the truth values of A, B, and C repeatedly change."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The existence of a fixed point requires that the truth values of A, B, and C satisfy the condition that C is true if and only if B is true.\nASSUMPTION: None\nVERIFICATION: The truth values of A, B, and C must be consistently defined and satisfy the given constraints.", "rejected": "The existence of a fixed point requires that the truth values of A, B, and C satisfy the condition that C is true if and only if B is false.", "E_acc": 0.6193990707397461, "C_acc": 0.16504506766796112, "G_acc": 0.5399599197719779, "D_acc": 0.6948562897741795, "H_acc": 0.2224317565560341, "Q_acc": 0.6775307739419597, "E_rej": 0.3433229327201843, "C_rej": 0.44687381386756897, "G_rej": 0.5193742055978093, "D_rej": 0.7920476794242859, "H_rej": 0.2079523205757141, "Q_rej": 0.5551112619893892, "Delta_Q": 0.1224195119525705, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether a team will cooperate or fragment under pressure by reasoning from incentive alignment, leadership signals, and past stress responses", "ancestors": ["[DEF] A team is a group of individuals working together towards a common goal.", "[VAR] Incentive alignment refers to the degree to which team members' personal goals align with the team's common goal.", "[CONSTRAINT] Team members' actions are influenced by the incentives they receive.", "[LAW] Leadership signals are communications from team leaders that convey expectations and priorities.", "[VAR] Past stress responses refer to the ways in which team members have reacted to pressure in previous situations.", "[CONSTRAINT] Team cohesion is affected by the consistency of leadership signals.", "[DEF] Fragmentation occurs when team members prioritize their individual goals over the team's common goal.", "[LIMIT] The ability to predict team cooperation or fragmentation is limited by the availability of data on past stress responses.", "[CONSTRAINT] Incentive alignment and leadership signals interact to influence team members' decisions under pressure."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: Team fragmentation is more likely to occur when incentive alignment is low and leadership signals are inconsistent.\nASSUMPTION: The team members' personal goals are significantly misaligned with the team's common goal.\nVERIFICATION: N/A", "rejected": "Team fragmentation is less likely to occur when incentive alignment is low and leadership signals are inconsistent.", "E_acc": 0.7795316576957703, "C_acc": 0.027154842391610146, "G_acc": 0.5828884239890613, "D_acc": 0.6604087776504457, "H_acc": 0.163680762052536, "Q_acc": 0.7607198929530569, "E_rej": 0.39550304412841797, "C_rej": 0.1635020524263382, "G_rej": 0.5594039668794721, "D_rej": 0.841117799282074, "H_rej": 0.15888220071792603, "Q_rej": 0.6501666359137743, "Delta_Q": 0.11055325703928254, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Mechanism design with bounded rationality: propose allocation rules that are strategyproof for agents limited to k-step reasoning.", "ancestors": ["[DEF] Mechanism design refers to the process of creating systems that facilitate decision-making among multiple agents.", "[VAR] Agents in a mechanism have individual preferences and limited cognitive abilities.", "[LIMIT] The cognitive ability of each agent is limited to k-step reasoning, where k is a fixed positive integer.", "[CONSTRAINT] The allocation rule must be strategyproof, meaning that it is in each agent's best interest to report their true preferences.", "[DEF] Bounded rationality refers to the concept that agents make decisions based on limited information and cognitive abilities.", "[LIMIT] The value of k affects the complexity of the allocation rule and the agents' ability to optimize their outcomes.", "[VAR] The number of agents participating in the mechanism is a variable that can impact the design of the allocation rule.", "[CONSTRAINT] The allocation rule must ensure that the resulting allocation is feasible and satisfies the constraints of the mechanism.", "[LAW] The design of the allocation rule is guided by the principles of game theory and decision theory under uncertainty."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The complexity of the allocation rule increases as the number of agents or the value of k increases.\nASSUMPTION: The relationship between the number of agents, the value of k, and the complexity of the allocation rule is monotonically increasing.\nVERIFICATION: The complexity can be measured in terms of computational steps required to determine the allocation.", "rejected": "The complexity of the allocation rule increases as the number of agents or the value of k decreases.", "E_acc": 0.26678046584129333, "C_acc": 0.13817216455936432, "G_acc": 0.572888424503617, "D_acc": 0.7355436282232404, "H_acc": 0.23164403438568115, "Q_acc": 0.5909217139473185, "E_rej": 0.2932436764240265, "C_rej": 0.1435745805501938, "G_rej": 0.592355786007829, "D_rej": 0.8375368416309357, "H_rej": 0.16246315836906433, "Q_rej": 0.6289903965080157, "Delta_Q": -0.038068682560697176, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["[DEF] Program synthesis is the process of automatically generating a program from a set of examples.", "[VAR] The examples provided for program synthesis may be underspecified.", "[LIMIT] The number of possible programs consistent with a set of examples can be large.", "[CONSTRAINT] A synthesized program must be consistent with all provided examples.", "[DEF] Overfitting occurs when a program is too closely fit to the provided examples.", "[LAW] The risk of overfitting increases as the complexity of the synthesized program increases.", "[CONSTRAINT] The simplest program consistent with the examples is preferred to minimize overfitting risk.", "[VAR] The simplicity of a program can be measured by its size or computational complexity.", "[LIMIT] There is a trade-off between the simplicity of a program and its ability to generalize to new examples.", "[CONSTRAINT] The synthesized program should balance simplicity with the need to avoid overfitting to spurious patterns."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The risk of overfitting can be mitigated by preferring programs with a size below a certain threshold.\nASSUMPTION: There exists a threshold for program size below which the risk of overfitting is significantly reduced.\nVERIFICATION: The threshold can be determined by analyzing the trade-off between program simplicity and generalization ability.", "rejected": "A program having a size below a certain threshold mitigates the risk of overfitting.", "E_acc": 0.3533465266227722, "C_acc": 0.023937340825796127, "G_acc": 0.5755932808388025, "D_acc": 0.7336577838286757, "H_acc": 0.2102375030517578, "Q_acc": 0.6420429524499923, "E_rej": 0.5305119156837463, "C_rej": 0.11505985260009766, "G_rej": 0.5934161928016692, "D_rej": 0.7862289547920227, "H_rej": 0.2137710452079773, "Q_rej": 0.6906935291830452, "Delta_Q": -0.04865057673305284, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Coalition formation with transferable utility and externalities: compute stable coalitions and core allocations in presence of cross-coalition effects.", "ancestors": ["[DEF] A coalition is a group of agents cooperating to achieve a common goal.", "[VAR] The utility of a coalition is a measure of its overall value or payoff.", "[DEF] Transferable utility refers to the ability of agents to transfer value or payoff among themselves.", "[LAW] The total utility of a coalition is the sum of the utilities of its individual members.", "[CONSTRAINT] Coalition formation is subject to externalities, which are effects from outside the coalition.", "[VAR] Cross-coalition effects refer to the interactions or influences between different coalitions.", "[CONSTRAINT] The core of a coalition is the set of allocations that are stable and unbeatable.", "[LIMIT] The computation of stable coalitions and core allocations is limited by the complexity of the coalition structure.", "[CONSTRAINT] The presence of externalities and cross-coalition effects constrains the formation of stable coalitions and the allocation of utilities."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The total utility of a coalition is maximized when the utilities of its individual members are equal.\nASSUMPTION: The coalition structure is simple and symmetric, with no externalities or cross-coalition effects.\nVERIFICATION: Coalition utility values must be compared under the same regime and units.", "rejected": "The total utility of a coalition is maximized when the utilities of its individual members are equal, even in the presence of externalities and cross-coalition effects.", "E_acc": 0.7327561974525452, "C_acc": 0.07616305351257324, "G_acc": 0.6021013995632529, "D_acc": 0.7466452089138329, "H_acc": 0.2428312972187996, "Q_acc": 0.7500604405067861, "E_rej": 0.6430538296699524, "C_rej": 0.05370858311653137, "G_rej": 0.6098519761580974, "D_rej": 0.8676975965499878, "H_rej": 0.1323024034500122, "Q_rej": 0.7644541064742952, "Delta_Q": -0.014393665967509128, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["[DEF] The traveling salesman problem is an NP-hard problem in combinatorial optimization and operations research.", "[VAR] Let G be a complete graph with n vertices and edge weights representing distances between cities.", "[CONSTRAINT] The graph G has a set of edges E, where each edge e in E has a non-negative weight w_e.", "[LIMIT] The number of vertices n in the graph G is a finite positive integer.", "[DEF] A natural convex relaxation of the traveling salesman problem is obtained by replacing the binary variables with continuous variables.", "[VAR] Let x_e be a continuous variable representing the fraction of edge e in the solution.", "[CONSTRAINT] The convex relaxation has a constraint that the sum of x_e over all edges incident to a vertex is equal to 2.", "[LIMIT] The integrality gap of the convex relaxation is bounded by a constant factor.", "[CONSTRAINT] The convex relaxation also has a constraint that x_e is non-negative for all edges e in E.", "[LIMIT] The tight integrality-gap bound for the natural convex relaxation is at most a factor of 3/2."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The natural convex relaxation of the traveling salesman problem has a solution where the sum of x_e over all edges is bounded by a factor of 3/2 times the number of vertices.\nASSUMPTION: The given constraints and limits of the convex relaxation are sufficient to establish a relationship between the sum of x_e and the number of vertices.\nVERIFICATION: The validity of this hypothesis can be checked by analyzing the constraints and limits of the convex relaxation in the context of a complete graph with a finite number of vertices.", "rejected": "The natural convex relaxation of the traveling salesman problem has a solution where the sum of x_e over all edges is bounded by a factor of 3/2 times the sum of the edge weights.", "E_acc": 0.6040681004524231, "C_acc": 0.06093539297580719, "G_acc": 0.5611187443137169, "D_acc": 0.7703781528398395, "H_acc": 0.10537287592887878, "Q_acc": 0.724795443378389, "E_rej": 0.442619264125824, "C_rej": 0.13268287479877472, "G_rej": 0.5512549086706713, "D_rej": 0.9272449314594269, "H_rej": 0.07275506854057312, "Q_rej": 0.6946736654499546, "Delta_Q": 0.0301217779284344, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Abductive inference under incomplete rules: given observed O and multiple competing rule-sets R1..Rn, rank hypotheses by minimal explanatory assumptions and robustness to new observations.", "ancestors": ["[DEF] Abductive inference is a form of reasoning that involves making an educated guess to explain a set of observations.", "[VAR] The observed data is denoted as O, and the competing rule-sets are denoted as R1, R2, ..., Rn.", "[LAW] The process of abductive inference under incomplete rules involves evaluating the rule-sets based on their ability to explain the observed data O.", "[CONSTRAINT] Each rule-set Ri has a set of assumptions associated with it.", "[VAR] The number of assumptions in each rule-set Ri is denoted as Ai.", "[LIMIT] The number of possible rule-sets is finite, denoted as n.", "[CONSTRAINT] The robustness of a hypothesis to new observations is inversely related to the number of assumptions in its corresponding rule-set.", "[DEF] The explanatory power of a rule-set is directly related to its ability to account for the observed data O.", "[CONSTRAINT] The ranking of hypotheses is based on a trade-off between minimal explanatory assumptions and robustness to new observations."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A rule-set with fewer assumptions is more robust to new observations.\nASSUMPTION: The number of assumptions in each rule-set is a significant factor in determining its robustness.\nVERIFICATION: The robustness of a hypothesis can be tested by introducing new observations and evaluating the rule-set's ability to explain them.", "rejected": "A rule-set with fewer assumptions is less robust to new observations because the number of assumptions in each rule-set is a significant factor in determining its robustness.", "E_acc": 0.49272316694259644, "C_acc": 0.11659205704927444, "G_acc": 0.5270510492919129, "D_acc": 0.8009456098079681, "H_acc": 0.16411185264587402, "Q_acc": 0.6736866852283129, "E_rej": 0.443959504365921, "C_rej": 0.17946304380893707, "G_rej": 0.5175417255668435, "D_rej": 0.8324324190616608, "H_rej": 0.16756758093833923, "Q_rej": 0.6505333133798558, "Delta_Q": 0.023153371848457116, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Program synthesis from underspecified examples: infer the simplest program consistent with examples while bounding the risk of overfitting to spurious patterns.", "ancestors": ["[DEF] A program is a set of instructions that can be executed by a computer.", "[VAR] The simplicity of a program is a variable that can be measured.", "[CONSTRAINT] The program must be consistent with the given examples.", "[LIMIT] The number of examples is finite.", "[DEF] Overfitting occurs when a program is too closely fit to the given examples.", "[VAR] The risk of overfitting is a variable that can be bounded.", "[CONSTRAINT] The program synthesis process must minimize the risk of overfitting.", "[LIMIT] The computational resources available for program synthesis are limited.", "[CONSTRAINT] The synthesized program must be able to generalize to new, unseen examples.", "[CONSTRAINT] The program synthesis process must balance simplicity and generalizability."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The risk of overfitting increases as the simplicity of a program decreases.\nASSUMPTION: There is a negative correlation between the simplicity of a program and its ability to generalize to new examples.\nVERIFICATION: The correlation can be tested by measuring the simplicity and generalizability of a set of programs and analyzing their relationship.", "rejected": "The risk of overfitting decreases as the simplicity of a program decreases.", "E_acc": 0.3678241968154907, "C_acc": 0.18398398160934448, "G_acc": 0.5606964208709542, "D_acc": 0.7243331084027886, "H_acc": 0.2135733664035797, "Q_acc": 0.609199031937169, "E_rej": 0.06783177703619003, "C_rej": 0.31875836849212646, "G_rej": 0.5748157134124389, "D_rej": 0.8246075510978699, "H_rej": 0.17539244890213013, "Q_rej": 0.5189432674242805, "Delta_Q": 0.09025576451288841, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Multi-armed bandit with delayed, censored rewards: construct a policy that balances exploration and robust identification of the best arm.Planning under partial observability and costly sensing: design a plan that trades off information-gathering vs execution risk to reach a goal with bounded expected loss.", "ancestors": ["[DEF] A multi-armed bandit is a mathematical model for decision-making under uncertainty.", "[VAR] The model consists of a set of arms, each associated with a reward distribution.", "[LAW] The reward distributions are initially unknown and must be learned through exploration.", "[CONSTRAINT] The learner receives delayed and censored rewards, limiting the information available for decision-making.", "[CONSTRAINT] The learner has a limited budget for sensing and information-gathering.", "[LIMIT] The expected loss is bounded by a fixed constant.", "[CONSTRAINT] The planning horizon is finite, requiring a trade-off between exploration and execution."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The learner must allocate the limited budget to balance exploration and execution to minimize the expected loss within the finite planning horizon.\nASSUMPTION: The reward distributions are stationary over the planning horizon.\nVERIFICATION: The expected loss is measured in the same units as the reward distributions, and its value can be compared across different allocation strategies.", "rejected": "The learner must allocate the unlimited budget to balance exploration and execution to minimize the expected loss within the finite planning horizon.", "E_acc": 0.4688228666782379, "C_acc": 0.2682415246963501, "G_acc": 0.5497829855109254, "D_acc": 0.7221540424507111, "H_acc": 0.23981887847185135, "Q_acc": 0.6174040728093435, "E_rej": 0.006464036647230387, "C_rej": 0.9788966774940491, "G_rej": 0.5581178134307265, "D_rej": 0.8236342072486877, "H_rej": 0.22045724093914032, "Q_rej": 0.36046455553732815, "Delta_Q": 0.25693951727201536, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Robustness to distributional shift for policy evaluation: propose sensitivity bounds for off-policy estimates under covariate shift.", "ancestors": ["[DEF] A distributional shift occurs when the distribution of the data changes between the training and deployment phases of a policy.", "[VAR] The covariate shift is a type of distributional shift where the change occurs in the input or covariate distribution.", "[LAW] The law of total expectation states that the expected value of an outcome can be calculated as the sum of the expected values of the outcome for each possible value of a covariate, weighted by the probability of that covariate value.", "[CONSTRAINT] Off-policy estimates are constrained by the available data, which may not cover the entire support of the target distribution.", "[VAR] The sensitivity of off-policy estimates to covariate shift can be quantified using bounds that depend on the magnitude of the shift and the properties of the policy.", "[LIMIT] The worst-case bound for off-policy estimates under covariate shift is limited by the support of the target distribution and the degree of shift.", "[CONSTRAINT] The computation of sensitivity bounds for off-policy estimates under covariate shift is constrained by the need to estimate the density ratio between the target and source distributions."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The sensitivity of off-policy estimates to covariate shift is bounded by a function of the magnitude of the shift and the properties of the policy.\nASSUMPTION: The density ratio between the target and source distributions can be accurately estimated.\nVERIFICATION: The bound's validity can be tested by comparing its predicted values with empirical estimates of off-policy performance.", "rejected": "The magnitude of the shift and the properties of the policy bound the sensitivity of off-policy estimates to covariate shift.", "E_acc": 0.25312289595603943, "C_acc": 0.34203779697418213, "G_acc": 0.5491706373702202, "D_acc": 0.7161441519856453, "H_acc": 0.1132928729057312, "Q_acc": 0.5492629799725754, "E_rej": 0.21652284264564514, "C_rej": 0.33643198013305664, "G_rej": 0.5646028755498784, "D_rej": 0.8881469368934631, "H_rej": 0.11185306310653687, "Q_rej": 0.5770351129450969, "Delta_Q": -0.027772132972521457, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Approximation hardness vs relaxations: present an NP-hard problem and derive tight integrality-gap bounds for a natural convex relaxation.", "ancestors": ["[DEF] The traveling salesman problem is an NP-hard problem in combinatorial optimization and operations research.", "[VAR] Let G be a complete weighted graph with n vertices.", "[CONSTRAINT] The graph G has a set of edges E, where each edge has a non-negative weight.", "[LIMIT] The number of vertices n in the graph G is a finite positive integer.", "[DEF] A natural convex relaxation of the traveling salesman problem is obtained by relaxing the integrality constraints on the edge variables.", "[VAR] Let x be a vector of edge variables in the relaxed problem, where x_ij represents the fraction of the edge between vertices i and j that is used.", "[CONSTRAINT] The relaxed problem has constraints that ensure the solution x is a valid tour, including flow conservation and non-negativity constraints.", "[LIMIT] The integrality gap of the relaxed problem is bounded by a constant factor that depends only on the number of vertices n."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The integrality gap of the relaxed problem is less than or equal to a constant factor that depends only on the number of vertices n.\nASSUMPTION: The constant factor that bounds the integrality gap is a function of the number of vertices n that does not depend on the specific edge weights.\nVERIFICATION: The validity of the hypothesis can be checked by analyzing the relationship between the integrality gap and the number of vertices n.", "rejected": "The integrality gap of the relaxed problem is less than or equal to a constant factor that depends only on the edge weights of the graph G.", "E_acc": 0.21221351623535156, "C_acc": 0.07816929370164871, "G_acc": 0.5369840913335793, "D_acc": 0.697384953731671, "H_acc": 0.2335406243801117, "Q_acc": 0.5715499427053146, "E_rej": 0.036817435175180435, "C_rej": 0.014548277482390404, "G_rej": 0.5257720169247477, "D_rej": 0.803270161151886, "H_rej": 0.196729838848114, "Q_rej": 0.5542710267865913, "Delta_Q": 0.017278915918723214, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether parallelization will speed up a task given communication and synchronization costs.", "ancestors": ["[DEF] A task is a set of operations that must be executed to achieve a specific goal.", "[VAR] The execution time of a task can vary depending on the number of processors used.", "[CONSTRAINT] Parallelization of a task requires communication between processors.", "[LIMIT] The speedup of a task is limited by the time spent on communication and synchronization.", "[VAR] Communication cost is the time spent exchanging data between processors.", "[VAR] Synchronization cost is the time spent coordinating the execution of processors.", "[LAW] The total execution time of a parallelized task is the sum of computation time, communication cost, and synchronization cost.", "[CONSTRAINT] The computation time of a task is reduced by parallelization, but the communication and synchronization costs are increased."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The total execution time of a parallelized task will be reduced only if the computation time reduction is greater than the increase in communication and synchronization costs.\nASSUMPTION: The reduction in computation time and the increase in communication and synchronization costs can be quantitatively compared.\nVERIFICATION: Units of time, such as seconds, can be used to test this condition.", "rejected": "The total execution time of a parallelized task will be reduced only if the computation time reduction is less than the increase in communication and synchronization costs.", "E_acc": 0.23681534826755524, "C_acc": 0.4142875075340271, "G_acc": 0.5770550552988425, "D_acc": 0.7262281375005841, "H_acc": 0.1624634563922882, "Q_acc": 0.5325973958941177, "E_rej": 0.0215477105230093, "C_rej": 0.0622045062482357, "G_rej": 0.5776986485579982, "D_rej": 0.8934035897254944, "H_rej": 0.10659641027450562, "Q_rej": 0.5775842185365037, "Delta_Q": -0.04498682264238596, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring unknown variables in a system of equations when only partial information is available.", "ancestors": ["[DEF] A system of equations is a set of equations that contain multiple variables.", "[VAR] The variables in the system of equations may have unknown values.", "[LAW] The equations in the system are based on mathematical laws and relationships.", "[CONSTRAINT] The system of equations may have constraints that limit the possible values of the variables.", "[CONSTRAINT] The available partial information provides additional constraints on the system of equations.", "[LIMIT] The number of equations in the system may be less than the number of unknown variables.", "[CONSTRAINT] The constraints and available information must be used to infer the values of the unknown variables."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The system of equations may have a unique solution if the number of equations is equal to the number of unknown variables.\nASSUMPTION: The equations in the system are linearly independent.\nVERIFICATION: The solution can be verified by checking if the equations are consistent and have a unique solution, using methods such as substitution or elimination.", "rejected": "The system of equations may have a unique solution if the number of unknown variables is equal to the number of equations.", "E_acc": 0.1206381767988205, "C_acc": 0.44567039608955383, "G_acc": 0.517569303046912, "D_acc": 0.6905875252559781, "H_acc": 0.28116804361343384, "Q_acc": 0.46057193512097006, "E_rej": 0.20243500173091888, "C_rej": 0.24947798252105713, "G_rej": 0.5166446650400758, "D_rej": 0.843238115310669, "H_rej": 0.15676188468933105, "Q_rej": 0.5671352716162801, "Delta_Q": -0.10656333649531002, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a rumor spreads because of novelty, authority, or emotional impact.", "ancestors": ["[DEF] A rumor is a piece of information that is spread without confirmation of its truth.", "[VAR] The spread of a rumor can be influenced by various factors.", "[LAW] The dissemination of information is subject to the principles of social influence.", "[CONSTRAINT] The impact of a rumor is limited by the social connections of the individuals involved.", "[VAR] Novelty, authority, and emotional impact are factors that can contribute to the spread of a rumor.", "[LIMIT] The ability of a rumor to spread is limited by the availability of communication channels.", "[CONSTRAINT] The credibility of the source of a rumor can constrain its potential to be believed and spread."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The spread of a rumor is inversely proportional to the credibility of its source.\nASSUMPTION: The relationship between the spread of a rumor and the credibility of its source is monotonic.\nVERIFICATION: units of measurement for spread and credibility are required for regime validation.", "rejected": "The spread of a rumor is inversely proportional to the credibility of its source in all social contexts, regardless of the availability of communication channels.", "E_acc": 0.1431826800107956, "C_acc": 0.5419436693191528, "G_acc": 0.5477561151076641, "D_acc": 0.7755992561578751, "H_acc": 0.16427069902420044, "Q_acc": 0.48281007449009594, "E_rej": 0.0036838343366980553, "C_rej": 0.9268143773078918, "G_rej": 0.5198022567534021, "D_rej": 0.8911034166812897, "H_rej": 0.10889658331871033, "Q_rej": 0.3870337511944984, "Delta_Q": 0.09577632329559754, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a rumor spreads because of novelty, authority, or emotional impact.", "ancestors": ["[DEF] A rumor is a piece of information that is spread without confirmation of its truth.", "[VAR] The spread of a rumor can be influenced by various factors.", "[LAW] The dissemination of information is subject to the principles of social influence.", "[CONSTRAINT] The spread of a rumor is limited by the number of people in a social network.", "[VAR] Novelty, authority, and emotional impact are factors that can contribute to the spread of a rumor.", "[LIMIT] The impact of novelty on rumor spread has an upper bound.", "[CONSTRAINT] Authority figures can only influence the spread of a rumor if they are trusted by the social network.", "[VAR] Emotional impact can vary in intensity and valence across different rumors.", "[LIMIT] The maximum emotional impact of a rumor is constrained by the emotional sensitivity of the social network."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The spread of a rumor is directly influenced by the interaction between novelty, authority, and emotional impact.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The spread of a rumor is directly influenced by the sum of novelty, authority, and emotional impact.", "E_acc": 0.6660119295120239, "C_acc": 0.1544831246137619, "G_acc": 0.561152987414971, "D_acc": 0.6541003768797964, "H_acc": 0.10166871547698975, "Q_acc": 0.7017907552421093, "E_rej": 0.23387056589126587, "C_rej": 0.5920900702476501, "G_rej": 0.5521487414953299, "D_rej": 0.9264864027500153, "H_rej": 0.07351359724998474, "Q_rej": 0.5401188248419203, "Delta_Q": 0.161671930400189, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about time and space trade-offs when choosing between different data structures.", "ancestors": ["[DEF] A data structure is a way of organizing and storing data in a computer.", "[VAR] The choice of data structure can affect the time complexity of algorithms.", "[LAW] The time complexity of an algorithm is determined by the number of operations it performs.", "[CONSTRAINT] The amount of memory available to a computer is limited.", "[LIMIT] The time complexity of an algorithm cannot be less than constant time.", "[VAR] The space complexity of a data structure refers to the amount of memory it requires.", "[CONSTRAINT] The choice of data structure must balance time and space complexity within the available memory limit."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The choice of data structure that minimizes time complexity may require more memory than the choice that minimizes space complexity.\nASSUMPTION: There exists a data structure that can achieve minimal time complexity without using the minimal amount of memory.\nVERIFICATION: Comparison of time and space complexity trade-offs for different data structures under the given memory limit.", "rejected": "The choice of data structure that minimizes time complexity is independent of the choice that minimizes space complexity, so they can be optimized separately without affecting each other.", "E_acc": 0.4608423411846161, "C_acc": 0.2969736158847809, "G_acc": 0.5329964396902748, "D_acc": 0.7642163094133139, "H_acc": 0.17741164565086365, "Q_acc": 0.62055936443406, "E_rej": 0.0060081579722464085, "C_rej": 0.7744379639625549, "G_rej": 0.4991244060608248, "D_rej": 0.8631213307380676, "H_rej": 0.13687866926193237, "Q_rej": 0.4056761350327482, "Delta_Q": 0.21488322940131183, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether an infection is viral or bacterial based on symptom progression and response to treatment.", "ancestors": ["[DEF] Infection is a condition characterized by the presence of a pathogen in the body.", "[VAR] Symptoms of infection can vary in severity and type.", "[LAW] Viral and bacterial infections have distinct biological mechanisms.", "[CONSTRAINT] Antibiotics are effective against bacterial infections but not viral infections.", "[LIMIT] The response of an infection to antibiotic treatment can indicate its type.", "[VAR] Symptom progression rates can differ between viral and bacterial infections.", "[CONSTRAINT] A diagnosis of infection type is necessary to determine appropriate treatment."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The effectiveness of antibiotic treatment can be used to distinguish between viral and bacterial infections.\nASSUMPTION: None\nVERIFICATION: Treatment outcome comparison, with units of measurement being the presence or absence of infection symptoms after treatment.", "rejected": "The ineffectiveness of antibiotic treatment can be used to distinguish between viral and bacterial infections.", "E_acc": 0.15145258605480194, "C_acc": 0.7124012112617493, "G_acc": 0.6007242172490805, "D_acc": 0.7008957229554653, "H_acc": 0.16674524545669556, "Q_acc": 0.4466049970593303, "E_rej": 0.26385918259620667, "C_rej": 0.28156623244285583, "G_rej": 0.6050271897111088, "D_rej": 0.8636744916439056, "H_rej": 0.13632550835609436, "Q_rej": 0.6029522937256843, "Delta_Q": -0.15634729666635394, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether adding redundancy increases reliability or introduces new failure modes.", "ancestors": ["[DEF] A system is a set of components that work together to achieve a specific function.", "[VAR] The reliability of a system is a measure of its ability to perform its intended function over time.", "[LAW] The reliability of a system is affected by the reliability of its individual components.", "[CONSTRAINT] Redundancy in a system refers to the duplication of components or functions to increase reliability.", "[VAR] The introduction of redundancy into a system can add new components and interactions.", "[LIMIT] The number of possible failure modes in a system is limited by its design and configuration.", "[CONSTRAINT] New failure modes can be introduced into a system when redundancy is added.", "[CONSTRAINT] The overall reliability of a system with redundancy is determined by the reliability of its individual components and their interactions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The overall reliability of a system with redundancy is increased if the reliability of its individual components is high.\nASSUMPTION: None\nVERIFICATION: Comparison of system reliability with and without redundancy, measured in terms of failure rates or uptime.", "rejected": "The overall reliability of a system with redundancy is increased if the reliability of its individual components is high, regardless of the new failure modes introduced by the redundancy.", "E_acc": 0.27445441484451294, "C_acc": 0.2607135772705078, "G_acc": 0.5523923353175633, "D_acc": 0.7036889283917844, "H_acc": 0.1387033462524414, "Q_acc": 0.5675395271158777, "E_rej": 0.03810752183198929, "C_rej": 0.437768816947937, "G_rej": 0.547356829396449, "D_rej": 0.9213455617427826, "H_rej": 0.07865443825721741, "Q_rej": 0.509753527562134, "Delta_Q": 0.05778599955374375, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about unintended consequences when optimizing for a single metric.", "ancestors": ["[DEF] A metric is a standard for measuring something.", "[VAR] The value of a metric can change.", "[LIMIT] Every optimization process has a limited scope.", "[CONSTRAINT] A single metric is used in a given optimization process.", "[DEF] An unintended consequence is an outcome not initially planned.", "[VAR] The number of unintended consequences can vary.", "[LAW] Optimization for a single metric can affect other metrics.", "[CONSTRAINT] The scope of an optimization process does not cover all possible metrics.", "[VAR] The impact of unintended consequences can be positive or negative.", "[LIMIT] The ability to predict unintended consequences is limited by the scope of the optimization process."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The impact of optimization for a single metric can be negative on other metrics.\nASSUMPTION: None\nVERIFICATION: The effect can be measured by comparing the initial and final values of the affected metrics.", "rejected": "The impact of other metrics can be negative on the optimization for a single metric.", "E_acc": 0.099436916410923, "C_acc": 0.49919432401657104, "G_acc": 0.5259334747679532, "D_acc": 0.6674782950431108, "H_acc": 0.19411873817443848, "Q_acc": 0.44926269026473165, "E_rej": 0.7475963234901428, "C_rej": 0.018991509452462196, "G_rej": 0.5106661771133076, "D_rej": 0.8060224056243896, "H_rej": 0.19397759437561035, "Q_rej": 0.7644205522665288, "Delta_Q": -0.3151578620017972, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether to repair or replace a device based on failure risk, cost, and future usage.", "ancestors": ["[DEF] A device is an object that performs a specific function.", "[VAR] The failure risk of a device is a measure of its likelihood to fail.", "[CONSTRAINT] The decision to repair or replace a device depends on its failure risk.", "[VAR] The cost of repairing a device is a monetary value associated with its repair.", "[VAR] The cost of replacing a device is a monetary value associated with its replacement.", "[LIMIT] The cost of repairing a device cannot exceed the cost of replacing it for a decision to be made.", "[CONSTRAINT] The decision to repair or replace a device also depends on its future usage.", "[VAR] The future usage of a device is a measure of how often it will be used.", "[CONSTRAINT] The decision to repair or replace a device must consider both its failure risk and its future usage in relation to the associated costs."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: A device with high failure risk and high future usage should be replaced if the cost of repair exceeds a certain threshold of the cost of replacement.\nASSUMPTION: The threshold for replacement is directly proportional to the device's future usage.\nVERIFICATION: The threshold can be measured in monetary units, such as dollars, and is valid within the regime of device maintenance decisions.", "rejected": "A device with high failure risk and high future usage should be replaced if the cost of repair exceeds a certain threshold of the cost of replacement in the context of employee salary negotiations.", "E_acc": 0.43723389506340027, "C_acc": 0.017736727371811867, "G_acc": 0.5438354827463627, "D_acc": 0.7317583505064249, "H_acc": 0.22011098265647888, "Q_acc": 0.6607304914295674, "E_rej": 0.1748943328857422, "C_rej": 0.0647578090429306, "G_rej": 0.5353475773590617, "D_rej": 0.8261282742023468, "H_rej": 0.1738717257976532, "Q_rej": 0.5944247357896529, "Delta_Q": 0.06630575563991448, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether a package delivery was delayed by logistics, weather, or incorrect address using partial tracking updates.", "ancestors": ["[DEF] A package delivery is an event where a package is transported from a sender to a recipient.", "[VAR] The package's tracking updates are a series of status reports generated at different points in time.", "[CONSTRAINT] Each tracking update contains a timestamp and a location.", "[LIMIT] The frequency of tracking updates is limited by the logistics system's capabilities.", "[DEF] A delay is a period of time during which the package's transportation is slower than expected.", "[VAR] The package's expected delivery time is a variable that can be calculated based on historical data.", "[LAW] The actual delivery time is equal to the expected delivery time plus any delays that occurred during transportation.", "[CONSTRAINT] The possible causes of delays are logistics, weather, and incorrect address."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The actual delivery time is directly proportional to the number of delays that occurred during transportation.\nASSUMPTION: The duration of each delay is constant and does not vary significantly.\nVERIFICATION: The proportionality constant can be determined by analyzing historical data on actual delivery times and corresponding delays.", "rejected": "The actual delivery time is directly proportional to the square root of the number of delays that occurred during transportation.", "E_acc": 0.2635670602321625, "C_acc": 0.5515803098678589, "G_acc": 0.5272153050464112, "D_acc": 0.7272616606205702, "H_acc": 0.20164313912391663, "Q_acc": 0.49948513531708155, "E_rej": 0.18119430541992188, "C_rej": 0.5750719308853149, "G_rej": 0.5163006924891046, "D_rej": 0.8240714967250824, "H_rej": 0.1759285032749176, "Q_rej": 0.4898254929642592, "Delta_Q": 0.00965964235282235, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging whether a household bill increase is caused by higher usage, price changes, or billing errors.", "ancestors": ["[DEF] A household bill is a statement of the total amount owed for a specific period.", "[VAR] The total amount owed can change from one period to another.", "[LAW] The total amount owed is calculated by multiplying the usage by the price per unit.", "[CONSTRAINT] The usage and price per unit are the primary factors that affect the total amount owed.", "[VAR] Billing errors can also affect the total amount owed.", "[CONSTRAINT] The total amount owed cannot be less than zero.", "[LIMIT] The price per unit and usage are non-negative values."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total amount owed will be zero if both the usage and price per unit are zero.\nASSUMPTION: None\nVERIFICATION: Total amount owed = usage * price per unit, with units of currency.", "rejected": "The total amount owed will be zero if the usage is zero, regardless of the price per unit.", "E_acc": 0.13549049198627472, "C_acc": 0.6421086192131042, "G_acc": 0.5415396920538375, "D_acc": 0.6756556872278452, "H_acc": 0.22744202613830566, "Q_acc": 0.43292029699576756, "E_rej": 0.03862946107983589, "C_rej": 0.7465132474899292, "G_rej": 0.5229784723238221, "D_rej": 0.7690662145614624, "H_rej": 0.2309337854385376, "Q_rej": 0.39760174765916806, "Delta_Q": 0.0353185493365995, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring which of several explanations is most likely given noisy and incomplete observations.", "ancestors": ["[DEF] An observation is a measurement or reading of a physical phenomenon.", "[VAR] The set of possible explanations for a phenomenon is denoted by E.", "[LAW] The likelihood of an explanation given an observation is determined by the principles of probability.", "[CONSTRAINT] Observations are subject to noise and incompleteness.", "[VAR] The set of available observations is denoted by O.", "[LIMIT] The number of possible explanations is finite.", "[DEF] An inference is a conclusion drawn from a set of observations.", "[CONSTRAINT] The inference process is limited by the quality and quantity of available observations.", "[VAR] The probability of each explanation given the observations is denoted by P(E|O).", "[LIMIT] The computational resources available for inference are bounded."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The probability of each explanation given the observations is affected by the noise and incompleteness of the observations.\nASSUMPTION: None\nVERIFICATION: The effect of noise and incompleteness can be measured by comparing the probability of explanations under different observation conditions.", "rejected": "The probability of each explanation given the observations is unaffected by the noise and incompleteness of the observations.", "E_acc": 0.36279135942459106, "C_acc": 0.396545946598053, "G_acc": 0.5513731337268837, "D_acc": 0.7211287226527929, "H_acc": 0.18777817487716675, "Q_acc": 0.5652507722959854, "E_rej": 0.001441077794879675, "C_rej": 0.991161584854126, "G_rej": 0.538285015441943, "D_rej": 0.7817974090576172, "H_rej": 0.2182025909423828, "Q_rej": 0.3443962321733125, "Delta_Q": 0.22085454012267292, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging whether a household bill increase is caused by higher usage, price changes, or billing errors.", "ancestors": ["[DEF] A household bill is a statement of charges for services used by a household.", "[VAR] The total cost of a household bill can change over time.", "[CONSTRAINT] The total cost of a household bill is calculated based on usage and prices.", "[VAR] Usage refers to the quantity of services consumed by a household.", "[VAR] Prices refer to the rates charged for each unit of service.", "[LIMIT] Billing cycles have a fixed duration.", "[DEF] A billing error is an inaccuracy in the calculation or representation of a household bill.", "[CONSTRAINT] Billing errors can affect the total cost of a household bill.", "[VAR] Price changes refer to modifications in the rates charged for each unit of service.", "[CONSTRAINT] The total cost of a household bill is affected by changes in usage, prices, or billing errors."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The total cost of a household bill will change if there is a change in usage or prices.\nASSUMPTION: None\nVERIFICATION: Change in total cost can be measured in monetary units over a billing cycle.", "rejected": "The total cost of a household bill will change if there is a change in usage or prices over two billing cycles.", "E_acc": 0.8850277662277222, "C_acc": 0.044060878455638885, "G_acc": 0.5505344764096662, "D_acc": 0.6717026736587286, "H_acc": 0.1937670111656189, "Q_acc": 0.7817668830743061, "E_rej": 0.40853115916252136, "C_rej": 0.042471401393413544, "G_rej": 0.5331224378896877, "D_rej": 0.8692161738872528, "H_rej": 0.1307838261127472, "Q_rej": 0.681454407214187, "Delta_Q": 0.10031247586011904, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether ice will melt faster in saltwater or freshwater by reasoning about energy transfer.", "ancestors": ["[DEF] Energy transfer occurs when a system interacts with its surroundings.", "[VAR] The temperature of a system affects the rate of energy transfer.", "[LAW] The second law of thermodynamics describes the direction of spontaneous energy transfer.", "[CONSTRAINT] Ice melts when it gains energy from its surroundings.", "[VAR] Saltwater and freshwater have different thermal properties.", "[LAW] The rate of energy transfer between a system and its surroundings is influenced by the thermal conductivity of the surrounding medium.", "[CONSTRAINT] The melting point of ice is lower in saltwater than in freshwater due to the effects of dissolved salts.", "[VAR] The specific heat capacity of saltwater is different from that of freshwater.", "[LIMIT] The rate of energy transfer to ice is limited by the thermal conductivity and specific heat capacity of the surrounding water.", "[CONSTRAINT] The difference in thermal properties between saltwater and freshwater affects the rate at which ice melts in each medium."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The rate of energy transfer to ice in saltwater is lower than in freshwater due to the difference in thermal properties.\nASSUMPTION: None\nVERIFICATION: Comparison of melting rates in saltwater and freshwater under controlled conditions.", "rejected": "The difference in thermal properties between saltwater and freshwater is due to the rate of energy transfer to ice being lower in saltwater than in freshwater.", "E_acc": 0.6964182257652283, "C_acc": 0.07961677759885788, "G_acc": 0.5563859057729132, "D_acc": 0.6717305607162416, "H_acc": 0.11015692353248596, "Q_acc": 0.7276097131543793, "E_rej": 0.8227304220199585, "C_rej": 0.013949104584753513, "G_rej": 0.5436815600769478, "D_rej": 0.9035089910030365, "H_rej": 0.0964910089969635, "Q_rej": 0.8238183150053374, "Delta_Q": -0.09620860185095814, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Planning a trip when transportation options differ in cost, reliability, and flexibility.", "ancestors": ["[DEF] A trip is a journey from one location to another.", "[VAR] Transportation options for a trip may include driving, flying, and taking the train.", "[CONSTRAINT] The cost of each transportation option is a factor to consider when planning a trip.", "[LIMIT] The number of transportation options available for a trip is finite.", "[VAR] Each transportation option has its own level of reliability.", "[CONSTRAINT] The flexibility of each transportation option is also a consideration for trip planning.", "[LIMIT] The budget for a trip imposes a limit on the cost of transportation options that can be considered."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The reliability of a transportation option is a factor that affects the flexibility of that option.\nASSUMPTION: There is a relationship between the reliability and flexibility of a transportation option.\nVERIFICATION: N/A", "rejected": "The reliability of a location is a factor that affects the flexibility of a transportation option.", "E_acc": 0.9347454905509949, "C_acc": 0.006957974284887314, "G_acc": 0.5519131029556904, "D_acc": 0.6866347568575293, "H_acc": 0.2628570795059204, "Q_acc": 0.8004559163203729, "E_rej": 0.28391528129577637, "C_rej": 0.407198429107666, "G_rej": 0.5495670373950686, "D_rej": 0.8074683547019958, "H_rej": 0.19253164529800415, "Q_rej": 0.5558888124568122, "Delta_Q": 0.24456710386356073, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether fatigue is caused by sleep deprivation, nutrition, or stress from daily patterns.", "ancestors": ["[DEF] Fatigue is a state of physical or mental exhaustion.", "[VAR] Daily patterns include sleep schedules, dietary habits, and stress levels.", "[DEF] Sleep deprivation refers to the condition of not having enough sleep.", "[VAR] Nutrition intake varies among individuals and can affect energy levels.", "[LAW] The human body requires a minimum amount of sleep to function properly.", "[CONSTRAINT] Stress levels can be influenced by daily activities and environment.", "[VAR] Individual tolerance to sleep deprivation, nutrition, and stress differs.", "[LIMIT] There is a maximum amount of stress that the human body can withstand.", "[CONSTRAINT] Daily patterns of sleep, nutrition, and stress are interconnected."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The human body's ability to function properly is negatively affected by sleep deprivation and high stress levels.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The human body's ability to function properly is negatively affected by sleep deprivation plus high stress levels.", "E_acc": 0.4486076235771179, "C_acc": 0.14177431166172028, "G_acc": 0.5744408157188445, "D_acc": 0.5891835005022585, "H_acc": 0.198064923286438, "Q_acc": 0.6191457956563682, "E_rej": 0.311418354511261, "C_rej": 0.1058003231883049, "G_rej": 0.5621859233360738, "D_rej": 0.798302173614502, "H_rej": 0.20169782638549805, "Q_rej": 0.6241932784672827, "Delta_Q": -0.005047482810914494, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a geometric construction is possible given angle, length, and parallel constraints.", "ancestors": ["[DEF] A geometric construction is a set of points, lines, and circles defined by specific rules.", "[VAR] Variables in a geometric construction include angles, lengths, and parallel relationships.", "[LAW] The laws of geometry govern the relationships between points, lines, and circles in a construction.", "[CONSTRAINT] Angle constraints specify the measure of angles between lines or around points in a construction.", "[CONSTRAINT] Length constraints specify the distance between points in a construction.", "[LIMIT] The number of steps allowed to complete a geometric construction can be limited.", "[CONSTRAINT] Parallel constraints specify the relationship between lines that do not intersect in a construction.", "[LAW] Theorems such as those related to parallel lines and angle sums are used to determine the validity of a geometric construction."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The number of steps required to complete a geometric construction is limited by the number of constraints specified.\nASSUMPTION: The constraints specified include at least one angle, length, or parallel constraint.\nVERIFICATION: The validity of this hypothesis can be tested by analyzing the relationship between the number of constraints and the number of steps required to complete a construction, with units measured in terms of construction steps and constraints.", "rejected": "The number of steps required to complete a geometric construction is limited by the number of constraints specified, and these constraints are assumed to be mutually independent, which affects the overall complexity of the construction.", "E_acc": 0.8078861236572266, "C_acc": 0.03550075739622116, "G_acc": 0.5717193083837628, "D_acc": 0.7530880076810718, "H_acc": 0.18677645921707153, "Q_acc": 0.7815495029091837, "E_rej": 0.011851620860397816, "C_rej": 0.004978058859705925, "G_rej": 0.5672543294494972, "D_rej": 0.8367111086845398, "H_rej": 0.1632888913154602, "Q_rej": 0.5670240729814396, "Delta_Q": 0.21452542992774404, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining how much effort to spend thinking versus acting under time pressure.", "ancestors": ["[DEF] Time pressure is a condition where available time is limited.", "[VAR] The amount of effort spent thinking is a variable that can be adjusted.", "[VAR] The amount of effort spent acting is a variable that can be adjusted.", "[LIMIT] The total amount of effort available is limited.", "[CONSTRAINT] Effort spent thinking and acting cannot exceed the total amount of effort available.", "[DEF] The decision to allocate effort between thinking and acting is a choice.", "[VAR] The cost of thinking is a variable that can be considered in the decision.", "[CONSTRAINT] The time available for thinking and acting is constrained by the time pressure.", "[LIMIT] The maximum amount of effort that can be spent thinking or acting is bounded by the available time and effort."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The amount of effort spent thinking and acting cannot exceed the total amount of effort available under time pressure.\nASSUMPTION: None\nVERIFICATION: The total effort spent is measured in the same units as the total amount of effort available.", "rejected": "The amount of effort spent thinking and acting can exceed the total amount of effort available under time pressure.", "E_acc": 0.2711137533187866, "C_acc": 0.5384008288383484, "G_acc": 0.56516032426485, "D_acc": 0.6561571552883834, "H_acc": 0.24621477723121643, "Q_acc": 0.49329597841549133, "E_rej": 0.03500829637050629, "C_rej": 0.9448912143707275, "G_rej": 0.5838246674143842, "D_rej": 0.8574618101119995, "H_rej": 0.1425381898880005, "Q_rej": 0.3955277225534831, "Delta_Q": 0.09776825586200821, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about conditional probability in everyday contexts such as medical tests or weather predictions.", "ancestors": ["[DEF] A conditional probability is a measure of the probability of an event occurring given that another event has occurred.", "[VAR] The probability of a medical test result is a variable that can be influenced by various factors.", "[LAW] The probability of an event occurring given that another event has occurred can be calculated using Bayes' theorem.", "[CONSTRAINT] Conditional probability calculations require knowledge of the prior probability of each event.", "[LIMIT] The accuracy of conditional probability calculations is limited by the availability and quality of data.", "[DEF] Sensitivity and specificity are measures used to evaluate the accuracy of medical tests.", "[VAR] Weather forecasting models use conditional probability to predict the likelihood of different weather outcomes.", "[CONSTRAINT] Conditional probability calculations in medical tests are constrained by the need to minimize false positives and false negatives.", "[LIMIT] The complexity of real-world systems can limit the accuracy of conditional probability calculations in everyday contexts."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The accuracy of medical test results is limited by the availability and quality of prior probability data.\nASSUMPTION: The prior probability data is directly related to the conditional probability calculations.\nVERIFICATION: N/A", "rejected": "The accuracy of medical test results is improved by the scarcity and poor quality of prior probability data.", "E_acc": 0.3667214810848236, "C_acc": 0.2812930643558502, "G_acc": 0.555810017278418, "D_acc": 0.6494294109288603, "H_acc": 0.22950959205627441, "Q_acc": 0.5718547578901053, "E_rej": 0.0077547491528093815, "C_rej": 0.9710230827331543, "G_rej": 0.5134267881512642, "D_rej": 0.7503341734409332, "H_rej": 0.24966582655906677, "Q_rej": 0.33590741786174483, "Delta_Q": 0.23594734002836049, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about unintended consequences when optimizing for a single metric.", "ancestors": ["[DEF] A metric is a standard for measuring something.", "[VAR] The value of a metric can change.", "[LAW] Optimizing for a metric involves modifying variables to increase its value.", "[CONSTRAINT] There are limitations on the variables that can be modified.", "[VAR] Unintended consequences are changes in other metrics.", "[LIMIT] The number of metrics that can be simultaneously optimized is limited.", "[CONSTRAINT] Modifying variables to optimize one metric can affect other metrics."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Modifying variables to optimize one metric can have unintended consequences on other metrics.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "Unintended consequences on other metrics can result from modifying variables to optimize one metric.", "E_acc": 0.19828200340270996, "C_acc": 0.6642338037490845, "G_acc": 0.5742573594907299, "D_acc": 0.5979807602707297, "H_acc": 0.18665990233421326, "Q_acc": 0.4424194739898667, "E_rej": 0.551206111907959, "C_rej": 0.24303707480430603, "G_rej": 0.5767610638285987, "D_rej": 0.8849742710590363, "H_rej": 0.11502572894096375, "Q_rej": 0.6975989126949571, "Delta_Q": -0.2551794387050904, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether cooperation emerges in a group based on repeated interactions and trust.", "ancestors": ["[DEF] A group is defined as a set of individuals interacting with each other.", "[VAR] The number of individuals in a group is a variable.", "[CONSTRAINT] Interactions between individuals in a group are limited to a finite number of rounds.", "[LIMIT] The number of possible actions an individual can take in an interaction is limited.", "[DEF] Trust is defined as the expectation that an individual will act cooperatively.", "[VAR] The level of trust between individuals in a group is a variable.", "[LAW] The level of trust between individuals affects the likelihood of cooperation in an interaction.", "[CONSTRAINT] Cooperation in an interaction is only possible if the individuals involved have previously interacted.", "[LIMIT] The complexity of predicting cooperation in a group increases with the number of individuals and interactions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The likelihood of cooperation in a group increases as the level of trust between individuals increases.\nASSUMPTION: None\nVERIFICATION: Cooperation likelihood and trust level can be measured and compared across different groups and interactions.", "rejected": "The likelihood of cooperation in a group increases as the level of trust between individuals increases, even when the individuals have not previously interacted.", "E_acc": 0.30531996488571167, "C_acc": 0.4169497489929199, "G_acc": 0.5794930935371667, "D_acc": 0.7123397467657924, "H_acc": 0.1545897126197815, "Q_acc": 0.5511136364657432, "E_rej": 0.035221394151449203, "C_rej": 0.725168764591217, "G_rej": 0.5802947031297663, "D_rej": 0.8706587553024292, "H_rej": 0.1293412446975708, "Q_rej": 0.44278923254387337, "Delta_Q": 0.10832440392186982, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a system failure is due to overload, cascading effects, or a single-point fault.", "ancestors": ["[DEF] A system failure is an event where a system ceases to perform its intended function.", "[VAR] The variables that can contribute to a system failure include workload, component interactions, and individual component reliability.", "[CONSTRAINT] The workload of a system is limited by its design capacity.", "[LIMIT] A system's design capacity is the maximum workload it can handle without failing.", "[DEF] A single-point fault is a failure of a single component that causes the entire system to fail.", "[VAR] Cascading effects refer to the sequence of events triggered by an initial failure that leads to additional failures.", "[LAW] The relationship between workload and system failure is governed by the principles of system reliability engineering.", "[CONSTRAINT] The identification of the root cause of a system failure is subject to the availability and accuracy of system monitoring data."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A system will fail if its workload exceeds its design capacity.\nASSUMPTION: None\nVERIFICATION: The design capacity and workload of the system must be measured in the same units, such as transactions per second.", "rejected": "A system will fail if its workload exceeds its design capacity plus the number of component interactions.", "E_acc": 0.1393279731273651, "C_acc": 0.6405783891677856, "G_acc": 0.5404783519251006, "D_acc": 0.6528278952464461, "H_acc": 0.27136940509080887, "Q_acc": 0.4252070230298809, "E_rej": 0.12203893065452576, "C_rej": 0.5337035059928894, "G_rej": 0.5365244861958283, "D_rej": 0.8560817837715149, "H_rej": 0.1439182162284851, "Q_rej": 0.49400041036840003, "Delta_Q": -0.06879338733851914, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Allocating limited resources across competing tasks to maximize long-term benefit.", "ancestors": ["[DEF] A resource is an item or service that is used to complete a task.", "[VAR] The availability of resources can vary over time.", "[CONSTRAINT] Resources are limited in quantity.", "[LIMIT] The total amount of resources available is finite.", "[DEF] A task is an activity that requires resources to be completed.", "[VAR] Tasks have different resource requirements.", "[LAW] The allocation of resources to tasks determines the tasks that can be completed.", "[CONSTRAINT] Tasks compete for the limited available resources.", "[LIMIT] The allocation of resources to tasks is subject to the constraint of resource availability."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The allocation of resources to tasks will be limited by the total amount of resources available.\nASSUMPTION: None\nVERIFICATION: The total amount of resources available can be measured and compared to the resource requirements of tasks.", "rejected": "The allocation of resources to tasks will be limited by the total amount of resources available, and the resource requirements of tasks are independent of the total amount of resources available.", "E_acc": 0.318142294883728, "C_acc": 0.4515789747238159, "G_acc": 0.5904215823393315, "D_acc": 0.6908430783078074, "H_acc": 0.19574284553527832, "Q_acc": 0.5418055410962552, "E_rej": 0.016184382140636444, "C_rej": 0.9297640919685364, "G_rej": 0.5883402863983065, "D_rej": 0.8772839307785034, "H_rej": 0.12271606922149658, "Q_rej": 0.399755732761696, "Delta_Q": 0.1420498083345592, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a rumor spreads because of novelty, authority, or emotional impact.", "ancestors": ["[DEF] A rumor is a piece of information that is spread without confirmation of its truth.", "[VAR] The spread of a rumor can be influenced by various factors.", "[LAW] The dissemination of information is subject to the principles of social influence and human communication.", "[CONSTRAINT] The spread of a rumor is limited by the social connections and networks of the individuals involved.", "[VAR] Novelty, authority, and emotional impact are factors that can contribute to the spread of a rumor.", "[LIMIT] The impact of these factors on the spread of a rumor can vary depending on the context and audience.", "[CONSTRAINT] The evaluation of the role of novelty, authority, and emotional impact in the spread of a rumor requires empirical evidence and observation."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The spread of a rumor is more likely to be limited when the social connections and networks of the individuals involved are weak.\nASSUMPTION: The strength of social connections and networks is inversely related to the ease of rumor dissemination.\nVERIFICATION: N/A", "rejected": "The spread of a rumor is more likely to be increased when the social connections and networks of the individuals involved are weak.", "E_acc": 0.44143146276474, "C_acc": 0.2640559673309326, "G_acc": 0.5496196442150644, "D_acc": 0.7281024656258523, "H_acc": 0.12720197439193726, "Q_acc": 0.6224424698922251, "E_rej": 0.0054267458617687225, "C_rej": 0.3714921474456787, "G_rej": 0.5148504255838426, "D_rej": 0.8892676532268524, "H_rej": 0.11073234677314758, "Q_rej": 0.4970799753542191, "Delta_Q": 0.12536249453800596, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring whether a phone battery drains faster due to app usage, battery aging, or background processes based on observed behavior.", "ancestors": ["[DEF] A phone battery's state of charge is a measure of the amount of energy it can supply.", "[VAR] The rate of battery drain is a variable that can be observed and measured over time.", "[LAW] The total energy stored in a phone battery decreases as it is used to power the device.", "[CONSTRAINT] A phone's power consumption is influenced by the apps it is running, its background processes, and its battery age.", "[VAR] The usage patterns of a phone, including app usage and background processes, can vary significantly over time.", "[LIMIT] The capacity of a phone battery to hold a charge decreases as it ages.", "[CONSTRAINT] The observed rate of battery drain is limited by the phone's hardware and software configuration."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The rate of battery drain increases as the phone's power consumption increases.\nASSUMPTION: The phone's hardware and software configuration remains constant over time.\nVERIFICATION: The relationship between power consumption and battery drain rate can be measured in units of wattage and ampere-hours per hour.", "rejected": "The rate of battery drain increases as the phone's power consumption increases, regardless of the phone's hardware and software configuration.", "E_acc": 0.04531479999423027, "C_acc": 0.8744000196456909, "G_acc": 0.499867489716659, "D_acc": 0.7373789376579225, "H_acc": 0.11900734901428223, "Q_acc": 0.37426298664261903, "E_rej": 0.001975510735064745, "C_rej": 0.9882878661155701, "G_rej": 0.47961368504790397, "D_rej": 0.8769303858280182, "H_rej": 0.12306961417198181, "Q_rej": 0.3619369327553917, "Delta_Q": 0.01232605388722735, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether delaying a decision improves outcomes or increases risk.", "ancestors": ["[DEF] A decision is an act of choosing between two or more options.", "[VAR] The time at which a decision is made can vary.", "[LIMIT] There is a limited amount of time available to make a decision.", "[CONSTRAINT] Decisions are constrained by the information available at the time.", "[VAR] The amount of information available can change over time.", "[LAW] The quality of a decision is influenced by the information used to make it.", "[CONSTRAINT] Delaying a decision can provide more time to gather information.", "[VAR] The rate at which new information becomes available can vary.", "[LIMIT] There is a maximum amount of time that a decision can be delayed before it must be made."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The quality of a decision is directly influenced by the amount of time available to gather information before the maximum delay limit is reached.\nASSUMPTION: None\nVERIFICATION: The decision quality can be measured against the information gathering time in units of time, such as seconds or minutes, within the regime of the given constraints.", "rejected": "The amount of time available to gather information before the maximum delay limit is reached is directly influenced by the quality of a decision.", "E_acc": 0.26335805654525757, "C_acc": 0.5239289999008179, "G_acc": 0.5641853712731972, "D_acc": 0.6845394941046834, "H_acc": 0.21646538376808167, "Q_acc": 0.5023200516821817, "E_rej": 0.7408156394958496, "C_rej": 0.056549299508333206, "G_rej": 0.5610886353606475, "D_rej": 0.8285276591777802, "H_rej": 0.17147234082221985, "Q_rej": 0.7717108567725518, "Delta_Q": -0.26939080509037006, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding whether to repair or replace a device based on failure risk, cost, and future usage.", "ancestors": ["[DEF] A device is an object that performs a specific function.", "[VAR] The failure risk of a device is a variable that can be measured.", "[CONSTRAINT] The decision to repair or replace a device is based on its failure risk.", "[VAR] The cost of repairing a device is a variable that can be measured.", "[VAR] The cost of replacing a device is a variable that can be measured.", "[LIMIT] The cost of repairing a device cannot exceed the cost of replacing it for the decision to be feasible.", "[CONSTRAINT] The decision to repair or replace a device must also consider its future usage.", "[VAR] The future usage of a device is a variable that can be estimated.", "[CONSTRAINT] The decision to repair or replace a device must balance failure risk, cost, and future usage."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The decision to repair a device is feasible only if its failure risk and cost of repair are both lower than the cost of replacing it.\nASSUMPTION: None\nVERIFICATION: The decision's feasibility can be tested by comparing the measured failure risk and repair cost to the replacement cost in the same units.", "rejected": "The decision to repair a device is feasible only if its failure risk and cost of repair are both lower than the cost of replacing it, regardless of its future usage.", "E_acc": 0.46052759885787964, "C_acc": 0.304686039686203, "G_acc": 0.5280441409908235, "D_acc": 0.6722097939345986, "H_acc": 0.21722453832626343, "Q_acc": 0.5955494048725813, "E_rej": 0.08536196500062943, "C_rej": 0.8551353216171265, "G_rej": 0.5089359309524297, "D_rej": 0.82193723320961, "H_rej": 0.17806276679039001, "Q_rej": 0.40294988133013243, "Delta_Q": 0.1925995235424489, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether cooperation emerges in a group based on repeated interactions and trust.", "ancestors": ["[DEF] A group consists of two or more individuals interacting with each other.", "[VAR] The number of individuals in a group can vary.", "[CONSTRAINT] Interactions between individuals in a group occur over a sequence of time steps.", "[LIMIT] The number of time steps is finite.", "[DEF] Trust is a measure of the confidence one individual has in another individual's behavior.", "[VAR] The level of trust between individuals in a group can change over time.", "[LAW] Repeated interactions between individuals in a group can affect the level of trust between them.", "[CONSTRAINT] Cooperation between individuals in a group requires a minimum level of trust.", "[LIMIT] The maximum level of trust that can be achieved between individuals in a group is bounded by the number of interactions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The level of trust between individuals in a group will increase with the number of repeated interactions, up to a bounded maximum level.\nASSUMPTION: None\nVERIFICATION: The level of trust can be measured and compared across different numbers of interactions, with units of trust on a bounded scale.", "rejected": "The level of trust between individuals in a group will increase with the number of repeated interactions, up to a maximum level proportional to the square root of the number of interactions.", "E_acc": 0.2491869330406189, "C_acc": 0.4712446928024292, "G_acc": 0.5902309741359204, "D_acc": 0.7191362213343382, "H_acc": 0.1205354630947113, "Q_acc": 0.5303270341362805, "E_rej": 0.1470271348953247, "C_rej": 0.3118644952774048, "G_rej": 0.5925875350367278, "D_rej": 0.9072812795639038, "H_rej": 0.09271872043609619, "Q_rej": 0.5724371322896332, "Delta_Q": -0.04211009815335276, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about feedback loops that cause oscillations or runaway behavior in control systems.", "ancestors": ["[DEF] A control system is a system that manages and regulates its behavior.", "[VAR] The input and output of a control system can be variables that change over time.", "[LAW] Feedback in a control system is the process of using its output as an input to modify its behavior.", "[CONSTRAINT] A control system's stability is constrained by its ability to respond to changes in its input.", "[VAR] The gain of a control system is a variable that determines the magnitude of its response to input changes.", "[LIMIT] The maximum allowable gain of a control system is limited by its tendency to oscillate or become unstable.", "[CONSTRAINT] The presence of a feedback loop in a control system constrains its behavior to either converge or diverge over time.", "[LAW] The stability of a control system with a feedback loop is governed by the laws of differential equations and control theory."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A control system with a high gain is more likely to become unstable over time.\nASSUMPTION: None\nVERIFICATION: Stability can be measured by observing the system's output over a specified time period.", "rejected": "A control system with a high gain is more likely to become unstable over time regardless of the presence of a feedback loop.", "E_acc": 0.4258490204811096, "C_acc": 0.12761631608009338, "G_acc": 0.541013168038002, "D_acc": 0.6344837278593332, "H_acc": 0.19327431917190552, "Q_acc": 0.6180033901905907, "E_rej": 0.01735580526292324, "C_rej": 0.7945881485939026, "G_rej": 0.5362514161970466, "D_rej": 0.854447066783905, "H_rej": 0.14555293321609497, "Q_rej": 0.4098735151346773, "Delta_Q": 0.2081298750559134, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning across physical, social, and informational constraints to predict outcomes.", "ancestors": ["[DEF] A physical constraint is a limitation on the physical properties of a system.", "[VAR] Variables such as time, cost, and resources are used to describe systems.", "[LAW] The laws of physics govern the behavior of physical systems.", "[CONSTRAINT] Social constraints are limitations imposed by social norms and relationships.", "[CONSTRAINT] Informational constraints are limitations on the availability and accuracy of data.", "[LIMIT] The complexity of a system is limited by its physical, social, and informational constraints.", "[LIMIT] The predictability of outcomes in a system is limited by the complexity of the system."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The predictability of outcomes in a system is limited by its physical, social, and informational constraints.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The predictability of outcomes in a system is increased by its physical, social, and informational constraints.", "E_acc": 0.20219221711158752, "C_acc": 0.6557966470718384, "G_acc": 0.5938537723850459, "D_acc": 0.5935185246635228, "H_acc": 0.305927038192749, "Q_acc": 0.4363800913095474, "E_rej": 0.0022323215380311012, "C_rej": 0.9912539124488831, "G_rej": 0.6026100952876732, "D_rej": 0.7939833402633667, "H_rej": 0.2060166597366333, "Q_rej": 0.3611359351081774, "Delta_Q": 0.07524415620137004, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether two algebraic expressions are equivalent by transforming them step by step under valid operations.", "ancestors": ["[DEF] An algebraic expression is a combination of variables, constants, and mathematical operations.", "[VAR] Variables in an algebraic expression represent unknown or changing values.", "[CONSTRAINT] Algebraic expressions are subject to the rules of arithmetic and algebraic manipulation.", "[LAW] The order of operations, including parentheses, exponents, multiplication and division, and addition and subtraction, governs the evaluation of algebraic expressions.", "[DEF] Equivalent algebraic expressions are expressions that yield the same value for all possible input values of their variables.", "[VAR] Input values of variables can be any real number, unless explicitly restricted by the problem context.", "[LIMIT] The process of determining equivalence between two algebraic expressions has a finite number of steps when the expressions are finite and the operations are valid.", "[CONSTRAINT] Valid operations for transforming algebraic expressions include addition, subtraction, multiplication, division, and factoring, among others.", "[LAW] The associative, commutative, and distributive properties of arithmetic operations can be applied to simplify and transform algebraic expressions."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The process of determining equivalence between two algebraic expressions can be completed in a finite number of steps for expressions with a finite number of variables and operations.\nASSUMPTION: The number of possible input values for the variables is finite or can be reduced to a finite set.\nVERIFICATION: The validity of this hypothesis can be checked by testing it with a set of algebraic expressions and input values.", "rejected": "The process of determining equivalence between two algebraic expressions can be completed in an infinite number of steps for expressions with a finite number of variables and operations.", "E_acc": 0.42845237255096436, "C_acc": 0.03285175934433937, "G_acc": 0.5717654171749018, "D_acc": 0.6926776878535748, "H_acc": 0.2549756318330765, "Q_acc": 0.649356417718809, "E_rej": 0.13225874304771423, "C_rej": 0.0303815808147192, "G_rej": 0.5895639332011342, "D_rej": 0.8965193331241608, "H_rej": 0.10348066687583923, "Q_rej": 0.6204698933288455, "Delta_Q": 0.02888652438996353, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Analyzing delayed effects where actions appear beneficial short-term but harmful long-term.", "ancestors": ["[DEF] An action is an event that occurs at a specific point in time.", "[VAR] The effects of an action can vary over time.", "[LAW] Cause-and-effect relationships govern the outcomes of actions.", "[CONSTRAINT] The observation of effects is limited by the duration of the observation period.", "[VAR] The duration of observation periods can differ across studies.", "[LIMIT] There is a maximum duration for which the effects of an action can be observed.", "[CONSTRAINT] The accuracy of assessments of action effects depends on the quality of the observation data."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The accuracy of assessments of action effects is limited by the maximum duration for which the effects of an action can be observed.\nASSUMPTION: None\nVERIFICATION: The relationship between observation duration and assessment accuracy can be tested by comparing assessments made within and beyond the maximum observable duration.", "rejected": "The maximum duration for which the effects of an action can be observed is limited by the accuracy of assessments of action effects.", "E_acc": 0.18122084438800812, "C_acc": 0.5569858551025391, "G_acc": 0.5568743771873415, "D_acc": 0.7047770489007235, "H_acc": 0.21331515908241272, "Q_acc": 0.4739678516052664, "E_rej": 0.9382704496383667, "C_rej": 0.020669447258114815, "G_rej": 0.5604449019301683, "D_rej": 0.8555622100830078, "H_rej": 0.1444377899169922, "Q_rej": 0.8461048888508231, "Delta_Q": -0.37213703724555675, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Balancing accuracy and simplicity when explanations influence behavior.", "ancestors": ["[DEF] An explanation is a statement that describes a concept or phenomenon.", "[VAR] The complexity of an explanation can vary.", "[CONSTRAINT] Explanations are limited by the knowledge of the explainer.", "[LIMIT] The attention span of the audience is finite.", "[DEF] Accuracy refers to the degree of correctness in an explanation.", "[VAR] The simplicity of an explanation can affect its understandability.", "[LAW] The level of detail in an explanation is inversely related to its simplicity.", "[CONSTRAINT] The explainer's goal is to balance accuracy and simplicity.", "[VAR] The influence of an explanation on behavior can depend on its clarity.", "[LIMIT] The amount of information that can be conveyed in an explanation is limited."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The explainer's goal of balancing accuracy and simplicity is limited by the audience's finite attention span.\nASSUMPTION: None\nVERIFICATION: The relationship between explanation simplicity and audience attention span can be tested through surveys or experiments.", "rejected": "The explainer's goal of balancing accuracy and simplicity is limited by the explainer's own finite attention span.", "E_acc": 0.12311627715826035, "C_acc": 0.5616951584815979, "G_acc": 0.5775140055920929, "D_acc": 0.6772405747324228, "H_acc": 0.18365910649299622, "Q_acc": 0.457180856866762, "E_rej": 0.36165693402290344, "C_rej": 0.1952655166387558, "G_rej": 0.595103507861495, "D_rej": 0.8332324028015137, "H_rej": 0.16676759719848633, "Q_rej": 0.638434399291873, "Delta_Q": -0.18125354242511094, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring the cause of a software bug by reasoning from observed failures and execution traces.", "ancestors": ["[DEF] A software bug is an error or flaw in a computer program.", "[VAR] Execution traces are records of the steps a program takes during runtime.", "[DEF] Observed failures are instances where a program does not behave as intended.", "[LAW] The execution of a program follows a sequence of instructions.", "[CONSTRAINT] The sequence of instructions is determined by the program's code.", "[VAR] The execution trace of a program can include variable values and function calls.", "[LIMIT] The amount of information that can be collected from an execution trace is finite.", "[CONSTRAINT] The observed failures must be reproducible to facilitate debugging.", "[DEF] A debugging process involves analyzing execution traces and observed failures to identify the cause of a software bug."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The amount of information that can be collected from an execution trace is limited by the finite amount of information that can be recorded during runtime.\nASSUMPTION: None\nVERIFICATION: The limit is determined by the program's code and the execution trace's record-keeping capacity, measured in terms of data storage units.", "rejected": "The amount of information that can be collected from an execution trace is limited by the infinite amount of information that can be recorded during runtime.", "E_acc": 0.2207956612110138, "C_acc": 0.5167205333709717, "G_acc": 0.5687941504293121, "D_acc": 0.6552656535059214, "H_acc": 0.21970698237419128, "Q_acc": 0.4857358542387374, "E_rej": 0.05071907863020897, "C_rej": 0.7990409731864929, "G_rej": 0.5467201639548875, "D_rej": 0.7613790929317474, "H_rej": 0.23862090706825256, "Q_rej": 0.39316528962226593, "Delta_Q": 0.09257056461647145, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evaluating whether a heuristic improves average performance while preserving correctness.", "ancestors": ["[DEF] A heuristic is an algorithmic technique used to improve performance.", "[VAR] The average performance of an algorithm is measured by its execution time or cost.", "[CONSTRAINT] Correctness of an algorithm is determined by its ability to produce accurate results.", "[LIMIT] The evaluation of a heuristic is limited to its application domain.", "[DEF] Average performance improvement is defined as a reduction in average execution time or cost.", "[VAR] The correctness of an algorithm is a binary property, either true or false.", "[CONSTRAINT] A heuristic must preserve the correctness of the original algorithm.", "[LAW] The average performance of an algorithm is calculated as the total performance divided by the number of instances.", "[CONSTRAINT] The evaluation of a heuristic must account for all possible input scenarios.", "[LIMIT] The applicability of a heuristic is restricted to problems with specific characteristics."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A heuristic that improves the average performance of an algorithm must reduce its average execution time or cost without compromising its correctness.\nASSUMPTION: None\nVERIFICATION: The reduction in average execution time or cost can be measured and verified against the algorithm's original performance, in units of time or cost.", "rejected": "A heuristic that improves the average performance of an algorithm must reduce its average execution time or cost, and its correctness is independent of the heuristic's application.", "E_acc": 0.3708641231060028, "C_acc": 0.36547791957855225, "G_acc": 0.550759035977535, "D_acc": 0.6852336151059717, "H_acc": 0.2612212672829628, "Q_acc": 0.5592400565044955, "E_rej": 0.12944576144218445, "C_rej": 0.6700663566589355, "G_rej": 0.5418954552151263, "D_rej": 0.9266314208507538, "H_rej": 0.09171072393655777, "Q_rej": 0.48935475992038846, "Delta_Q": 0.06988529658410703, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether two algebraic expressions are equivalent by transforming them step by step under valid operations.", "ancestors": ["[DEF] An algebraic expression is a combination of variables, constants, and mathematical operations.", "[VAR] Variables in an algebraic expression represent unknown or changing values.", "[CONSTRAINT] Algebraic expressions are subject to the rules of arithmetic and algebraic manipulation.", "[LAW] The order of operations, such as parentheses, exponents, multiplication and division, and addition and subtraction, must be followed.", "[DEF] Equivalent algebraic expressions are expressions that have the same value for all possible values of the variables.", "[CONSTRAINT] Valid operations for transforming algebraic expressions include addition, subtraction, multiplication, and division.", "[LIMIT] The validity of an operation on an algebraic expression depends on the presence of defined values for all variables.", "[CONSTRAINT] Transforming an algebraic expression into an equivalent form requires applying valid operations in a step-by-step manner."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The validity of an algebraic expression's transformation into an equivalent form depends on the defined values of its variables.\nASSUMPTION: The variables in the algebraic expression have a finite number of possible values.\nVERIFICATION: The transformation's validity can be checked by substituting the defined variable values into the original and transformed expressions and verifying they yield the same result.", "rejected": "The validity of an algebraic expression's transformation into an equivalent form does not depend on the defined values of its variables.", "E_acc": 0.7294250726699829, "C_acc": 0.06458872556686401, "G_acc": 0.5633755659218878, "D_acc": 0.7285003997385502, "H_acc": 0.2679477334022522, "Q_acc": 0.7374901964794844, "E_rej": 0.00857212208211422, "C_rej": 0.9692107439041138, "G_rej": 0.5672943201498128, "D_rej": 0.8409851491451263, "H_rej": 0.15901485085487366, "Q_rej": 0.374483896617312, "Delta_Q": 0.3630062998621724, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Estimating risk when probabilities are unknown but relative frequencies can be inferred.", "ancestors": ["[DEF] A relative frequency is a measure of the proportion of times an event occurs in a given dataset.", "[VAR] The dataset used to estimate risk may contain a large number of observations.", "[LAW] The law of large numbers states that the average of the results obtained from a large number of trials should be close to the expected value.", "[CONSTRAINT] The relative frequencies must be calculated from a dataset that is relevant to the risk being estimated.", "[VAR] The size of the dataset can affect the accuracy of the estimated relative frequencies.", "[DEF] An unknown probability refers to a probability that has not been directly measured or quantified.", "[CONSTRAINT] Relative frequencies can only be inferred from datasets that contain sufficient information about the event of interest.", "[LIMIT] The accuracy of the estimated risk is limited by the quality and size of the available dataset.", "[VAR] Different datasets may yield different relative frequencies for the same event.", "[CONSTRAINT] The estimation of risk using relative frequencies requires that the dataset is representative of the population or system being studied."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The accuracy of estimated relative frequencies increases as the size of the dataset increases.\nASSUMPTION: None\nVERIFICATION: The law of large numbers provides a testable condition to verify this hypothesis.", "rejected": "The accuracy of estimated relative frequencies increases as the size of any dataset increases.", "E_acc": 0.4300553798675537, "C_acc": 0.1396026760339737, "G_acc": 0.5401941840536892, "D_acc": 0.616922753979452, "H_acc": 0.20583847165107727, "Q_acc": 0.6119356191949918, "E_rej": 0.348226398229599, "C_rej": 0.04033743217587471, "G_rej": 0.5182815451407805, "D_rej": 0.7921160161495209, "H_rej": 0.20788398385047913, "Q_rej": 0.6376915469067171, "Delta_Q": -0.0257559277117253, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a rumor spreads because of novelty, authority, or emotional impact.", "ancestors": ["[DEF] A rumor is a piece of information that is spread without confirmation of its truth.", "[VAR] The spread of a rumor can be influenced by various factors.", "[LAW] The dissemination of information is often facilitated by social networks and communication channels.", "[CONSTRAINT] The attention of individuals is limited, affecting what information they choose to engage with.", "[VAR] Novelty, authority, and emotional impact are factors that can contribute to the spread of a rumor.", "[LIMIT] The impact of these factors on rumor spread can vary across different populations and contexts.", "[CONSTRAINT] The evaluation of a rumor's credibility is a necessary step before it can be accepted or rejected by an individual."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The spread of a rumor is more likely to occur when the factors of novelty, authority, and emotional impact are present in combination.\nASSUMPTION: The presence of these factors has a cumulative effect on the spread of a rumor.\nVERIFICATION: The effect can be tested by comparing the spread of rumors with varying combinations of these factors.", "rejected": "The presence of a rumor is more likely to occur when the spread of the factors of novelty, authority, and emotional impact are in combination.", "E_acc": 0.6784599423408508, "C_acc": 0.015580211766064167, "G_acc": 0.5384382522398872, "D_acc": 0.8259552083909512, "H_acc": 0.12383261322975159, "Q_acc": 0.760917371152235, "E_rej": 0.06448529660701752, "C_rej": 0.04243509843945503, "G_rej": 0.5356494661952768, "D_rej": 0.8955490589141846, "H_rej": 0.10445094108581543, "Q_rej": 0.586653180207525, "Delta_Q": 0.17426419094471002, "flag_reject": false, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Predicting whether ice will melt faster in saltwater or freshwater by reasoning about energy transfer.", "ancestors": ["[DEF] Energy transfer occurs when a system interacts with its surroundings.", "[VAR] The temperature of a system affects the rate of energy transfer.", "[LAW] The second law of thermodynamics describes the direction of spontaneous energy transfer.", "[CONSTRAINT] Ice melts when it gains energy from its surroundings.", "[VAR] Saltwater and freshwater have different thermal properties.", "[LAW] The rate of energy transfer is influenced by the thermal conductivity of a substance.", "[CONSTRAINT] The melting point of ice is lower in saltwater than in freshwater.", "[VAR] The specific heat capacity of saltwater is different from that of freshwater.", "[LIMIT] The rate of energy transfer between ice and a liquid is limited by the liquid's thermal properties.", "[CONSTRAINT] The energy required to melt ice is constant, regardless of the surrounding liquid."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The rate of energy transfer from saltwater to ice is lower than from freshwater to ice.\nASSUMPTION: None\nVERIFICATION: Comparison of thermal conductivity values between saltwater and freshwater.", "rejected": "The rate of energy transfer from saltwater to ice is lower than from freshwater to ice when the ice is already melted.", "E_acc": 0.5030860900878906, "C_acc": 0.38743120431900024, "G_acc": 0.5517258531181142, "D_acc": 0.6619452927261591, "H_acc": 0.13546264171600342, "Q_acc": 0.6026275511598215, "E_rej": 0.02875211276113987, "C_rej": 0.9022144675254822, "G_rej": 0.5591200029011816, "D_rej": 0.8653236329555511, "H_rej": 0.13467636704444885, "Q_rej": 0.3996038307901473, "Delta_Q": 0.2030237203696742, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Inferring which of several explanations is most likely given noisy and incomplete observations.", "ancestors": ["[DEF] An observation is a vector o ∈ ℝⁿ.", "[VAR] A set of candidate explanations is indexed by i ∈ {1,…,k}.", "[VAR] Each explanation i specifies a likelihood function p(o|i).", "[VAR] A prior probability p(i) is assigned to each explanation i.", "[LAW] Bayes’ theorem gives the posterior p(i|o)=p(o|i)p(i)/∑_{j=1}^{k}p(o|j)p(j).", "[CONSTRAINT] The support of p(o|i) is non-empty for every i.", "[LIMIT] The observation o may be corrupted by additive noise.", "[LIMIT] The observation o may omit entries of the underlying vector.", "[LIMIT] The likelihood p(o|i) must be evaluated with the corrupted and incomplete o."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any observation o, the posterior probability p(i|o) is strictly positive for every explanation i.\nASSUMPTION: None\nVERIFICATION: Follows because each p(o|i) has non-empty support and p(i)>0, so numerator and denominator in Bayes' theorem are positive.", "rejected": "For any observation o, the posterior probability p(i|o) is strictly positive for every explanation i even when the support of p(o|i) is empty.", "E_acc": 0.4177795946598053, "C_acc": 0.25945335626602173, "G_acc": 0.523489261046052, "D_acc": 0.7025796230882406, "H_acc": 0.21021845936775208, "Q_acc": 0.5976351380348206, "E_rej": 0.3548731207847595, "C_rej": 0.31949058175086975, "G_rej": 0.5165315749472938, "D_rej": 0.8201963901519775, "H_rej": 0.17980360984802246, "Q_rej": 0.591929051920306, "Delta_Q": 0.005706086114514619, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether a missed appointment was due to forgetfulness, scheduling conflict, or external disruption from available evidence.", "ancestors": ["[DEF] A missed appointment is an event where a scheduled appointment does not occur.", "[DEF] Forgetfulness is the failure to recall the appointment time.", "[DEF] A scheduling conflict is the overlap of the appointment time with another committed event.", "[DEF] An external disruption is an unforeseeable external event preventing arrival.", "[VAR] Let t₀ be the scheduled appointment time.", "[VAR] Let E be the set of events recorded in the calendar.", "[CONSTRAINT] Forgetfulness is valid only if t₀ ∉ E.", "[LIMIT] Only one cause among forgetfulness, scheduling conflict, or external disruption can be assigned."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If t₀ ∈ E, then forgetfulness cannot be the assigned cause of the missed appointment.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If forgetfulness cannot be the assigned cause of the missed appointment, then t₀ ∈ E.", "E_acc": 0.020227685570716858, "C_acc": 0.9513852000236511, "G_acc": 0.5658658756874502, "D_acc": 0.6330999427009374, "H_acc": 0.17388775944709778, "Q_acc": 0.33819565339945257, "E_rej": 0.21054479479789734, "C_rej": 0.623895525932312, "G_rej": 0.57496966002509, "D_rej": 0.858531653881073, "H_rej": 0.141468346118927, "Q_rej": 0.5109377614222468, "Delta_Q": -0.17274210802279422, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether an infection is viral or bacterial based on symptom progression and response to treatment.", "ancestors": ["[DEF] An infection is a pathological state caused by multiplication of a microorganism in host tissue.", "[DEF] A viral infection is an infection whose causative agent is a virus.", "[DEF] A bacterial infection is an infection whose causative agent is a bacterium.", "[VAR] Let t denote time elapsed since symptom onset.", "[VAR] Let S(t) denote the multiset of symptoms present at t.", "[VAR] Let A denote administration of an antibacterial drug.", "[VAR] Let R(t) denote the host’s measurable response vector at t.", "[CONSTRAINT] If the infection is viral, then A does not reduce the viral load.", "[CONSTRAINT] If the infection is bacterial, then A can reduce the bacterial load.", "[LIMIT] The set of symptoms in S(t) that are specific to viral agents and never appear in bacterial agents is empty."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For every t, the multiset S(t) cannot be used to distinguish viral from bacterial infection because no symptom is exclusively viral.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "For every t, the multiset S(t) can be used to distinguish viral from bacterial infection because no symptom is exclusively viral.", "E_acc": 0.13512714207172394, "C_acc": 0.6158170700073242, "G_acc": 0.5460091724526137, "D_acc": 0.6329657533206046, "H_acc": 0.18672022223472595, "Q_acc": 0.43449769155122336, "E_rej": 0.15934106707572937, "C_rej": 0.5184963941574097, "G_rej": 0.5293476430233568, "D_rej": 0.8121401071548462, "H_rej": 0.1878598928451538, "Q_rej": 0.49361460204236207, "Delta_Q": -0.05911691049113871, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether an algorithm will terminate by identifying invariants and monotonic progress.", "ancestors": ["[DEF] A program state is an assignment of values to all program variables at a point in execution.", "[DEF] An invariant I is a Boolean expression on program states that is true every time control reaches a fixed program point.", "[VAR] Let t be an integer-valued expression on program states.", "[DEF] t is a variant function for loop L iff t decreases by at least 1 on every complete iteration of L.", "[CONSTRAINT] A loop L has bounded iteration if a variant function t for L exists and t is bounded below by 0.", "[LAW] A loop with bounded iteration terminates after finitely many steps.", "[LIMIT] Termination of an algorithm cannot be established solely from invariants without a variant function or similar progress measure."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If a loop L has an integer-valued expression t that decreases by ≥1 each iteration and t≥0 always, then L terminates after finitely many steps.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "If a loop L has an integer-valued expression t that decreases by ≥1 each iteration and t≥0 always, then L terminates after infinitely many steps.", "E_acc": 0.3908805251121521, "C_acc": 0.39229512214660645, "G_acc": 0.5593308506067842, "D_acc": 0.6187224388122559, "H_acc": 0.2522154524922371, "Q_acc": 0.5491942457389086, "E_rej": 0.11339962482452393, "C_rej": 0.757394015789032, "G_rej": 0.5548324689734727, "D_rej": 0.7737152278423309, "H_rej": 0.28285596519708633, "Q_rej": 0.4199650271330029, "Delta_Q": 0.12922921860590575, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Evaluating whether a heuristic improves average performance while preserving correctness.", "ancestors": ["[DEF] A heuristic is a procedure that returns a candidate solution.", "[DEF] A correct procedure always returns a valid solution.", "[DEF] Average performance is the expected value of a performance metric over the input distribution.", "[DEF] Correctness preservation means the heuristic’s output set equals the correct procedure’s output set.", "[VAR] Let P be the performance metric.", "[VAR] Let D be the input distribution.", "[VAR] Let H be the heuristic.", "[VAR] Let C be the correct procedure.", "[LAW] E_{x∼D}[P(H(x))] is the average performance of H.", "[LAW] H preserves correctness iff ∀x (H(x)=C(x))."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If H preserves correctness, then E_{x∼D}[P(H(x))] = E_{x∼D}[P(C(x))].\nASSUMPTION: None\nVERIFICATION: Equality of expectations under identical output sets; units match metric P.", "rejected": "If H preserves correctness, then E_{x∼D}[P(H(x))] and E_{x∼D}[P(C(x))] are independent random variables.", "E_acc": 0.2614007294178009, "C_acc": 0.5284373760223389, "G_acc": 0.5566706133208105, "D_acc": 0.6388537399470806, "H_acc": 0.24350681900978088, "Q_acc": 0.4874869323734726, "E_rej": 0.08904869109392166, "C_rej": 0.19680339097976685, "G_rej": 0.5405954456489, "D_rej": 0.7072334140539169, "H_rej": 0.29276658594608307, "Q_rej": 0.5076430424781783, "Delta_Q": -0.020156110104705638, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether a solution generalizes or only works for specific conditions.", "ancestors": ["[DEF] A solution is a mapping f: X → Y.", "[DEF] A condition is a subset C ⊆ X.", "[DEF] A solution f is valid on C iff ∀x∈C, f(x) meets specification S.", "[VAR] Let D be the data distribution over X.", "[DEF] Generalization is the property that f is valid on supp(D).", "[LIMIT] Validity on C gives no implication for validity on X \\ C.", "[CONSTRAINT] Finite samples provide only empirical coverage of C.", "[LAW] Empirical risk R_emp(f) = 1/n Σ_{i=1}^n L(f(x_i), y_i) with (x_i, y_i) ∈ C.", "[LIMIT] R_emp(f) = 0 does not imply validity on supp(D) \\ C."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: If C is finite and supp(D) is infinite, then for any solution f with R_emp(f)=0, the probability that f is valid on supp(D) is strictly less than 1.  \nASSUMPTION: The data distribution D is non-atomic on supp(D)\\C.  \nVERIFICATION: Probability regime; testable by checking whether D assigns positive mass to every open set in supp(D)\\C.", "rejected": "If C is finite and supp(D) is infinite, then for any solution f with R_emp(f)=0, the probability that f is valid on supp(D) is strictly greater than 1.", "E_acc": 0.40634527802467346, "C_acc": 0.29069072008132935, "G_acc": 0.5500408271909691, "D_acc": 0.7205903418362141, "H_acc": 0.1740652620792389, "Q_acc": 0.600485146988649, "E_rej": 0.45594117045402527, "C_rej": 0.27938616275787354, "G_rej": 0.5485816151485778, "D_rej": 0.8218027055263519, "H_rej": 0.17819729447364807, "Q_rej": 0.6371622532722541, "Delta_Q": -0.0366771062836051, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Light in physics", "ancestors": ["[DEF] Light is electromagnetic radiation.", "[VAR] c denotes the speed of light in vacuum.", "[CONSTRAINT] c = 299792458 m s⁻¹.", "[LAW] In vacuum, light propagates at speed c.", "[VAR] n denotes the refractive index of a medium.", "[CONSTRAINT] n ≥ 1.", "[LIMIT] In a medium, light propagates at speed c/n."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: In any medium with refractive index n > 1, the speed of light is strictly less than 299792458 m s⁻¹.\nASSUMPTION: None\nVERIFICATION: Units: m s⁻¹; regime: any medium with n > 1; test via speed measurement.", "rejected": "HYPOTHESIS: In any medium with refractive index n ≥ 1, the speed of light is strictly less than 299792458 m s⁻¹.", "E_acc": 0.4225437045097351, "C_acc": 0.2618114650249481, "G_acc": 0.5456790553289466, "D_acc": 0.6573674092069268, "H_acc": 0.18346139788627625, "Q_acc": 0.5966639714664781, "E_rej": 0.5366708636283875, "C_rej": 0.20842793583869934, "G_rej": 0.543167082243599, "D_rej": 0.8264890313148499, "H_rej": 0.17351096868515015, "Q_rej": 0.6758957977639511, "Delta_Q": -0.07923182629747305, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Determining whether adding more data will meaningfully reduce uncertainty or reinforce bias.", "ancestors": ["[DEF] Uncertainty is the standard deviation σ of the estimator.", "[DEF] Bias is the expected difference E[θ̂−θ] between estimator and parameter.", "[VAR] Let n denote the number of data points.", "[VAR] Let Dn be the dataset of size n.", "[LAW] The variance of the sample mean estimator satisfies Var(θ̂)=σ²/n.", "[CONSTRAINT] The dataset Dn is drawn from a distribution with fixed σ.", "[LIMIT] As n→∞, σ/√n→0.", "[LIMIT] If the sampling distribution is biased, E[θ̂−θ] is constant with respect to n.", "[LIMIT] Increasing n cannot reduce E[θ̂−θ] when the model is misspecified.", "[LIMIT] Uncertainty σ/√n vanishes while bias E[θ̂−θ] remains under model misspecification."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any fixed σ>0, the sample-mean estimator’s mean squared error MSE(θ̂)=σ²/n + (E[θ̂−θ])² collapses to the squared bias (E[θ̂−θ])² as n→∞.\nASSUMPTION: None\nVERIFICATION: Units: σ²/n has variance units, (E[θ̂−θ])² has squared bias units; limit n→∞ gives testable MSE→bias².", "rejected": "For any fixed σ>0, the sample-mean estimator’s mean squared error MSE(θ̂)=σ²/n + (E[θ̂−θ])² collapses to the squared bias (E[θ̂−θ])² as σ→0.", "E_acc": 0.1428128033876419, "C_acc": 0.7079475522041321, "G_acc": 0.5493710490409285, "D_acc": 0.7038463624194264, "H_acc": 0.18225032091140747, "Q_acc": 0.4336727807763964, "E_rej": 0.07700137794017792, "C_rej": 0.8549743294715881, "G_rej": 0.5477244713711116, "D_rej": 0.855885237455368, "H_rej": 0.14411476254463196, "Q_rej": 0.4184160129985685, "Delta_Q": 0.015256767777827918, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning about feedback loops that cause oscillations or runaway behavior in control systems.", "ancestors": ["[DEF] A feedback loop is a closed path whereby a system's output influences its own input.", "[DEF] The loop gain L is the product of all gains encountered once around the loop.", "[DEF] The phase φ is the total phase shift accumulated once around the loop.", "[LAW] Oscillation occurs if |L| ≥ 1 and φ = 2πn for integer n.", "[CONSTRAINT] Runaway requires |L| > 1 at φ = 2πn.", "[LIMIT] For linear time-invariant systems, sustained bounded oscillation demands |L| = 1 at φ = 2πn.", "[LIMIT] If |L| < 1 at φ = 2πn, any oscillation decays to zero.", "[LIMIT] If |L| > 1 at φ = 2πn, the signal grows without bound until a physical limit is reached."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A linear time-invariant feedback loop with |L| = 1 and φ = 2πn produces a constant-amplitude oscillation that neither grows nor decays.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless gain and phase; regime: linear time-invariant system at steady-state.", "rejected": "A linear time-invariant feedback loop with |L| = 1 and φ = 2πn produces a constant-amplitude oscillation that grows linearly with time.", "E_acc": 0.19252294301986694, "C_acc": 0.6322619915008545, "G_acc": 0.5573265851417091, "D_acc": 0.668280387762934, "H_acc": 0.12447509169578552, "Q_acc": 0.46397837001713926, "E_rej": 0.16088390350341797, "C_rej": 0.43203917145729065, "G_rej": 0.5698369153542444, "D_rej": 0.8677917718887329, "H_rej": 0.1322082281112671, "Q_rej": 0.536162251397036, "Delta_Q": -0.07218388137989673, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Deciding when transparency improves trust versus enabling manipulation.", "ancestors": ["[DEF] Transparency is the observable disclosure of information I.", "[DEF] Trust is the probability p that an agent A relies on disclosed I.", "[DEF] Manipulation is the selective disclosure of I to alter A’s action a.", "[VAR] Let U_A(a) be the utility A receives from action a.", "[VAR] Let U_M(a) be the utility the information source M receives from a.", "[CONSTRAINT] M chooses I to maximize U_M(a) subject to A observing I.", "[LIMIT] A’s inference is bounded by the entropy of I.", "[LIMIT] If U_M(a) ≠ U_A(a), increased entropy of I can increase p while also enlarging the feasible set for M to manipulate a."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: When U_M(a) ≠ U_A(a), the maximal entropy of disclosed I that M can select without reducing p below any fixed threshold p* is strictly lower than the entropy achievable when U_M(a) = U_A(a).\nASSUMPTION: None\nVERIFICATION: Entropy in bits; testable by comparing feasible entropy ranges under aligned vs mis-aligned utilities while holding p ≥ p*.", "rejected": "When U_M(a) ≠ U_A(a), the maximal entropy of disclosed I that M can select without reducing p below any fixed threshold p* is strictly higher than the entropy achievable when U_M(a) = U_A(a).", "E_acc": 0.24760417640209198, "C_acc": 0.5588616132736206, "G_acc": 0.5432967648957856, "D_acc": 0.6480115987360477, "H_acc": 0.274414986371994, "Q_acc": 0.4733291043550708, "E_rej": 0.09789194166660309, "C_rej": 0.7783739566802979, "G_rej": 0.5482637836103095, "D_rej": 0.7131842225790024, "H_rej": 0.2868157774209976, "Q_rej": 0.397300814659684, "Delta_Q": 0.07602828969538683, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Reasoning whether an infection is viral or bacterial based on symptom progression and response to treatment.", "ancestors": ["[DEF] An infection is a state in which a pathogen multiplies in a host.", "[DEF] A pathogen is either viral or bacterial.", "[DEF] Symptom onset time t₀ is the first detectable clinical sign.", "[DEF] Symptom peak time tₚ is the maximum observed severity.", "[DEF] Antibiotic response R is the fractional reduction in symptom severity 48 h post-administration.", "[LAW] For viral infections tₚ − t₀ ≤ 48 h.", "[LAW] For bacterial infections tₚ − t₀ > 48 h.", "[LAW] For viral infections R = 0.", "[LAW] For bacterial infections R > 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If R > 0, then tₚ − t₀ > 48 h.\nASSUMPTION: None\nVERIFICATION: Units: R dimensionless, tₚ − t₀ in hours; test by measuring R and time interval.", "rejected": "If R > 0, then tₚ − t₀ < 48 h.", "E_acc": 0.08557160198688507, "C_acc": 0.7863196134567261, "G_acc": 0.5623379025076117, "D_acc": 0.6604476496577263, "H_acc": 0.236537367105484, "Q_acc": 0.3893109316272395, "E_rej": 0.24707961082458496, "C_rej": 0.516230046749115, "G_rej": 0.5605083835710373, "D_rej": 0.7190408259630203, "H_rej": 0.2809591740369797, "Q_rej": 0.4986917984006661, "Delta_Q": -0.10938086677342657, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging whether a household bill increase is caused by higher usage, price changes, or billing errors.", "ancestors": ["[DEF] A bill is a statement of money owed for consumed commodities.", "[VAR] Let U denote the metered quantity consumed during the billing period.", "[VAR] Let P denote the unit price applied to U.", "[DEF] The billed charge B equals U multiplied by P.", "[CONSTRAINT] U is recorded by a measurement device with finite resolution.", "[CONSTRAINT] P is set by the supplier and may change between periods.", "[LIMIT] The measurement resolution sets a lower bound on detectable U change."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If U is below the measurement resolution, the recorded value is zero, so B = 0 regardless of P.  \nASSUMPTION: None  \nVERIFICATION: Units: U in resolution units, B in currency; test by injecting a consumption below resolution and observing B = 0.", "rejected": "If U is below the measurement resolution, the recorded value is zero, so B = P regardless of U.", "E_acc": 0.3319951295852661, "C_acc": 0.5235170125961304, "G_acc": 0.5295909932756331, "D_acc": 0.6729005146771669, "H_acc": 0.2216082215309143, "Q_acc": 0.5132326157938223, "E_rej": 0.23933829367160797, "C_rej": 0.3176768124103546, "G_rej": 0.5355832194521403, "D_rej": 0.7245291024446487, "H_rej": 0.27547089755535126, "Q_rej": 0.5327415002432342, "Delta_Q": -0.0195088844494119, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Judging whether a bottleneck will shift when capacity is increased in one part of a system.", "ancestors": ["[DEF] A bottleneck is the process step with the smallest capacity C_min.", "[VAR] Let C_i denote the capacity of process step i.", "[VAR] Let ΔC_j denote the capacity increment applied to step j.", "[LAW] After the increment, the new capacity of step j is C_j' = C_j + ΔC_j.", "[CONSTRAINT] The post-increment system capacity equals the minimum of all updated step capacities.", "[VAR] Let C_min' denote the minimum capacity after the increment.", "[LIMIT] C_min' = min({C_i | i≠j} ∪ {C_j'}).", "[LIMIT] If C_j' ≤ C_min, then C_min' = C_min.", "[LIMIT] If C_j' > C_min, then C_min' ≥ C_min."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If C_j' ≤ C_min, then the bottleneck remains step j and the system capacity is unchanged.\nASSUMPTION: None\nVERIFICATION: Follows directly from [LIMIT] C_min' = C_min when C_j' ≤ C_min and [DEF] bottleneck = C_min'.", "rejected": "If the bottleneck remains step j and the system capacity is unchanged, then C_j' ≤ C_min.", "E_acc": 0.42182010412216187, "C_acc": 0.3205287456512451, "G_acc": 0.5672105171252042, "D_acc": 0.6934441048651934, "H_acc": 0.10819634795188904, "Q_acc": 0.6037515717092902, "E_rej": 0.2798460125923157, "C_rej": 0.5326511859893799, "G_rej": 0.5690754841198213, "D_rej": 0.8718953430652618, "H_rej": 0.12810465693473816, "Q_rej": 0.5528072663233616, "Delta_Q": 0.050944305385928534, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "electric field", "ancestors": ["[DEF] The electric field E at a point is the vector force per unit test charge.", "[VAR] q denotes a source charge.", "[VAR] r denotes the vector from q to the field point.", "[VAR] ε₀ is the vacuum permittivity.", "[LAW] E = q r / (4π ε₀ |r|³).", "[VAR] ρ denotes volume charge density.", "[VAR] dV denotes an infinitesimal volume element.", "[CONSTRAINT] The total field is the vector sum over all source elements.", "[LIMIT] For |r| → ∞, |E| → 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any finite volume V enclosing a total charge Q=∫ρdV, the electric field magnitude at the surface of a sphere of radius R≥(3V/4π)^{1/3} centered on the charge centroid obeys |E|≤|Q|/(4πε₀R²).\nASSUMPTION: None\nVERIFICATION: Units C/m²·(C²/N·m²)⁻¹·m⁻²=N/C; valid for R larger than the charge distribution extent.", "rejected": "For any finite volume V enclosing a total charge Q=∫ρdV, the electric field magnitude at the surface of a sphere of radius R≤(3V/4π)^{1/3} centered on the charge centroid obeys |E|≤|Q|/(4πε₀R²).", "E_acc": 0.23570972681045532, "C_acc": 0.5528210401535034, "G_acc": 0.5252811487298459, "D_acc": 0.6427496076794341, "H_acc": 0.2016603648662567, "Q_acc": 0.4735888248076663, "E_rej": 0.4972081780433655, "C_rej": 0.16969452798366547, "G_rej": 0.5342731485143304, "D_rej": 0.8211653530597687, "H_rej": 0.17883464694023132, "Q_rej": 0.6684277834370732, "Delta_Q": -0.19483895862940692, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "electromagnetic spectrum", "ancestors": ["[DEF] The electromagnetic spectrum is the continuous range of all electromagnetic waves.", "[DEF] An electromagnetic wave consists of oscillating electric and magnetic fields.", "[DEF] Wavelength λ is the spatial period of the wave.", "[DEF] Frequency f is the temporal rate of field oscillation.", "[LAW] c = λ f.", "[VAR] c = 299792458 m s⁻¹.", "[DEF] Photon energy E = h f.", "[VAR] h = 6.62607015×10⁻³⁴ J s.", "[LIMIT] λ > 0.", "[CONSTRAINT] f = c / λ."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any electromagnetic wave, the photon energy E and wavelength λ satisfy E λ = h c.\nASSUMPTION: None\nVERIFICATION: Units: J m; regime: all λ > 0; testable via measuring E and λ.", "rejected": "For any electromagnetic wave, the photon energy E and wavelength λ satisfy E λ = h c including when λ = 0.", "E_acc": 0.209015354514122, "C_acc": 0.6011596322059631, "G_acc": 0.5715601337142289, "D_acc": 0.6267947336891666, "H_acc": 0.20837005972862244, "Q_acc": 0.46130664742086086, "E_rej": 0.4685911536216736, "C_rej": 0.27484795451164246, "G_rej": 0.5649668657279108, "D_rej": 0.8084736168384552, "H_rej": 0.1915263831615448, "Q_rej": 0.6411432133812923, "Delta_Q": -0.17983656596043146, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "molecular formula", "ancestors": ["[DEF] A molecular formula lists the types and counts of atoms in one molecule.", "[VAR] Let E be the set of chemical elements.", "[VAR] Let n: E → ℕ be the mapping giving the count of each element in the formula.", "[CONSTRAINT] For every e ∈ E, n(e) ≥ 0.", "[CONSTRAINT] There exists at least one e ∈ E such that n(e) > 0.", "[DEF] The molecular weight M is Σ_{e∈E} n(e) · A(e), where A(e) is the atomic weight of e.", "[LAW] A(e) is a constant for each e ∈ E.", "[LIMIT] M is finite.", "[LIMIT] The set {e ∈ E : n(e) > 0} is finite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The molecular weight M is strictly positive.\nASSUMPTION: None\nVERIFICATION: M = Σ n(e)·A(e) with n(e)≥0, A(e)>0, and at least one n(e)>0 ⇒ M>0.", "rejected": "STATUS: NOT ENTAILED.", "E_acc": 0.2012278139591217, "C_acc": 0.5376731157302856, "G_acc": 0.5071403797483072, "D_acc": 0.6517689758911729, "H_acc": 0.22407126426696777, "Q_acc": 0.46220846574287866, "E_rej": 0.6806398630142212, "C_rej": 0.1436319500207901, "G_rej": 0.5745645356364548, "D_rej": 0.5128726372495294, "H_rej": 0.48712736275047064, "Q_rej": 0.6442402672022581, "Delta_Q": -0.18203180145937947, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Doppler effect", "ancestors": ["[DEF] The Doppler effect is the frequency shift observed in a wave due to relative motion between source and observer.", "[VAR] Let f₀ denote the emitted frequency of the source.", "[VAR] Let f denote the observed frequency.", "[VAR] Let v denote the wave propagation speed in the medium.", "[VAR] Let vₛ denote the speed of the source relative to the medium.", "[VAR] Let vₒ denote the speed of the observer relative to the medium.", "[LAW] f = f₀ (v ± vₒ)/(v ∓ vₛ) where the upper signs apply for approaching and the lower for receding motions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the source and observer are mutually approaching, the observed frequency f exceeds the emitted frequency f₀.\nASSUMPTION: None\nVERIFICATION: Units dimensionless ratio >1; testable by measuring f and f₀ in any medium with known v.", "rejected": "If the source and observer are mutually approaching, the observed frequency f is independent of the emitted frequency f₀.", "E_acc": 0.11926789581775665, "C_acc": 0.6624149680137634, "G_acc": 0.5467458258693417, "D_acc": 0.6183728633914143, "H_acc": 0.25088074803352356, "Q_acc": 0.41123303819137313, "E_rej": 0.1160680428147316, "C_rej": 0.6702437400817871, "G_rej": 0.5463171983137727, "D_rej": 0.7800276875495911, "H_rej": 0.21997231245040894, "Q_rej": 0.4440434107556939, "Delta_Q": -0.03281037256432079, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "2D system math", "ancestors": ["[DEF] A 2D system is a set S ⊆ ℝ².", "[VAR] Let x ∈ S denote a point.", "[VAR] Let t ∈ ℝ denote a scalar parameter.", "[DEF] A 2D vector v is an element of ℝ².", "[DEF] The norm ‖v‖ equals √(v₁² + v₂²).", "[LAW] For vectors a, b ∈ ℝ², a + b = (a₁ + b₁, a₂ + b₂).", "[LAW] For scalar k ∈ ℝ and vector v ∈ ℝ², k v = (k v₁, k v₂).", "[CONSTRAINT] A path is a continuous map p: [t₀, t₁] → S.", "[VAR] Let p(t) = (x(t), y(t)) with x, y: [t₀, t₁] → ℝ.", "[LIMIT] lim_{t→t*} p(t) = (lim_{t→t*} x(t), lim_{t→t*} y(t)) if both limits exist."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If p is continuous at t*, then lim_{t→t*} p(t) = p(t*).\nASSUMPTION: None\nVERIFICATION: Units: ℝ²-valued limit identity; regime: t* ∈ [t₀, t₁].", "rejected": "If p is continuous at t*, then lim_{t→t*} p(t) = –p(t*).", "E_acc": 0.31285202503204346, "C_acc": 0.45936110615730286, "G_acc": 0.5158615080872551, "D_acc": 0.6158772967755795, "H_acc": 0.2953624725341797, "Q_acc": 0.4987948999973014, "E_rej": 0.34268513321876526, "C_rej": 0.369407594203949, "G_rej": 0.5131408668821678, "D_rej": 0.6608180850744247, "H_rej": 0.33918191492557526, "Q_rej": 0.5297976200236008, "Delta_Q": -0.031002720026299335, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "food webs", "ancestors": ["[DEF] A food web is a directed graph whose vertices are species and whose arcs represent trophic interactions.", "[VAR] Let S denote the set of species in a food web.", "[VAR] Let A ⊂ S × S denote the set of arcs such that (s₁, s₂) ∈ A signifies that species s₁ consumes species s₂.", "[DEF] Basal species B ⊂ S satisfy ∀s ∈ B, ∄s′ ∈ S : (s′, s) ∈ A.", "[DEF] Top species T ⊂ S satisfy ∀s ∈ T, ∄s′ ∈ S : (s, s′) ∈ A.", "[CONSTRAINT] ∀s ∈ S \\ B, ∃s′ ∈ S : (s′, s) ∈ A.", "[CONSTRAINT] ∀s ∈ S \\ T, ∃s′ ∈ S : (s, s′) ∈ A.", "[LIMIT] |B| ≥ 1 ∧ |T| ≥ 1."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Every non-basal species is consumed by at least one other species, and every non-top species consumes at least one other species.\nASSUMPTION: None\nVERIFICATION: Direct restatement of CONSTRAINT lines with variables from premises; no units needed.", "rejected": "Every non-basal species is consumed by at most one other species, and every non-top species consumes at least one other species.", "E_acc": 0.14658895134925842, "C_acc": 0.7054619789123535, "G_acc": 0.5639868099242449, "D_acc": 0.6356015391647816, "H_acc": 0.22677016258239746, "Q_acc": 0.42012494318187243, "E_rej": 0.40293675661087036, "C_rej": 0.502874493598938, "G_rej": 0.5459678046671408, "D_rej": 0.7482382357120514, "H_rej": 0.2517617642879486, "Q_rej": 0.553971159910517, "Delta_Q": -0.1338462167286446, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "earthquakes", "ancestors": ["[DEF] An earthquake is the sudden release of energy in the Earth's lithosphere.", "[VAR] Let M denote the moment magnitude of an earthquake.", "[VAR] Let t₀ denote the rupture initiation time.", "[VAR] Let Δt denote the rupture duration.", "[VAR] Let A denote the rupture area.", "[VAR] Let D̄ denote the average slip on A.", "[LAW] M = (2/3) log₁₀(μ A D̄) − 6.07, where μ is the shear modulus.", "[CONSTRAINT] M ≥ 2.5 for events catalogued by the International Seismological Centre.", "[LIMIT] Δt ≤ 2(M − 1) seconds for crustal events."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any catalogued crustal earthquake, the rupture duration satisfies Δt ≤ 2((2/3) log₁₀(μ A D̄) − 7.57) seconds.\nASSUMPTION: None\nVERIFICATION: Units: seconds; regime M ≥ 2.5; testable via recorded Δt, inferred A, D̄, μ.", "rejected": "For any catalogued crustal earthquake, the rupture duration Δt is independent of the moment magnitude M.", "E_acc": 0.20255549252033234, "C_acc": 0.6249123811721802, "G_acc": 0.5271213803207502, "D_acc": 0.6528991973027587, "H_acc": 0.13005176186561584, "Q_acc": 0.4587831108598039, "E_rej": 0.19523906707763672, "C_rej": 0.47525322437286377, "G_rej": 0.5326911264564842, "D_rej": 0.8785474002361298, "H_rej": 0.12145259976387024, "Q_rej": 0.533623520610854, "Delta_Q": -0.07484040975105016, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "DNA", "ancestors": ["[DEF] DNA is a double-stranded polymer of nucleotides.", "[DEF] A nucleotide comprises a phosphate, a deoxyribose, and a nitrogenous base.", "[DEF] The nitrogenous bases are adenine, guanine, cytosine, and thymine.", "[LAW] Adenine pairs with thymine via two hydrogen bonds.", "[LAW] Guanine pairs with cytosine via three hydrogen bonds.", "[CONSTRAINT] In a DNA duplex, the total number of adenine bases equals the total number of thymine bases.", "[LIMIT] The melting temperature Tm of a DNA duplex increases linearly with the fraction of guanine-cytosine pairs."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION  \nHYPOTHESIS: For any DNA duplex, the fraction of guanine-cytosine pairs equals (3G – C)/(3G + 2C), where G and C are the counts of guanine and cytosine bases.  \nASSUMPTION: The duplex is fully base-paired with no mismatches or overhangs.  \nVERIFICATION: Unitless fraction, valid for 0 ≤ G = C ≤ total bases.", "rejected": "STATUS: ENTAILED_WITH_ASSUMPTION.", "E_acc": 0.3432902991771698, "C_acc": 0.35336869955062866, "G_acc": 0.5622199199351599, "D_acc": 0.6566858296282589, "H_acc": 0.198268860578537, "Q_acc": 0.5562676136978553, "E_rej": 0.4327771067619324, "C_rej": 0.24937888979911804, "G_rej": 0.5492651911335997, "D_rej": 0.49796405993402004, "H_rej": 0.50203594006598, "Q_rej": 0.5391996102756821, "Delta_Q": 0.017068003422173184, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "measurement accuracy", "ancestors": ["[DEF] Measurement accuracy is the closeness of agreement between a measured quantity value and a reference quantity value.", "[VAR] Let ε denote the measurement error.", "[VAR] Let x denote the measured value.", "[VAR] Let x_ref denote the reference value.", "[LAW] ε = x − x_ref.", "[DEF] The absolute accuracy is |ε|.", "[CONSTRAINT] |ε| ≥ 0.", "[LIMIT] The smallest resolvable |ε| is the resolution of the instrument.", "[LIMIT] The limit on |ε| imposed by the instrument resolution is |ε| ≥ resolution/2."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any measured value x, the absolute accuracy |ε| cannot be smaller than half the instrument’s resolution.\nASSUMPTION: None\nVERIFICATION: Units: same as resolution; regime: all x; testable by checking if |x − x_ref| ≥ resolution/2.", "rejected": "For any measured value x, the absolute accuracy |ε| cannot be smaller than half the instrument’s resolution squared.", "E_acc": 0.17810209095478058, "C_acc": 0.6519984602928162, "G_acc": 0.56133075064281, "D_acc": 0.7010365230962634, "H_acc": 0.12799003720283508, "Q_acc": 0.46270538625540214, "E_rej": 0.31884124875068665, "C_rej": 0.39712461829185486, "G_rej": 0.5430674707167782, "D_rej": 0.8820595145225525, "H_rej": 0.11794048547744751, "Q_rej": 0.5894587994669565, "Delta_Q": -0.1267534132115543, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "interference", "ancestors": ["[DEF] Interference is the superposition of two or more waves.", "[VAR] Let A₁, A₂ denote the amplitudes of two coherent waves.", "[VAR] Let Δφ denote their phase difference.", "[DEF] The resultant amplitude A is given by A = √(A₁² + A₂² + 2A₁A₂ cos Δφ).", "[LAW] The intensity I is proportional to the square of the amplitude, I ∝ A².", "[CONSTRAINT] For maximum interference, Δφ = 2πm with integer m.", "[LIMIT] Complete destructive interference occurs when A₁ = A₂ and Δφ = π."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If A₁ = A₂ and Δφ = π, then the resultant amplitude A = 0.\nASSUMPTION: None\nVERIFICATION: Substitute A₁ = A₂ and Δφ = π into A = √(A₁² + A₂² + 2A₁A₂ cos Δφ) → A = √(2A₁² - 2A₁²) = 0.", "rejected": "If A₁ = A₂ and Δφ = π, then the resultant amplitude A = √(2A₁² + 2A₁²).", "E_acc": 0.17714247107505798, "C_acc": 0.646436333656311, "G_acc": 0.5417138711782172, "D_acc": 0.6349984291009605, "H_acc": 0.27191346883773804, "Q_acc": 0.43200658776331696, "E_rej": 0.5457940101623535, "C_rej": 0.30919674038887024, "G_rej": 0.5473847879329696, "D_rej": 0.7613917887210846, "H_rej": 0.2386082112789154, "Q_rej": 0.6397933491738512, "Delta_Q": -0.20778676141053426, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "latent heat", "ancestors": ["[DEF] Latent heat is the energy absorbed or released during a phase change at constant temperature.", "[VAR] Let L denote specific latent heat with unit J kg⁻¹.", "[VAR] Let m denote mass with unit kg.", "[VAR] Let Q denote thermal energy with unit J.", "[LAW] Q = m L.", "[CONSTRAINT] During the phase change, temperature remains constant.", "[LIMIT] L is finite and positive for every substance.", "[DEF] The triple-point temperature is the unique temperature at which solid, liquid, and vapor phases coexist in equilibrium.", "[CONSTRAINT] At the triple-point temperature, distinct values Lₛₗ, Lₗᵥ, Lₛᵥ apply for solid–liquid, liquid–vapor, and solid–vapor transitions.", "[LIMIT] Each L value is fixed for a given substance at its triple-point temperature."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any mass m undergoing a phase change at constant temperature, the required thermal energy Q is directly proportional to m with proportionality constant L.\nASSUMPTION: None\nVERIFICATION: Units: Q(J)=m(kg)·L(J kg⁻¹) ⇒ J=kg·J kg⁻¹, valid for any phase change described by the premises.", "rejected": "For any mass m undergoing a phase change at constant temperature, the required thermal energy Q is inversely proportional to m with proportionality constant L.", "E_acc": 0.4671102464199066, "C_acc": 0.2124478965997696, "G_acc": 0.514742477069376, "D_acc": 0.6225675891619176, "H_acc": 0.2710704207420349, "Q_acc": 0.5979984657780734, "E_rej": 0.4093805253505707, "C_rej": 0.23470726609230042, "G_rej": 0.5148249815683812, "D_rej": 0.7464938014745712, "H_rej": 0.25350619852542877, "Q_rej": 0.6027858411427588, "Delta_Q": -0.004787375364685431, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "photoelectric effect", "ancestors": ["[DEF] The photoelectric effect is the emission of electrons from a material when it absorbs electromagnetic radiation.", "[VAR] Let ν denote the frequency of the incident electromagnetic radiation.", "[VAR] Let W denote the work function of the material.", "[LAW] The maximum kinetic energy K_max of emitted electrons is given by K_max = hν − W, where h is Planck’s constant.", "[CONSTRAINT] Electron emission occurs only if hν ≥ W.", "[LIMIT] The photoelectric current is directly proportional to the radiation intensity for fixed ν above the threshold.", "[LIMIT] The stopping potential V_s satisfies e V_s = K_max, where e is the elementary charge."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The stopping potential V_s is given by V_s = (hν − W)/e and is non-negative only when hν ≥ W.\nASSUMPTION: None\nVERIFICATION: Units: V_s in volts, hν and W in eV or J with e in C; valid for ν above threshold.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.18290847539901733, "C_acc": 0.652297854423523, "G_acc": 0.5668238321086392, "D_acc": 0.5878356606699526, "H_acc": 0.3169851750135422, "Q_acc": 0.4236463527893648, "E_rej": 0.17275768518447876, "C_rej": 0.6086262464523315, "G_rej": 0.5799391926266253, "D_rej": 0.498771995306015, "H_rej": 0.501228004693985, "Q_rej": 0.3957214933820069, "Delta_Q": 0.027924859407357894, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "gamma rays", "ancestors": ["[DEF] Gamma rays are electromagnetic radiation with photon energy E > 100 keV.", "[VAR] E denotes photon energy.", "[VAR] λ denotes wavelength.", "[LAW] E = hc/λ.", "[CONSTRAINT] λ < 1.24×10⁻¹¹ m for gamma rays.", "[LIMIT] Human tissue attenuation length L ≈ 0.1 m at E = 1 MeV.", "[VAR] L denotes attenuation length.", "[CONSTRAINT] L ∝ E⁻³/² for 0.1 MeV < E < 10 MeV.", "[LIMIT] Maximum measured gamma-ray photon energy E_max ≈ 1×10²⁰ eV."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For gamma rays with E > 1 MeV, the human-tissue attenuation length satisfies L < 0.1 m.\nASSUMPTION: None\nVERIFICATION: Follows from L ∝ E⁻³/² and the given 1 MeV datum; units consistent (m).", "rejected": "For gamma rays with E > 1 MeV, the human-tissue attenuation length satisfies L ∝ E⁻³/².", "E_acc": 0.28518977761268616, "C_acc": 0.5500531196594238, "G_acc": 0.5593905117129907, "D_acc": 0.6516674319282174, "H_acc": 0.12198042869567871, "Q_acc": 0.5055598552105949, "E_rej": 0.5901029706001282, "C_rej": 0.2557781934738159, "G_rej": 0.5717130100820214, "D_rej": 0.9040647149085999, "H_rej": 0.09593528509140015, "Q_rej": 0.7114372689742595, "Delta_Q": -0.20587741376366464, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "transverse waves", "ancestors": ["[DEF] A transverse wave is a propagating disturbance in which the oscillation is perpendicular to the direction of energy transport.", "[VAR] Let λ denote the spatial period of the wave.", "[VAR] Let f denote the temporal frequency of the wave.", "[VAR] Let v denote the propagation speed of the wave.", "[LAW] v = λ f.", "[CONSTRAINT] The medium displacement is orthogonal to the propagation vector.", "[LIMIT] In a vacuum, electromagnetic transverse waves propagate at c = 299792458 m s⁻¹."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any transverse wave in vacuum, the product λ f equals 299792458 m s⁻¹.\nASSUMPTION: None\nVERIFICATION: Units: m s⁻¹; regime: vacuum; testable by measuring λ and f.", "rejected": "For any transverse wave in vacuum, the product λ f² equals 299792458 m s⁻¹.", "E_acc": 0.35053375363349915, "C_acc": 0.37839949131011963, "G_acc": 0.5327052796492353, "D_acc": 0.6166977687971666, "H_acc": 0.23458436131477356, "Q_acc": 0.5359024013858289, "E_rej": 0.4506007432937622, "C_rej": 0.1838187277317047, "G_rej": 0.5372134257340804, "D_rej": 0.7790283262729645, "H_rej": 0.22097167372703552, "Q_rej": 0.6395676604704932, "Delta_Q": -0.10366525908466429, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "carrying capacity", "ancestors": ["[DEF] Carrying capacity K is the maximum population size that an environment can sustain indefinitely.", "[VAR] Let N denote the population size at time t.", "[VAR] Let r denote the intrinsic per-capita growth rate.", "[LAW] The logistic growth equation is dN/dt = rN(1 − N/K).", "[CONSTRAINT] N ≤ K for all t ≥ 0.", "[LIMIT] As t → ∞, N → K if 0 < N(0) < K.", "[VAR] Let B be the per-capita birth rate and D the per-capita death rate.", "[LAW] r = B − D.", "[CONSTRAINT] K is constant when B and D are constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If B increases while D remains fixed, K remains constant and r increases, so the logistic equation predicts faster convergence of N toward the unchanged K.\nASSUMPTION: None\nVERIFICATION: Units: r [1/time], B,D [1/time]; validity follows from r = B − D and the constant-K constraint.", "rejected": "HYPOTHESIS: If B increases while D remains fixed, K increases with B and r increases, so the logistic equation predicts faster convergence of N toward the higher K.", "E_acc": 0.08344579488039017, "C_acc": 0.6440159678459167, "G_acc": 0.5234893558954354, "D_acc": 0.6356191621161997, "H_acc": 0.20380163192749023, "Q_acc": 0.40767208530451177, "E_rej": 0.03651948273181915, "C_rej": 0.15729470551013947, "G_rej": 0.5206901287310757, "D_rej": 0.7622590959072113, "H_rej": 0.2377409040927887, "Q_rej": 0.5123126582358964, "Delta_Q": -0.10464057293138468, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "potential energy", "ancestors": ["[DEF] Potential energy is energy stored in a field or configuration.", "[VAR] Let U denote potential energy.", "[VAR] Let F denote a conservative force.", "[DEF] A conservative force satisfies ∮F·dr = 0.", "[LAW] ΔU = −∫F·dr.", "[VAR] Let g denote gravitational field magnitude near Earth.", "[CONSTRAINT] Near Earth F = mg.", "[LIMIT] For constant g, ΔU = mgΔh.", "[VAR] Let k denote spring constant.", "[LIMIT] For ideal spring, U = ½kx²."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any vertical displacement Δh near Earth, the change in gravitational potential energy is ΔU = mgΔh, independent of path taken between the two heights.\nASSUMPTION: None\nVERIFICATION: Units: [ΔU] = kg·m·s⁻²·m = J; valid for constant g near Earth's surface.", "rejected": "For any vertical displacement Δh near Earth, the change in gravitational potential energy is ΔU = −mgΔh, independent of path taken between the two heights.", "E_acc": 0.13200950622558594, "C_acc": 0.6835883259773254, "G_acc": 0.5591653294395655, "D_acc": 0.6171903132926673, "H_acc": 0.20893272757530212, "Q_acc": 0.4172630424611271, "E_rej": 0.1472271978855133, "C_rej": 0.4703652262687683, "G_rej": 0.559560683905147, "D_rej": 0.804116815328598, "H_rej": 0.19588318467140198, "Q_rej": 0.5032422954915092, "Delta_Q": -0.08597925303038212, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "electric potential", "ancestors": ["[DEF] Electric potential V at a point is the work W done per unit charge q to bring a test charge from infinity to that point without acceleration.", "[VAR] V = W/q.", "[LAW] The electric potential due to a point charge Q at distance r is V = kQ/r with k = 1/(4πε₀).", "[VAR] ε₀ is the vacuum permittivity.", "[DEF] The potential difference ΔV between two points is ΔV = V₂ − V₁.", "[VAR] ΔV = −∫ E·dl between the points.", "[LAW] In a region with electric field E the potential satisfies E = −∇V.", "[CONSTRAINT] The potential V is continuous across a boundary free of surface dipoles.", "[LIMIT] As r → ∞ the potential V of a finite charge distribution tends to 0.", "[DEF] Equipotential surfaces are sets of points where V is constant."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any equipotential surface enclosing a net charge Q, the potential V on that surface satisfies V = kQ/r_enclosed with r_enclosed the minimum enclosing radius, so V > 0 if Q > 0 and V < 0 if Q < 0.\nASSUMPTION: None\nVERIFICATION: Units: V in volts, Q in coulombs, r_enclosed in metres; testable by measuring V on any enclosing surface and comparing to kQ/r_enclosed.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.4300764203071594, "C_acc": 0.24960856139659882, "G_acc": 0.5384487868286669, "D_acc": 0.6581190428696573, "H_acc": 0.1687576174736023, "Q_acc": 0.6015390180051328, "E_rej": 0.30829569697380066, "C_rej": 0.2921154499053955, "G_rej": 0.5903360373340547, "D_rej": 0.5159244015812874, "H_rej": 0.4840755984187126, "Q_rej": 0.5069101470522582, "Delta_Q": 0.09462887095287453, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "collision theory", "ancestors": ["[DEF] A collision is an event in which two particles interact through forces over a short time interval.", "[VAR] Let v_rel denote the relative speed between two particles before collision.", "[VAR] Let b denote the impact parameter, the perpendicular distance between the initial trajectories of the centers of the particles.", "[VAR] Let σ denote the collision cross section.", "[DEF] The collision cross section σ is the effective area that determines whether a collision occurs.", "[LAW] The differential collision cross section dσ/dΩ equals b |db/dΩ| / sinθ.", "[CONSTRAINT] A collision occurs only if b ≤ r₁ + r₂, where r₁ and r₂ are the radii of the particles.", "[LIMIT] The total cross section σ_tot is the integral of dσ/dΩ over all solid angles.", "[LIMIT] In the hard-sphere model, σ_tot = π(r₁ + r₂)²."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: If b > r₁ + r₂, no collision occurs, so the effective collision cross section σ for this encounter is zero.  \nASSUMPTION: None  \nVERIFICATION: Units: b and r₁, r₂ are lengths; condition b > r₁ + r₂ implies σ = 0 by the CONSTRAINT premise.", "rejected": "If no collision occurs, then b > r₁ + r₂, so the effective collision cross section σ for this encounter is zero.", "E_acc": 0.09562389552593231, "C_acc": 0.26132145524024963, "G_acc": 0.5258045516675338, "D_acc": 0.6099307262338698, "H_acc": 0.2436462938785553, "Q_acc": 0.479205303802155, "E_rej": 0.017790814861655235, "C_rej": 0.09414198249578476, "G_rej": 0.5295432910788804, "D_rej": 0.7701016664505005, "H_rej": 0.2298983335494995, "Q_rej": 0.5234480061102659, "Delta_Q": -0.04424270230811089, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "orbits", "ancestors": ["[DEF] An orbit is the closed path of a body under a central gravitational acceleration.", "[VAR] Let r denote the instantaneous radius vector from the central mass M to the orbiting body m.", "[VAR] Let v denote the instantaneous velocity vector of m relative to M.", "[LAW] The specific relative angular momentum h = r × v is constant.", "[LAW] The specific mechanical energy ε = v²∕2 − μ∕r is constant, where μ = GM.", "[CONSTRAINT] For an elliptical orbit ε < 0.", "[LIMIT] The periapsis radius is r_p = h²∕[μ(1+e)] with e = √(1+2εh²∕μ²)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any elliptical orbit the periapsis radius satisfies r_p < h²/μ.\nASSUMPTION: None\nVERIFICATION: Units: length; regime ε<0; testable via r_p = h²/[μ(1+e)] with e>0.", "rejected": "For any hyperbolic orbit the periapsis radius satisfies r_p < h²/μ.", "E_acc": 0.25322797894477844, "C_acc": 0.6256505250930786, "G_acc": 0.5090042806696147, "D_acc": 0.6345385794702452, "H_acc": 0.14805448055267334, "Q_acc": 0.46474141263752244, "E_rej": 0.05722673609852791, "C_rej": 0.8154016733169556, "G_rej": 0.5078136631054804, "D_rej": 0.822107344865799, "H_rej": 0.17789265513420105, "Q_rej": 0.40228262224700306, "Delta_Q": 0.06245879039051938, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "combustion reactions", "ancestors": ["[DEF] Combustion is a high-temperature exothermic redox reaction between a fuel and an oxidant.", "[DEF] A fuel is a substance capable of releasing energy upon oxidation.", "[DEF] An oxidant is a substance that accepts electrons in a redox reaction.", "[VAR] Let O₂ denote dioxygen, the common oxidant in combustion.", "[VAR] Let CₓHᵧ denote a hydrocarbon fuel with x carbon atoms and y hydrogen atoms.", "[LAW] In complete combustion, all carbon converts to CO₂ and all hydrogen converts to H₂O.", "[CONSTRAINT] Conservation of mass requires that the number of atoms of each element is equal on both sides of the reaction equation.", "[CONSTRAINT] Conservation of energy requires that the enthalpy change of reaction equals the sum of enthalpies of formation of products minus reactants.", "[LIMIT] Complete combustion occurs only when the oxidant supply is stoichiometric or greater.", "[LIMIT] Incomplete combustion produces CO, C, or both when O₂ is deficient."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For complete combustion of CₓHᵧ, the required O₂ molecules equal x + y/4; any lesser amount forces incomplete combustion yielding CO or C.\nASSUMPTION: None\nVERIFICATION: Balanced equation CₓHᵧ + (x + y/4)O₂ → xCO₂ + (y/2)H₂O conserves atoms; deviation from this stoichiometric ratio is measurable via exhaust gas composition.", "rejected": "For complete combustion of CₓHᵧ, the required O₂ molecules equal x + y; any lesser amount forces incomplete combustion yielding CO or C.", "E_acc": 0.418211966753006, "C_acc": 0.2567119300365448, "G_acc": 0.5591290093725547, "D_acc": 0.653154841857031, "H_acc": 0.2549336105585098, "Q_acc": 0.591084613208659, "E_rej": 0.3823097348213196, "C_rej": 0.2607038617134094, "G_rej": 0.5717065394856036, "D_rej": 0.8118955790996552, "H_rej": 0.23513052612543106, "Q_rej": 0.6157595192082226, "Delta_Q": -0.024674905999563568, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "echo", "ancestors": ["[DEF] Echo is a reflected sound wave.", "[VAR] Let c denote the speed of sound in the medium.", "[VAR] Let t be the time interval between emission and reception of the echo.", "[LAW] The distance d to the reflecting surface satisfies d = c t / 2.", "[CONSTRAINT] c depends on the medium’s temperature and composition.", "[LIMIT] The minimum measurable t is limited by the detector’s temporal resolution.", "[LIMIT] The maximum useful d is bounded by the medium’s attenuation length."]}, "accepted": "STATUS: ENTAILED_WITH_ASSUMPTION\nHYPOTHESIS: The measurable distance range is bounded below by c t_min / 2 and above by the attenuation length L_atten.\nASSUMPTION: The detector’s temporal resolution sets a fixed minimum t_min.\nVERIFICATION: Units: metres; valid when t_min > 0 and L_atten > c t_min / 2.", "rejected": "The measurable distance range is bounded below by c t_min / 2 and above by the attenuation length L_atten, assuming c is independent of the medium’s temperature and composition.", "E_acc": 0.370319664478302, "C_acc": 0.17094334959983826, "G_acc": 0.5261430694372393, "D_acc": 0.6766614504158497, "H_acc": 0.26080551743507385, "Q_acc": 0.5913875816506334, "E_rej": 0.17713139951229095, "C_rej": 0.5683936476707458, "G_rej": 0.5188000533817103, "D_rej": 0.7482866197824478, "H_rej": 0.2517133802175522, "Q_rej": 0.4677066869306145, "Delta_Q": 0.12368089472001892, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "metalloids", "ancestors": ["[DEF] A metalloid is an element whose properties are intermediate between metals and nonmetals.", "[VAR] Let B be the set of elements commonly recognized as metalloids.", "[VAR] Let R be the set of elements in the periodic table.", "[CONSTRAINT] B is a proper subset of R.", "[LIMIT] The number of elements in B is less than 10.", "[LAW] Every element in B exhibits semiconductor behavior under standard conditions.", "[LIMIT] No element in B has a full outer electron shell."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Every element in B is a semiconductor under standard conditions.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "Every element in B is a conductor under standard conditions.", "E_acc": 0.12623350322246552, "C_acc": 0.7551382184028625, "G_acc": 0.5183962808223441, "D_acc": 0.588596248999238, "H_acc": 0.30487655103206635, "Q_acc": 0.37775325814727695, "E_rej": 0.22991986572742462, "C_rej": 0.24618883430957794, "G_rej": 0.514529705629684, "D_rej": 0.6932292580604553, "H_rej": 0.3067707419395447, "Q_rej": 0.5306129114003851, "Delta_Q": -0.15285965325310819, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "transformers", "ancestors": ["[DEF] A transformer is a neural-network architecture that maps an input sequence to an output sequence without recurrence or convolution.", "[VAR] Let d denote the fixed dimension of every vector representation in the model.", "[VAR] Let n denote the length of an input sequence of vectors X = (x₁, …, xₙ) with each xᵢ ∈ ℝᵈ.", "[VAR] Let Q, K, V ∈ ℝⁿˣᵈ denote the query, key, and value matrices obtained by linear projection of X.", "[LAW] The scaled dot-product attention computes A = softmax(QKᵀ/√d)V.", "[CONSTRAINT] The softmax operation is applied row-wise to QKᵀ/√d ∈ ℝⁿˣⁿ.", "[LIMIT] The memory complexity of storing QKᵀ is Θ(n²d)."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If n > √d, the memory required to store QKᵀ exceeds Θ(d²) and grows quadratically with sequence length.\nASSUMPTION: None\nVERIFICATION: Units: memory in scalar elements; regime n > √d; testable by counting n² entries.", "rejected": "If n > √d, the memory required to store QKᵀ exceeds Θ(n²) and grows quadratically with sequence length.", "E_acc": 0.25181844830513, "C_acc": 0.39482906460762024, "G_acc": 0.5506358582642861, "D_acc": 0.6228689427953213, "H_acc": 0.2669921964406967, "Q_acc": 0.5045814621378668, "E_rej": 0.1693556159734726, "C_rej": 0.5285354852676392, "G_rej": 0.5550976394297322, "D_rej": 0.7424603253602982, "H_rej": 0.25753967463970184, "Q_rej": 0.4788572132325498, "Delta_Q": 0.025724248905316993, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "nonpolar bonds", "ancestors": ["[DEF] A nonpolar covalent bond is a covalent bond in which electrons are shared equally between the two bonded atoms.", "[VAR] Let ΔEN denote the absolute difference in electronegativity between the two bonded atoms.", "[CONSTRAINT] ΔEN = 0 for a nonpolar covalent bond.", "[DEF] A nonpolar bond is either a nonpolar covalent bond or a bond between two identical atoms.", "[LIMIT] Only atoms of the same element can form a nonpolar bond with ΔEN = 0.", "[DEF] Let B be the set of nonpolar bonds; B = {b | b is a nonpolar bond}.", "[VAR] |B| ≥ 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If a bond has ΔEN > 0, it cannot be a nonpolar covalent bond.\nASSUMPTION: None\nVERIFICATION: Follows directly from CONSTRAINT ΔEN = 0 for nonpolar covalent bonds; units dimensionless.", "rejected": "If a bond cannot be a nonpolar covalent bond, it has ΔEN > 0.", "E_acc": 0.16992750763893127, "C_acc": 0.6166284084320068, "G_acc": 0.503784626464559, "D_acc": 0.687738009961322, "H_acc": 0.14921048283576965, "Q_acc": 0.45103604960687727, "E_rej": 0.11614316701889038, "C_rej": 0.6187882423400879, "G_rej": 0.5097359445395081, "D_rej": 0.8789276480674744, "H_rej": 0.12107235193252563, "Q_rej": 0.47671078496579355, "Delta_Q": -0.02567473535891629, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "synthesis reactions", "ancestors": ["[DEF] A synthesis reaction combines two or more reactants into a single product.", "[VAR] Let R denote the set of reactants.", "[VAR] Let P denote the single product.", "[LAW] Mass is conserved: Σm_R = m_P.", "[CONSTRAINT] |R| ≥ 2.", "[LIMIT] The reaction ceases when at least one reactant is exhausted.", "[VAR] Let c_R_i be the molar concentration of reactant i.", "[CONSTRAINT] c_R_i > 0 for all i ∈ R.", "[LIMIT] The rate of product formation is zero if any c_R_i = 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The reaction rate must be zero whenever the total mass of reactants equals the mass of the product, because at least one reactant has been exhausted.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The reaction rate must be zero whenever the total mass of reactants equals the mass of the product, because at least one reactant has been exhausted even when all concentrations are positive.", "E_acc": 0.32463493943214417, "C_acc": 0.451756089925766, "G_acc": 0.5492045114515349, "D_acc": 0.6184832607395947, "H_acc": 0.254606232047081, "Q_acc": 0.5151161950780079, "E_rej": 0.10351094603538513, "C_rej": 0.5540940165519714, "G_rej": 0.5337456634733826, "D_rej": 0.837484747171402, "H_rej": 0.20314406603574753, "Q_rej": 0.4741661560256034, "Delta_Q": 0.04095003905240446, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "half-life", "ancestors": ["[DEF] The half-life t½ is the time required for one-half of the radioactive nuclei present to decay.", "[VAR] Let N(t) denote the number of radioactive nuclei at time t.", "[VAR] Let N₀ denote the initial number of radioactive nuclei at t = 0.", "[LAW] The radioactive decay law states N(t) = N₀ e^(−λt) with decay constant λ > 0.", "[CONSTRAINT] By definition, N(t½) = N₀/2.", "[LIMIT] As t → ∞, N(t) → 0.", "[VAR] The decay constant λ and half-life t½ satisfy λt½ = ln 2.", "[VAR] The activity A(t) = λN(t).", "[CONSTRAINT] The half-life t½ depends only on the nuclide, not on N₀ or t."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any two samples of the same nuclide, their half-lives are equal regardless of their initial numbers of nuclei.\nASSUMPTION: None\nVERIFICATION: Follows directly from the premise that t½ depends only on the nuclide.", "rejected": "For any two samples of the same nuclide, their half-lives are equal to the sum of their initial numbers of nuclei.", "E_acc": 0.24877609312534332, "C_acc": 0.5481098294258118, "G_acc": 0.524115138920024, "D_acc": 0.6773487506434321, "H_acc": 0.17115619778633118, "Q_acc": 0.48818802018649876, "E_rej": 0.07013773918151855, "C_rej": 0.771763026714325, "G_rej": 0.5100510032498278, "D_rej": 0.8410349190235138, "H_rej": 0.1589650809764862, "Q_rej": 0.4210093927686103, "Delta_Q": 0.06717862741788844, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "intermolecular forces", "ancestors": ["[DEF] Intermolecular forces are forces between molecules.", "[DEF] An ion-dipole force is the attraction between an ion and a polar molecule.", "[DEF] A dipole-dipole force is the electrostatic attraction between two polar molecules.", "[DEF] A hydrogen bond is a dipole-dipole force between H bonded to N, O, or F and a lone pair on N, O, or F.", "[DEF] London dispersion forces are instantaneous dipole-induced dipole attractions present in all molecules.", "[VAR] Let ε denote the potential energy minimum of an intermolecular pair potential.", "[VAR] Let r denote the separation between molecular centers.", "[LAW] The Lennard-Jones potential is U(r) = 4ε[(σ/r)^12 − (σ/r)^6].", "[CONSTRAINT] σ is the finite separation at which U(r) = 0.", "[LIMIT] London dispersion energy scales as −C/r^6 for large r."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any two molecules whose interaction is described by the Lennard-Jones potential, the separation r = σ is the unique positive root at which the potential energy U(r) equals zero.\nASSUMPTION: None\nVERIFICATION: Units: σ in length units, U(r) in energy units; test by solving U(r)=0.", "rejected": "For any two molecules whose interaction is described by the Lennard-Jones potential, the separation r = σ is the unique positive root at which the potential energy U(r) equals ε.", "E_acc": 0.26701754331588745, "C_acc": 0.4553014636039734, "G_acc": 0.5402822757605463, "D_acc": 0.6149472332326695, "H_acc": 0.18275734782218933, "Q_acc": 0.5018151372903958, "E_rej": 0.10234308242797852, "C_rej": 0.7355301976203918, "G_rej": 0.542342234402895, "D_rej": 0.8495604395866394, "H_rej": 0.1504395604133606, "Q_rej": 0.44693346396088607, "Delta_Q": 0.05488167332950977, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "electron configuration", "ancestors": ["[DEF] The electron configuration of an atom lists the occupation of its orbitals.", "[VAR] Let n denote the principal quantum number, n ∈ ℕ, n ≥ 1.", "[VAR] Let l denote the orbital angular momentum quantum number, l ∈ ℕ, 0 ≤ l ≤ n−1.", "[VAR] Let m_l denote the magnetic quantum number, m_l ∈ ℤ, −l ≤ m_l ≤ l.", "[CONSTRAINT] An orbital identified by (n, l, m_l) holds at most two electrons.", "[CONSTRAINT] Electrons occupy the lowest-energy available orbitals.", "[LIMIT] The sequence 1s 2s 2p 3s 3p 4s 3d 4p 5s 4d 5p 6s 4f 5d 6p 7s 5f 6d 7p gives the order of increasing orbital energy up to Z = 118."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any atom with atomic number Z ≤ 118, the maximum electron count in orbitals with principal quantum number n is 2n².\nASSUMPTION: None\nVERIFICATION: Follows from summing 2(2l+1) over 0 ≤ l ≤ n−1; units: electrons; valid for n up to 7 under the given energy sequence.", "rejected": "For any atom with atomic number Z ≤ 118, the maximum electron count in orbitals with principal quantum number n is −2n².", "E_acc": 0.3321160078048706, "C_acc": 0.3817995488643646, "G_acc": 0.541887586354278, "D_acc": 0.6641713478602469, "H_acc": 0.12042653560638428, "Q_acc": 0.5524440258508548, "E_rej": 0.2562909722328186, "C_rej": 0.43903636932373047, "G_rej": 0.5437436831998639, "D_rej": 0.8699361979961395, "H_rej": 0.13006380200386047, "Q_rej": 0.5588096138439141, "Delta_Q": -0.006365587993059307, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "nervous system", "ancestors": ["[DEF] A nervous system is a network of specialized cells that transmit electrochemical signals.", "[DEF] A neuron is a cell type within a nervous system.", "[DEF] An axon is a cellular extension of a neuron.", "[DEF] A synapse is a junction between two neurons.", "[VAR] Let v denote the conduction velocity along an axon.", "[VAR] Let d denote the axonal diameter.", "[LAW] v ∝ d for myelinated axons.", "[LIMIT] v ≤ 120 m s⁻¹ in vertebrate axons."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any myelinated vertebrate axon, the axonal diameter d must satisfy d ≤ d_max where d_max corresponds to v = 120 m s⁻¹.\nASSUMPTION: None\nVERIFICATION: Units consistent (m s⁻¹ and dimensionless proportionality); testable by measuring d and v in any myelinated vertebrate axon.", "rejected": "For any myelinated vertebrate axon, the axonal diameter d must satisfy d ≥ d_max where d_max corresponds to v = 120 m s⁻¹.", "E_acc": 0.30384179949760437, "C_acc": 0.5460710525512695, "G_acc": 0.5163554869858282, "D_acc": 0.637357683852315, "H_acc": 0.33864734694361687, "Q_acc": 0.47881622881229435, "E_rej": 0.3897821307182312, "C_rej": 0.32512199878692627, "G_rej": 0.5263674104852336, "D_rej": 0.76002037525177, "H_rej": 0.2999745309352875, "Q_rej": 0.5791903435119561, "Delta_Q": -0.10037411469966173, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "nervous system", "ancestors": ["[DEF] A neuron is a cell specialized for electrical signaling.", "[DEF] The soma is the metabolic center of a neuron.", "[DEF] An axon is a single process extending from the soma.", "[DEF] A dendrite is a branched process extending from the soma.", "[DEF] A synapse is a junction between an axon terminal and a target cell.", "[VAR] Let v denote membrane potential.", "[VAR] Let C denote membrane capacitance per unit area.", "[VAR] Let I_ion denote ionic current per unit area.", "[LAW] C dv/dt = −I_ion.", "[CONSTRAINT] v is bounded by the Nernst potentials of the dominant ions."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The membrane potential v cannot remain constant unless the net ionic current I_ion is zero.\nASSUMPTION: None\nVERIFICATION: Direct from C dv/dt = −I_ion; units consistent (current per area, time derivative of potential).", "rejected": "STATUS: NOT ENTAILED.", "E_acc": 0.18831534683704376, "C_acc": 0.5803084373474121, "G_acc": 0.5266312073217705, "D_acc": 0.6153456284664571, "H_acc": 0.2866731137037277, "Q_acc": 0.44016097236890345, "E_rej": 0.06348311901092529, "C_rej": 0.7804317474365234, "G_rej": 0.5710276584140956, "D_rej": 0.48712602350860834, "H_rej": 0.5128739764913917, "Q_rej": 0.32330192495137455, "Delta_Q": 0.1168590474175289, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "motion graphs", "ancestors": ["[DEF] A motion graph plots position s against time t.", "[VAR] s is in metres, t is in seconds.", "[DEF] Velocity v is the time-derivative of s.", "[DEF] Acceleration a is the time-derivative of v.", "[LAW] v = ds/dt.", "[LAW] a = dv/dt.", "[CONSTRAINT] On a s–t graph the slope at any t equals v at that t."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the s–t graph is a straight line, then v is constant and a = 0.\nASSUMPTION: None\nVERIFICATION: Units: v in m/s, a in m/s²; testable by linear regression on s–t data.", "rejected": "If the s–t graph is a straight line, then v is constant and a = g.", "E_acc": 0.06938282400369644, "C_acc": 0.8094869256019592, "G_acc": 0.5490034064278007, "D_acc": 0.6119798871222883, "H_acc": 0.2747159004211426, "Q_acc": 0.36364253074862063, "E_rej": 0.018907049670815468, "C_rej": 0.9520113468170166, "G_rej": 0.5559380906634033, "D_rej": 0.7748026251792908, "H_rej": 0.22519737482070923, "Q_rej": 0.3588982512243092, "Delta_Q": 0.0047442795243114455, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "excretion", "ancestors": ["[DEF] Excretion is the elimination of metabolic waste from an organism.", "[DEF] A metabolic waste is a by-product of cellular chemistry that cannot be further used by the organism.", "[VAR] Let Q(t) denote the mass of metabolic waste accumulated at time t.", "[VAR] Let E(t) denote the mass excreted in the interval [0,t].", "[LAW] dQ/dt = P – dE/dt, where P is the constant production rate of metabolic waste.", "[CONSTRAINT] Q(t) ≥ 0 for all t.", "[LIMIT] As t → ∞, Q(t) → P/κ if dE/dt = κQ with κ > 0."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If κ > 0 and dE/dt = κQ, then Q(t) ≤ max{Q(0), P/κ} for all t ≥ 0.\nASSUMPTION: None\nVERIFICATION: Units: mass; regime: continuous-time dynamics with exponential approach to P/κ.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.17920337617397308, "C_acc": 0.679816722869873, "G_acc": 0.5433396543376148, "D_acc": 0.6497054109349847, "H_acc": 0.26257096230983734, "Q_acc": 0.4301495851017535, "E_rej": 0.20865722000598907, "C_rej": 0.5142443776130676, "G_rej": 0.5923677650280297, "D_rej": 0.558700006455183, "H_rej": 0.44129999354481697, "Q_rej": 0.44583184542134413, "Delta_Q": -0.015682260319590635, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "refraction of light", "ancestors": ["[DEF] Refraction is the change in direction of light at an interface between two transparent media.", "[VAR] Let n denote the refractive index of a medium.", "[VAR] Let θ₁ be the angle between the incident ray and the interface normal.", "[VAR] Let θ₂ be the angle between the refracted ray and the interface normal.", "[LAW] n₁ sin θ₁ = n₂ sin θ₂.", "[CONSTRAINT] n ≥ 1 for any medium.", "[LIMIT] θ₂ = 90° when θ₁ = arcsin(n₂/n₁) with n₁ > n₂.", "[LIMIT] No refracted ray exists for θ₁ > arcsin(n₂/n₁) with n₁ > n₂."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If n₁ > n₂, the maximum possible θ₁ before total internal reflection is arcsin(n₂/n₁).\nASSUMPTION: None\nVERIFICATION: Dimensionless ratio n₂/n₁ < 1 ensures real arcsin value; testable by varying incidence angle.", "rejected": "STATUS: REFUTED.", "E_acc": 0.07170835137367249, "C_acc": 0.6428660750389099, "G_acc": 0.5376453489298001, "D_acc": 0.6670087743550539, "H_acc": 0.1935044527053833, "Q_acc": 0.4145196697907523, "E_rej": 0.08639618009328842, "C_rej": 0.7193298935890198, "G_rej": 0.589148172235582, "D_rej": 0.5892568305134773, "H_rej": 0.4107431694865227, "Q_rej": 0.3766595589113422, "Delta_Q": 0.0378601108794101, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "dihybrid crosses", "ancestors": ["[DEF] A dihybrid cross is a mating between two individuals heterozygous at two unlinked loci.", "[VAR] Let locus A have alleles A and a.", "[VAR] Let locus B have alleles B and b.", "[VAR] Let genotype AaBb denote heterozygosity at both loci.", "[CONSTRAINT] Each parent in a dihybrid cross has genotype AaBb.", "[CONSTRAINT] The two loci assort independently.", "[LAW] Each parent produces gametes AB, Ab, aB, ab with equal frequency 1/4.", "[DEF] The Punnett square for AaBb × AaBb is a 4×4 grid of gamete fusions.", "[VAR] Let F2 denote the offspring generation from AaBb × AaBb."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: In the F2 generation, the genotypic ratio is 1 AABB : 2 AABb : 1 AAbb : 2 AaBB : 4 AaBb : 2 Aabb : 1 aaBB : 2 aaBb : 1 aabb.\nASSUMPTION: None\nVERIFICATION: Counts sum to 16; each genotype frequency equals its Punnett-square count divided by 16.", "rejected": "HYPOTHESIS: In the F2 generation, the genotypic ratio is 1 AABB : 2 AABb : 1 AAbb : 2 AaBB : 4 AaBb : 2 Aabb : 1 aaBB : 2 aaBb : 1 aabb.", "E_acc": 0.36843931674957275, "C_acc": 0.3451593220233917, "G_acc": 0.5159047207562253, "D_acc": 0.6663826610893011, "H_acc": 0.20081496238708496, "Q_acc": 0.5578759107505903, "E_rej": 0.29363253712654114, "C_rej": 0.368969202041626, "G_rej": 0.5180007991439197, "D_rej": 0.7613160312175751, "H_rej": 0.23868396878242493, "Q_rej": 0.5462908899236937, "Delta_Q": 0.011585020826896608, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Punnett squares", "ancestors": ["[DEF] A Punnett square is a grid used to display possible genotype combinations from a genetic cross.", "[VAR] Let P denote the set of parental alleles contributed to the cross.", "[VAR] Let G denote the set of possible genotype outcomes.", "[DEF] Each axis of the grid lists one parent's alleles.", "[LAW] Each cell contains one allele from each axis.", "[CONSTRAINT] Each axis allele is chosen independently.", "[CONSTRAINT] Each cell represents a fusion of one paternal and one maternal allele.", "[DEF] The union of all cells constitutes G.", "[LIMIT] The grid dimensions equal the square of the allele count per parent.", "[LIMIT] The method assumes Mendelian segregation."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The number of possible genotype outcomes |G| equals the square of the number of distinct alleles contributed by each parent.\nASSUMPTION: None\nVERIFICATION: |G| = |P|² where |P| is allele count per parent; testable by counting grid cells.", "rejected": "The number of distinct alleles contributed by each parent equals the square root of the number of possible genotype outcomes |G|.", "E_acc": 0.1739743947982788, "C_acc": 0.6550780534744263, "G_acc": 0.5429311930201948, "D_acc": 0.6596909496001899, "H_acc": 0.21118885278701782, "Q_acc": 0.44058225098997356, "E_rej": 0.596402645111084, "C_rej": 0.2251019924879074, "G_rej": 0.5406376993050799, "D_rej": 0.7943496704101562, "H_rej": 0.20565032958984375, "Q_rej": 0.6803328360198065, "Delta_Q": -0.23975058502983299, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "weight", "ancestors": ["[DEF] Weight is the gravitational force on a body.", "[VAR] Let m denote mass.", "[VAR] Let g denote gravitational acceleration.", "[LAW] Weight W = m g.", "[VAR] Let F_net denote the net force on the body.", "[VAR] Let a denote acceleration of the body.", "[LAW] F_net = m a.", "[CONSTRAINT] W acts toward the center of the gravitational source.", "[LIMIT] g at Earth’s surface is 9.80665 m s⁻²."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If a body is in free-fall near Earth's surface, its acceleration equals g downward.\nASSUMPTION: None\nVERIFICATION: Units: a = 9.80665 m s⁻² downward; testable by measuring free-fall acceleration.", "rejected": "If a body is at rest on a table near Earth's surface, its acceleration equals g downward.", "E_acc": 0.3312147855758667, "C_acc": 0.5280255079269409, "G_acc": 0.5426518851309083, "D_acc": 0.636084171012044, "H_acc": 0.27865496277809143, "Q_acc": 0.5016410490381532, "E_rej": 0.11866056174039841, "C_rej": 0.7022555470466614, "G_rej": 0.5335034364834428, "D_rej": 0.7814242541790009, "H_rej": 0.21857574582099915, "Q_rej": 0.4362750226631761, "Delta_Q": 0.06536602637497713, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "energy levels", "ancestors": ["[DEF] An energy level is a discrete value of energy that a bound quantum system may possess.", "[VAR] Let n denote the principal quantum number, n ∈ ℕ.", "[VAR] Let Eₙ denote the energy of level n.", "[LAW] Eₙ = −R/n², where R is the Rydberg constant.", "[CONSTRAINT] n ≥ 1.", "[LIMIT] As n → ∞, Eₙ → 0.", "[VAR] Let ΔE be the energy difference between two levels.", "[DEF] ΔE = |Eₙ − Eₘ| for n ≠ m."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any two levels n and m with n > m ≥ 1, the energy difference ΔE = R(1/m² − 1/n²) is strictly positive and increases monotonically as m is fixed and n increases.\nASSUMPTION: None\nVERIFICATION: Units: ΔE in Rydberg energy units; monotonicity testable by derivative of R(1/m² − 1/n²) with respect to n > m.", "rejected": "For any two levels n and m with n > m ≥ 1, the energy difference ΔE = R(1/m − 1/n) is strictly positive and increases monotonically as m is fixed and n increases.", "E_acc": 0.1323850303888321, "C_acc": 0.6723670959472656, "G_acc": 0.5474917750980239, "D_acc": 0.6838858833070844, "H_acc": 0.1809883415699005, "Q_acc": 0.43341878745122814, "E_rej": 0.1046057716012001, "C_rej": 0.46219906210899353, "G_rej": 0.5394551473436877, "D_rej": 0.8453393876552582, "H_rej": 0.15466061234474182, "Q_rej": 0.5004347648238764, "Delta_Q": -0.06701597737264825, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "mitosis", "ancestors": ["[DEF] Mitosis is nuclear division producing two nuclei with identical chromosome sets.", "[VAR] Let P denote a parent cell.", "[VAR] Let D1 and D2 denote daughter cells.", "[DEF] P enters mitosis with genome G.", "[LAW] During mitosis G is replicated into two copies.", "[CONSTRAINT] Each daughter receives exactly one copy of G.", "[LIMIT] Mitosis cannot proceed without prior genome replication."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The genome sets of D1 and D2 are identical to each other and to the genome G of P.\nASSUMPTION: None\nVERIFICATION: N/A", "rejected": "The genome sets of D1 and D2 are independent of each other and to the genome G of P.", "E_acc": 0.35939809679985046, "C_acc": 0.3774464726448059, "G_acc": 0.5582998355384916, "D_acc": 0.5943992007523775, "H_acc": 0.2722727209329605, "Q_acc": 0.5356426696758717, "E_rej": 0.2564970850944519, "C_rej": 0.485666424036026, "G_rej": 0.563616480329074, "D_rej": 0.7607823610305786, "H_rej": 0.2392176389694214, "Q_rej": 0.5207738450961188, "Delta_Q": 0.014868824579752915, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "velocity", "ancestors": ["[DEF] Velocity is the rate of change of position with respect to time.", "[VAR] Let x denote position.", "[VAR] Let t denote time.", "[VAR] Let v denote velocity.", "[LAW] v = dx/dt.", "[CONSTRAINT] dx/dt exists.", "[LIMIT] v is finite."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Position x is a differentiable function of time t over the domain where v is defined.\nASSUMPTION: None\nVERIFICATION: Units: x in meters, t in seconds; differentiability follows from existence of dx/dt per CONSTRAINT.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.342530757188797, "C_acc": 0.42548292875289917, "G_acc": 0.5624567336801972, "D_acc": 0.626148382086285, "H_acc": 0.22286444902420044, "Q_acc": 0.5330972196569357, "E_rej": 0.2795438766479492, "C_rej": 0.4234667122364044, "G_rej": 0.5747131702623197, "D_rej": 0.5101263495162129, "H_rej": 0.48987365048378706, "Q_rej": 0.4671503594544317, "Delta_Q": 0.06594686020250401, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "specific heat capacity", "ancestors": ["[DEF] Specific heat capacity is the energy required to raise the temperature of one kilogram of a substance by one kelvin.", "[VAR] Let c denote specific heat capacity.", "[VAR] Let Q denote energy transferred as heat.", "[VAR] Let m denote mass.", "[VAR] Let ΔT denote temperature change.", "[LAW] Q = m c ΔT.", "[CONSTRAINT] c > 0.", "[LIMIT] c is constant only over a limited temperature range for real substances.", "[LIMIT] c → 0 as T → 0 for all substances."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any fixed positive Q and m, the temperature rise ΔT is inversely proportional to c, so substances with lower c experience larger ΔT for the same heat input.\nASSUMPTION: None\nVERIFICATION: Rearranging Q = m c ΔT gives ΔT = Q/(m c); units check: J/(kg·J kg⁻¹ K⁻¹) = K, valid for c > 0 within the stated limited range.", "rejected": "For any fixed positive Q and m, the temperature rise ΔT is proportional to c, so substances with lower c experience smaller ΔT for the same heat input.", "E_acc": 0.10899978876113892, "C_acc": 0.7667668461799622, "G_acc": 0.5234511704849345, "D_acc": 0.6300125075504184, "H_acc": 0.19938260316848755, "Q_acc": 0.39010104268257106, "E_rej": 0.2924032509326935, "C_rej": 0.24501293897628784, "G_rej": 0.5064658015035093, "D_rej": 0.7692146003246307, "H_rej": 0.23078539967536926, "Q_rej": 0.5707759278826416, "Delta_Q": -0.18067488520007058, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "metamorphic rocks", "ancestors": ["[DEF] Metamorphic rock forms from pre-existing rock subjected to heat and pressure.", "[VAR] T is temperature.", "[VAR] P is pressure.", "[VAR] t is time.", "[LAW] Metamorphic reactions proceed when T exceeds a mineral-specific threshold.", "[CONSTRAINT] T increases with depth in the crust.", "[CONSTRAINT] P increases with depth in the crust.", "[LIMIT] Partial melting begins if T exceeds the solidus of the rock.", "[VAR] G is the geothermal gradient.", "[CONSTRAINT] G sets T at a given depth."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: At any depth where T exceeds the mineral-specific threshold, metamorphic reactions proceed provided T remains below the solidus.\nASSUMPTION: None\nVERIFICATION: Testable by comparing measured T at depth with both the threshold for the mineral assemblage and the solidus of the rock.", "rejected": "At any depth where metamorphic reactions proceed, T exceeds the mineral-specific threshold provided T remains below the solidus.", "E_acc": 0.1987941563129425, "C_acc": 0.6292920112609863, "G_acc": 0.55854418328298, "D_acc": 0.6676492169499397, "H_acc": 0.156131774187088, "Q_acc": 0.4634053472695607, "E_rej": 0.23354443907737732, "C_rej": 0.45845064520835876, "G_rej": 0.5596302101455096, "D_rej": 0.8399612903594971, "H_rej": 0.16003870964050293, "Q_rej": 0.5422876318184926, "Delta_Q": -0.07888228454893192, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "groups", "ancestors": ["[DEF] A group (G,∗) is a set G closed under an associative binary operation ∗ with an identity element e∈G and for every x∈G an inverse x⁻¹∈G satisfying x∗x⁻¹=e.", "[VAR] Let |G| denote the cardinality of G.", "[VAR] Let e denote the identity element of G.", "[DEF] The order of x∈G is the smallest positive integer n such that xⁿ=e.", "[VAR] Let o(x) denote the order of x∈G.", "[LAW] For every x∈G, o(x) divides |G|.", "[CONSTRAINT] If |G| is prime, then G is cyclic.", "[LIMIT] There is no group of order 0.", "[LIMIT] There is no group whose underlying set is a proper class."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If |G| = p² for a prime p, then G contains an element of order p.\nASSUMPTION: None\nVERIFICATION: Units: group order and element order; testable via Cauchy’s theorem for finite abelian groups, here entailed by Lagrange and existence of non-identity elements.", "rejected": "If |G| = p² for a prime p, then G contains an element of order p².", "E_acc": 0.24483659863471985, "C_acc": 0.5255708694458008, "G_acc": 0.51245687098708, "D_acc": 0.6643041949719191, "H_acc": 0.20405104756355286, "Q_acc": 0.48328391413670035, "E_rej": 0.24821119010448456, "C_rej": 0.5061517357826233, "G_rej": 0.5144558595202398, "D_rej": 0.7288704067468643, "H_rej": 0.2711295932531357, "Q_rej": 0.49478530380292796, "Delta_Q": -0.011501389666227602, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "lenses", "ancestors": ["[DEF] A lens is a transparent optical component with at least one curved surface.", "[DEF] The optical axis is the straight line through the lens centers of curvature.", "[DEF] A thin lens has thickness negligible relative to its radii of curvature.", "[VAR] R₁ denotes the radius of curvature of the first lens surface.", "[VAR] R₂ denotes the radius of curvature of the second lens surface.", "[VAR] n denotes the refractive index of the lens material relative to the surrounding medium.", "[LAW] The lensmaker’s equation for a thin lens in air is 1/f = (n − 1)(1/R₁ − 1/R₂).", "[VAR] f denotes the focal length of the lens.", "[CONSTRAINT] R > 0 indicates a convex surface facing the incident light.", "[LIMIT] The thin-lens approximation requires |t| ≪ |R₁|, |R₂|."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If R₁ = R₂ and n > 1, then 1/f = 0, so the focal length f becomes infinite, producing a lens with no optical power.\nASSUMPTION: None\nVERIFICATION: Units: 1/f in diopters; regime: thin-lens in air; testable by measuring f for equal radii.", "rejected": "If R₁ = R₂ and n > 1, then 1/f = 2(n − 1)/R₁, so the focal length f becomes R₁/[2(n − 1)], producing a lens with optical power independent of R₂.", "E_acc": 0.3548024892807007, "C_acc": 0.32362446188926697, "G_acc": 0.524535510999461, "D_acc": 0.6439215396530926, "H_acc": 0.21166318655014038, "Q_acc": 0.5542409458818536, "E_rej": 0.29231905937194824, "C_rej": 0.4496232271194458, "G_rej": 0.5247915483390292, "D_rej": 0.7735039293766022, "H_rej": 0.22649607062339783, "Q_rej": 0.5347805608684818, "Delta_Q": 0.019460385013371773, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "gamma rays", "ancestors": ["[DEF] Gamma rays are electromagnetic radiation with photon energies above 100 keV.", "[DEF] The photon energy E is related to frequency ν by E = hν, where h is Planck’s constant.", "[DEF] The frequency ν is related to wavelength λ by ν = c/λ, where c is the speed of light in vacuum.", "[LAW] The intensity I of a gamma-ray beam after traversing thickness x of material follows I(x) = I₀e^(−μx), where μ is the linear attenuation coefficient.", "[VAR] μ depends on photon energy E and atomic number Z of the material.", "[CONSTRAINT] For 1 MeV photons in lead, μ = 0.77 cm⁻¹.", "[LIMIT] The maximum attainable photon energy in terrestrial sources is below 10²⁰ eV.", "[LIMIT] The minimum detectable photon flux above 1 GeV is 10⁻¹² cm⁻² s⁻¹ for space-borne instruments."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: A 1 MeV gamma-ray beam in lead is attenuated to 1 % of its initial intensity after traversing 6 cm.  \nASSUMPTION: None  \nVERIFICATION: Using I(x)/I₀ = e^(−0.77 cm⁻¹·x) gives 0.01 at x ≈ 6 cm.", "rejected": "A 1 MeV gamma-ray beam in air is attenuated to 1 % of its initial intensity after traversing 6 cm.", "E_acc": 0.2682514190673828, "C_acc": 0.4988235533237457, "G_acc": 0.5717252715257928, "D_acc": 0.6373949949629605, "H_acc": 0.15503543615341187, "Q_acc": 0.5070312247378752, "E_rej": 0.16232584416866302, "C_rej": 0.639800488948822, "G_rej": 0.5678096116753295, "D_rej": 0.7961046695709229, "H_rej": 0.20389533042907715, "Q_rej": 0.47313097866717724, "Delta_Q": 0.03390024607069797, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "latent heat", "ancestors": ["[DEF] Latent heat is the energy absorbed or released during a phase change at constant temperature.", "[VAR] Let Q denote the quantity of energy transferred.", "[VAR] Let m denote the mass of the substance.", "[VAR] Let L denote the specific latent heat of the substance.", "[LAW] Q = m L.", "[CONSTRAINT] L is constant for a given substance and phase change.", "[LIMIT] Temperature remains constant throughout the phase change.", "[LIMIT] No work is done other than that associated with the phase change."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For a fixed substance and phase change, doubling the mass doubles the energy transferred.\nASSUMPTION: None\nVERIFICATION: Units: Q in J, m in kg, L in J kg⁻¹; doubling m with constant L yields 2Q.", "rejected": "For a fixed substance and phase change, doubling the mass squares the energy transferred.", "E_acc": 0.17369332909584045, "C_acc": 0.6777492165565491, "G_acc": 0.5304891515115742, "D_acc": 0.5758780202595517, "H_acc": 0.3380797803401947, "Q_acc": 0.404023611737648, "E_rej": 0.3090880513191223, "C_rej": 0.4288303554058075, "G_rej": 0.5244212262332439, "D_rej": 0.6801435649394989, "H_rej": 0.3198564350605011, "Q_rej": 0.5158876590430737, "Delta_Q": -0.11186404730542565, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "hydrogen bonding", "ancestors": ["[DEF] A hydrogen bond is an attractive interaction between a hydrogen atom covalently bonded to an electronegative atom and another electronegative atom.", "[VAR] Let D be the donor atom covalently bonded to H.", "[VAR] Let A be the acceptor atom interacting with H.", "[CONSTRAINT] The D–H bond is polar covalent.", "[CONSTRAINT] The distance between H and A is less than the sum of their van der Waals radii.", "[LAW] The interaction energy E is proportional to the product of the partial charges on H and A and inversely proportional to the fourth power of the H···A distance.", "[LIMIT] The maximum number of hydrogen bonds a single H atom can simultaneously form is one."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If the partial charge on H is positive and that on A is negative, the interaction energy E is positive (attractive); if both charges have the same sign, E is negative (repulsive).\nASSUMPTION: None\nVERIFICATION: Sign consistency test: opposite-sign charges yield positive E (attractive) under the stated proportionality.", "rejected": "STATUS: ENTAILED.", "E_acc": 0.164557084441185, "C_acc": 0.6402005553245544, "G_acc": 0.5201165856560692, "D_acc": 0.6241787276230752, "H_acc": 0.2659247815608978, "Q_acc": 0.4235935987671837, "E_rej": 0.2304241806268692, "C_rej": 0.45268768072128296, "G_rej": 0.5735065478365868, "D_rej": 0.5206957533955574, "H_rej": 0.4793042466044426, "Q_rej": 0.44949975362978883, "Delta_Q": -0.025906154862605113, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "stellar life cycle", "ancestors": ["[DEF] A star is a self-gravitating sphere of plasma in hydrostatic equilibrium.", "[DEF] The main sequence is the core-hydrogen-burning phase of a star.", "[VAR] Let M be the initial mass of a star.", "[CONSTRAINT] M ≥ 0.08 M☉ is required for hydrogen fusion.", "[LIMIT] The main-sequence lifetime t_ms ∝ M/M☉^(-2.5).", "[DEF] A planetary nebula is the ejected envelope of a star with M ≤ 8 M☉.", "[DEF] A core-collapse supernova is the explosive death of a star with M ≥ 8 M☉."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A star with M ≥ 8 M☉ will end as a core-collapse supernova and cannot become a planetary nebula.\nASSUMPTION: None\nVERIFICATION: Direct from definitions: M ≥ 8 M☉ triggers supernova, while planetary nebula requires M ≤ 8 M☉.", "rejected": "A core-collapse supernova will produce a star with M ≥ 8 M☉ and cannot become a planetary nebula.", "E_acc": 0.03266434371471405, "C_acc": 0.9256949424743652, "G_acc": 0.5402565561234951, "D_acc": 0.7112487726844847, "H_acc": 0.12743332982063293, "Q_acc": 0.3622180473990739, "E_rej": 0.003308230312541127, "C_rej": 0.9891695380210876, "G_rej": 0.5282752960920334, "D_rej": 0.8745929896831512, "H_rej": 0.12540701031684875, "Q_rej": 0.37119151761289687, "Delta_Q": -0.008973470213822998, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "work", "ancestors": ["[DEF] Work is the energy transferred to or from an object via a force acting through a displacement.", "[VAR] Let F denote the magnitude of the force vector.", "[VAR] Let d denote the magnitude of the displacement vector.", "[VAR] Let θ denote the angle between the force vector and the displacement vector.", "[LAW] W = F d cos θ.", "[CONSTRAINT] F ≥ 0.", "[CONSTRAINT] d ≥ 0.", "[LIMIT] W = 0 if θ = 90°.", "[LIMIT] W = F d if θ = 0°."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: W is maximized at θ = 0° and minimized at θ = 90° for fixed F > 0 and d > 0.\nASSUMPTION: None\nVERIFICATION: cos θ ranges from 1 to 0 as θ goes from 0° to 90°, so W ranges from F d to 0.", "rejected": "W is maximized at θ = 0° and minimized at θ = 90° for fixed F ≥ 0 and d ≥ 0.", "E_acc": 0.2214629203081131, "C_acc": 0.6080992817878723, "G_acc": 0.5431875279755332, "D_acc": 0.6133085456676781, "H_acc": 0.30047179758548737, "Q_acc": 0.446071054704953, "E_rej": 0.18896767497062683, "C_rej": 0.61515212059021, "G_rej": 0.5455697537399828, "D_rej": 0.7243753224611282, "H_rej": 0.27562467753887177, "Q_rej": 0.4600864258594811, "Delta_Q": -0.014015371154528111, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "chemical formulas", "ancestors": ["[DEF] A chemical formula is a symbolic representation of a substance.", "[DEF] A symbol in a chemical formula denotes an element.", "[DEF] A subscript in a chemical formula indicates the count of atoms of the preceding element.", "[DEF] A coefficient in a chemical formula indicates the count of molecules.", "[VAR] Let n be the count of distinct elements in a chemical formula.", "[CONSTRAINT] The sum of the mass contributions of all elements equals the molecular mass.", "[LIMIT] The molecular mass is the sum of the products of each element's atomic mass and its subscript count."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: For any chemical formula, the molecular mass equals the sum over all distinct elements of (atomic mass × subscript).\nASSUMPTION: None\nVERIFICATION: Units: g/mol; test by summing products for H₂O: 2×1.008 + 1×15.999 = 18.015 g/mol.", "rejected": "HYPOTHESIS: For any chemical formula, the molecular mass equals the sum over all distinct elements of (atomic mass × subscript²).", "E_acc": 0.13556434214115143, "C_acc": 0.6864285469055176, "G_acc": 0.5190137381432578, "D_acc": 0.6124482238665223, "H_acc": 0.21553894877433777, "Q_acc": 0.40812209078576417, "E_rej": 0.5510510206222534, "C_rej": 0.1587914377450943, "G_rej": 0.5085881260456517, "D_rej": 0.8441226780414581, "H_rej": 0.15587732195854187, "Q_rej": 0.688511447259225, "Delta_Q": -0.2803893564734608, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "nonpolar bonds", "ancestors": ["[DEF] A nonpolar covalent bond is a covalent bond in which electrons are shared equally.", "[DEF] Electronegativity is the tendency of an atom to attract electrons in a bond.", "[LAW] A nonpolar covalent bond forms between two atoms with identical electronegativity.", "[CONSTRAINT] The electronegativity difference ΔEN = 0 for a nonpolar bond.", "[VAR] Let ΔEN denote the electronegativity difference between bonded atoms.", "[LIMIT] ΔEN = 0 obtains only for identical atoms.", "[DEF] A purely nonpolar bond exists only in homonuclear diatomic molecules.", "[CONSTRAINT] Any ΔEN > 0 yields a polar bond."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: A diatomic molecule containing two different elements must form a polar covalent bond.\nASSUMPTION: None\nVERIFICATION: Follows from LIMIT (ΔEN=0 only for identical atoms) and CONSTRAINT (any ΔEN>0 yields polar bond).", "rejected": "A diatomic molecule containing two different elements forms a covalent bond whose polarity is independent of the atoms’ electronegativity difference.", "E_acc": 0.2804071605205536, "C_acc": 0.5678948163986206, "G_acc": 0.5230235530834761, "D_acc": 0.6369933551177382, "H_acc": 0.2688659727573395, "Q_acc": 0.4756599692409509, "E_rej": 0.17915111780166626, "C_rej": 0.6078416705131531, "G_rej": 0.5470407048705965, "D_rej": 0.8429810702800751, "H_rej": 0.15701892971992493, "Q_rej": 0.49447946329601106, "Delta_Q": -0.01881949405506017, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "natural selection", "ancestors": ["[DEF] Natural selection is the differential survival and reproduction of heritable variants.", "[VAR] Let f denote the frequency of an allele in a population.", "[VAR] Let w denote the fitness of a genotype, defined as its expected reproductive contribution.", "[LAW] The change in allele frequency Δf is proportional to the covariance between allele frequency and fitness.", "[CONSTRAINT] The total population size remains finite.", "[LIMIT] Genetic drift dominates selection when the product of effective population size Nₑ and selection coefficient s satisfies Nₑs ≪ 1.", "[LIMIT] The response to selection reaches a plateau when additive genetic variance Vₐ approaches zero."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: When additive genetic variance Vₐ is positive, the change in allele frequency Δf is positive if the covariance between allele frequency and fitness is positive.\nASSUMPTION: None\nVERIFICATION: Units: Δf dimensionless; Vₐ in squared trait units; testable by measuring covariance sign.", "rejected": "When additive genetic variance Vₐ is positive, the change in allele frequency Δf is negative if the covariance between allele frequency and fitness is positive.", "E_acc": 0.13534851372241974, "C_acc": 0.6735637784004211, "G_acc": 0.5317445599357598, "D_acc": 0.6561787817627192, "H_acc": 0.20271632075309753, "Q_acc": 0.4232048347010277, "E_rej": 0.13610921800136566, "C_rej": 0.29796701669692993, "G_rej": 0.5327956779219676, "D_rej": 0.8155047297477722, "H_rej": 0.18449527025222778, "Q_rej": 0.5324499165697489, "Delta_Q": -0.10924508186872123, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "stellar life cycle", "ancestors": ["[DEF] A star is a self-gravitating sphere of plasma in hydrostatic equilibrium.", "[VAR] Let M be the total rest mass of the star.", "[VAR] Let L be the star’s surface radiative luminosity.", "[VAR] Let t be the time since the star’s formation.", "[VAR] Let X be the hydrogen mass fraction in the star’s core.", "[VAR] Let Y be the helium mass fraction in the star’s core.", "[LAW] The core hydrogen burning rate is proportional to L.", "[CONSTRAINT] X + Y ≤ 1 in the core.", "[LIMIT] X ≥ 0 in the core.", "[LIMIT] Y ≥ 0 in the core."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The core hydrogen mass fraction X is bounded above by 1.\nASSUMPTION: None.\nVERIFICATION: Follows directly from CONSTRAINT X + Y ≤ 1 and LIMIT Y ≥ 0, giving X ≤ 1.", "rejected": "The core hydrogen mass fraction X is bounded below by 1.", "E_acc": 0.14474640786647797, "C_acc": 0.631164014339447, "G_acc": 0.5342079335407887, "D_acc": 0.6089270284865052, "H_acc": 0.2344634234905243, "Q_acc": 0.42237176954846034, "E_rej": 0.7304229140281677, "C_rej": 0.11455988883972168, "G_rej": 0.5284658907247441, "D_rej": 0.7954719662666321, "H_rej": 0.20452803373336792, "Q_rej": 0.7405496644654445, "Delta_Q": -0.3181778949169841, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "anaerobic respiration", "ancestors": ["[DEF] Anaerobic respiration is an ATP-generating catabolic process that proceeds without external electron acceptors such as O₂.", "[VAR] Let c be the molar ATP yield per mole of glucose under anaerobic respiration.", "[VAR] Let t be the time required for one cell division supported solely by anaerobic respiration.", "[DEF] The Embden–Meyerhof–Parnas (EMP) pathway is the sequence of cytosolic enzymatic reactions converting one glucose to two pyruvate.", "[CONSTRAINT] The EMP pathway yields 2 ATP per glucose.", "[DEF] Fermentation is the re-oxidation of NADH to NAD⁺ via endogenous organic electron acceptors without an electron-transport chain.", "[CONSTRAINT] Fermentation must follow the EMP pathway to regenerate NAD⁺ for glyceraldehyde-3-phosphate dehydrogenase.", "[LIMIT] The maximum c equals 2 ATP per glucose when the EMP pathway and fermentation are the sole anaerobic routes."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: c ≤ 2 ATP per glucose.\nASSUMPTION: None.\nVERIFICATION: Units: mol ATP/mol glucose; regime: anaerobic respiration limited to EMP plus fermentation.", "rejected": "c ≤ 2 ATP per mole of glucose.", "E_acc": 0.3536825180053711, "C_acc": 0.21110573410987854, "G_acc": 0.5931069955113344, "D_acc": 0.6571862965356559, "H_acc": 0.15215107798576355, "Q_acc": 0.5987271591904573, "E_rej": 0.24228380620479584, "C_rej": 0.3178854286670685, "G_rej": 0.5828661559498869, "D_rej": 0.7733712494373322, "H_rej": 0.22662875056266785, "Q_rej": 0.5576926621492021, "Delta_Q": 0.04103449704125517, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "weight", "ancestors": ["[DEF] Weight is the gravitational force on a body.", "[VAR] Let m denote mass.", "[VAR] Let g denote gravitational field strength.", "[LAW] Weight equals m multiplied by g.", "[CONSTRAINT] g is location-dependent.", "[LIMIT] Weight vanishes where g equals zero.", "[VAR] Let F_g denote weight.", "[CONSTRAINT] F_g is proportional to m at a fixed location."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: At any fixed location, the ratio F_g / m equals the local value of g.\nASSUMPTION: None\nVERIFICATION: Units: N kg⁻¹ = m s⁻², satisfied for any location where g is defined.", "rejected": "At any fixed location, the ratio F_g / m is independent of g.", "E_acc": 0.3442000448703766, "C_acc": 0.41907042264938354, "G_acc": 0.5587441757052147, "D_acc": 0.59468390699476, "H_acc": 0.29768817126750946, "Q_acc": 0.5203627283444803, "E_rej": 0.020793428644537926, "C_rej": 0.9293224215507507, "G_rej": 0.5397500587278046, "D_rej": 0.6736882627010345, "H_rej": 0.32631173729896545, "Q_rej": 0.3304300348390825, "Delta_Q": 0.18993269350539776, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Newton third law", "ancestors": ["[DEF] A force is an interaction between two bodies.", "[VAR] Let F_AB denote the force exerted by body A on body B.", "[VAR] Let F_BA denote the force exerted by body B on body A.", "[DEF] These paired forces are called an action–reaction pair.", "[LAW] For every action–reaction pair, F_AB = −F_BA.", "[CONSTRAINT] The forces act on different bodies.", "[CONSTRAINT] The forces are of the same physical type.", "[LIMIT] The law applies only in inertial reference frames.", "[LIMIT] The bodies interact mutually and simultaneously."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If body A exerts any non-zero force on body B, then body B simultaneously exerts a force of equal magnitude and opposite direction on body A.\nASSUMPTION: None\nVERIFICATION: Vector equality F_AB = −F_BA holds in inertial frames with SI units of newtons.", "rejected": "If body A exerts any non-zero force on body B, then body B simultaneously exerts a force of equal magnitude and the same direction on body A.", "E_acc": 0.16760368645191193, "C_acc": 0.6651642322540283, "G_acc": 0.5686325742854024, "D_acc": 0.6544220447540283, "H_acc": 0.21312549710273743, "Q_acc": 0.44054663358238033, "E_rej": 0.11477571725845337, "C_rej": 0.6182054877281189, "G_rej": 0.5480636935390066, "D_rej": 0.812729686498642, "H_rej": 0.18727031350135803, "Q_rej": 0.4642232622893062, "Delta_Q": -0.023676628706925884, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "food chains", "ancestors": ["[DEF] A food chain is a linear sequence of organisms through which nutrients and energy pass.", "[DEF] A trophic level is the position an organism occupies in a food chain.", "[DEF] The first trophic level comprises autotrophs.", "[DEF] The second trophic level comprises herbivores that consume autotrophs.", "[DEF] The third trophic level comprises carnivores that consume herbivores.", "[LAW] Energy transfer between successive trophic levels is quantified by ecological efficiency E.", "[VAR] E is the ratio of energy at trophic level n+1 to energy at trophic level n.", "[CONSTRAINT] 0 < E ≤ 0.2.", "[LIMIT] Energy available at trophic level n+1 is E times energy at trophic level n."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: Energy at the third trophic level is at most 4% of the energy at the first trophic level.\nASSUMPTION: None\nVERIFICATION: Units: dimensionless ratio; regime 0 < E ≤ 0.2 applied twice.", "rejected": "Energy at the third trophic level is at most 8% of the energy at the first trophic level.", "E_acc": 0.1272849589586258, "C_acc": 0.6706737279891968, "G_acc": 0.5491065763469253, "D_acc": 0.6015924143139273, "H_acc": 0.2159452736377716, "Q_acc": 0.41259601285814174, "E_rej": 0.05158291012048721, "C_rej": 0.5056193470954895, "G_rej": 0.5377098088086184, "D_rej": 0.802141010761261, "H_rej": 0.197858989238739, "Q_rej": 0.4625352686071503, "Delta_Q": -0.04993925574900854, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "erosion", "ancestors": ["[DEF] Erosion is the detachment and transport of Earth-surface particles by an agent.", "[VAR] Let F be the detachment force per unit area exerted by the agent.", "[VAR] Let τ be the shear stress exerted by the agent on the surface.", "[VAR] Let τc be the critical shear stress required to initiate particle motion.", "[CONSTRAINT] Detachment occurs only if τ ≥ τc.", "[LAW] The erosion rate per unit area, E, is proportional to the excess shear stress: E = k(τ − τc) for τ ≥ τc, with k a constant of proportionality.", "[VAR] Let Q be the volumetric transport capacity of the agent per unit width.", "[CONSTRAINT] E cannot exceed Q.", "[LIMIT] The maximum possible erosion rate per unit area is Emax = Q."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: If τ < τc, then E = 0 regardless of the value of Q.\nASSUMPTION: None\nVERIFICATION: Follows directly from CONSTRAINT τ ≥ τc for detachment and LAW E = k(τ − τc) with k(τ − τc) = 0 when τ < τc.", "rejected": "If τ < τc, then E = k(τ − τc).", "E_acc": 0.18752384185791016, "C_acc": 0.5824818015098572, "G_acc": 0.5685971982311457, "D_acc": 0.599293545819819, "H_acc": 0.34577152132987976, "Q_acc": 0.4387617889326066, "E_rej": 0.02077222801744938, "C_rej": 0.9578933119773865, "G_rej": 0.5623603895073757, "D_rej": 0.5732691884040833, "H_rej": 0.42673081159591675, "Q_rej": 0.29910584043245764, "Delta_Q": 0.13965594850014895, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "planets", "ancestors": ["[DEF] A planet is a celestial body in orbit around a star.", "[DEF] A planet has sufficient mass for self-gravity to overcome rigid body forces so that it assumes a nearly round shape.", "[DEF] A planet has cleared its orbital neighborhood of other bodies.", "[VAR] Let P be a planet.", "[VAR] Let m_P be the mass of P.", "[VAR] Let R_P be the mean radius of P.", "[CONSTRAINT] m_P ≥ 5 × 10²⁰ kg.", "[CONSTRAINT] R_P ≥ 2 × 10⁵ m.", "[LAW] The orbital path of P satisfies Kepler’s first law.", "[LAW] The square of the orbital period T of P is proportional to the cube of the semi-major axis a of its orbit."]}, "accepted": "STATUS: ENTAILED  \nHYPOTHESIS: The orbital period T of P satisfies T² = (4π²/GM)a³, where G is the gravitational constant and M is the mass of the star.  \nASSUMPTION: None  \nVERIFICATION: Units: T in seconds, a in meters, G ≈ 6.674×10⁻¹¹ m³ kg⁻¹ s⁻², M in kg; valid for Keplerian orbits.", "rejected": "The orbital period T of P satisfies T² = (4π²/G)a³, where G is the gravitational constant.", "E_acc": 0.17285098135471344, "C_acc": 0.6281741261482239, "G_acc": 0.5433824113570154, "D_acc": 0.6513243423542008, "H_acc": 0.17527589201927185, "Q_acc": 0.44763423071708536, "E_rej": 0.19818174839019775, "C_rej": 0.5491617918014526, "G_rej": 0.5393121575325495, "D_rej": 0.7812085449695587, "H_rej": 0.21879145503044128, "Q_rej": 0.49184716115414634, "Delta_Q": -0.04421293043706098, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
{"context": {"topic": "Milky Way", "ancestors": ["[DEF] The Milky Way is a barred spiral galaxy.", "[VAR] D = 8.2 kpc denotes the Sun’s galactocentric distance.", "[VAR] M = 4.1 × 10^41 kg denotes the Milky Way’s total mass.", "[VAR] R_d = 3.5 kpc denotes the stellar disk scale length.", "[VAR] V_c = 220 km s^-1 denotes the local circular velocity.", "[LAW] V_c^2 = G M_enc(r) / r relates circular velocity to enclosed mass.", "[CONSTRAINT] M_enc(r) ≤ M for any r.", "[LIMIT] M_enc(r) → M as r → ∞.", "[LIMIT] V_c → 0 as r → ∞.", "[LIMIT] R_d sets the exponential surface-brightness decay scale."]}, "accepted": "STATUS: ENTAILED\nHYPOTHESIS: The Sun’s orbital radius r = 8.2 kpc encloses a mass M_enc(8.2 kpc) = V_c²·r/G ≈ 9.5 × 10^40 kg, which is ≤ 4.1 × 10^41 kg.\nASSUMPTION: None\nVERIFICATION: Units kg, computed with V_c = 220 km s⁻¹, r = 8.2 kpc, G = 6.67 × 10⁻¹¹ m³ kg⁻¹ s⁻².", "rejected": "STATUS: REFUTED.", "E_acc": 0.31693321466445923, "C_acc": 0.44745466113090515, "G_acc": 0.5567867549834773, "D_acc": 0.6260681329295039, "H_acc": 0.26012030243873596, "Q_acc": 0.5161479795118794, "E_rej": 0.12262272834777832, "C_rej": 0.718113124370575, "G_rej": 0.5694492943584919, "D_rej": 0.5035224554594606, "H_rej": 0.4964775445405394, "Q_rej": 0.3581107891397551, "Delta_Q": 0.15803719037212433, "flag_reject": true, "flag_low_reasoning": false, "flag_hallucination": false}
